{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"MLOpsVN Courses T\u1ea7m nh\u00ecn MLOpsVN l\u00e0 m\u1ed9t t\u1ed5 ch\u1ee9c v\u1edbi mong mu\u1ed1n thu ng\u1eafn kho\u1ea3ng c\u00e1ch gi\u1eefa tr\u00ed tu\u1ec7 nh\u00e2n t\u1ea1o (Artificial Intelligence - AI) v\u00e0 h\u1ecdc m\u00e1y (Machine Learning - ML) trong l\u00fd thuy\u1ebft v\u00e0 \u1ee9ng d\u1ee5ng th\u1ef1c t\u1ebf trong production. Ki\u1ebfn th\u1ee9c l\u00e0 ch\u00eca kho\u00e1 \u0111\u1ebfn c\u01a1 h\u1ed9i trong ng\u00e0nh AI/ML v\u1edbi nh\u1eefng con ng\u01b0\u1eddi nhi\u1ec7t huy\u1ebft. Ch\u00fang t\u00f4i hi v\u1ecdng th\u00fac \u0111\u1ea9y qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n c\u1ee7a AI/ML t\u1ea1i Vi\u1ec7t Nam th\u00f4ng qua c\u00e1c ho\u1ea1t \u0111\u1ed9ng \u0111\u1ecbnh h\u01b0\u1edbng c\u1ed9ng \u0111\u1ed3ng. Li\u00ean h\u1ec7 Facebook group Facebook page Discord channel Email: mlopsvn@openfactor.org","title":"Home"},{"location":"index.html#mlopsvn-courses","text":"","title":"MLOpsVN Courses"},{"location":"index.html#tam-nhin","text":"MLOpsVN l\u00e0 m\u1ed9t t\u1ed5 ch\u1ee9c v\u1edbi mong mu\u1ed1n thu ng\u1eafn kho\u1ea3ng c\u00e1ch gi\u1eefa tr\u00ed tu\u1ec7 nh\u00e2n t\u1ea1o (Artificial Intelligence - AI) v\u00e0 h\u1ecdc m\u00e1y (Machine Learning - ML) trong l\u00fd thuy\u1ebft v\u00e0 \u1ee9ng d\u1ee5ng th\u1ef1c t\u1ebf trong production. Ki\u1ebfn th\u1ee9c l\u00e0 ch\u00eca kho\u00e1 \u0111\u1ebfn c\u01a1 h\u1ed9i trong ng\u00e0nh AI/ML v\u1edbi nh\u1eefng con ng\u01b0\u1eddi nhi\u1ec7t huy\u1ebft. Ch\u00fang t\u00f4i hi v\u1ecdng th\u00fac \u0111\u1ea9y qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n c\u1ee7a AI/ML t\u1ea1i Vi\u1ec7t Nam th\u00f4ng qua c\u00e1c ho\u1ea1t \u0111\u1ed9ng \u0111\u1ecbnh h\u01b0\u1edbng c\u1ed9ng \u0111\u1ed3ng.","title":"T\u1ea7m nh\u00ecn"},{"location":"index.html#lien-he","text":"Facebook group Facebook page Discord channel Email: mlopsvn@openfactor.org","title":"Li\u00ean h\u1ec7"},{"location":"CODE_OF_CONDUCT.html","text":"This code of conduct outlines expectations for participation in MLOpsVN-managed open source communities, as well as steps for reporting unacceptable behavior. We are committed to providing a welcoming and inspiring community for all. People violating this code of conduct may be banned from the community. Our open source communities strive to: Be friendly and patient: Remember you might not be communicating in someone else's primary spoken or programming language, and others may not have your level of understanding. Be welcoming: Our communities welcome and support people of all backgrounds and identities. This includes, but is not limited to members of any race, ethnicity, culture, national origin, color, immigration status, social and economic class, educational level, sex, sexual orientation, gender identity and expression, age, size, family status, political belief, religion, and mental and physical ability. Be respectful: We are a world-wide community of professionals, and we conduct ourselves professionally. Disagreement is no excuse for poor behavior and poor manners. Disrespectful and unacceptable behavior includes, but is not limited to: Violent threats or language. Discriminatory or derogatory jokes and language. Posting sexually explicit or violent material. Posting, or threatening to post, people's personally identifying information (\"doxing\"). Insults, especially those using discriminatory terms or slurs. Behavior that could be perceived as sexual attention. Advocating for or encouraging any of the above behaviors. Understand disagreements: Disagreements, both social and technical, are useful learning opportunities. Seek to understand the other viewpoints and resolve differences constructively. This code is not exhaustive or complete. It serves to capture our common understanding of a productive, collaborative environment. We expect the code to be followed in spirit as much as in the letter. Scope This code of conduct applies to all repos and communities for MLOpsVN-managed open source projects regardless of whether or not the repo explicitly calls out its use of this code. The code also applies in public spaces when an individual is representing a project or its community. Examples include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Note: Some MLOpsVN-managed communities have codes of conduct that pre-date this document and issue resolution process. While communities are not required to change their code, they are expected to use the resolution process outlined here. The review team will coordinate with the communities involved to address your concerns. Reporting Code of Conduct Issues We encourage all communities to resolve issues on their own whenever possible. This builds a broader and deeper understanding and ultimately a healthier interaction. In the event that an issue cannot be resolved locally, please feel free to report your concerns by contacting mlopsvn@openfactor.org . In your report please include: Your contact information. Names (real, usernames or pseudonyms) of any individuals involved. If there are additional witnesses, please include them as well. Your account of what occurred, and if you believe the incident is ongoing. If there is a publicly available record (e.g. a mailing list archive or a public chat log), please include a link or attachment. Any additional information that may be helpful. All reports will be reviewed by a multi-person team and will result in a response that is deemed necessary and appropriate to the circumstances. Where additional perspectives are needed, the team may seek insight from others with relevant expertise or experience. The confidentiality of the person reporting the incident will be kept at all times. Involved parties are never part of the review team. Anyone asked to stop unacceptable behavior is expected to comply immediately. If an individual engages in unacceptable behavior, the review team may take any action they deem appropriate, including a permanent ban from the community. This code of conduct is based on the Microsoft Open Source Code of Conduct which was based on the template established by the TODO Group and used by numerous other large communities (e.g., Facebook , Yahoo , Twitter , GitHub ) and the Scope section from the Contributor Covenant version 1.4 .","title":"Code of Conduct"},{"location":"CODE_OF_CONDUCT.html#scope","text":"This code of conduct applies to all repos and communities for MLOpsVN-managed open source projects regardless of whether or not the repo explicitly calls out its use of this code. The code also applies in public spaces when an individual is representing a project or its community. Examples include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Note: Some MLOpsVN-managed communities have codes of conduct that pre-date this document and issue resolution process. While communities are not required to change their code, they are expected to use the resolution process outlined here. The review team will coordinate with the communities involved to address your concerns.","title":"Scope"},{"location":"CODE_OF_CONDUCT.html#reporting-code-of-conduct-issues","text":"We encourage all communities to resolve issues on their own whenever possible. This builds a broader and deeper understanding and ultimately a healthier interaction. In the event that an issue cannot be resolved locally, please feel free to report your concerns by contacting mlopsvn@openfactor.org . In your report please include: Your contact information. Names (real, usernames or pseudonyms) of any individuals involved. If there are additional witnesses, please include them as well. Your account of what occurred, and if you believe the incident is ongoing. If there is a publicly available record (e.g. a mailing list archive or a public chat log), please include a link or attachment. Any additional information that may be helpful. All reports will be reviewed by a multi-person team and will result in a response that is deemed necessary and appropriate to the circumstances. Where additional perspectives are needed, the team may seek insight from others with relevant expertise or experience. The confidentiality of the person reporting the incident will be kept at all times. Involved parties are never part of the review team. Anyone asked to stop unacceptable behavior is expected to comply immediately. If an individual engages in unacceptable behavior, the review team may take any action they deem appropriate, including a permanent ban from the community. This code of conduct is based on the Microsoft Open Source Code of Conduct which was based on the template established by the TODO Group and used by numerous other large communities (e.g., Facebook , Yahoo , Twitter , GitHub ) and the Scope section from the Contributor Covenant version 1.4 .","title":"Reporting Code of Conduct Issues"},{"location":"CONTRIBUTING.html","text":"We realise that the initial content we created is just a starting point and our hope is that the community can help in the journey refining and extending the contents. As a contributor, you represent that the content you submit is not plagiarised. By submitting the content, you (and, if applicable, your employer) are licensing the submitted content to MLOpsVN and the open source community subject to the Creative Commons Attribution 4.0 International Public License. Repository URL: https://github.com/mlopsvn/courses.mlops.vn Contributing Guidelines Ensure that you adhere to the following guidelines: Should be about principles and concepts that can be applied in any company or individual project. Do not focus on particular tools or tech stack (which usually change over time). Adhere to the Code of Conduct . Should be relevant to MLOps. Should be locally tested (see steps for testing) and well formatted. It is good practice to open an issue first and discuss your changes before submitting a pull request. This way, you can incorporate ideas from others before you even start. Building and testing locally Run the following commands to build and view the site locally before opening a PR. python3 -m venv .venv source .venv/bin/activate pip install -r requirements.txt mkdocs build mkdocs serve # Fork this repo, create a feature branch, commit your changes and open a PR to this repo.","title":"Contributing"},{"location":"mlops-crash-course/index.html","text":"Photo by NASA on Unsplash Gi\u1edbi thi\u1ec7u V\u1edbi s\u1ef1 ph\u00e1t tri\u1ec3n m\u1ea1nh m\u1ebd c\u1ee7a \u0111i\u1ec7n to\u00e1n \u0111\u00e1m m\u00e2y (Cloud Computing), s\u1ef1 b\u00f9ng n\u1ed5 c\u1ee7a d\u1eef li\u1ec7u l\u1edbn (Big Data) v\u00e0 s\u1ef1 ph\u00e1t tri\u1ec3n kh\u00f4ng ng\u1eebng ngh\u1ec9 c\u1ee7a khoa h\u1ecdc c\u00f4ng ngh\u1ec7, h\u1ecdc m\u00e1y (Machine Learning - ML) \u0111\u00e3 v\u00e0 \u0111ang \u0111\u01b0\u1ee3c \u1ee9ng d\u1ee5ng r\u1ed9ng r\u00e3i \u1edf nhi\u1ec1u ng\u00e0nh ngh\u1ec1 kh\u00e1c nhau. V\u1ea5n \u0111\u1ec1 n\u1ea3y sinh l\u00e0 l\u00e0m th\u1ebf n\u00e0o \u0111\u1ec3 t\u0103ng hi\u1ec7u n\u0103ng (performance), \u0111\u1ed9 tin c\u1eady (reliability) c\u1ee7a c\u00e1c \u1ee9ng d\u1ee5ng ML v\u00e0 gi\u1ea3m thi\u1ec3u th\u1eddi gian ra s\u1ea3n ph\u1ea9m/th\u1ecb tr\u01b0\u1eddng ( go-to-market ) c\u1ee7a qu\u00e1 tr\u00ecnh x\u00e2y d\u1ef1ng v\u00e0 \u1ee9ng d\u1ee5ng AI/ML. T\u1eeb \u0111\u00f3, m\u1ed9t lo\u1ea1t c\u00e1c quy chu\u1ea9n v\u1ec1 c\u00e1ch v\u1eadn h\u00e0nh, tri\u1ec3n khai c\u00e1c d\u1ef1 \u00e1n ML d\u1ea7n \u0111\u01b0\u1ee3c h\u00ecnh th\u00e0nh, m\u1edf ra m\u1ed9t h\u01b0\u1edbng \u0111i ho\u00e0n to\u00e0n m\u1edbi cho Machine Learning Engineer v\u00e0 Data Scientist, \u0111\u00f3 l\u00e0 Machine Learning Operations hay ch\u00ednh l\u00e0 MLOps . V\u1edbi mong mu\u1ed1n th\u00fac \u0111\u1ea9y qu\u00e1 tr\u00ecnh \u0111\u01b0a c\u00e1c s\u1ea3n ph\u1ea9m ML ra th\u1ef1c t\u1ebf (production) nhanh ch\u00f3ng v\u00e0 hi\u1ec7u qu\u1ea3 h\u01a1n, MLOpsVN \u0111\u00e3 cho ra \u0111\u1eddi kho\u00e1 h\u1ecdc MLOps Crash Course . Kho\u00e1 h\u1ecdc \u0111\u01b0\u1ee3c t\u1ea1o ra v\u1edbi 3 t\u00f4n ch\u1ec9: ng\u1eafn g\u1ecdn , d\u1ec5 hi\u1ec3u , th\u1ef1c t\u1ebf . Trong su\u1ed1t c\u1ea3 kh\u00f3a h\u1ecdc, ch\u00fang ta s\u1ebd c\u00f9ng nhau t\u00ecm hi\u1ec3u v\u00e0 gi\u1ea3i quy\u1ebft m\u1ed9t b\u00e0i to\u00e1n th\u1ef1c t\u1ebf c\u1ee5 th\u1ec3, t\u1eeb b\u01b0\u1edbc ph\u00e2n t\u00edch y\u00eau c\u1ea7u cho \u0111\u1ebfn thi\u1ebft k\u1ebf v\u00e0 tri\u1ec3n khai h\u1ec7 th\u1ed1ng. Kho\u00e1 h\u1ecdc c\u0169ng s\u1ebd bao g\u1ed3m c\u00e1c c\u00e1ch th\u1ee9c t\u1ed1t nh\u1ea5t (best practices) \u0111\u01b0\u1ee3c t\u1ed5ng h\u1ee3p t\u1eeb nhi\u1ec1u h\u1ec7 th\u1ed1ng ML trong c\u00e1c t\u1ed5 ch\u1ee9c l\u1edbn, nhi\u1ec1u k\u0129 s\u01b0 c\u00f3 kinh nghi\u1ec7m tri\u1ec3n khai c\u00e1c d\u1ef1 \u00e1n ML trong th\u1ef1c t\u1ebf t\u1eeb nhi\u1ec1u n\u01a1i tr\u00ean th\u1ebf gi\u1edbi. T\u00e0i li\u1ec7u t\u1ea1o ra ch\u1eafc ch\u1eafn kh\u00f4ng tr\u00e1nh kh\u1ecfi thi\u1ebfu s\u00f3t, r\u1ea5t mong nh\u1eadn \u0111\u01b0\u1ee3c s\u1ef1 \u0111\u00f3ng g\u00f3p c\u1ee7a c\u00e1c b\u1ea1n. C\u00e1ch th\u1ee9c \u0111\u00f3ng g\u00f3p vui l\u00f2ng xem t\u1ea1i \u0111\u00e2y . MLOpsVN Team xin g\u1eedi l\u1eddi c\u1ea3m \u01a1n ch\u00e2n th\u00e0nh t\u1edbi c\u00e1c Reviewers v\u00e0 Advisors t\u1edbi t\u1eeb c\u1ed9ng \u0111\u1ed3ng MLOpsVN \u0111\u00e3 d\u00e0nh th\u1eddi gian v\u00e0 c\u00f4ng s\u1ee9c \u0111\u00f3ng g\u00f3p \u00fd ki\u1ebfn cho kho\u00e1 h\u1ecdc. Kho\u00e1 h\u1ecdc MLOps Crash Course s\u1ebd kh\u00f4ng th\u1ec3 ho\u00e0n th\u00e0nh n\u1ebfu thi\u1ebfu ph\u1ea3n h\u1ed3i c\u1ee7a c\u00e1c b\u1ea1n. Authors Tung Dao Quan Dang Advisors/Editors Xuan-Son Vu Senior Researcher Ume\u00e5 University, Sweden Harry Nguyen Assistant Professor UCC, Ireland Reviewers ChiT DangVanThuc \u0110inh V\u0103n Qu\u00fd H\u1ed3ng H\u1ea1nh ming \u0111\u00e2y NguyenDHN PP PTSon QuynhAnhDang sudohainguyen Toan Nguyen Manh Viet Anh","title":"MLOps Crash Course"},{"location":"mlops-crash-course/index.html#gioi-thieu","text":"V\u1edbi s\u1ef1 ph\u00e1t tri\u1ec3n m\u1ea1nh m\u1ebd c\u1ee7a \u0111i\u1ec7n to\u00e1n \u0111\u00e1m m\u00e2y (Cloud Computing), s\u1ef1 b\u00f9ng n\u1ed5 c\u1ee7a d\u1eef li\u1ec7u l\u1edbn (Big Data) v\u00e0 s\u1ef1 ph\u00e1t tri\u1ec3n kh\u00f4ng ng\u1eebng ngh\u1ec9 c\u1ee7a khoa h\u1ecdc c\u00f4ng ngh\u1ec7, h\u1ecdc m\u00e1y (Machine Learning - ML) \u0111\u00e3 v\u00e0 \u0111ang \u0111\u01b0\u1ee3c \u1ee9ng d\u1ee5ng r\u1ed9ng r\u00e3i \u1edf nhi\u1ec1u ng\u00e0nh ngh\u1ec1 kh\u00e1c nhau. V\u1ea5n \u0111\u1ec1 n\u1ea3y sinh l\u00e0 l\u00e0m th\u1ebf n\u00e0o \u0111\u1ec3 t\u0103ng hi\u1ec7u n\u0103ng (performance), \u0111\u1ed9 tin c\u1eady (reliability) c\u1ee7a c\u00e1c \u1ee9ng d\u1ee5ng ML v\u00e0 gi\u1ea3m thi\u1ec3u th\u1eddi gian ra s\u1ea3n ph\u1ea9m/th\u1ecb tr\u01b0\u1eddng ( go-to-market ) c\u1ee7a qu\u00e1 tr\u00ecnh x\u00e2y d\u1ef1ng v\u00e0 \u1ee9ng d\u1ee5ng AI/ML. T\u1eeb \u0111\u00f3, m\u1ed9t lo\u1ea1t c\u00e1c quy chu\u1ea9n v\u1ec1 c\u00e1ch v\u1eadn h\u00e0nh, tri\u1ec3n khai c\u00e1c d\u1ef1 \u00e1n ML d\u1ea7n \u0111\u01b0\u1ee3c h\u00ecnh th\u00e0nh, m\u1edf ra m\u1ed9t h\u01b0\u1edbng \u0111i ho\u00e0n to\u00e0n m\u1edbi cho Machine Learning Engineer v\u00e0 Data Scientist, \u0111\u00f3 l\u00e0 Machine Learning Operations hay ch\u00ednh l\u00e0 MLOps . V\u1edbi mong mu\u1ed1n th\u00fac \u0111\u1ea9y qu\u00e1 tr\u00ecnh \u0111\u01b0a c\u00e1c s\u1ea3n ph\u1ea9m ML ra th\u1ef1c t\u1ebf (production) nhanh ch\u00f3ng v\u00e0 hi\u1ec7u qu\u1ea3 h\u01a1n, MLOpsVN \u0111\u00e3 cho ra \u0111\u1eddi kho\u00e1 h\u1ecdc MLOps Crash Course . Kho\u00e1 h\u1ecdc \u0111\u01b0\u1ee3c t\u1ea1o ra v\u1edbi 3 t\u00f4n ch\u1ec9: ng\u1eafn g\u1ecdn , d\u1ec5 hi\u1ec3u , th\u1ef1c t\u1ebf . Trong su\u1ed1t c\u1ea3 kh\u00f3a h\u1ecdc, ch\u00fang ta s\u1ebd c\u00f9ng nhau t\u00ecm hi\u1ec3u v\u00e0 gi\u1ea3i quy\u1ebft m\u1ed9t b\u00e0i to\u00e1n th\u1ef1c t\u1ebf c\u1ee5 th\u1ec3, t\u1eeb b\u01b0\u1edbc ph\u00e2n t\u00edch y\u00eau c\u1ea7u cho \u0111\u1ebfn thi\u1ebft k\u1ebf v\u00e0 tri\u1ec3n khai h\u1ec7 th\u1ed1ng. Kho\u00e1 h\u1ecdc c\u0169ng s\u1ebd bao g\u1ed3m c\u00e1c c\u00e1ch th\u1ee9c t\u1ed1t nh\u1ea5t (best practices) \u0111\u01b0\u1ee3c t\u1ed5ng h\u1ee3p t\u1eeb nhi\u1ec1u h\u1ec7 th\u1ed1ng ML trong c\u00e1c t\u1ed5 ch\u1ee9c l\u1edbn, nhi\u1ec1u k\u0129 s\u01b0 c\u00f3 kinh nghi\u1ec7m tri\u1ec3n khai c\u00e1c d\u1ef1 \u00e1n ML trong th\u1ef1c t\u1ebf t\u1eeb nhi\u1ec1u n\u01a1i tr\u00ean th\u1ebf gi\u1edbi. T\u00e0i li\u1ec7u t\u1ea1o ra ch\u1eafc ch\u1eafn kh\u00f4ng tr\u00e1nh kh\u1ecfi thi\u1ebfu s\u00f3t, r\u1ea5t mong nh\u1eadn \u0111\u01b0\u1ee3c s\u1ef1 \u0111\u00f3ng g\u00f3p c\u1ee7a c\u00e1c b\u1ea1n. C\u00e1ch th\u1ee9c \u0111\u00f3ng g\u00f3p vui l\u00f2ng xem t\u1ea1i \u0111\u00e2y . MLOpsVN Team xin g\u1eedi l\u1eddi c\u1ea3m \u01a1n ch\u00e2n th\u00e0nh t\u1edbi c\u00e1c Reviewers v\u00e0 Advisors t\u1edbi t\u1eeb c\u1ed9ng \u0111\u1ed3ng MLOpsVN \u0111\u00e3 d\u00e0nh th\u1eddi gian v\u00e0 c\u00f4ng s\u1ee9c \u0111\u00f3ng g\u00f3p \u00fd ki\u1ebfn cho kho\u00e1 h\u1ecdc. Kho\u00e1 h\u1ecdc MLOps Crash Course s\u1ebd kh\u00f4ng th\u1ec3 ho\u00e0n th\u00e0nh n\u1ebfu thi\u1ebfu ph\u1ea3n h\u1ed3i c\u1ee7a c\u00e1c b\u1ea1n.","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/index.html#authors","text":"Tung Dao Quan Dang","title":"Authors"},{"location":"mlops-crash-course/index.html#advisorseditors","text":"Xuan-Son Vu Senior Researcher Ume\u00e5 University, Sweden Harry Nguyen Assistant Professor UCC, Ireland","title":"Advisors/Editors"},{"location":"mlops-crash-course/index.html#reviewers","text":"ChiT DangVanThuc \u0110inh V\u0103n Qu\u00fd H\u1ed3ng H\u1ea1nh ming \u0111\u00e2y NguyenDHN PP PTSon QuynhAnhDang sudohainguyen Toan Nguyen Manh Viet Anh","title":"Reviewers"},{"location":"mlops-crash-course/ci-cd/data-pipeline.html","text":"Photo from flexagon.com Gi\u1edbi thi\u1ec7u \u1ede b\u00e0i h\u1ecdc v\u1ec1 data pipeline , ch\u00fang ta \u0111\u00e3 c\u00f9ng nhau x\u00e2y d\u1ef1ng v\u00e0 deploy data pipeline theo c\u00e1c b\u01b0\u1edbc nh\u01b0 sau: \u0110\u00f3ng g\u00f3i code v\u00e0 m\u00f4i tr\u01b0\u1eddng th\u00e0nh image \u0111\u1ec3 ch\u1ea1y c\u00e1c b\u01b0\u1edbc trong pipeline Th\u1ef1c hi\u1ec7n ki\u1ec3m th\u1eed code Copy Python script \u0111\u1ecbnh ngh\u0129a DAG sang th\u01b0 m\u1ee5c dags/ c\u1ee7a Airflow N\u1ebfu t\u1ef1 \u0111\u1ed9ng h\u00f3a \u0111\u01b0\u1ee3c c\u00e1c b\u01b0\u1edbc n\u00e0y th\u00ec c\u00f3 th\u1ec3 \u0111\u1ea9y nhanh qu\u00e1 tr\u00ecnh release version m\u1edbi cho pipeline m\u1ed7i khi developer thay \u0111\u1ed5i code. \u1ede b\u00e0i h\u1ecdc n\u00e0y ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng Jenkins \u0111\u1ec3 l\u00e0m \u0111i\u1ec1u n\u00e0y. Jenkins pipeline Ch\u00fang ta s\u1ebd vi\u1ebft Jenkinsfile cho 3 b\u01b0\u1edbc tr\u00ean nh\u01b0 sau: flowchart LR n1[1. Build data pipeline] --> n2[2. Test data pipeline] --> n3[3. Deploy data pipeline] Info \u1ede b\u00e0i h\u1ecdc n\u00e0y, ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng agent l\u1ea3 docker image python:3.9 , do \u0111\u00f3 tr\u01b0\u1edbc h\u1ebft b\u1ea1n c\u1ea7n truy c\u00e2p http://localhost:8081/pluginManager/ v\u00e0 c\u00e0i \u0111\u1eb7t th\u00eam plugin Docker Pipeline . Jenkinsfile_data_pipeline 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 pipeline { agent { docker { image 'python:3.9' # (1) } } stages { stage ( 'build data pipeline' ) { when { changeset \"data_pipeline/**\" } steps { echo 'Building data pipeline..' sh 'cd data_pipeline && make build_image' # (2) } } stage ( 'test data pipeline' ) { when { changeset \"data_pipeline/**\" } steps { echo 'Testing data pipeline..' # (3) } } stage ( 'deploy data pipeline' ) { when { changeset \"data_pipeline/**\" } steps { sh 'cd data_pipeline && make deploy_dags' # (4) } } } } \u0110\u1ecbnh ngh\u0129a agent l\u00e0 docker image python:3.9 . Image n\u00e0y \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng m\u1eb7c \u0111\u1ecbnh cho t\u1ea5t c\u1ea3 c\u00e1c stage trong pipeline. Build image cho \u0111\u1ec3 ch\u1ea1y c\u00e1c b\u01b0\u1edbc trong Airflow pipeline Test code, ph\u1ea7n n\u00e0y b\u1ea1n s\u1ebd b\u1ed5 sung unit test , integration test , .v.v. d\u1ef1a v\u00e0o b\u00e0i h\u1ecdc v\u1ec1 ki\u1ec3m th\u1eed h\u1ec7 th\u1ed1ng Copy script ch\u1ee9a DAG qua folder dags/ c\u1ee7a Airflow Warning \u1ede \u0111\u00e2y, ch\u00fang ta \u0111\u1ec3 \u00fd file \u0111\u1ecbnh ngh\u0129a Jenkins CI/CD l\u00e0 Jenkinsfile_data_pipeline , kh\u00f4ng ph\u1ea3i t\u00ean m\u1eb7c \u0111\u1ecbnh l\u00e0 Jenkinsfile , do \u0111\u00f3 ch\u00fang ta ph\u1ea3i th\u00eam m\u1ed9t b\u01b0\u1edbc c\u00e0i \u0111\u1eb7t tr\u00ean Jenkins \u0111\u1ec3 khai b\u00e1o file n\u00e0y. \u0110\u1ec3 l\u00e0m \u0111i\u1ec1u n\u00e0y, ch\u00fang ta truy c\u1eadp \u0111\u01b0\u1eddng d\u1eabn http://localhost:8081/job/mlops-demo/configure v\u00e0 thay \u0111\u1ed5i Script Path t\u1eeb Jenkinsfile sang Jenkinsfile_data_pipeline . Bug N\u1ebfu b\u1ea1n g\u1eb7p hi\u1ec7n t\u01b0\u1ee3ng Github API Rate Limit nh\u01b0 sau: Th\u00ec b\u1ea1n th\u00eam Credentials \u1edf m\u1ee5c Github b\u1eb1ng c\u00e1ch \u1ea5n v\u00e0o Add nh\u01b0 h\u00ecnh d\u01b0\u1edbi: Sau khi b\u1ea1n thay \u0111\u1ed5i code \u1edf folder data-pipeline/ v\u00e0 push code l\u00ean Github, b\u1ea1n s\u1ebd th\u1ea5y Console Output t\u01b0\u01a1ng \u1ee9ng v\u1edbi commit n\u00e0y hi\u1ec3n th\u1ecb t\u01b0\u01a1ng t\u1ef1 nh\u01b0 sau: T\u1ed5ng k\u1ebft \u1ede b\u00e0i h\u1ecdc v\u1eeba r\u1ed3i, ch\u00fang ta \u0111\u00e3 s\u1eed d\u1ee5ng Jenkins \u0111\u1ec3 x\u00e2y d\u1ef1ng m\u1ed9t CI/CD pipeline v\u1edbi 3 b\u01b0\u1edbc: buid image, test code v\u00e0 deploy Airflow pipeline. Developer b\u00e2y gi\u1edd ch\u1ec9 c\u1ea7n t\u1eadp trung v\u00e0o code, khi n\u00e0o code xong th\u00ec push l\u00ean Github v\u00e0 \u0111\u1ec3 CI/CD pipeline lo nh\u1eefng ph\u1ea7n c\u00f2n l\u1ea1i m\u1ed9t c\u00e1ch ti\u1ec7n l\u1ee3i. \u1ede b\u00e0i h\u1ecdc ti\u1ebfp theo, ch\u00fang ta s\u1ebd x\u00e2y d\u1ef1ng m\u1ed9t CI/CD pipeline ph\u1ee9c t\u1ea1p h\u01a1n m\u1ed9t ch\u00fat cho model serving .","title":"CI/CD cho data pipeline"},{"location":"mlops-crash-course/ci-cd/data-pipeline.html#gioi-thieu","text":"\u1ede b\u00e0i h\u1ecdc v\u1ec1 data pipeline , ch\u00fang ta \u0111\u00e3 c\u00f9ng nhau x\u00e2y d\u1ef1ng v\u00e0 deploy data pipeline theo c\u00e1c b\u01b0\u1edbc nh\u01b0 sau: \u0110\u00f3ng g\u00f3i code v\u00e0 m\u00f4i tr\u01b0\u1eddng th\u00e0nh image \u0111\u1ec3 ch\u1ea1y c\u00e1c b\u01b0\u1edbc trong pipeline Th\u1ef1c hi\u1ec7n ki\u1ec3m th\u1eed code Copy Python script \u0111\u1ecbnh ngh\u0129a DAG sang th\u01b0 m\u1ee5c dags/ c\u1ee7a Airflow N\u1ebfu t\u1ef1 \u0111\u1ed9ng h\u00f3a \u0111\u01b0\u1ee3c c\u00e1c b\u01b0\u1edbc n\u00e0y th\u00ec c\u00f3 th\u1ec3 \u0111\u1ea9y nhanh qu\u00e1 tr\u00ecnh release version m\u1edbi cho pipeline m\u1ed7i khi developer thay \u0111\u1ed5i code. \u1ede b\u00e0i h\u1ecdc n\u00e0y ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng Jenkins \u0111\u1ec3 l\u00e0m \u0111i\u1ec1u n\u00e0y.","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/ci-cd/data-pipeline.html#jenkins-pipeline","text":"Ch\u00fang ta s\u1ebd vi\u1ebft Jenkinsfile cho 3 b\u01b0\u1edbc tr\u00ean nh\u01b0 sau: flowchart LR n1[1. Build data pipeline] --> n2[2. Test data pipeline] --> n3[3. Deploy data pipeline] Info \u1ede b\u00e0i h\u1ecdc n\u00e0y, ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng agent l\u1ea3 docker image python:3.9 , do \u0111\u00f3 tr\u01b0\u1edbc h\u1ebft b\u1ea1n c\u1ea7n truy c\u00e2p http://localhost:8081/pluginManager/ v\u00e0 c\u00e0i \u0111\u1eb7t th\u00eam plugin Docker Pipeline . Jenkinsfile_data_pipeline 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 pipeline { agent { docker { image 'python:3.9' # (1) } } stages { stage ( 'build data pipeline' ) { when { changeset \"data_pipeline/**\" } steps { echo 'Building data pipeline..' sh 'cd data_pipeline && make build_image' # (2) } } stage ( 'test data pipeline' ) { when { changeset \"data_pipeline/**\" } steps { echo 'Testing data pipeline..' # (3) } } stage ( 'deploy data pipeline' ) { when { changeset \"data_pipeline/**\" } steps { sh 'cd data_pipeline && make deploy_dags' # (4) } } } } \u0110\u1ecbnh ngh\u0129a agent l\u00e0 docker image python:3.9 . Image n\u00e0y \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng m\u1eb7c \u0111\u1ecbnh cho t\u1ea5t c\u1ea3 c\u00e1c stage trong pipeline. Build image cho \u0111\u1ec3 ch\u1ea1y c\u00e1c b\u01b0\u1edbc trong Airflow pipeline Test code, ph\u1ea7n n\u00e0y b\u1ea1n s\u1ebd b\u1ed5 sung unit test , integration test , .v.v. d\u1ef1a v\u00e0o b\u00e0i h\u1ecdc v\u1ec1 ki\u1ec3m th\u1eed h\u1ec7 th\u1ed1ng Copy script ch\u1ee9a DAG qua folder dags/ c\u1ee7a Airflow Warning \u1ede \u0111\u00e2y, ch\u00fang ta \u0111\u1ec3 \u00fd file \u0111\u1ecbnh ngh\u0129a Jenkins CI/CD l\u00e0 Jenkinsfile_data_pipeline , kh\u00f4ng ph\u1ea3i t\u00ean m\u1eb7c \u0111\u1ecbnh l\u00e0 Jenkinsfile , do \u0111\u00f3 ch\u00fang ta ph\u1ea3i th\u00eam m\u1ed9t b\u01b0\u1edbc c\u00e0i \u0111\u1eb7t tr\u00ean Jenkins \u0111\u1ec3 khai b\u00e1o file n\u00e0y. \u0110\u1ec3 l\u00e0m \u0111i\u1ec1u n\u00e0y, ch\u00fang ta truy c\u1eadp \u0111\u01b0\u1eddng d\u1eabn http://localhost:8081/job/mlops-demo/configure v\u00e0 thay \u0111\u1ed5i Script Path t\u1eeb Jenkinsfile sang Jenkinsfile_data_pipeline . Bug N\u1ebfu b\u1ea1n g\u1eb7p hi\u1ec7n t\u01b0\u1ee3ng Github API Rate Limit nh\u01b0 sau: Th\u00ec b\u1ea1n th\u00eam Credentials \u1edf m\u1ee5c Github b\u1eb1ng c\u00e1ch \u1ea5n v\u00e0o Add nh\u01b0 h\u00ecnh d\u01b0\u1edbi: Sau khi b\u1ea1n thay \u0111\u1ed5i code \u1edf folder data-pipeline/ v\u00e0 push code l\u00ean Github, b\u1ea1n s\u1ebd th\u1ea5y Console Output t\u01b0\u01a1ng \u1ee9ng v\u1edbi commit n\u00e0y hi\u1ec3n th\u1ecb t\u01b0\u01a1ng t\u1ef1 nh\u01b0 sau:","title":"Jenkins pipeline"},{"location":"mlops-crash-course/ci-cd/data-pipeline.html#tong-ket","text":"\u1ede b\u00e0i h\u1ecdc v\u1eeba r\u1ed3i, ch\u00fang ta \u0111\u00e3 s\u1eed d\u1ee5ng Jenkins \u0111\u1ec3 x\u00e2y d\u1ef1ng m\u1ed9t CI/CD pipeline v\u1edbi 3 b\u01b0\u1edbc: buid image, test code v\u00e0 deploy Airflow pipeline. Developer b\u00e2y gi\u1edd ch\u1ec9 c\u1ea7n t\u1eadp trung v\u00e0o code, khi n\u00e0o code xong th\u00ec push l\u00ean Github v\u00e0 \u0111\u1ec3 CI/CD pipeline lo nh\u1eefng ph\u1ea7n c\u00f2n l\u1ea1i m\u1ed9t c\u00e1ch ti\u1ec7n l\u1ee3i. \u1ede b\u00e0i h\u1ecdc ti\u1ebfp theo, ch\u00fang ta s\u1ebd x\u00e2y d\u1ef1ng m\u1ed9t CI/CD pipeline ph\u1ee9c t\u1ea1p h\u01a1n m\u1ed9t ch\u00fat cho model serving .","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/ci-cd/gioi-thieu.html","text":"Gi\u1edbi thi\u1ec7u C\u00e1c c\u00f4ng vi\u1ec7c c\u1ea7n nhi\u1ec1u thao t\u00e1c th\u1ee7 c\u00f4ng c\u1ee7a con ng\u01b0\u1eddi th\u01b0\u1eddng d\u1ec5 x\u1ea3y ra sai s\u00f3t, v\u00e0 n\u1ebfu nh\u1eefng vi\u1ec7c n\u00e0y l\u1eb7p l\u1ea1i c\u00e0ng nhi\u1ec1u th\u00ec t\u1ec9 l\u1ec7 sai s\u00f3t c\u00e0ng cao v\u00e0 h\u1eadu qu\u1ea3 c\u00e0ng nghi\u00eam tr\u1ecdng. Trong b\u00e0i h\u1ecdc n\u00e0y, ch\u00fang ta s\u1ebd c\u00f9ng nhau t\u00ecm hi\u1ec3u v\u1ec1 t\u1ef1 \u0111\u1ed9ng h\u00f3a trong ML: t\u1ef1 \u0111\u1ed9ng h\u00f3a nh\u1eefng g\u00ec v\u00e0 nh\u01b0 th\u1ebf n\u00e0o. T\u1ef1 \u0111\u1ed9ng h\u00f3a nh\u1eefng g\u00ec Continuous... Chi ti\u1ebft Tool Integration (CI) T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh ki\u1ec3m th\u1eed Gitlab CI ho\u1eb7c Jenkins T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh \u0111\u00f3ng g\u00f3i code v\u00e0 m\u00f4i tr\u01b0\u1eddng Gitlab CI ho\u1eb7c Jenkins Delivery (CD) T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh deploy serving API Gitlab CI ho\u1eb7c Jenkins T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh deploy c\u00e1c pipeline Gitlab CI ho\u1eb7c Jenkins Training (CT) T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh run c\u00e1c data pipeline chu\u1ea9n b\u1ecb feature cho model Airflow ho\u1eb7c Kubeflow Pipelines T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh run training pipeline \u0111\u1ec3 train model Airflow ho\u1eb7c Kubeflow Pipelines Monitoring (CM) T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh theo d\u00f5i v\u00e0 c\u1ea3nh b\u00e1o hi\u1ec7u n\u0103ng model v\u00e0 t\u00e0i nguy\u00ean h\u1ec7 th\u1ed1ng Prometheus v\u00e0 Grafana Tip \u0110\u00f4i khi b\u1ea1n s\u1ebd th\u1ea5y m\u1ed9t kh\u00e1i ni\u1ec7m CD kh\u00e1c l\u00e0 Continous Deployment . Lo\u1ea1i n\u00e0y c\u00f3 m\u1ee9c \u0111\u1ed9 t\u1ef1 \u0111\u1ed9ng cao h\u01a1n Continous Delivery , khi m\u00e0 qu\u00e1 tr\u00ecnh t\u1eeb \u0111\u00f3ng g\u00f3i t\u1edbi deploy \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng ho\u00e0n to\u00e0n, thay v\u00ec trigger th\u1ee7 c\u00f4ng b\u01b0\u1edbc deploy nh\u01b0 Continuous Delivery . Tri\u1ec3n khai t\u1ef1 \u0111\u1ed9ng h\u00f3a theo t\u1eebng giai \u0111o\u1ea1n T\u00f9y t\u1eebng y\u00eau c\u1ea7u \u0111\u1ea7u ra v\u00e0 ti\u1ebfn \u0111\u1ed9 hi\u1ec7n t\u1ea1i c\u1ee7a d\u1ef1 \u00e1n, nh\u00e0 ph\u00e1t tri\u1ec3n c\u1ea7n c\u00e2n nh\u1eafc n\u00ean t\u1ef1 \u0111\u1ed9ng h\u00f3a nh\u1eefng g\u00ec v\u1edbi th\u1ee9 t\u1ef1 v\u00e0 \u0111\u1ed9 \u01b0u ti\u00ean ra sao. Example \u0110\u1ea7u ra c\u1ee7a d\u1ef1 \u00e1n l\u00e0 1 model serving API \u0111\u1ec3 m\u1ed9t team s\u1ea3n ph\u1ea9m t\u00edch h\u1ee3p v\u00e0o h\u1ec7 th\u1ed1ng c\u1ee7a h\u1ecd, khi \u0111\u00f3 ch\u00fang ta c\u00f3 th\u1ec3 c\u00e2n nh\u1eafc tri\u1ec3n khai theo th\u1ee9 t\u1ef1 sau: CI: T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh ki\u1ec3m th\u1eed model (k\u1ebft qu\u1ea3 d\u1ef1 \u0111o\u00e1n c\u00f3 reproducible v\u00e0 gi\u1ed1ng k\u1ebft qu\u1ea3 m\u00e0 ch\u00fang ta ch\u1ea1y \u1edf m\u00e1y c\u00e1 nh\u00e2n kh\u00f4ng, .v.v.), code (th\u1ef1c hi\u1ec7n unit test c\u00e1c h\u00e0m logic) T\u1ef1 \u0111\u1ed9ng \u0111\u00f3ng g\u00f3i model, code v\u00e0 m\u00f4i tr\u01b0\u1eddng th\u00e0nh Docker image CD: T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh deploy model serving API CM: S\u1eed d\u1ee5ng Prometheus v\u00e0 Grafana \u0111\u1ec3 ki\u1ec3m tra m\u1ee9c \u0111\u1ed9 s\u1eed d\u1ee5ng t\u00e0i nguy\u00ean c\u1ee7a h\u1ec7 th\u1ed1ng v\u00e0 ki\u1ec3m tra model drift, t\u1ef1 \u0111\u1ed9ng c\u1ea3nh b\u00e1o qua email ho\u1eb7c Slack khi c\u00f3 nh\u1eefng b\u1ea5t th\u01b0\u1eddng. M\u00f4i tr\u01b0\u1eddng tri\u1ec3n khai d\u1ef1 \u00e1n Th\u00f4ng th\u01b0\u1eddng c\u00f3 3 m\u00f4i tr\u01b0\u1eddng tri\u1ec3n khai d\u1ef1 \u00e1n bao g\u1ed3m: Development / Dev: m\u00f4i tr\u01b0\u1eddng n\u00e0y th\u01b0\u1eddng c\u00f3 c\u1ea5u h\u00ecnh y\u1ebfu, v\u1edbi quy\u1ec1n truy c\u1eadp d\u1eef li\u1ec7u th\u1eadt \"g\u1ea7n nh\u01b0\" b\u1eb1ng 0. \u1ede m\u00f4i tr\u01b0\u1eddng n\u00e0y s\u1ebd d\u00f9ng d\u1eef li\u1ec7u gi\u1ea3, c\u00f9ng schema v\u1edbi d\u1eef li\u1ec7u th\u1ef1c t\u1ebf. Staging: m\u00f4i tr\u01b0\u1eddng n\u00e0y th\u01b0\u1eddng c\u00f3 c\u1ea5u h\u00ecnh v\u00e0 quy\u1ec1n truy c\u1eadp d\u1eef li\u1ec7u gi\u1ed1ng nh\u01b0 m\u00f4i tr\u01b0\u1eddng production Production / Prod: m\u00f4i tr\u01b0\u1eddng ch\u1ea1y th\u1ef1c t\u1ebf T\u1ed5ng k\u1ebft \u1ede b\u00e0i h\u1ecdc v\u1eeba r\u1ed3i, ch\u00fang ta \u0111\u00e3 c\u00f9ng nhau \u0111i qua c\u00e1c kh\u00e1i ni\u1ec7m c\u01a1 b\u1ea3n v\u1ec1 CI/CD. \u1ede b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd \u1ee9ng d\u1ee5ng \u0111\u1ec3 t\u1ef1 \u0111\u1ed9ng h\u00f3a vi\u1ec7c tri\u1ec3n khai model serving v\u00e0 c\u00e1c pipeline, thay v\u00ec l\u00e0m th\u1ee7 c\u00f4ng nh\u01b0 nh\u1eefng b\u00e0i tr\u01b0\u1edbc. T\u00e0i li\u1ec7u tham kh\u1ea3o https://mlops-guide.github.io/MLOps/PipelineAutomation/ https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/ci-cd/gioi-thieu.html#gioi-thieu","text":"C\u00e1c c\u00f4ng vi\u1ec7c c\u1ea7n nhi\u1ec1u thao t\u00e1c th\u1ee7 c\u00f4ng c\u1ee7a con ng\u01b0\u1eddi th\u01b0\u1eddng d\u1ec5 x\u1ea3y ra sai s\u00f3t, v\u00e0 n\u1ebfu nh\u1eefng vi\u1ec7c n\u00e0y l\u1eb7p l\u1ea1i c\u00e0ng nhi\u1ec1u th\u00ec t\u1ec9 l\u1ec7 sai s\u00f3t c\u00e0ng cao v\u00e0 h\u1eadu qu\u1ea3 c\u00e0ng nghi\u00eam tr\u1ecdng. Trong b\u00e0i h\u1ecdc n\u00e0y, ch\u00fang ta s\u1ebd c\u00f9ng nhau t\u00ecm hi\u1ec3u v\u1ec1 t\u1ef1 \u0111\u1ed9ng h\u00f3a trong ML: t\u1ef1 \u0111\u1ed9ng h\u00f3a nh\u1eefng g\u00ec v\u00e0 nh\u01b0 th\u1ebf n\u00e0o.","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/ci-cd/gioi-thieu.html#tu-ong-hoa-nhung-gi","text":"Continuous... Chi ti\u1ebft Tool Integration (CI) T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh ki\u1ec3m th\u1eed Gitlab CI ho\u1eb7c Jenkins T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh \u0111\u00f3ng g\u00f3i code v\u00e0 m\u00f4i tr\u01b0\u1eddng Gitlab CI ho\u1eb7c Jenkins Delivery (CD) T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh deploy serving API Gitlab CI ho\u1eb7c Jenkins T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh deploy c\u00e1c pipeline Gitlab CI ho\u1eb7c Jenkins Training (CT) T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh run c\u00e1c data pipeline chu\u1ea9n b\u1ecb feature cho model Airflow ho\u1eb7c Kubeflow Pipelines T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh run training pipeline \u0111\u1ec3 train model Airflow ho\u1eb7c Kubeflow Pipelines Monitoring (CM) T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh theo d\u00f5i v\u00e0 c\u1ea3nh b\u00e1o hi\u1ec7u n\u0103ng model v\u00e0 t\u00e0i nguy\u00ean h\u1ec7 th\u1ed1ng Prometheus v\u00e0 Grafana Tip \u0110\u00f4i khi b\u1ea1n s\u1ebd th\u1ea5y m\u1ed9t kh\u00e1i ni\u1ec7m CD kh\u00e1c l\u00e0 Continous Deployment . Lo\u1ea1i n\u00e0y c\u00f3 m\u1ee9c \u0111\u1ed9 t\u1ef1 \u0111\u1ed9ng cao h\u01a1n Continous Delivery , khi m\u00e0 qu\u00e1 tr\u00ecnh t\u1eeb \u0111\u00f3ng g\u00f3i t\u1edbi deploy \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng ho\u00e0n to\u00e0n, thay v\u00ec trigger th\u1ee7 c\u00f4ng b\u01b0\u1edbc deploy nh\u01b0 Continuous Delivery .","title":"T\u1ef1 \u0111\u1ed9ng h\u00f3a nh\u1eefng g\u00ec"},{"location":"mlops-crash-course/ci-cd/gioi-thieu.html#trien-khai-tu-ong-hoa-theo-tung-giai-oan","text":"T\u00f9y t\u1eebng y\u00eau c\u1ea7u \u0111\u1ea7u ra v\u00e0 ti\u1ebfn \u0111\u1ed9 hi\u1ec7n t\u1ea1i c\u1ee7a d\u1ef1 \u00e1n, nh\u00e0 ph\u00e1t tri\u1ec3n c\u1ea7n c\u00e2n nh\u1eafc n\u00ean t\u1ef1 \u0111\u1ed9ng h\u00f3a nh\u1eefng g\u00ec v\u1edbi th\u1ee9 t\u1ef1 v\u00e0 \u0111\u1ed9 \u01b0u ti\u00ean ra sao. Example \u0110\u1ea7u ra c\u1ee7a d\u1ef1 \u00e1n l\u00e0 1 model serving API \u0111\u1ec3 m\u1ed9t team s\u1ea3n ph\u1ea9m t\u00edch h\u1ee3p v\u00e0o h\u1ec7 th\u1ed1ng c\u1ee7a h\u1ecd, khi \u0111\u00f3 ch\u00fang ta c\u00f3 th\u1ec3 c\u00e2n nh\u1eafc tri\u1ec3n khai theo th\u1ee9 t\u1ef1 sau: CI: T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh ki\u1ec3m th\u1eed model (k\u1ebft qu\u1ea3 d\u1ef1 \u0111o\u00e1n c\u00f3 reproducible v\u00e0 gi\u1ed1ng k\u1ebft qu\u1ea3 m\u00e0 ch\u00fang ta ch\u1ea1y \u1edf m\u00e1y c\u00e1 nh\u00e2n kh\u00f4ng, .v.v.), code (th\u1ef1c hi\u1ec7n unit test c\u00e1c h\u00e0m logic) T\u1ef1 \u0111\u1ed9ng \u0111\u00f3ng g\u00f3i model, code v\u00e0 m\u00f4i tr\u01b0\u1eddng th\u00e0nh Docker image CD: T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh deploy model serving API CM: S\u1eed d\u1ee5ng Prometheus v\u00e0 Grafana \u0111\u1ec3 ki\u1ec3m tra m\u1ee9c \u0111\u1ed9 s\u1eed d\u1ee5ng t\u00e0i nguy\u00ean c\u1ee7a h\u1ec7 th\u1ed1ng v\u00e0 ki\u1ec3m tra model drift, t\u1ef1 \u0111\u1ed9ng c\u1ea3nh b\u00e1o qua email ho\u1eb7c Slack khi c\u00f3 nh\u1eefng b\u1ea5t th\u01b0\u1eddng.","title":"Tri\u1ec3n khai t\u1ef1 \u0111\u1ed9ng h\u00f3a theo t\u1eebng giai \u0111o\u1ea1n"},{"location":"mlops-crash-course/ci-cd/gioi-thieu.html#moi-truong-trien-khai-du-an","text":"Th\u00f4ng th\u01b0\u1eddng c\u00f3 3 m\u00f4i tr\u01b0\u1eddng tri\u1ec3n khai d\u1ef1 \u00e1n bao g\u1ed3m: Development / Dev: m\u00f4i tr\u01b0\u1eddng n\u00e0y th\u01b0\u1eddng c\u00f3 c\u1ea5u h\u00ecnh y\u1ebfu, v\u1edbi quy\u1ec1n truy c\u1eadp d\u1eef li\u1ec7u th\u1eadt \"g\u1ea7n nh\u01b0\" b\u1eb1ng 0. \u1ede m\u00f4i tr\u01b0\u1eddng n\u00e0y s\u1ebd d\u00f9ng d\u1eef li\u1ec7u gi\u1ea3, c\u00f9ng schema v\u1edbi d\u1eef li\u1ec7u th\u1ef1c t\u1ebf. Staging: m\u00f4i tr\u01b0\u1eddng n\u00e0y th\u01b0\u1eddng c\u00f3 c\u1ea5u h\u00ecnh v\u00e0 quy\u1ec1n truy c\u1eadp d\u1eef li\u1ec7u gi\u1ed1ng nh\u01b0 m\u00f4i tr\u01b0\u1eddng production Production / Prod: m\u00f4i tr\u01b0\u1eddng ch\u1ea1y th\u1ef1c t\u1ebf","title":"M\u00f4i tr\u01b0\u1eddng tri\u1ec3n khai d\u1ef1 \u00e1n"},{"location":"mlops-crash-course/ci-cd/gioi-thieu.html#tong-ket","text":"\u1ede b\u00e0i h\u1ecdc v\u1eeba r\u1ed3i, ch\u00fang ta \u0111\u00e3 c\u00f9ng nhau \u0111i qua c\u00e1c kh\u00e1i ni\u1ec7m c\u01a1 b\u1ea3n v\u1ec1 CI/CD. \u1ede b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd \u1ee9ng d\u1ee5ng \u0111\u1ec3 t\u1ef1 \u0111\u1ed9ng h\u00f3a vi\u1ec7c tri\u1ec3n khai model serving v\u00e0 c\u00e1c pipeline, thay v\u00ec l\u00e0m th\u1ee7 c\u00f4ng nh\u01b0 nh\u1eefng b\u00e0i tr\u01b0\u1edbc.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/ci-cd/gioi-thieu.html#tai-lieu-tham-khao","text":"https://mlops-guide.github.io/MLOps/PipelineAutomation/ https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning","title":"T\u00e0i li\u1ec7u tham kh\u1ea3o"},{"location":"mlops-crash-course/ci-cd/jenkins-co-ban.html","text":"Photo from wiki.jenkins.io Gi\u1edbi thi\u1ec7u V\u1eeba r\u1ed3i, ch\u00fang ta \u0111\u00e3 \u0111\u01b0\u1ee3c l\u00e0m quen v\u1edbi m\u1ed9t s\u1ed1 kh\u00e1i ni\u1ec7m li\u00ean quan t\u1edbi CI/CD v\u00e0 c\u00e1c b\u00e0i h\u1ecdc v\u1ec1 ki\u1ec3m th\u1eed trong m\u1ed9t h\u1ec7 th\u1ed1ng ML. C\u00e2u h\u1ecfi \u0111\u01b0\u1ee3c \u0111\u1eb7t ra \u0111\u00f3 l\u00e0 l\u00e0m th\u1ebf n\u00e0o \u0111\u1ec3 tri\u1ec3n khai m\u1ed9t CI/CD pipeline t\u1ef1 \u0111\u1ed9ng h\u00f3a g\u1ed3m c\u00e1c b\u01b0\u1edbc nh\u01b0 build, test, deploy? Jenkins l\u00e0 m\u1ed9t open source cho ph\u00e9p hi\u1ec7n th\u1ef1c h\u00e1o \u0111i\u1ec1u n\u00e0y. \u1ede b\u00e0i h\u1ecdc n\u00e0y, b\u1ea1n s\u1ebd: C\u00e0i \u0111\u1eb7t Jenkins tr\u00ean m\u00e1y c\u00e1 nh\u00e2n K\u1ebft n\u1ed1i Jenkins t\u1edbi Github V\u00e0 ch\u1ea1y th\u1eed m\u1ed9t CI/CD pipeline \u0111\u01a1n gi\u1ea3n C\u00e0i \u0111\u1eb7t Jenkins C\u00e1c b\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 c\u00e0i \u0111\u1eb7t: V\u00e0o repo mlops-crash-course-platform/ v\u00e0 ch\u1ea1y: bash run.sh jenkins up Ki\u1ec3m tra t\u00ecnh tr\u1ea1ng service: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f81b55f1b151 jenkins/jenkins:lts \"/usr/bin/tini -- /u\u2026\" 41 minutes ago Up 41 minutes 0 .0.0.0:50000->50000/tcp, :::50000->50000/tcp, 0 .0.0.0:8081->8080/tcp, :::8081->8080/tcp jenkins Truy c\u1eadp http://localhost:8081 , c\u00e1c b\u1ea1n s\u1ebd th\u1ea5y: Ki\u1ec3m tra logs c\u1ee7a jenkins container \u0111\u1ec3 l\u1ea5y m\u1eadt kh\u1ea9u admin : docker logs jenkins C\u00e1c b\u1ea1n s\u1ebd th\u1ea5y m\u1eadt kh\u1ea9u nh\u01b0 sau: ************************************************************* ************************************************************* ************************************************************* Jenkins initial setup is required. An admin user has been created and a password generated. Please use the following password to proceed to installation: e6623e35c18847e7a7ccfd07863feb4a This may also be found at: /var/jenkins_home/secrets/initialAdminPassword Ch\u1ecdn Install suggested plugins v\u00e0 ch\u1edd Jenkins c\u00e0i \u0111\u1eb7t c\u00e1c plugins. \u1ede giao di\u1ec7n \u0111\u0103ng k\u00fd user s\u1eed d\u1ee5ng Jenkins ch\u1ecdn Skip and continue as admin Tip Trong th\u1ef1c t\u1ebf, ng\u01b0\u1eddi qu\u1ea3n tr\u1ecb Jenkins s\u1ebd ph\u1ea3i t\u1ea1o user v\u00e0 c\u1ea5p quy\u1ec1n ph\u00f9 h\u1ee3p. \u1ede \u0111\u00e2y ch\u00fang ta s\u1eed d\u1ee5ng t\u00e0i kho\u1ea3n admin \u0111\u1ec3 tr\u00e1nh \u0111i qu\u00e1 s\u00e2u v\u00e0o ph\u1ea7n qu\u1ea3n tr\u1ecb n\u00e0y. C\u1ea5u h\u00ecnh Jenkins URL nh\u01b0 sau: Cu\u1ed1i c\u00f9ng, giao di\u1ec7n s\u1ebd nh\u01b0 sau: K\u1ebft n\u1ed1i Jenkins v\u1edbi Github B\u00e2y gi\u1edd ch\u00fang ta s\u1ebd k\u1ebft n\u1ed1i Jenkins \u1edf local v\u1edbi Github \u0111\u1ec3 m\u1ed7i khi push code l\u00ean th\u00ec Github s\u1ebd trigger CI/CD pipeline tr\u00ean m\u00e1y c\u00e1 nh\u00e2n c\u1ee7a ch\u00fang ta. Expose Jenkins v\u1edbi ngrok C\u00e1c b\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau: C\u00e0i \u0111\u1eb7t ngrok , x\u00e1c nh\u1eadn email, set token theo h\u01b0\u1edbng d\u1eadn t\u1ea1i \u0111\u00e2y Expose Jenkins service t\u1ea1i local v\u1edbi c\u00e2u l\u1ec7nh: ngrok http 8081 B\u1ea1n s\u1ebd th\u1ea5y console hi\u1ec3n th\u1ecb nh\u01b0 sau: ngrok by @inconshreveable ( Ctrl+C to quit ) Session Status online Account dangvanquan.xyz@gmail.com ( Plan: Free ) Version 2 .3.40 Region United States ( us ) Web Interface http://127.0.0.1:4040 Forwarding http://a846-183-80-56-103.ngrok.io -> http://local Forwarding https://a846-183-80-56-103.ngrok.io -> http://loca Connections ttl opn rt1 rt5 p50 p90 0 0 0 .00 0 .00 0 .00 0 .00 Truy c\u1eadp Jenkins qua link forward \u1edf tr\u00ean https://a846-183-80-56-103.ngrok.io Th\u00eam Jenkins webhook v\u00e0o Github \u0110\u1ea7u ti\u00ean b\u1ea1n push code \u0111\u00e3 clone t\u1eeb mlops-crash-course-code l\u00ean Github repo c\u1ee7a b\u1ea1n, link repo sau khi \u0111\u1ea9y l\u00ean s\u1ebd c\u00f3 d\u1ea1ng https://github.com/<yourusername>/mlops-crash-course-code . V\u00ed d\u1ee5: n\u1ebfu Github username l\u00e0 MLOps thi \u0111\u01b0\u1eddng link t\u1edbi repo s\u1ebd l\u00e0 https://github.com/MLOps/mlops-crash-course-code . N\u1ed9i dung b\u00ean d\u01b0\u1edbi v\u00e0 c\u00e1c n\u1ed9i dung k\u1ebf ti\u1ebfp trong module b\u00e0i gi\u1ea3ng v\u1ec1 ci-cd , b\u1ea1n s\u1ebd l\u00e0m vi\u1ec7c tr\u00ean repo https://github.com/<yourusername>/mlops-crash-course-code c\u1ee7a m\u00ecnh. Do \u0111\u00f3, khi m\u00e0 b\u1ea1n th\u1ea5y t\u00e1c gi\u1ea3 \u0111\u1ec1 c\u1eadp t\u1edbi repo https://github.com/MLOpsVN/mlops-crash-course-code , th\u00ec c\u00e1c b\u1ea1n h\u00e3y th\u1ef1c h\u00e0nh tr\u00ean repo t\u01b0\u01a1ng \u1ee9ng c\u1ee7a b\u1ea1n nh\u00e9. V\u00e0o Settings \u1edf repo code, ch\u1ecdn Webhooks \u1ea4n Add webhook , \u0111i\u1ec1n Payload URL l\u00e0 https://a846-183-80-56-103.ngrok.io/github-webhook/ , Content type l\u00e0 application/json \u1ede ph\u1ea7n Which events would you like to trigger this webhook? , ch\u1ecdn Let me select individual events. , tick v\u00e0o ph\u1ea7n Pushes v\u00e0 Pull requests \u1ea4n Add webhook \u0111\u1ec3 ho\u00e0n t\u1ea5t Th\u00eam Github repo v\u00e0o Jenkins Tr\u1edf l\u1ea1i m\u00e0 h\u00ecnh home c\u1ee7a Jenkins qua URL https://a846-183-80-56-103.ngrok.io \u1ea4n + New Item , \u0111i\u1ec1n t\u00ean d\u1ef1 \u00e1n v\u00e0o ph\u1ea7n b\u00ean d\u01b0\u1edbi Enter an item name , ch\u1ecdn Multibranch Pipeline v\u00e0 \u1ea5n OK \u1ede ph\u1ea7n Branch Sources , \u1ea5n Add source ch\u1ecdn GitHub Th\u00eam Github repo b\u1eb1ng c\u00e1ch ch\u1ecdn Add repository , \u0111i\u1ec1n v\u00e0o Repository URL \u1ea4n Apply \u0111\u1ec3 ho\u00e0n t\u1ea5t Trigger Jenkins pipeline Sau khi c\u00e0i \u0111\u1eb7t theo c\u00e1c b\u01b0\u1edbc nh\u01b0 \u1edf tr\u00ean, ch\u00fang ta s\u1ebd th\u1ea5y c\u00f3 project mlops-demo nh\u01b0 b\u00ean d\u01b0\u1edbi Bug N\u1ebfu b\u1ea1n kh\u00f4ng th\u1ea5y branch n\u00e0o, th\u00ec b\u1ea1n \u1ea5n Scan Repository Now nh\u01b0 b\u00ean d\u01b0\u1edbi v\u00e0 reload l\u1ea1i trang l\u00e0 \u0111\u01b0\u1ee3c. N\u1ebfu \u1ea5n v\u00e0o project mlops-demo , ch\u00fang ta s\u1ebd th\u1ea5y \u1edf g\u00f3c tay tr\u00e1i b\u00ean d\u01b0\u1edbi c\u00f3 Build History , ch\u00ednh l\u00e0 l\u1ecbch s\u1eed c\u00e1c l\u1ea7n push code trigger CI/CD pipeline c\u1ee7a ch\u00fang ta. Tuy\u1ec7t v\u1eddi, ti\u1ebfp theo ch\u00fang ta s\u1ebd chu\u1ea9n b\u1ecb 1 file Jenkinsfile \u0111\u01a1n gi\u1ea3n \u1edf trong folder mlops-crash-course-code/ mlops-crash-course-code/ \u251c\u2500\u2500 data_pipeline/ \u251c\u2500\u2500 Jenkinsfile \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 model_serving/ \u251c\u2500\u2500 README.md \u251c\u2500\u2500 .gitignore \u251c\u2500\u2500 stream_emitting/ \u2514\u2500\u2500 training_pipeline/ \u2514\u2500\u2500 monitoring_service/ v\u1edbi n\u1ed9i dung nh\u01b0 sau: Jenkinsfile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 pipeline { agent any # (1) stages { stage ( 'Build' ) { # (2) steps { echo 'Building something..' # (3) } } stage ( 'Test' ) { steps { echo 'Testing something..' } } stage ( 'Deploy' ) { steps { echo 'Deploying something..' } } } } \u0110\u1ecbnh ngh\u0129a executor ch\u1ea1y pipeline ( ip:port ho\u1eb7c docker image ), \u1edf \u0111\u00e2y any \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 m\u1ed9t executor b\u1ea5t k\u1ef3 Khai b\u00e1o m\u1ed9t b\u01b0\u1edbc trong pipeline Ch\u1ea1y c\u00e2u l\u1ec7nh echo ... trong b\u01b0\u1edbc n\u00e0y Sau khi \u0111\u00e3 th\u00eam file n\u00e0y v\u00e0o folder, ch\u00fang ta s\u1ebd th\u1ef1c hi\u1ec7n push commit l\u00ean branch b\u1ea5t k\u1ef3 git init git add Jenkinsfile git push origin your_branch L\u00fac n\u00e0y ch\u00fang ta s\u1ebd th\u1ea5y c\u00f3 th\u00eam #2 \u1edf Build History v\u1edbi 3 b\u01b0\u1edbc Build , Test v\u00e0 Deploy , ch\u1ee9ng t\u1ecf \u0111\u00e3 th\u00f4ng lu\u1ed3ng t\u1eeb push code cho t\u1edbi trigger Jenkins pipeline. N\u1ebfu ch\u00fang ta \u1ea5n v\u00e0o #2 , ch\u1ecdn Console Output , ch\u00fang ta s\u1ebd th\u1ea5y hi\u1ec3n th\u1ecb nh\u01b0 sau: [ Pipeline ] } [ Pipeline ] // stage [ Pipeline ] withEnv [ Pipeline ] { [ Pipeline ] stage [ Pipeline ] { ( Build ) [ Pipeline ] echo Building something.. [ Pipeline ] } [ Pipeline ] // stage [ Pipeline ] stage [ Pipeline ] { ( Test ) [ Pipeline ] echo Testing something.. [ Pipeline ] } [ Pipeline ] // stage [ Pipeline ] stage [ Pipeline ] { ( Deploy ) [ Pipeline ] echo Deploying something.. [ Pipeline ] } [ Pipeline ] // stage [ Pipeline ] } [ Pipeline ] // withEnv [ Pipeline ] } [ Pipeline ] // node [ Pipeline ] End of Pipeline Finished: SUCCESS Tip N\u1ebfu mu\u1ed1n ch\u1ea1y stage ch\u1ec9 khi c\u00f3 thay \u0111\u1ed5i \u1edf file ho\u1eb7c folder li\u00ean quan, v\u00ed d\u1ee5 ch\u1ec9 test data pipeline khi c\u00f3 thay \u0111\u1ed5i \u1edf folder data_pipeline/ , ch\u00fang ta th\u00eam \u0111i\u1ec1u ki\u1ec7n when nh\u01b0 sau: ````py title=\"Jenkinsfile\" linenums=\"1\" pipeline { ... stage('test data pipeline') { when {changeset \"data_pipeline/*.*\" } steps { echo 'Testing data pipeline..' } } ... } } ``` ```` Info Ki\u1ec3u vi\u1ebft Jenkinsfile nh\u01b0 \u1edf tr\u00ean, tu\u00e2n theo c\u00e1c rule v\u00e0 syntax \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a s\u1eb5n, g\u1ecdi l\u00e0 Declarative Pipeline . Ngo\u00e0i ra c\u00f2n m\u1ed9t c\u00e1ch vi\u1ebft kh\u00e1c d\u00f9ng Groovy script g\u1ecdi l\u00e0 Scripted Pipeline , c\u00e1ch n\u00e0y th\u00f4ng th\u01b0\u1eddng s\u1eed d\u1ee5ng cho nh\u1eefng logic ph\u1ee9c t\u1ea1p. T\u1ed5ng k\u1ebft \u1ede b\u00e0i h\u1ecdc v\u1eeba r\u1ed3i, Jenkins \u0111\u00e3 \u0111\u01b0\u1ee3c c\u00e0i \u0111\u1eb7t \u0111\u1ec3 c\u00f3 th\u1ec3 t\u1ef1 \u0111\u1ed9ng ch\u1ea1y CI/CD pipeline m\u1ed7i khi c\u00f3 s\u1ef1 thay \u0111\u1ed5i \u1edf repo yourusername/mlops-crash-course-code c\u1ee7a b\u1ea1n. Ch\u00fang ta \u0111\u00e3 x\u00e2y d\u1ef1ng v\u00e0 ch\u1ea1y th\u1eed m\u1ed9t file Jenkinsfile \u0111\u01a1n gi\u1ea3n \u0111\u1ec3 smoke test c\u00e1c c\u00e0i \u0111\u1eb7t xem c\u00f3 v\u1ea5n \u0111\u1ec1 g\u00ec kh\u00f4ng. \u1ede b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng Jenkinsfile \u0111\u1ec3 x\u00e2y d\u1ef1ng c\u00e1c CI/CD pipeline cho data pipeline.","title":"Jenkins c\u01a1 b\u1ea3n"},{"location":"mlops-crash-course/ci-cd/jenkins-co-ban.html#gioi-thieu","text":"V\u1eeba r\u1ed3i, ch\u00fang ta \u0111\u00e3 \u0111\u01b0\u1ee3c l\u00e0m quen v\u1edbi m\u1ed9t s\u1ed1 kh\u00e1i ni\u1ec7m li\u00ean quan t\u1edbi CI/CD v\u00e0 c\u00e1c b\u00e0i h\u1ecdc v\u1ec1 ki\u1ec3m th\u1eed trong m\u1ed9t h\u1ec7 th\u1ed1ng ML. C\u00e2u h\u1ecfi \u0111\u01b0\u1ee3c \u0111\u1eb7t ra \u0111\u00f3 l\u00e0 l\u00e0m th\u1ebf n\u00e0o \u0111\u1ec3 tri\u1ec3n khai m\u1ed9t CI/CD pipeline t\u1ef1 \u0111\u1ed9ng h\u00f3a g\u1ed3m c\u00e1c b\u01b0\u1edbc nh\u01b0 build, test, deploy? Jenkins l\u00e0 m\u1ed9t open source cho ph\u00e9p hi\u1ec7n th\u1ef1c h\u00e1o \u0111i\u1ec1u n\u00e0y. \u1ede b\u00e0i h\u1ecdc n\u00e0y, b\u1ea1n s\u1ebd: C\u00e0i \u0111\u1eb7t Jenkins tr\u00ean m\u00e1y c\u00e1 nh\u00e2n K\u1ebft n\u1ed1i Jenkins t\u1edbi Github V\u00e0 ch\u1ea1y th\u1eed m\u1ed9t CI/CD pipeline \u0111\u01a1n gi\u1ea3n","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/ci-cd/jenkins-co-ban.html#cai-at-jenkins","text":"C\u00e1c b\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 c\u00e0i \u0111\u1eb7t: V\u00e0o repo mlops-crash-course-platform/ v\u00e0 ch\u1ea1y: bash run.sh jenkins up Ki\u1ec3m tra t\u00ecnh tr\u1ea1ng service: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f81b55f1b151 jenkins/jenkins:lts \"/usr/bin/tini -- /u\u2026\" 41 minutes ago Up 41 minutes 0 .0.0.0:50000->50000/tcp, :::50000->50000/tcp, 0 .0.0.0:8081->8080/tcp, :::8081->8080/tcp jenkins Truy c\u1eadp http://localhost:8081 , c\u00e1c b\u1ea1n s\u1ebd th\u1ea5y: Ki\u1ec3m tra logs c\u1ee7a jenkins container \u0111\u1ec3 l\u1ea5y m\u1eadt kh\u1ea9u admin : docker logs jenkins C\u00e1c b\u1ea1n s\u1ebd th\u1ea5y m\u1eadt kh\u1ea9u nh\u01b0 sau: ************************************************************* ************************************************************* ************************************************************* Jenkins initial setup is required. An admin user has been created and a password generated. Please use the following password to proceed to installation: e6623e35c18847e7a7ccfd07863feb4a This may also be found at: /var/jenkins_home/secrets/initialAdminPassword Ch\u1ecdn Install suggested plugins v\u00e0 ch\u1edd Jenkins c\u00e0i \u0111\u1eb7t c\u00e1c plugins. \u1ede giao di\u1ec7n \u0111\u0103ng k\u00fd user s\u1eed d\u1ee5ng Jenkins ch\u1ecdn Skip and continue as admin Tip Trong th\u1ef1c t\u1ebf, ng\u01b0\u1eddi qu\u1ea3n tr\u1ecb Jenkins s\u1ebd ph\u1ea3i t\u1ea1o user v\u00e0 c\u1ea5p quy\u1ec1n ph\u00f9 h\u1ee3p. \u1ede \u0111\u00e2y ch\u00fang ta s\u1eed d\u1ee5ng t\u00e0i kho\u1ea3n admin \u0111\u1ec3 tr\u00e1nh \u0111i qu\u00e1 s\u00e2u v\u00e0o ph\u1ea7n qu\u1ea3n tr\u1ecb n\u00e0y. C\u1ea5u h\u00ecnh Jenkins URL nh\u01b0 sau: Cu\u1ed1i c\u00f9ng, giao di\u1ec7n s\u1ebd nh\u01b0 sau:","title":"C\u00e0i \u0111\u1eb7t Jenkins"},{"location":"mlops-crash-course/ci-cd/jenkins-co-ban.html#ket-noi-jenkins-voi-github","text":"B\u00e2y gi\u1edd ch\u00fang ta s\u1ebd k\u1ebft n\u1ed1i Jenkins \u1edf local v\u1edbi Github \u0111\u1ec3 m\u1ed7i khi push code l\u00ean th\u00ec Github s\u1ebd trigger CI/CD pipeline tr\u00ean m\u00e1y c\u00e1 nh\u00e2n c\u1ee7a ch\u00fang ta.","title":"K\u1ebft n\u1ed1i Jenkins v\u1edbi Github"},{"location":"mlops-crash-course/ci-cd/jenkins-co-ban.html#expose-jenkins-voi-ngrok","text":"C\u00e1c b\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau: C\u00e0i \u0111\u1eb7t ngrok , x\u00e1c nh\u1eadn email, set token theo h\u01b0\u1edbng d\u1eadn t\u1ea1i \u0111\u00e2y Expose Jenkins service t\u1ea1i local v\u1edbi c\u00e2u l\u1ec7nh: ngrok http 8081 B\u1ea1n s\u1ebd th\u1ea5y console hi\u1ec3n th\u1ecb nh\u01b0 sau: ngrok by @inconshreveable ( Ctrl+C to quit ) Session Status online Account dangvanquan.xyz@gmail.com ( Plan: Free ) Version 2 .3.40 Region United States ( us ) Web Interface http://127.0.0.1:4040 Forwarding http://a846-183-80-56-103.ngrok.io -> http://local Forwarding https://a846-183-80-56-103.ngrok.io -> http://loca Connections ttl opn rt1 rt5 p50 p90 0 0 0 .00 0 .00 0 .00 0 .00 Truy c\u1eadp Jenkins qua link forward \u1edf tr\u00ean https://a846-183-80-56-103.ngrok.io","title":"Expose Jenkins v\u1edbi ngrok"},{"location":"mlops-crash-course/ci-cd/jenkins-co-ban.html#them-jenkins-webhook-vao-github","text":"\u0110\u1ea7u ti\u00ean b\u1ea1n push code \u0111\u00e3 clone t\u1eeb mlops-crash-course-code l\u00ean Github repo c\u1ee7a b\u1ea1n, link repo sau khi \u0111\u1ea9y l\u00ean s\u1ebd c\u00f3 d\u1ea1ng https://github.com/<yourusername>/mlops-crash-course-code . V\u00ed d\u1ee5: n\u1ebfu Github username l\u00e0 MLOps thi \u0111\u01b0\u1eddng link t\u1edbi repo s\u1ebd l\u00e0 https://github.com/MLOps/mlops-crash-course-code . N\u1ed9i dung b\u00ean d\u01b0\u1edbi v\u00e0 c\u00e1c n\u1ed9i dung k\u1ebf ti\u1ebfp trong module b\u00e0i gi\u1ea3ng v\u1ec1 ci-cd , b\u1ea1n s\u1ebd l\u00e0m vi\u1ec7c tr\u00ean repo https://github.com/<yourusername>/mlops-crash-course-code c\u1ee7a m\u00ecnh. Do \u0111\u00f3, khi m\u00e0 b\u1ea1n th\u1ea5y t\u00e1c gi\u1ea3 \u0111\u1ec1 c\u1eadp t\u1edbi repo https://github.com/MLOpsVN/mlops-crash-course-code , th\u00ec c\u00e1c b\u1ea1n h\u00e3y th\u1ef1c h\u00e0nh tr\u00ean repo t\u01b0\u01a1ng \u1ee9ng c\u1ee7a b\u1ea1n nh\u00e9. V\u00e0o Settings \u1edf repo code, ch\u1ecdn Webhooks \u1ea4n Add webhook , \u0111i\u1ec1n Payload URL l\u00e0 https://a846-183-80-56-103.ngrok.io/github-webhook/ , Content type l\u00e0 application/json \u1ede ph\u1ea7n Which events would you like to trigger this webhook? , ch\u1ecdn Let me select individual events. , tick v\u00e0o ph\u1ea7n Pushes v\u00e0 Pull requests \u1ea4n Add webhook \u0111\u1ec3 ho\u00e0n t\u1ea5t","title":"Th\u00eam Jenkins webhook v\u00e0o Github"},{"location":"mlops-crash-course/ci-cd/jenkins-co-ban.html#them-github-repo-vao-jenkins","text":"Tr\u1edf l\u1ea1i m\u00e0 h\u00ecnh home c\u1ee7a Jenkins qua URL https://a846-183-80-56-103.ngrok.io \u1ea4n + New Item , \u0111i\u1ec1n t\u00ean d\u1ef1 \u00e1n v\u00e0o ph\u1ea7n b\u00ean d\u01b0\u1edbi Enter an item name , ch\u1ecdn Multibranch Pipeline v\u00e0 \u1ea5n OK \u1ede ph\u1ea7n Branch Sources , \u1ea5n Add source ch\u1ecdn GitHub Th\u00eam Github repo b\u1eb1ng c\u00e1ch ch\u1ecdn Add repository , \u0111i\u1ec1n v\u00e0o Repository URL \u1ea4n Apply \u0111\u1ec3 ho\u00e0n t\u1ea5t","title":"Th\u00eam Github repo v\u00e0o Jenkins"},{"location":"mlops-crash-course/ci-cd/jenkins-co-ban.html#trigger-jenkins-pipeline","text":"Sau khi c\u00e0i \u0111\u1eb7t theo c\u00e1c b\u01b0\u1edbc nh\u01b0 \u1edf tr\u00ean, ch\u00fang ta s\u1ebd th\u1ea5y c\u00f3 project mlops-demo nh\u01b0 b\u00ean d\u01b0\u1edbi Bug N\u1ebfu b\u1ea1n kh\u00f4ng th\u1ea5y branch n\u00e0o, th\u00ec b\u1ea1n \u1ea5n Scan Repository Now nh\u01b0 b\u00ean d\u01b0\u1edbi v\u00e0 reload l\u1ea1i trang l\u00e0 \u0111\u01b0\u1ee3c. N\u1ebfu \u1ea5n v\u00e0o project mlops-demo , ch\u00fang ta s\u1ebd th\u1ea5y \u1edf g\u00f3c tay tr\u00e1i b\u00ean d\u01b0\u1edbi c\u00f3 Build History , ch\u00ednh l\u00e0 l\u1ecbch s\u1eed c\u00e1c l\u1ea7n push code trigger CI/CD pipeline c\u1ee7a ch\u00fang ta. Tuy\u1ec7t v\u1eddi, ti\u1ebfp theo ch\u00fang ta s\u1ebd chu\u1ea9n b\u1ecb 1 file Jenkinsfile \u0111\u01a1n gi\u1ea3n \u1edf trong folder mlops-crash-course-code/ mlops-crash-course-code/ \u251c\u2500\u2500 data_pipeline/ \u251c\u2500\u2500 Jenkinsfile \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 model_serving/ \u251c\u2500\u2500 README.md \u251c\u2500\u2500 .gitignore \u251c\u2500\u2500 stream_emitting/ \u2514\u2500\u2500 training_pipeline/ \u2514\u2500\u2500 monitoring_service/ v\u1edbi n\u1ed9i dung nh\u01b0 sau: Jenkinsfile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 pipeline { agent any # (1) stages { stage ( 'Build' ) { # (2) steps { echo 'Building something..' # (3) } } stage ( 'Test' ) { steps { echo 'Testing something..' } } stage ( 'Deploy' ) { steps { echo 'Deploying something..' } } } } \u0110\u1ecbnh ngh\u0129a executor ch\u1ea1y pipeline ( ip:port ho\u1eb7c docker image ), \u1edf \u0111\u00e2y any \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 m\u1ed9t executor b\u1ea5t k\u1ef3 Khai b\u00e1o m\u1ed9t b\u01b0\u1edbc trong pipeline Ch\u1ea1y c\u00e2u l\u1ec7nh echo ... trong b\u01b0\u1edbc n\u00e0y Sau khi \u0111\u00e3 th\u00eam file n\u00e0y v\u00e0o folder, ch\u00fang ta s\u1ebd th\u1ef1c hi\u1ec7n push commit l\u00ean branch b\u1ea5t k\u1ef3 git init git add Jenkinsfile git push origin your_branch L\u00fac n\u00e0y ch\u00fang ta s\u1ebd th\u1ea5y c\u00f3 th\u00eam #2 \u1edf Build History v\u1edbi 3 b\u01b0\u1edbc Build , Test v\u00e0 Deploy , ch\u1ee9ng t\u1ecf \u0111\u00e3 th\u00f4ng lu\u1ed3ng t\u1eeb push code cho t\u1edbi trigger Jenkins pipeline. N\u1ebfu ch\u00fang ta \u1ea5n v\u00e0o #2 , ch\u1ecdn Console Output , ch\u00fang ta s\u1ebd th\u1ea5y hi\u1ec3n th\u1ecb nh\u01b0 sau: [ Pipeline ] } [ Pipeline ] // stage [ Pipeline ] withEnv [ Pipeline ] { [ Pipeline ] stage [ Pipeline ] { ( Build ) [ Pipeline ] echo Building something.. [ Pipeline ] } [ Pipeline ] // stage [ Pipeline ] stage [ Pipeline ] { ( Test ) [ Pipeline ] echo Testing something.. [ Pipeline ] } [ Pipeline ] // stage [ Pipeline ] stage [ Pipeline ] { ( Deploy ) [ Pipeline ] echo Deploying something.. [ Pipeline ] } [ Pipeline ] // stage [ Pipeline ] } [ Pipeline ] // withEnv [ Pipeline ] } [ Pipeline ] // node [ Pipeline ] End of Pipeline Finished: SUCCESS Tip N\u1ebfu mu\u1ed1n ch\u1ea1y stage ch\u1ec9 khi c\u00f3 thay \u0111\u1ed5i \u1edf file ho\u1eb7c folder li\u00ean quan, v\u00ed d\u1ee5 ch\u1ec9 test data pipeline khi c\u00f3 thay \u0111\u1ed5i \u1edf folder data_pipeline/ , ch\u00fang ta th\u00eam \u0111i\u1ec1u ki\u1ec7n when nh\u01b0 sau: ````py title=\"Jenkinsfile\" linenums=\"1\" pipeline { ... stage('test data pipeline') { when {changeset \"data_pipeline/*.*\" } steps { echo 'Testing data pipeline..' } } ... } } ``` ```` Info Ki\u1ec3u vi\u1ebft Jenkinsfile nh\u01b0 \u1edf tr\u00ean, tu\u00e2n theo c\u00e1c rule v\u00e0 syntax \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a s\u1eb5n, g\u1ecdi l\u00e0 Declarative Pipeline . Ngo\u00e0i ra c\u00f2n m\u1ed9t c\u00e1ch vi\u1ebft kh\u00e1c d\u00f9ng Groovy script g\u1ecdi l\u00e0 Scripted Pipeline , c\u00e1ch n\u00e0y th\u00f4ng th\u01b0\u1eddng s\u1eed d\u1ee5ng cho nh\u1eefng logic ph\u1ee9c t\u1ea1p.","title":"Trigger Jenkins pipeline"},{"location":"mlops-crash-course/ci-cd/jenkins-co-ban.html#tong-ket","text":"\u1ede b\u00e0i h\u1ecdc v\u1eeba r\u1ed3i, Jenkins \u0111\u00e3 \u0111\u01b0\u1ee3c c\u00e0i \u0111\u1eb7t \u0111\u1ec3 c\u00f3 th\u1ec3 t\u1ef1 \u0111\u1ed9ng ch\u1ea1y CI/CD pipeline m\u1ed7i khi c\u00f3 s\u1ef1 thay \u0111\u1ed5i \u1edf repo yourusername/mlops-crash-course-code c\u1ee7a b\u1ea1n. Ch\u00fang ta \u0111\u00e3 x\u00e2y d\u1ef1ng v\u00e0 ch\u1ea1y th\u1eed m\u1ed9t file Jenkinsfile \u0111\u01a1n gi\u1ea3n \u0111\u1ec3 smoke test c\u00e1c c\u00e0i \u0111\u1eb7t xem c\u00f3 v\u1ea5n \u0111\u1ec1 g\u00ec kh\u00f4ng. \u1ede b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng Jenkinsfile \u0111\u1ec3 x\u00e2y d\u1ef1ng c\u00e1c CI/CD pipeline cho data pipeline.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/ci-cd/kiem-thu-he-thong.html","text":"Gi\u1edbi thi\u1ec7u Kh\u00e1c v\u1edbi c\u00e1c h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m truy\u1ec3n th\u1ed1ng: m\u1ed9t developer ng\u1ed3i ngh\u0129 ra c\u00e1c rule v\u00e0 l\u1eadp tr\u00ecnh b\u1eb1ng Python, Java, ho\u1eb7c... LOLCODE, th\u00ec ML model s\u1ebd t\u1ef1 sinh ra c\u00e1c rule s\u1eed d\u1ee5ng d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c cung c\u1ea5p. \u0110i\u1ec1u n\u00e0y \u0111\u01b0\u01a1ng nhi\u00ean l\u00e0 t\u1ed1t, v\u00ec kh\u00f4ng ph\u1ea3i rule n\u00e0o con ng\u01b0\u1eddi c\u0169ng ngh\u0129 ra \u0111\u01b0\u1ee3c, tuy nhi\u00ean n\u00f3 c\u0169ng c\u00f3 m\u1eb7t tr\u00e1i c\u1ee7a n\u00f3: rule \u0111\u01b0\u1ee3c sinh ra c\u00f3 th\u1ec3 thay \u0111\u1ed5i, theo h\u01b0\u1edbng t\u1ed1t, x\u1ea5u ho\u1eb7c b\u1ecb BUG. \u0110i\u1ec1u n\u00e0y d\u1eabn t\u1edbi vi\u1ec7c ki\u1ec3m th\u1eed v\u00e0 debug m\u1ed9t h\u1ec7 th\u1ed1ng ML kh\u00f4ng h\u1ec1 \u0111\u01a1n gi\u1ea3n. \u1ede b\u00e0i h\u1ecdc n\u00e0y ch\u00fang ta h\u00e3y c\u00f9ng t\u00ecm hi\u1ec3u v\u1ec1 v\u1ea5 n \u0111\u1ec1 h\u00f3c b\u00faa n\u00e0y: ki\u1ec3m th\u1eed trong h\u1ec7 th\u1ed1ng ML. graph LR n01[ ] --\"\u0110\u1ea7u v\u00e0o\"--> n1[H\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m<br>truy\u1ec1n th\u1ed1ng] --K\u1ebft qu\u1ea3--> n02[ ] n03[ ] --Thu\u1eadt to\u00e1n--> n1 n04[ ] --\"\u0110\u1ea7u v\u00e0o\"--> n2[H\u1ec7 th\u1ed1ng<br>Machine Learning] --\"Thu\u1eadt to\u00e1n<br>(model)\"--> n05[ ] n06[ ] --K\u1ebft qu\u1ea3<br>mong mu\u1ed1n--> n2 style n01 height:0px; style n02 height:0px; style n03 height:0px; style n04 height:0px; style n05 height:0px; style n06 height:0px; Ki\u1ec3m th\u1eed h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m truy\u1ec1n th\u1ed1ng Th\u00f4ng th\u01b0\u1eddng c\u00f3 2 lo\u1ea1i ki\u1ec3m th\u1eed ph\u1ea7n m\u1ec1m: Functional Testing: ki\u1ec3m tra xem h\u1ec7 th\u1ed1ng \u0111\u00e3 \u0111\u1ea3m b\u1ea3o y\u00eau c\u1ea7u v\u1ec1 ch\u1ee9c n\u0103ng ch\u01b0a, v\u00ed d\u1ee5 \u1ea5n t\u1eaft windows update m\u00e3i m\u00e0 n\u00f3 v\u1eabn update th\u00ec kh\u00f4ng \u0111\u01b0\u1ee3c Non-functional Testing: ki\u1ec3m tra xem h\u1ec7 th\u1ed1ng c\u00f3 \u0111\u00e1p \u1ee9ng \u0111\u01b0\u1ee3c k\u1ef3 v\u1ecdng c\u1ee7a kh\u00e1ch h\u00e0ng kh\u00f4ng, v\u00ed d\u1ee5 t\u1ea5t c\u1ea3 ng\u01b0\u1eddi tr\u00ean th\u1ebf gi\u1edbi c\u00f9ng \u1ea5n n\u00fat tham gia group MLOpsVN th\u00ec group c\u0169ng kh\u00f4ng \u0111\u01b0\u1ee3c s\u1eadp Functional Testing Th\u00f4ng th\u01b0\u1eddng lo\u1ea1i n\u00e0y bao g\u1ed3m: Unit testing: test t\u1eebng module nh\u1ecf Integration testing: test m\u1ed9t module l\u1edbn bao g\u1ed3m nhi\u1ec1u module nh\u1ecf \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o khi k\u1ebft h\u1ee3p kh\u00f4ng x\u1ea3y ra v\u1ea5n \u0111\u1ec1 g\u00ec Tip Theo nguy\u00ean t\u1eafc KISS , h\u00e3y lu\u00f4n c\u1ed1 g\u1eafng b\u1ebb v\u1ea5n \u0111\u1ec1 th\u00e0nh nhi\u1ec1u module \u0111\u1ee7 nh\u1ecf v\u00e0 \u0111\u1ee7 d\u1ec5 hi\u1ec3u. V\u00ed d\u1ee5 d\u01b0\u1edbi \u0111\u00e2y \u0111\u01b0\u1ee3c tr\u00edch t\u1eeb Machine learning mastery blog cho th\u1ea5y t\u00e1c gi\u1ea3 \u0111\u00e3 \u00e1p d\u1ee5ng r\u1ea5t t\u1ed1t nguy\u00ean t\u1eafc n\u00e0y, th\u1ec3 hi\u1ec7n qua vi\u1ec7c c\u1ed1 g\u1eafng s\u1eed d\u1ee5ng nhi\u1ec1u h\u00e0m nh\u1ea5t c\u00f3 th\u1ec3, v\u00ed d\u1ee5 train_test_split , accuracy_score v\u00e0 confusion_matrix , khi \u0111\u00f3 chuy\u1ec7n test v\u00e0 debug s\u1ebd d\u1ec5 d\u00e0ng h\u01a1n r\u1ea5t nhi\u1ec1u. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # make predictions from pandas import read_csv from sklearn.model_selection import train_test_split from sklearn.metrics import classification_report from sklearn.metrics import confusion_matrix from sklearn.metrics import accuracy_score from sklearn.svm import SVC # Load dataset url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\" names = [ 'sepal-length' , 'sepal-width' , 'petal-length' , 'petal-width' , 'class' ] dataset = read_csv ( url , names = names ) # Split-out validation dataset array = dataset . values X = array [:, 0 : 4 ] y = array [:, 4 ] X_train , X_validation , Y_train , Y_validation = train_test_split ( X , y , test_size = 0.20 , random_state = 1 ) # Make predictions on validation dataset model = SVC ( gamma = 'auto' ) model . fit ( X_train , Y_train ) predictions = model . predict ( X_validation ) # Evaluate predictions print ( accuracy_score ( Y_validation , predictions )) print ( confusion_matrix ( Y_validation , predictions )) print ( classification_report ( Y_validation , predictions )) Regression testing: ki\u1ec3m tra l\u1ea1i to\u00e0n b\u1ed9 ch\u1ee9c n\u0103ng c\u1ee7a h\u1ec7 th\u1ed1ng m\u1ed7i khi c\u00f3 thay \u0111\u1ed5i c\u1ee7a m\u1ed9t ho\u1eb7c v\u00e0i ch\u1ee9c n\u0103ng n\u00e0o \u0111\u00f3 Smoke testing: ch\u1ea1y m\u1ed9t b\u00e0i test c\u01a1 b\u1ea3n v\u1edbi ch\u1ee9c n\u0103ng t\u1ed1i thi\u1ec3u \u0111\u1ec3 xem h\u1ec7 th\u1ed1ng s\u1eb5n s\u00e0ng cho vi\u1ec7c test ch\u01b0a M\u1ed9t v\u00ed d\u1ee5 \u0111\u01a1n gi\u1ea3n: B\u1eaft \u0111\u1ea7u ki\u1ec3m tra m\u1ed9t h\u1ec7 th\u1ed1ng b\u00f3ng \u0111\u00e8n, v\u1eeba \u1ea5n n\u00fat xong kh\u00f3i (smoke) b\u1ed1c l\u00ean nghi ng\u00fat th\u00ec kh\u00f4ng \u0111\u01b0\u1ee3c Non-functional Testing Load testing: x\u00e1c \u0111\u1ecbnh \u0111\u1ed9 ch\u1ecbu t\u1ea3i, SLA (Service Level Agreement) c\u1ee7a h\u1ec7 th\u1ed1ng Stress testing: \u0111\u00e1nh gi\u00e1 h\u00e0nh vi c\u1ee7a h\u1ec7 th\u1ed1ng t\u1ea1i c\u00e1c \u0111i\u1ec1u ki\u1ec7n kh\u00f4ng l\u01b0\u1eddng tr\u01b0\u1edbc, v\u00ed d\u1ee5 m\u1ed9t ph\u1ea7n h\u1ec7 th\u1ed1ng \u0111\u1ed9t nhi\u00ean shutdown th\u00ec ph\u1ea3n h\u1ed3i c\u00f3 ch\u1ea5p nh\u1eadn \u0111\u01b0\u1ee3c kh\u00f4ng Lu\u1ed3ng ph\u00e1t tri\u1ec3n ph\u1ea7n m\u1ec1m c\u01a1 b\u1ea3n Th\u00f4ng th\u01b0\u1eddng, c\u00e1c developer tu\u00e2n th\u1ee7 m\u1ed9t s\u1ed1 quy \u01b0\u1edbc sau khi ph\u00e1t tri\u1ec3n ph\u1ea7n m\u1ec1m: Kh\u00f4ng merge code n\u1ebfu ch\u01b0a ch\u1ea1y c\u00e1c test case Lu\u00f4n vi\u1ebft code test khi commit logic m\u1edbi Khi fix bug, lu\u00f4n vi\u1ebft code test \u0111\u1ec3 b\u1eaft bug v\u00e0 ph\u00f2ng x\u1ea3y ra tr\u01b0\u1eddng h\u1ee3p t\u01b0\u01a1ng t\u1ef1 trong t\u01b0\u01a1ng lai Source: https://www.jeremyjordan.me/testing-ml/ H\u1ec7 th\u1ed1ng ML c\u1ea7n ki\u1ec3m th\u1eed nh\u1eefng g\u00ec? Nh\u1eefng b\u00e0i test cho h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m c\u00f3 th\u1ec3 \u1ee9ng d\u1ee5ng cho h\u1ea7u h\u1ebft ML code, tuy nhi\u00ean v\u1eabn ch\u01b0a \u0111\u1ec3 \u0111\u1ee7 \u0111\u1ea3m b\u1ea3o h\u1ec7 th\u1ed1ng ML c\u00f3 th\u1ec3 ho\u1ea1t \u0111\u1ed9ng v\u1edbi \u0111\u1ed9 tin c\u1eady cao. Source: https://learning.oreilly.com/library/view/building-machine-learning \u0110\u1ec3 h\u1ec7 th\u1ed1ng ML tin t\u01b0\u1edfng \u0111\u01b0\u1ee3c th\u00ec c\u1ea7n ki\u1ec3m tra th\u00eam nh\u1eefng ph\u1ea7n sau: Data pipeline testing: \u0111\u1ea3m b\u1ea3o d\u1eef li\u1ec7u kh\u00f4ng b\u1ecb corrupt, \u0111\u00fang format v\u00e0 \u0111\u00fang schema (ki\u1ec3u d\u1eef li\u1ec7u), ... Data l\u00e0 m\u1ed9t ph\u1ea7n kh\u00f4ng th\u1ec3 thi\u1ebfu trong m\u1ed9t h\u1ec7 th\u1ed1ng ML, do \u0111\u00f3 duy tr\u00ec m\u1ed9t data pipeline v\u1edbi \u0111\u1ed9 tin c\u1eady cao l\u00e0 \u0111i\u1ec1u r\u1ea5t quan tr\u1ecdng. H\u00ecnh d\u01b0\u1edbi \u0111\u00e2y l\u00e0 v\u00ed d\u1ee5 v\u1ec1 1 data pipeline v\u00e0 nh\u1eefng th\u1ee9 y\u1ebfu t\u1ed1 c\u1ea7n c\u00e2n nh\u1eafc \u1edf m\u1ed7i b\u01b0\u1edbc: Model testing: \u0111\u1ea3m b\u1ea3o model \u0111\u1ea1t hi\u1ec3u qu\u1ea3 (v\u00ed d\u1ee5 accuracy) nh\u01b0 mong mu\u1ed1n v\u00e0 model c\u00f3 consistent kh\u00f4ng, ... C\u00f3 th\u1ec3 chia th\u00e0nh 2 lo\u1ea1i model testing: Testing Pre-train testing: t\u00ecm bug tr\u01b0\u1edbc khi train/evaluate Ki\u1ec3m tra xem c\u00f3 data leakage (leak th\u00f4ng tin), v\u00ed d\u1ee5 observation trong t\u1eadp train c\u0169ng c\u00f3 \u1edf t\u1eadp validation/test Ki\u1ec3m tra xem c\u00f3 feature leakage (feature mang th\u00f4ng tin c\u1ee7a label) Ki\u1ec3m tra model output c\u00f3 shape ho\u1eb7c c\u00f3 mi\u1ec1n gi\u00e1 tr\u1ecb nh\u01b0 \u00fd mu\u1ed1n Post-train testing: ho\u1ea1t \u0111\u1ed9ng c\u1ee7a model (model behavior) c\u00f3 nh\u01b0 \u00fd mu\u1ed1n \u1edf c\u00e1c t\u00ecnh hu\u1ed1ng (scenarios) kh\u00e1c nhau? Invariance testing: m\u00f4 t\u1ea3 nh\u1eefng thay \u0111\u1ed5i c\u1ee7a input m\u00e0 kh\u00f4ng l\u00e0m thay \u0111\u1ed5i k\u1ebft qu\u1ea3 d\u1ef1 \u0111o\u00e1n c\u1ee7a model V\u00ed d\u1ee5: trong b\u00e0i to\u00e1n sentiment analysis, th\u00ec 2 c\u00e2u sau n\u00ean c\u00f3 c\u00f9ng m\u1ed9t output: B\u1ed9 phim A hay qu\u00e1! B\u1ed9 phim B hay qu\u00e1! Directional expectation test: m\u00f4 t\u1ea3 nh\u1eefng thay \u0111\u1ed5i c\u1ee7a input s\u1ebd l\u00e0m thay \u0111\u1ed5i k\u1ebft qu\u1ea3 d\u1ef1 \u0111o\u00e1n c\u1ee7a model m\u1ed9t c\u00e1ch c\u00f3 th\u1ec3 l\u01b0\u1eddng tr\u01b0\u1edbc. V\u00ed d\u1ee5: trong b\u00e0i to\u00e1n d\u1ef1 \u0111o\u00e1n gi\u00e1 nh\u00e0, c\u00f3 th\u1ec3 \u0111o\u00e1n tr\u01b0\u1edbc n\u1ebfu kh\u00f4ng gian t\u0103ng th\u00ec gi\u00e1 nh\u00e0 s\u1ebd t\u0103ng. Bias/Fairness: ki\u1ec3m tra xem model c\u00f3 d\u1ef1 \u0111o\u00e1n c\u00f4ng b\u1eb1ng kh\u00f4ng, v\u00ed d\u1ee5 d\u1ef1 \u0111o\u00e1n income c\u1ee7a ng\u01b0\u1eddi ch\u00e2u M\u1ef9 ch\u00ednh x\u00e1c h\u01a1n ng\u01b0\u1eddi ch\u00e2u \u00c1, ch\u1ee9ng t\u1ecf model \u0111ang b\u1ecb bias. Model Output Consistency: v\u1edbi c\u00f9ng 1 d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o, model output c\u00f3 b\u1ecb thay \u0111\u1ed5i sau nhi\u1ec1u l\u1ea7n ch\u1ea1y kh\u00e1c nhau kh\u00f4ng? Note: C\u00f4ng c\u1ee5 What-If h\u1ed7 tr\u1ee3 r\u1ea5t t\u1ed1t trong vi\u1ec7c ki\u1ec3m tra model behavior \u1edf c\u00e1c t\u00ecnh hu\u1ed1ng kh\u00e1c nhau. Evaluation: \u0111\u00e1nh gi\u00e1 hi\u1ec7u qu\u1ea3 c\u1ee7a model th\u00f4ng qua c\u00e1c metrics nh\u01b0 accuracy v\u00e0 F1, ... tr\u00ean t\u1eadp validation/test. M\u1ed9t s\u1ed1 tool hay d\u00f9ng \u0111\u1ec3 test v\u00e0 debug pdb \u0111\u1ec3 debug python code pytest l\u00e0 framework h\u1ed7 tr\u1ee3 vi\u1ebft code test Coverage.py \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh \u0111o\u1ea1n code n\u00e0o c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c execute nh\u01b0ng \u0111\u00e3 kh\u00f4ng pylint \u0111\u1ec3 ki\u1ec3m tra l\u1ed7i c\u00fa ph\u00e1p/logic T\u1ed5ng k\u1ebft \u1ede b\u00e0i h\u1ecdc v\u1eeba r\u1ed3i, ch\u00fang ta \u0111\u00e3 t\u00ecm hi\u1ec3u v\u1ec1 ki\u1ec3m th\u1eed ph\u1ea7n m\u1ec1m truy\u1ec1n th\u1ed1ng, c\u0169ng nh\u01b0 trong ML v\u00e0 c\u00e1c tool h\u1eefu \u00edch \u0111\u1ec3 tri\u1ec3n khai qu\u00e1 tr\u00ecnh ki\u1ec3m th\u1eed n\u00e0y. Hy v\u1ecdng t\u00e0i li\u1ec7u n\u00e0y gi\u00fap \u00edch cho b\u1ea1n trong vi\u1ec7c \u0111\u1ea3m b\u1ea3o h\u1ec7 th\u1ed1ng ML \u0111\u00e1ng tin c\u1eady h\u01a1n. T\u00e0i li\u1ec7u tham kh\u1ea3o https://serokell.io/blog/machine-learning-testing https://developers.google.com/machine-learning/testing-debugging/common/overview Emmanuel Ameisen, Building Machine Learning Powered Applications: Going from Idea to Product https://www.jeremyjordan.me/testing-ml/ https://homes.cs.washington.edu/~marcotcr/acl20_checklist.pdf https://fontysblogt.nl/software-engineering-for-machine-learning-applications/ https://futurice.com/blog/differences-between-machine-learning-and-software-engineering https://www.geeksforgeeks.org/differences-between-functional-and-non-functional-testing/ https://eugeneyan.com/writing/testing-ml/","title":"Ki\u1ec3m th\u1eed h\u1ec7 th\u1ed1ng"},{"location":"mlops-crash-course/ci-cd/kiem-thu-he-thong.html#gioi-thieu","text":"Kh\u00e1c v\u1edbi c\u00e1c h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m truy\u1ec3n th\u1ed1ng: m\u1ed9t developer ng\u1ed3i ngh\u0129 ra c\u00e1c rule v\u00e0 l\u1eadp tr\u00ecnh b\u1eb1ng Python, Java, ho\u1eb7c... LOLCODE, th\u00ec ML model s\u1ebd t\u1ef1 sinh ra c\u00e1c rule s\u1eed d\u1ee5ng d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c cung c\u1ea5p. \u0110i\u1ec1u n\u00e0y \u0111\u01b0\u01a1ng nhi\u00ean l\u00e0 t\u1ed1t, v\u00ec kh\u00f4ng ph\u1ea3i rule n\u00e0o con ng\u01b0\u1eddi c\u0169ng ngh\u0129 ra \u0111\u01b0\u1ee3c, tuy nhi\u00ean n\u00f3 c\u0169ng c\u00f3 m\u1eb7t tr\u00e1i c\u1ee7a n\u00f3: rule \u0111\u01b0\u1ee3c sinh ra c\u00f3 th\u1ec3 thay \u0111\u1ed5i, theo h\u01b0\u1edbng t\u1ed1t, x\u1ea5u ho\u1eb7c b\u1ecb BUG. \u0110i\u1ec1u n\u00e0y d\u1eabn t\u1edbi vi\u1ec7c ki\u1ec3m th\u1eed v\u00e0 debug m\u1ed9t h\u1ec7 th\u1ed1ng ML kh\u00f4ng h\u1ec1 \u0111\u01a1n gi\u1ea3n. \u1ede b\u00e0i h\u1ecdc n\u00e0y ch\u00fang ta h\u00e3y c\u00f9ng t\u00ecm hi\u1ec3u v\u1ec1 v\u1ea5 n \u0111\u1ec1 h\u00f3c b\u00faa n\u00e0y: ki\u1ec3m th\u1eed trong h\u1ec7 th\u1ed1ng ML. graph LR n01[ ] --\"\u0110\u1ea7u v\u00e0o\"--> n1[H\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m<br>truy\u1ec1n th\u1ed1ng] --K\u1ebft qu\u1ea3--> n02[ ] n03[ ] --Thu\u1eadt to\u00e1n--> n1 n04[ ] --\"\u0110\u1ea7u v\u00e0o\"--> n2[H\u1ec7 th\u1ed1ng<br>Machine Learning] --\"Thu\u1eadt to\u00e1n<br>(model)\"--> n05[ ] n06[ ] --K\u1ebft qu\u1ea3<br>mong mu\u1ed1n--> n2 style n01 height:0px; style n02 height:0px; style n03 height:0px; style n04 height:0px; style n05 height:0px; style n06 height:0px;","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/ci-cd/kiem-thu-he-thong.html#kiem-thu-he-thong-phan-mem-truyen-thong","text":"Th\u00f4ng th\u01b0\u1eddng c\u00f3 2 lo\u1ea1i ki\u1ec3m th\u1eed ph\u1ea7n m\u1ec1m: Functional Testing: ki\u1ec3m tra xem h\u1ec7 th\u1ed1ng \u0111\u00e3 \u0111\u1ea3m b\u1ea3o y\u00eau c\u1ea7u v\u1ec1 ch\u1ee9c n\u0103ng ch\u01b0a, v\u00ed d\u1ee5 \u1ea5n t\u1eaft windows update m\u00e3i m\u00e0 n\u00f3 v\u1eabn update th\u00ec kh\u00f4ng \u0111\u01b0\u1ee3c Non-functional Testing: ki\u1ec3m tra xem h\u1ec7 th\u1ed1ng c\u00f3 \u0111\u00e1p \u1ee9ng \u0111\u01b0\u1ee3c k\u1ef3 v\u1ecdng c\u1ee7a kh\u00e1ch h\u00e0ng kh\u00f4ng, v\u00ed d\u1ee5 t\u1ea5t c\u1ea3 ng\u01b0\u1eddi tr\u00ean th\u1ebf gi\u1edbi c\u00f9ng \u1ea5n n\u00fat tham gia group MLOpsVN th\u00ec group c\u0169ng kh\u00f4ng \u0111\u01b0\u1ee3c s\u1eadp","title":"Ki\u1ec3m th\u1eed h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m truy\u1ec1n th\u1ed1ng"},{"location":"mlops-crash-course/ci-cd/kiem-thu-he-thong.html#functional-testing","text":"Th\u00f4ng th\u01b0\u1eddng lo\u1ea1i n\u00e0y bao g\u1ed3m: Unit testing: test t\u1eebng module nh\u1ecf Integration testing: test m\u1ed9t module l\u1edbn bao g\u1ed3m nhi\u1ec1u module nh\u1ecf \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o khi k\u1ebft h\u1ee3p kh\u00f4ng x\u1ea3y ra v\u1ea5n \u0111\u1ec1 g\u00ec Tip Theo nguy\u00ean t\u1eafc KISS , h\u00e3y lu\u00f4n c\u1ed1 g\u1eafng b\u1ebb v\u1ea5n \u0111\u1ec1 th\u00e0nh nhi\u1ec1u module \u0111\u1ee7 nh\u1ecf v\u00e0 \u0111\u1ee7 d\u1ec5 hi\u1ec3u. V\u00ed d\u1ee5 d\u01b0\u1edbi \u0111\u00e2y \u0111\u01b0\u1ee3c tr\u00edch t\u1eeb Machine learning mastery blog cho th\u1ea5y t\u00e1c gi\u1ea3 \u0111\u00e3 \u00e1p d\u1ee5ng r\u1ea5t t\u1ed1t nguy\u00ean t\u1eafc n\u00e0y, th\u1ec3 hi\u1ec7n qua vi\u1ec7c c\u1ed1 g\u1eafng s\u1eed d\u1ee5ng nhi\u1ec1u h\u00e0m nh\u1ea5t c\u00f3 th\u1ec3, v\u00ed d\u1ee5 train_test_split , accuracy_score v\u00e0 confusion_matrix , khi \u0111\u00f3 chuy\u1ec7n test v\u00e0 debug s\u1ebd d\u1ec5 d\u00e0ng h\u01a1n r\u1ea5t nhi\u1ec1u. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # make predictions from pandas import read_csv from sklearn.model_selection import train_test_split from sklearn.metrics import classification_report from sklearn.metrics import confusion_matrix from sklearn.metrics import accuracy_score from sklearn.svm import SVC # Load dataset url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\" names = [ 'sepal-length' , 'sepal-width' , 'petal-length' , 'petal-width' , 'class' ] dataset = read_csv ( url , names = names ) # Split-out validation dataset array = dataset . values X = array [:, 0 : 4 ] y = array [:, 4 ] X_train , X_validation , Y_train , Y_validation = train_test_split ( X , y , test_size = 0.20 , random_state = 1 ) # Make predictions on validation dataset model = SVC ( gamma = 'auto' ) model . fit ( X_train , Y_train ) predictions = model . predict ( X_validation ) # Evaluate predictions print ( accuracy_score ( Y_validation , predictions )) print ( confusion_matrix ( Y_validation , predictions )) print ( classification_report ( Y_validation , predictions )) Regression testing: ki\u1ec3m tra l\u1ea1i to\u00e0n b\u1ed9 ch\u1ee9c n\u0103ng c\u1ee7a h\u1ec7 th\u1ed1ng m\u1ed7i khi c\u00f3 thay \u0111\u1ed5i c\u1ee7a m\u1ed9t ho\u1eb7c v\u00e0i ch\u1ee9c n\u0103ng n\u00e0o \u0111\u00f3 Smoke testing: ch\u1ea1y m\u1ed9t b\u00e0i test c\u01a1 b\u1ea3n v\u1edbi ch\u1ee9c n\u0103ng t\u1ed1i thi\u1ec3u \u0111\u1ec3 xem h\u1ec7 th\u1ed1ng s\u1eb5n s\u00e0ng cho vi\u1ec7c test ch\u01b0a M\u1ed9t v\u00ed d\u1ee5 \u0111\u01a1n gi\u1ea3n: B\u1eaft \u0111\u1ea7u ki\u1ec3m tra m\u1ed9t h\u1ec7 th\u1ed1ng b\u00f3ng \u0111\u00e8n, v\u1eeba \u1ea5n n\u00fat xong kh\u00f3i (smoke) b\u1ed1c l\u00ean nghi ng\u00fat th\u00ec kh\u00f4ng \u0111\u01b0\u1ee3c","title":"Functional Testing"},{"location":"mlops-crash-course/ci-cd/kiem-thu-he-thong.html#non-functional-testing","text":"Load testing: x\u00e1c \u0111\u1ecbnh \u0111\u1ed9 ch\u1ecbu t\u1ea3i, SLA (Service Level Agreement) c\u1ee7a h\u1ec7 th\u1ed1ng Stress testing: \u0111\u00e1nh gi\u00e1 h\u00e0nh vi c\u1ee7a h\u1ec7 th\u1ed1ng t\u1ea1i c\u00e1c \u0111i\u1ec1u ki\u1ec7n kh\u00f4ng l\u01b0\u1eddng tr\u01b0\u1edbc, v\u00ed d\u1ee5 m\u1ed9t ph\u1ea7n h\u1ec7 th\u1ed1ng \u0111\u1ed9t nhi\u00ean shutdown th\u00ec ph\u1ea3n h\u1ed3i c\u00f3 ch\u1ea5p nh\u1eadn \u0111\u01b0\u1ee3c kh\u00f4ng","title":"Non-functional Testing"},{"location":"mlops-crash-course/ci-cd/kiem-thu-he-thong.html#luong-phat-trien-phan-mem-co-ban","text":"Th\u00f4ng th\u01b0\u1eddng, c\u00e1c developer tu\u00e2n th\u1ee7 m\u1ed9t s\u1ed1 quy \u01b0\u1edbc sau khi ph\u00e1t tri\u1ec3n ph\u1ea7n m\u1ec1m: Kh\u00f4ng merge code n\u1ebfu ch\u01b0a ch\u1ea1y c\u00e1c test case Lu\u00f4n vi\u1ebft code test khi commit logic m\u1edbi Khi fix bug, lu\u00f4n vi\u1ebft code test \u0111\u1ec3 b\u1eaft bug v\u00e0 ph\u00f2ng x\u1ea3y ra tr\u01b0\u1eddng h\u1ee3p t\u01b0\u01a1ng t\u1ef1 trong t\u01b0\u01a1ng lai Source: https://www.jeremyjordan.me/testing-ml/","title":"Lu\u1ed3ng ph\u00e1t tri\u1ec3n ph\u1ea7n m\u1ec1m c\u01a1 b\u1ea3n"},{"location":"mlops-crash-course/ci-cd/kiem-thu-he-thong.html#he-thong-ml-can-kiem-thu-nhung-gi","text":"Nh\u1eefng b\u00e0i test cho h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m c\u00f3 th\u1ec3 \u1ee9ng d\u1ee5ng cho h\u1ea7u h\u1ebft ML code, tuy nhi\u00ean v\u1eabn ch\u01b0a \u0111\u1ec3 \u0111\u1ee7 \u0111\u1ea3m b\u1ea3o h\u1ec7 th\u1ed1ng ML c\u00f3 th\u1ec3 ho\u1ea1t \u0111\u1ed9ng v\u1edbi \u0111\u1ed9 tin c\u1eady cao. Source: https://learning.oreilly.com/library/view/building-machine-learning \u0110\u1ec3 h\u1ec7 th\u1ed1ng ML tin t\u01b0\u1edfng \u0111\u01b0\u1ee3c th\u00ec c\u1ea7n ki\u1ec3m tra th\u00eam nh\u1eefng ph\u1ea7n sau: Data pipeline testing: \u0111\u1ea3m b\u1ea3o d\u1eef li\u1ec7u kh\u00f4ng b\u1ecb corrupt, \u0111\u00fang format v\u00e0 \u0111\u00fang schema (ki\u1ec3u d\u1eef li\u1ec7u), ... Data l\u00e0 m\u1ed9t ph\u1ea7n kh\u00f4ng th\u1ec3 thi\u1ebfu trong m\u1ed9t h\u1ec7 th\u1ed1ng ML, do \u0111\u00f3 duy tr\u00ec m\u1ed9t data pipeline v\u1edbi \u0111\u1ed9 tin c\u1eady cao l\u00e0 \u0111i\u1ec1u r\u1ea5t quan tr\u1ecdng. H\u00ecnh d\u01b0\u1edbi \u0111\u00e2y l\u00e0 v\u00ed d\u1ee5 v\u1ec1 1 data pipeline v\u00e0 nh\u1eefng th\u1ee9 y\u1ebfu t\u1ed1 c\u1ea7n c\u00e2n nh\u1eafc \u1edf m\u1ed7i b\u01b0\u1edbc: Model testing: \u0111\u1ea3m b\u1ea3o model \u0111\u1ea1t hi\u1ec3u qu\u1ea3 (v\u00ed d\u1ee5 accuracy) nh\u01b0 mong mu\u1ed1n v\u00e0 model c\u00f3 consistent kh\u00f4ng, ... C\u00f3 th\u1ec3 chia th\u00e0nh 2 lo\u1ea1i model testing: Testing Pre-train testing: t\u00ecm bug tr\u01b0\u1edbc khi train/evaluate Ki\u1ec3m tra xem c\u00f3 data leakage (leak th\u00f4ng tin), v\u00ed d\u1ee5 observation trong t\u1eadp train c\u0169ng c\u00f3 \u1edf t\u1eadp validation/test Ki\u1ec3m tra xem c\u00f3 feature leakage (feature mang th\u00f4ng tin c\u1ee7a label) Ki\u1ec3m tra model output c\u00f3 shape ho\u1eb7c c\u00f3 mi\u1ec1n gi\u00e1 tr\u1ecb nh\u01b0 \u00fd mu\u1ed1n Post-train testing: ho\u1ea1t \u0111\u1ed9ng c\u1ee7a model (model behavior) c\u00f3 nh\u01b0 \u00fd mu\u1ed1n \u1edf c\u00e1c t\u00ecnh hu\u1ed1ng (scenarios) kh\u00e1c nhau? Invariance testing: m\u00f4 t\u1ea3 nh\u1eefng thay \u0111\u1ed5i c\u1ee7a input m\u00e0 kh\u00f4ng l\u00e0m thay \u0111\u1ed5i k\u1ebft qu\u1ea3 d\u1ef1 \u0111o\u00e1n c\u1ee7a model V\u00ed d\u1ee5: trong b\u00e0i to\u00e1n sentiment analysis, th\u00ec 2 c\u00e2u sau n\u00ean c\u00f3 c\u00f9ng m\u1ed9t output: B\u1ed9 phim A hay qu\u00e1! B\u1ed9 phim B hay qu\u00e1! Directional expectation test: m\u00f4 t\u1ea3 nh\u1eefng thay \u0111\u1ed5i c\u1ee7a input s\u1ebd l\u00e0m thay \u0111\u1ed5i k\u1ebft qu\u1ea3 d\u1ef1 \u0111o\u00e1n c\u1ee7a model m\u1ed9t c\u00e1ch c\u00f3 th\u1ec3 l\u01b0\u1eddng tr\u01b0\u1edbc. V\u00ed d\u1ee5: trong b\u00e0i to\u00e1n d\u1ef1 \u0111o\u00e1n gi\u00e1 nh\u00e0, c\u00f3 th\u1ec3 \u0111o\u00e1n tr\u01b0\u1edbc n\u1ebfu kh\u00f4ng gian t\u0103ng th\u00ec gi\u00e1 nh\u00e0 s\u1ebd t\u0103ng. Bias/Fairness: ki\u1ec3m tra xem model c\u00f3 d\u1ef1 \u0111o\u00e1n c\u00f4ng b\u1eb1ng kh\u00f4ng, v\u00ed d\u1ee5 d\u1ef1 \u0111o\u00e1n income c\u1ee7a ng\u01b0\u1eddi ch\u00e2u M\u1ef9 ch\u00ednh x\u00e1c h\u01a1n ng\u01b0\u1eddi ch\u00e2u \u00c1, ch\u1ee9ng t\u1ecf model \u0111ang b\u1ecb bias. Model Output Consistency: v\u1edbi c\u00f9ng 1 d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o, model output c\u00f3 b\u1ecb thay \u0111\u1ed5i sau nhi\u1ec1u l\u1ea7n ch\u1ea1y kh\u00e1c nhau kh\u00f4ng? Note: C\u00f4ng c\u1ee5 What-If h\u1ed7 tr\u1ee3 r\u1ea5t t\u1ed1t trong vi\u1ec7c ki\u1ec3m tra model behavior \u1edf c\u00e1c t\u00ecnh hu\u1ed1ng kh\u00e1c nhau. Evaluation: \u0111\u00e1nh gi\u00e1 hi\u1ec7u qu\u1ea3 c\u1ee7a model th\u00f4ng qua c\u00e1c metrics nh\u01b0 accuracy v\u00e0 F1, ... tr\u00ean t\u1eadp validation/test.","title":"H\u1ec7 th\u1ed1ng ML c\u1ea7n ki\u1ec3m th\u1eed nh\u1eefng g\u00ec?"},{"location":"mlops-crash-course/ci-cd/kiem-thu-he-thong.html#mot-so-tool-hay-dung-e-test-va-debug","text":"pdb \u0111\u1ec3 debug python code pytest l\u00e0 framework h\u1ed7 tr\u1ee3 vi\u1ebft code test Coverage.py \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh \u0111o\u1ea1n code n\u00e0o c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c execute nh\u01b0ng \u0111\u00e3 kh\u00f4ng pylint \u0111\u1ec3 ki\u1ec3m tra l\u1ed7i c\u00fa ph\u00e1p/logic","title":"M\u1ed9t s\u1ed1 tool hay d\u00f9ng \u0111\u1ec3 test v\u00e0 debug"},{"location":"mlops-crash-course/ci-cd/kiem-thu-he-thong.html#tong-ket","text":"\u1ede b\u00e0i h\u1ecdc v\u1eeba r\u1ed3i, ch\u00fang ta \u0111\u00e3 t\u00ecm hi\u1ec3u v\u1ec1 ki\u1ec3m th\u1eed ph\u1ea7n m\u1ec1m truy\u1ec1n th\u1ed1ng, c\u0169ng nh\u01b0 trong ML v\u00e0 c\u00e1c tool h\u1eefu \u00edch \u0111\u1ec3 tri\u1ec3n khai qu\u00e1 tr\u00ecnh ki\u1ec3m th\u1eed n\u00e0y. Hy v\u1ecdng t\u00e0i li\u1ec7u n\u00e0y gi\u00fap \u00edch cho b\u1ea1n trong vi\u1ec7c \u0111\u1ea3m b\u1ea3o h\u1ec7 th\u1ed1ng ML \u0111\u00e1ng tin c\u1eady h\u01a1n.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/ci-cd/kiem-thu-he-thong.html#tai-lieu-tham-khao","text":"https://serokell.io/blog/machine-learning-testing https://developers.google.com/machine-learning/testing-debugging/common/overview Emmanuel Ameisen, Building Machine Learning Powered Applications: Going from Idea to Product https://www.jeremyjordan.me/testing-ml/ https://homes.cs.washington.edu/~marcotcr/acl20_checklist.pdf https://fontysblogt.nl/software-engineering-for-machine-learning-applications/ https://futurice.com/blog/differences-between-machine-learning-and-software-engineering https://www.geeksforgeeks.org/differences-between-functional-and-non-functional-testing/ https://eugeneyan.com/writing/testing-ml/","title":"T\u00e0i li\u1ec7u tham kh\u1ea3o"},{"location":"mlops-crash-course/ci-cd/model-serving.html","text":"Photo from www.mabl.com Gi\u1edbi thi\u1ec7u \u1ede b\u00e0i h\u1ecdc tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 c\u00f9ng nhau x\u00e2y d\u1ef1ng Jenkins pipeline \u0111\u1ec3 t\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh release data pipeline . Trong b\u00e0i h\u1ecdc n\u00e0y ch\u00fang ta s\u1ebd s\u1eeda Jenkinsfile \u0111\u1ec3 ph\u1ee5c v\u1ee5 cho model serving . Jenkins pipeline CI/CD pipeline cho model serving s\u1ebd \u0111\u01b0\u1ee3c thay \u0111\u1ed5i th\u00e0nh nh\u01b0 sau: graph LR n1[1. Build model serving] --> n2[2. Test model serving] n2[2. Test model serving] --> n3[3.1. Deploy offline batch serving pipeline] n2[2. Test model serving] --> n4[3.2. Deploy online serving API] Tip \u1ede \u0111\u00e2y ch\u00fang ta s\u1ebd d\u00f9ng 1 image cho c\u1ea3 online serving API v\u00e0 offline batch serving pipeline \u0111\u1ec3 h\u1ea1n ch\u1ebf s\u1ef1 kh\u00e1c nhau gi\u1eefa code v\u00e0 m\u00f4i tr\u01b0\u1eddng ch\u1ea1y. Jenkinsfile_model_serving 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 pipeline { agent { docker { image 'python:3.9' } } stages { stage ( 'build model serving' ) { when { changeset \"model_serving/**\" } steps { echo 'Building model serving..' sh 'cd model_serving && make build_image' } } stage ( 'test model serving' ) { when { changeset \"model_serving/**\" } steps { echo 'Testing model serving..' # (1) } } stage ( 'deploy model serving' ) { parallel { # (2) stage ( 'batch serving pipeline' ) { when { changeset \"model_serving/**\" } steps { sh 'cd model_serving && make deploy_dags' } } stage ( 'online serving API' ) { when { changeset \"model_serving/**\" } steps { sh 'cd model_serving && make compose_up' } } } } } } Test code, ph\u1ea7n n\u00e0y b\u1ea1n s\u1ebd b\u1ed5 sung unit test , integration test , .v.v. d\u1ef1a v\u00e0o b\u00e0i h\u1ecdc v\u1ec1 ki\u1ec3m th\u1eed h\u1ec7 th\u1ed1ng \u0110\u1ecbnh ngh\u0129a 2 b\u01b0\u1edbc ch\u1ea1y song song l\u00e0 serving pipeline v\u00e0 online serving API . Sau khi b\u1ea1n thay \u0111\u1ed5i code \u1edf folder model_serving/ v\u00e0 push code l\u00ean Github, b\u1ea1n s\u1ebd th\u1ea5y Console Output t\u01b0\u01a1ng \u1ee9ng v\u1edbi commit n\u00e0y hi\u1ec3n th\u1ecb t\u01b0\u01a1ng t\u1ef1 nh\u01b0 sau: T\u1ed5ng k\u1ebft \u1ede b\u00e0i h\u1ecdc n\u00e0y, ch\u00fang ta \u0111\u00e3 c\u1ea3i ti\u1ebfn Jenkinsfile c\u1ee7a data pipeline \u0111\u1ec3 t\u1ef1 \u0111\u1ed9ng h\u00f3a model serving b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng t\u1eeb kh\u00f3a parallel . B\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc th\u00eam Jenkins document t\u1ea1i \u0111\u00e2y v\u00e0 ti\u1ebfp t\u1ee5c tu\u1ef3 bi\u1ebfn CI/CD pipeline, v\u00ed d\u1ee5: bi\u1ebfn b\u01b0\u1edbc deploy trong CI/CD sang manual, thay v\u00ec t\u1ef1 \u0111\u1ed9ng ch\u1ea1y c\u1ea3 pipeline m\u1ed9t l\u00fac.","title":"CI/CD cho model serving"},{"location":"mlops-crash-course/ci-cd/model-serving.html#gioi-thieu","text":"\u1ede b\u00e0i h\u1ecdc tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 c\u00f9ng nhau x\u00e2y d\u1ef1ng Jenkins pipeline \u0111\u1ec3 t\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh release data pipeline . Trong b\u00e0i h\u1ecdc n\u00e0y ch\u00fang ta s\u1ebd s\u1eeda Jenkinsfile \u0111\u1ec3 ph\u1ee5c v\u1ee5 cho model serving .","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/ci-cd/model-serving.html#jenkins-pipeline","text":"CI/CD pipeline cho model serving s\u1ebd \u0111\u01b0\u1ee3c thay \u0111\u1ed5i th\u00e0nh nh\u01b0 sau: graph LR n1[1. Build model serving] --> n2[2. Test model serving] n2[2. Test model serving] --> n3[3.1. Deploy offline batch serving pipeline] n2[2. Test model serving] --> n4[3.2. Deploy online serving API] Tip \u1ede \u0111\u00e2y ch\u00fang ta s\u1ebd d\u00f9ng 1 image cho c\u1ea3 online serving API v\u00e0 offline batch serving pipeline \u0111\u1ec3 h\u1ea1n ch\u1ebf s\u1ef1 kh\u00e1c nhau gi\u1eefa code v\u00e0 m\u00f4i tr\u01b0\u1eddng ch\u1ea1y. Jenkinsfile_model_serving 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 pipeline { agent { docker { image 'python:3.9' } } stages { stage ( 'build model serving' ) { when { changeset \"model_serving/**\" } steps { echo 'Building model serving..' sh 'cd model_serving && make build_image' } } stage ( 'test model serving' ) { when { changeset \"model_serving/**\" } steps { echo 'Testing model serving..' # (1) } } stage ( 'deploy model serving' ) { parallel { # (2) stage ( 'batch serving pipeline' ) { when { changeset \"model_serving/**\" } steps { sh 'cd model_serving && make deploy_dags' } } stage ( 'online serving API' ) { when { changeset \"model_serving/**\" } steps { sh 'cd model_serving && make compose_up' } } } } } } Test code, ph\u1ea7n n\u00e0y b\u1ea1n s\u1ebd b\u1ed5 sung unit test , integration test , .v.v. d\u1ef1a v\u00e0o b\u00e0i h\u1ecdc v\u1ec1 ki\u1ec3m th\u1eed h\u1ec7 th\u1ed1ng \u0110\u1ecbnh ngh\u0129a 2 b\u01b0\u1edbc ch\u1ea1y song song l\u00e0 serving pipeline v\u00e0 online serving API . Sau khi b\u1ea1n thay \u0111\u1ed5i code \u1edf folder model_serving/ v\u00e0 push code l\u00ean Github, b\u1ea1n s\u1ebd th\u1ea5y Console Output t\u01b0\u01a1ng \u1ee9ng v\u1edbi commit n\u00e0y hi\u1ec3n th\u1ecb t\u01b0\u01a1ng t\u1ef1 nh\u01b0 sau:","title":"Jenkins pipeline"},{"location":"mlops-crash-course/ci-cd/model-serving.html#tong-ket","text":"\u1ede b\u00e0i h\u1ecdc n\u00e0y, ch\u00fang ta \u0111\u00e3 c\u1ea3i ti\u1ebfn Jenkinsfile c\u1ee7a data pipeline \u0111\u1ec3 t\u1ef1 \u0111\u1ed9ng h\u00f3a model serving b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng t\u1eeb kh\u00f3a parallel . B\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc th\u00eam Jenkins document t\u1ea1i \u0111\u00e2y v\u00e0 ti\u1ebfp t\u1ee5c tu\u1ef3 bi\u1ebfn CI/CD pipeline, v\u00ed d\u1ee5: bi\u1ebfn b\u01b0\u1edbc deploy trong CI/CD sang manual, thay v\u00ec t\u1ef1 \u0111\u1ed9ng ch\u1ea1y c\u1ea3 pipeline m\u1ed9t l\u00fac.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/data-pipeline/airflow-co-ban.html","text":"Photo from airflow-tutorial Gi\u1edbi thi\u1ec7u \u1ede b\u00e0i tr\u01b0\u1edbc, ch\u00fang ta \u0111i v\u00e0o t\u00ecm hi\u1ec3u t\u1ea1i sao ph\u1ea3i x\u00e2y d\u1ef1ng pipeline, v\u00e0 \u1edf b\u00e0i h\u1ecdc n\u00e0y s\u1ebd gi\u00fap b\u1ea1n h\u00ecnh dung r\u00f5 h\u01a1n v\u1ec1 c\u00e1ch x\u00e2y d\u1ef1ng pipeline th\u00f4ng qua Airflow. C\u00e1c kh\u00e1i ni\u1ec7m c\u01a1 b\u1ea3n Airflow l\u00e0 m\u1ed9t n\u1ec1n t\u1ea3ng cung c\u1ea5p SDK v\u00e0 UI \u0111\u1ec3 h\u1ed7 tr\u1ee3 x\u00e2y d\u1ef1ng, \u0111\u1eb7t l\u1ecbch th\u1ef1c thi v\u00e0 theo d\u00f5i c\u00e1c pipeline. M\u1ed9t s\u1ed1 kh\u00e1i ni\u1ec7m c\u01a1 b\u1ea3n trong Airflow: task: m\u1ed9t th\u00e0nh ph\u1ea7n (ho\u1eb7c m\u1ed9t b\u01b0\u1edbc) trong pipeline DAG (Directed Acyclic Graph): \u0111\u1ecbnh ngh\u0129a th\u1ee9 t\u1ef1 th\u1ef1c thi, l\u1ecbch ch\u1ea1y v\u00e0 s\u1ed1 l\u01b0\u1ee3ng l\u1ea7n retry.v.v. cho c\u00e1c task Task \u0110\u1ec3 t\u1ea1o ra task , ch\u00fang ta s\u1ebd d\u00f9ng c\u00e1c operators cung c\u1ea5p b\u1edfi Airflow SDK. M\u1ed9t s\u1ed1 lo\u1ea1i operator ph\u1ed5 bi\u1ebfn bao g\u1ed3m: BashOperator: th\u1ef1c thi c\u00e1c bash command PythonOperator: th\u1ef1c thi c\u00e1c Python script EmailOperator: g\u1eedi email DockerOperator: th\u1ef1c hi\u1ec7n c\u00e1c command b\u00ean trong docker container MySQLOperator: th\u1ef1c thi c\u00e1c MySQL query, ngo\u00e0i ra c\u00f2n r\u1ea5t nhi\u1ec1u operator kh\u00e1c \u0111\u01b0\u1ee3c ph\u00e1t tri\u1ec3n b\u1edfi c\u1ed9ng \u0111\u1ed3ng, b\u1ea1n xem th\u00eam t\u1ea1i \u0111\u00e2y \u1ede series n\u00e0y ch\u00fang ta s\u1ebd ch\u1ee7 y\u1ebfu s\u1eed d\u1ee5ng 2 lo\u1ea1i operators l\u00e0 DockerOperator v\u00e0 BashOperator . Tip Vi\u1ec7c s\u1eed d\u1ee5ng DockerOperator thay cho PythonOperator \u0111\u1ea3m b\u1ea3o m\u00f4i tr\u01b0\u1eddng ch\u1ea1y code \u0111\u01b0\u1ee3c \u0111\u00f3ng g\u00f3i v\u00e0 c\u00f3 th\u1ec3 ch\u1ea1y code n\u00e0y \u1edf tr\u00ean b\u1ea5t k\u1ef3 m\u00e1y n\u00e0o m\u00e0 kh\u00f4ng b\u1ecb c\u00e1c v\u1ea5n \u0111\u1ec1 v\u1ec1 c\u00e0i \u0111\u1eb7t ho\u1eb7c xung \u0111\u1ed9t th\u01b0 vi\u1ec7n. DAG Sau khi \u0111\u00e3 code xong c\u00e1c task , ch\u00fang ta s\u1ebd \u0111\u01b0a c\u00e1c task n\u00e0y v\u00e0o trong DAG nh\u01b0 v\u00ed d\u1ee5 sau: 1 2 3 4 5 6 7 8 with DAG ( \"my_dag_name\" , start_date = pendulum . datetime ( 2021 , 1 , 1 , tz = \"UTC\" ), # (1) schedule = \"@daily\" , catchup = False ) as dag : ingest_task = PythonOperator ( ... ) # (2) clean_task = PythonOperator ( ... ) validate_task = PythonOperator ( ... ) ingest_task >> clean_task >> [ explore_task , validate_task ] # (3) \u0110\u1ecbnh ngh\u0129a th\u1eddi gian b\u1eaft \u0111\u1ea7u ch\u1ea1y pipeline t\u1eeb 1/1/2021, l\u1ecbch ch\u1ea1y l\u00e0 daily v\u00e0 kh\u00f4ng catchup, t\u1ee9c l\u00e0 kh\u00f4ng ch\u1ea1y pipeline tr\u01b0\u1edbc start_date \u0110\u1ecbnh ngh\u0129a task b\u1eb1ng PythonOperator . B\u1ea1n t\u1ef1 truy\u1ec1n c\u00e1c config v\u00e0o (...) Th\u1ee9 t\u1ef1 ch\u1ea1y: ingest_task t\u1edbi clean_task , cu\u1ed1i c\u00f9ng l\u00e0 2 task song song: explore_task v\u00e0 _validate_task T\u1ed5ng k\u1ebft \u1ede b\u00e0i h\u1ecdc h\u00f4m nay, ch\u00fang ta \u0111\u00e3 t\u00ecm hi\u1ec3u v\u1ec1 m\u1ed9t s\u1ed1 kh\u00e1i ni\u1ec7m c\u01a1 b\u1ea3n trong Airflow v\u00e0 l\u00e0m quen v\u1edbi Airflow Python SDK \u0111\u1ec3 x\u00e2y d\u1ef1ng task v\u00e0 DAG . B\u00e0i h\u1ecdc ti\u1ebfp theo, ch\u00fang ta s\u1ebd c\u1ee5 th\u1ec3 h\u00f3a vi\u1ec7c x\u00e2y d\u1ef1ng pipeline b\u1eb1ng c\u00e1ch \u1ee9ng d\u1ee5ng v\u00e0o m\u1ed9t b\u00e0i to\u00e1n c\u1ee5 th\u1ec3. T\u00e0i li\u1ec7u tham kh\u1ea3o https://airflow.apache.org/docs/apache-airflow/stable/concepts/operators.html","title":"Airflow c\u01a1 b\u1ea3n"},{"location":"mlops-crash-course/data-pipeline/airflow-co-ban.html#gioi-thieu","text":"\u1ede b\u00e0i tr\u01b0\u1edbc, ch\u00fang ta \u0111i v\u00e0o t\u00ecm hi\u1ec3u t\u1ea1i sao ph\u1ea3i x\u00e2y d\u1ef1ng pipeline, v\u00e0 \u1edf b\u00e0i h\u1ecdc n\u00e0y s\u1ebd gi\u00fap b\u1ea1n h\u00ecnh dung r\u00f5 h\u01a1n v\u1ec1 c\u00e1ch x\u00e2y d\u1ef1ng pipeline th\u00f4ng qua Airflow.","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/data-pipeline/airflow-co-ban.html#cac-khai-niem-co-ban","text":"Airflow l\u00e0 m\u1ed9t n\u1ec1n t\u1ea3ng cung c\u1ea5p SDK v\u00e0 UI \u0111\u1ec3 h\u1ed7 tr\u1ee3 x\u00e2y d\u1ef1ng, \u0111\u1eb7t l\u1ecbch th\u1ef1c thi v\u00e0 theo d\u00f5i c\u00e1c pipeline. M\u1ed9t s\u1ed1 kh\u00e1i ni\u1ec7m c\u01a1 b\u1ea3n trong Airflow: task: m\u1ed9t th\u00e0nh ph\u1ea7n (ho\u1eb7c m\u1ed9t b\u01b0\u1edbc) trong pipeline DAG (Directed Acyclic Graph): \u0111\u1ecbnh ngh\u0129a th\u1ee9 t\u1ef1 th\u1ef1c thi, l\u1ecbch ch\u1ea1y v\u00e0 s\u1ed1 l\u01b0\u1ee3ng l\u1ea7n retry.v.v. cho c\u00e1c task","title":"C\u00e1c kh\u00e1i ni\u1ec7m c\u01a1 b\u1ea3n"},{"location":"mlops-crash-course/data-pipeline/airflow-co-ban.html#task","text":"\u0110\u1ec3 t\u1ea1o ra task , ch\u00fang ta s\u1ebd d\u00f9ng c\u00e1c operators cung c\u1ea5p b\u1edfi Airflow SDK. M\u1ed9t s\u1ed1 lo\u1ea1i operator ph\u1ed5 bi\u1ebfn bao g\u1ed3m: BashOperator: th\u1ef1c thi c\u00e1c bash command PythonOperator: th\u1ef1c thi c\u00e1c Python script EmailOperator: g\u1eedi email DockerOperator: th\u1ef1c hi\u1ec7n c\u00e1c command b\u00ean trong docker container MySQLOperator: th\u1ef1c thi c\u00e1c MySQL query, ngo\u00e0i ra c\u00f2n r\u1ea5t nhi\u1ec1u operator kh\u00e1c \u0111\u01b0\u1ee3c ph\u00e1t tri\u1ec3n b\u1edfi c\u1ed9ng \u0111\u1ed3ng, b\u1ea1n xem th\u00eam t\u1ea1i \u0111\u00e2y \u1ede series n\u00e0y ch\u00fang ta s\u1ebd ch\u1ee7 y\u1ebfu s\u1eed d\u1ee5ng 2 lo\u1ea1i operators l\u00e0 DockerOperator v\u00e0 BashOperator . Tip Vi\u1ec7c s\u1eed d\u1ee5ng DockerOperator thay cho PythonOperator \u0111\u1ea3m b\u1ea3o m\u00f4i tr\u01b0\u1eddng ch\u1ea1y code \u0111\u01b0\u1ee3c \u0111\u00f3ng g\u00f3i v\u00e0 c\u00f3 th\u1ec3 ch\u1ea1y code n\u00e0y \u1edf tr\u00ean b\u1ea5t k\u1ef3 m\u00e1y n\u00e0o m\u00e0 kh\u00f4ng b\u1ecb c\u00e1c v\u1ea5n \u0111\u1ec1 v\u1ec1 c\u00e0i \u0111\u1eb7t ho\u1eb7c xung \u0111\u1ed9t th\u01b0 vi\u1ec7n.","title":"Task"},{"location":"mlops-crash-course/data-pipeline/airflow-co-ban.html#dag","text":"Sau khi \u0111\u00e3 code xong c\u00e1c task , ch\u00fang ta s\u1ebd \u0111\u01b0a c\u00e1c task n\u00e0y v\u00e0o trong DAG nh\u01b0 v\u00ed d\u1ee5 sau: 1 2 3 4 5 6 7 8 with DAG ( \"my_dag_name\" , start_date = pendulum . datetime ( 2021 , 1 , 1 , tz = \"UTC\" ), # (1) schedule = \"@daily\" , catchup = False ) as dag : ingest_task = PythonOperator ( ... ) # (2) clean_task = PythonOperator ( ... ) validate_task = PythonOperator ( ... ) ingest_task >> clean_task >> [ explore_task , validate_task ] # (3) \u0110\u1ecbnh ngh\u0129a th\u1eddi gian b\u1eaft \u0111\u1ea7u ch\u1ea1y pipeline t\u1eeb 1/1/2021, l\u1ecbch ch\u1ea1y l\u00e0 daily v\u00e0 kh\u00f4ng catchup, t\u1ee9c l\u00e0 kh\u00f4ng ch\u1ea1y pipeline tr\u01b0\u1edbc start_date \u0110\u1ecbnh ngh\u0129a task b\u1eb1ng PythonOperator . B\u1ea1n t\u1ef1 truy\u1ec1n c\u00e1c config v\u00e0o (...) Th\u1ee9 t\u1ef1 ch\u1ea1y: ingest_task t\u1edbi clean_task , cu\u1ed1i c\u00f9ng l\u00e0 2 task song song: explore_task v\u00e0 _validate_task","title":"DAG"},{"location":"mlops-crash-course/data-pipeline/airflow-co-ban.html#tong-ket","text":"\u1ede b\u00e0i h\u1ecdc h\u00f4m nay, ch\u00fang ta \u0111\u00e3 t\u00ecm hi\u1ec3u v\u1ec1 m\u1ed9t s\u1ed1 kh\u00e1i ni\u1ec7m c\u01a1 b\u1ea3n trong Airflow v\u00e0 l\u00e0m quen v\u1edbi Airflow Python SDK \u0111\u1ec3 x\u00e2y d\u1ef1ng task v\u00e0 DAG . B\u00e0i h\u1ecdc ti\u1ebfp theo, ch\u00fang ta s\u1ebd c\u1ee5 th\u1ec3 h\u00f3a vi\u1ec7c x\u00e2y d\u1ef1ng pipeline b\u1eb1ng c\u00e1ch \u1ee9ng d\u1ee5ng v\u00e0o m\u1ed9t b\u00e0i to\u00e1n c\u1ee5 th\u1ec3.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/data-pipeline/airflow-co-ban.html#tai-lieu-tham-khao","text":"https://airflow.apache.org/docs/apache-airflow/stable/concepts/operators.html","title":"T\u00e0i li\u1ec7u tham kh\u1ea3o"},{"location":"mlops-crash-course/data-pipeline/feature-store.html","text":"Gi\u1edbi thi\u1ec7u C\u00e2u chuy\u1ec7n b\u1eaft \u0111\u1ea7u \u1edf m\u1ed9t c\u00f4ng ty X n\u1ecd c\u00f3 2 \u00f4ng data scientist l\u00e0m 2 b\u00e0i to\u00e1n kh\u00e1c nhau l\u00e0 credit score v\u00e0 churn prediction. V\u00e0o m\u1ed9t ng\u00e0y \u0111\u1eb9p tr\u1eddi \u0111\u1ea7y n\u1eafng v\u00e0 gi\u00f3, 2 \u00f4ng ng\u1ed3i tr\u00e0 \u0111\u00e1 v\u00e0 chia s\u1ebb v\u1edbi nhau v\u1ec1 b\u00e0i to\u00e1n m\u00ecnh \u0111ang l\u00e0m th\u00ec ch\u1ee3t nh\u1eadn ra c\u1ea3 2 \u0111\u1ec1u \u0111ang t\u1ea1o m\u1ed9t t\u1eadp h\u1ee3p c\u00e1c t\u00ednh n\u0103ng v\u1ec1 demographics (nh\u01b0 \u0111\u1ed9 tu\u1ed5i, gi\u1edbi t\u00ednh, ng\u00f4n ng\u1eef, .v.v.) m\u1ed9t c\u00e1ch \u0111\u1ed9c l\u1eadp, m\u00e0 \u0111\u00e1ng l\u1ebd ra l\u00e0 c\u00f3 th\u1ec3 chia s\u1ebb cho nhau. 2 \u00f4ng ch\u1ee3t n\u00e0y ra \u00fd t\u01b0\u1edfng v\u1ec1 m\u1ed9t n\u01a1i l\u01b0u tr\u1eef feature chung \u0111\u1ec3 c\u00f3 th\u1ec3 d\u1ec5 d\u00e0ng s\u1eed d\u1ee5ng cho nhi\u1ec1u v\u1ea5n \u0111\u1ec1 kh\u00e1c nhau, th\u1ebf l\u00e0 phi\u00ean b\u1ea3n \u0111\u1ea7u ti\u00ean c\u1ee7a feature store ra \u0111\u1eddi. Li\u1ec7u r\u1eb1ng feature store c\u00f2n c\u00f3 c\u00f4ng d\u1ee5ng g\u00ec kh\u00f4ng v\u00e0 x\u00e2y d\u1ef1ng feature store nh\u01b0 th\u1ebf n\u00e0o, m\u1eddi b\u1ea1n \u0111\u1ebfn v\u1edbi n\u1ed9i dung b\u00e0i h\u1ecdc h\u00f4m nay. M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n C\u00e1c b\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 c\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n: C\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng Python 3.9 m\u1edbi v\u1edbi c\u00e1c th\u01b0 vi\u1ec7n c\u1ea7n thi\u1ebft trong file data_pipeline/dev_requirements.txt Feast s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong b\u00e0i n\u00e0y. B\u1ea1n v\u00e0o repo mlops-crash-course-platform/ v\u00e0 ch\u1ea1y: bash run.sh feast up Note Trong qu\u00e1 tr\u00ecnh ch\u1ea1y code cho t\u1ea5t c\u1ea3 c\u00e1c ph\u1ea7n d\u01b0\u1edbi \u0111\u00e2y, ch\u00fang ta gi\u1ea3 s\u1eed r\u1eb1ng folder g\u1ed1c n\u01a1i ch\u00fang ta l\u00e0m vi\u1ec7c l\u00e0 folder data_pipeline . Feature store Feature store l\u00e0 m\u1ed9t h\u1ec7 th\u1ed1ng gi\u00fap l\u01b0u tr\u1eef, t\u01b0\u01a1ng t\u00e1c v\u00e0 qu\u1ea3n l\u00fd feature. C\u00f4ng c\u1ee5 n\u00e0y sinh ra \u0111\u1ec3 gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1 v\u1ec1: Feature reuse: l\u01b0u tr\u1eef c\u00e1c feature \u0111\u00e3 \u0111\u01b0\u1ee3c t\u1ea1o ra \u0111\u1ec3 t\u00e1i s\u1eed d\u1ee5ng khi c\u1ea7n thi\u1ebft Feature sharing: chia s\u1ebb feature gi\u1eefa c\u00e1c th\u00e0nh vi\u00ean trong team ho\u1eb7c v\u1edbi nhi\u1ec1u team kh\u00e1c nhau Feature consistency: m\u1ed9t ngu\u1ed3n d\u1eef li\u1ec7u cho c\u1ea3 m\u1ee5c \u0111\u00edch training v\u00e0 serving Feature monitoring: theo d\u00f5i thay \u0111\u1ed5i (drift) v\u00e0 ch\u1ea5t l\u01b0\u1ee3ng d\u1eef li\u1ec7u tr\u01b0\u1edbc khi \u0111\u01b0a qua model s\u1eed d\u1ee5ng Data leakage: \u0111\u1ea3m b\u1ea3o kh\u00f4ng x\u1ea3y ra hi\u1ec7n t\u01b0\u1ee3ng r\u00f2 r\u1ec9 (leak) d\u1eef li\u1ec7u trong t\u1eadp training. V\u00ed d\u1ee5: d\u1eef li\u1ec7u training v\u00e0o th\u1eddi \u0111i\u1ec3m b\u1ea5t k\u1ef3 kh\u00f4ng \u0111\u01b0\u1ee3c bao g\u1ed3m d\u1eef li\u1ec7u m\u00e0 c\u00f3 timestamp sau \u0111\u00f3. C\u00f3 r\u1ea5t nhi\u1ec1u feature store \u1edf th\u1eddi \u0111i\u1ec3m hi\u1ec7n t\u1ea1i, c\u00f3 th\u1ec3 k\u1ec3 t\u1edbi m\u1ed9t s\u1ed1 nh\u01b0: Open-source: Feast, Hopsworks Tr\u1ea3 ph\u00ed: Tecton (Feast phi\u00ean b\u1ea3n enterprise), Hopworks (phi\u00ean b\u1ea3n enterprise), Amazon SageMaker Feature Store, Vertex AI Feature Store Feast \u1ede series n\u00e0y ch\u00fang ta s\u1ebd t\u00ecm hi\u1ec3u v\u1ec1 feature store th\u00f4ng qua Feast . Feast c\u00f3 2 kh\u00e1i ni\u1ec7m stores l\u00e0: Offline store: l\u01b0u tr\u1eef d\u1eef li\u1ec7u l\u1ecbch s\u1eed \u0111\u1ec3 ph\u1ee5c v\u1ee5 m\u1ee5c \u0111\u00edch training ho\u1eb7c offline batch serving. Hi\u1ec7n t\u1ea1i Feast h\u1ed7 tr\u1ee3 ch\u1ecdn m\u1ed9t trong lo\u1ea1i data source sau \u0111\u1ec3 l\u00e0m offline store: File, Snowflake, Bigquery v\u00e0 Redshift. Ngo\u00e0i ra c\u00f2n c\u00e1c lo\u1ea1i kh\u00e1c \u0111\u01b0\u1ee3c contribute b\u1edfi c\u1ed9ng \u0111\u1ed3ng v\u00ed d\u1ee5 nh\u01b0 PostgreSQL, Spark, Trino, .v.v.., tuy nhi\u00ean n\u00ean h\u1ea1n ch\u1ebf d\u00f9ng v\u00ec ch\u01b0a \u0111\u1ea1t full test coverage. Online store: l\u01b0u tr\u1eef d\u1eef li\u1ec7u m\u1edbi nh\u1ea5t cho m\u1ed7i ID. Store n\u00e0y c\u1ea7n c\u00f3 kh\u1ea3 n\u0103ng serve v\u1edbi low latency \u0111\u1ec3 s\u1eed d\u1ee5ng cho online serving. C\u00e1c lo\u1ea1i data source m\u00e0 Feast h\u1ed7 tr\u1ee3 \u0111\u1ec3 l\u00e0m online store bao g\u1ed3m: SQLite, Snowflake, Redis, MongoDB v\u00e0 Datastore. C\u00e1c lo\u1ea1i kh\u00e1c contribute b\u1edfi c\u1ed9ng \u0111\u1ed3ng c\u00f3 th\u1ec3 k\u1ec3 \u0111\u1ebfn nh\u01b0 PostgreSQL v\u00e0 Cassandra + Astra DB. T\u1ea5t c\u1ea3 c\u00e1c config cho Feast bao g\u1ed3m data source cho m\u1ed7i lo\u1ea1i store, \u0111\u1ecbnh ngh\u0129a c\u00e1c feature v\u00e0 entity (ID) n\u1eb1m trong folder sau: data_pipeline/feature_repo \u251c\u2500\u2500 data_sources.py: \u0111\u1ecbnh ngh\u0129a c\u00e1c data source \u251c\u2500\u2500 entities.py: \u0111\u1ecbnh ngh\u0129a entity \u251c\u2500\u2500 features.py: \u0111\u1ecbnh ngh\u0129a c\u00e1c b\u1ea3ng feature v\u00e0 c\u00e1c feature c\u00f9ng ki\u1ec3u d\u1eef li\u1ec7u trong t\u1eebng b\u1ea3ng \u2514\u2500\u2500 feature_store.yaml: \u0111\u1ecbnh ngh\u0129a lo\u1ea1i data source v\u00e0 \u0111\u01b0\u1eddng d\u1eabn t\u1edbi feature definition object store C\u00e1c b\u1ea3ng feature (c\u00f2n g\u1ecdi l\u00e0 feature view) ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng bao g\u1ed3m: driver_stats_view: feature view v\u1edbi data source d\u1ea1ng file driver_stats_stream: stream feature view v\u1edbi data source l\u00e0 Kafka v\u00e0 x\u1eed l\u00fd d\u1eef li\u1ec7u b\u1eb1ng Spark. Do b\u1ea3ng n\u00e0y l\u1ea5y d\u1eef li\u1ec7u t\u1eeb stream source n\u00ean feature s\u1ebd m\u1edbi h\u01a1n so v\u1edbi driver_stats_view Code \u0111\u1ecbnh ngh\u0129a c\u00e1c data source nh\u01b0 sau: data_pipeline/feature_repo/data_sources.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 driver_stats_parquet_file = \"../data_sources/driver_stats.parquet\" # local Parquet file as data source driver_stats_batch_source = FileSource ( name = \"driver_stats\" , file_format = ParquetFormat (), path = driver_stats_parquet_file , timestamp_field = \"datetime\" , created_timestamp_column = \"created\" , ) # Kafka for stream source driver_stats_stream_source = KafkaSource ( name = \"driver_stats_stream\" , kafka_bootstrap_servers = \"localhost:29092\" , topic = \"drivers\" , timestamp_field = \"datetime\" , batch_source = driver_stats_batch_source , message_format = JsonFormat ( schema_json = \"driver_id integer, acc_rate double, conv_rate double, datetime timestamp, created timestamp\" ), watermark_delay_threshold = timedelta ( minutes = 5 ), # (1) description = \"The Kafka stream containing the driver stats\" , ) Kho\u1ea3ng th\u1eddi gian \u0111\u1ebfn mu\u1ed9n cho ph\u00e9p c\u1ee7a feature tr\u01b0\u1edbc khi n\u00f3 b\u1ecb lo\u1ea1i b\u1ecf Code \u0111\u1ecbnh ngh\u0129a c\u00e1c feature view nh\u01b0 d\u01b0\u1edbi \u0111\u00e2y: data_pipeline/feature_repo/features.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 driver_stats_view = FeatureView ( name = \"driver_stats\" , description = \"driver features\" , entities = [ driver ], # (1) ttl = timedelta ( days = 36500 ), # (2) schema = [ Field ( name = \"conv_rate\" , dtype = Float32 ), # (3) Field ( name = \"acc_rate\" , dtype = Float32 ), Field ( name = \"avg_daily_trips\" , dtype = Int32 ), ], online = True , # (4) source = driver_stats_batch_source , # (5) tags = {}, owner = \"batch_source_owner@gmail.com\" , ) @stream_feature_view ( entities = [ driver ], ttl = timedelta ( days = 36500 ), mode = \"spark\" , # (6) schema = [ Field ( name = \"conv_rate\" , dtype = Float32 ), Field ( name = \"acc_rate\" , dtype = Float32 ), ], timestamp_field = \"datetime\" , online = True , source = driver_stats_stream_source , tags = {}, owner = \"stream_source_owner@gmail.com\" , ) def driver_stats_stream ( df : DataFrame ): from pyspark.sql.functions import col return ( df . withColumn ( \"conv_percentage\" , col ( \"conv_rate\" ) * 100.0 ) . withColumn ( \"acc_percentage\" , col ( \"acc_rate\" ) * 100.0 ) . drop ( \"conv_rate\" , \"acc_rate\" ) . withColumnRenamed ( \"conv_percentage\" , \"conv_rate\" ) . withColumnRenamed ( \"acc_percentage\" , \"acc_rate\" ) ) \u0110\u1ecbnh ngh\u0129a entity cho b\u1ea3ng feature Time-to-live: Th\u1eddi gian s\u1eed d\u1ee5ng c\u1ee7a feature tr\u01b0\u1edbc khi b\u1ecb stale \u0110\u1ecbnh ngh\u0129a feature v\u00e0 ki\u1ec3u d\u1eef li\u1ec7u Cho ph\u00e9p online serving \u0110\u1ecbnh ngh\u0129a data source cho b\u1ea3ng feature S\u1eed d\u1ee5ng Spark \u0111\u1ec3 x\u1eed l\u00fd d\u1eef li\u1ec7u stream Sau khi config feature store b\u1eb1ng c\u00e1ch thay \u0111\u1ed5i c\u00e1c file trong repo feature_repo/ , ch\u00fang ta c\u1ea7n \u0111\u1ea3m b\u1ea3o c\u00e1c data source \u0111\u00e3 s\u1eb5n s\u00e0ng, bao g\u1ed3m: FileSource: \u0111\u1ea3m b\u1ea3o \u0111\u01b0\u1eddng d\u1eabn t\u1ed3n t\u1ea1i, file kh\u00f4ng b\u1ecb l\u1ed7i KafkaSource: \u0111\u1ea3m b\u1ea3o bootstrap servers \u0111ang ch\u1ea1y. \u0110\u1ec3 start bootstrap server n\u00e0y, c\u00e1c b\u1ea1n ch\u1ea1y: cd ../stream_emitting bash deploy.sh start cd ../data_pipeline N\u1ebfu c\u00e1c b\u1ea1n s\u1ebd th\u1ea5y console nh\u01b0 sau, t\u1ee9c l\u00e0 Kafka \u0111ang stream d\u1eef li\u1ec7u driver v\u1ec1 Tip \u0110\u1ec3 stop server, c\u00e1c b\u1ea1n ch\u1ea1y: bash deploy.sh stop cd ../stream_emitting bash deploy.sh stop cd ../data_pipeline \u0110\u1ec3 teardown server (stop v\u00e0 remove t\u1ea5t c\u1ea3 docker volume li\u00ean quan), c\u00e1c b\u1ea1n ch\u1ea1y: cd ../stream_emitting bash deploy.sh teardown cd ../data_pipeline V\u00e0 cu\u1ed1i c\u00f9ng ch\u00fang ta s\u1ebd c\u1eadp nh\u1eadt Offline Feature store b\u1eb1ng c\u00e1ch ch\u1ea1y: cd feature_repo feast apply Info feast apply ch\u1ec9 c\u1eadp nh\u1eadt \u0111\u1ecbnh ngh\u0129a c\u1ee7a c\u00e1c features. feast apply ch\u1ec9 c\u1ea7n ch\u1ea1y khi b\u1ea1n c\u1ea7n th\u00eam c\u1ed9t, s\u1eeda ki\u1ec3u d\u1eef li\u1ec7u c\u1ee7a c\u1ed9t, v.v... T\u1ed5ng k\u1ebft Ch\u00fang ta v\u1eeba l\u00e0m quen v\u1edbi m\u1ed9t s\u1ed1 kh\u00e1i ni\u1ec7m v\u1ec1 feature store th\u00f4ng qua Feast. \u1ede b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd: L\u1ea5y feature t\u1eeb Feast aterialize feature t\u1eeb offline qua online store \u0110\u1ea9y d\u1eef li\u1ec7u stream v\u1ec1 online store v\u00e0 offline store X\u00e2y d\u1ef1ng c\u00e1c Airflow pipeline \u0111\u1ec3 t\u1ef1 \u0111\u1ed9ng h\u00f3a c\u00e1c c\u00f4ng vi\u1ec7c tr\u00ean. T\u00e0i li\u1ec7u tham kh\u1ea3o https://feast.dev/","title":"Feature store"},{"location":"mlops-crash-course/data-pipeline/feature-store.html#gioi-thieu","text":"C\u00e2u chuy\u1ec7n b\u1eaft \u0111\u1ea7u \u1edf m\u1ed9t c\u00f4ng ty X n\u1ecd c\u00f3 2 \u00f4ng data scientist l\u00e0m 2 b\u00e0i to\u00e1n kh\u00e1c nhau l\u00e0 credit score v\u00e0 churn prediction. V\u00e0o m\u1ed9t ng\u00e0y \u0111\u1eb9p tr\u1eddi \u0111\u1ea7y n\u1eafng v\u00e0 gi\u00f3, 2 \u00f4ng ng\u1ed3i tr\u00e0 \u0111\u00e1 v\u00e0 chia s\u1ebb v\u1edbi nhau v\u1ec1 b\u00e0i to\u00e1n m\u00ecnh \u0111ang l\u00e0m th\u00ec ch\u1ee3t nh\u1eadn ra c\u1ea3 2 \u0111\u1ec1u \u0111ang t\u1ea1o m\u1ed9t t\u1eadp h\u1ee3p c\u00e1c t\u00ednh n\u0103ng v\u1ec1 demographics (nh\u01b0 \u0111\u1ed9 tu\u1ed5i, gi\u1edbi t\u00ednh, ng\u00f4n ng\u1eef, .v.v.) m\u1ed9t c\u00e1ch \u0111\u1ed9c l\u1eadp, m\u00e0 \u0111\u00e1ng l\u1ebd ra l\u00e0 c\u00f3 th\u1ec3 chia s\u1ebb cho nhau. 2 \u00f4ng ch\u1ee3t n\u00e0y ra \u00fd t\u01b0\u1edfng v\u1ec1 m\u1ed9t n\u01a1i l\u01b0u tr\u1eef feature chung \u0111\u1ec3 c\u00f3 th\u1ec3 d\u1ec5 d\u00e0ng s\u1eed d\u1ee5ng cho nhi\u1ec1u v\u1ea5n \u0111\u1ec1 kh\u00e1c nhau, th\u1ebf l\u00e0 phi\u00ean b\u1ea3n \u0111\u1ea7u ti\u00ean c\u1ee7a feature store ra \u0111\u1eddi. Li\u1ec7u r\u1eb1ng feature store c\u00f2n c\u00f3 c\u00f4ng d\u1ee5ng g\u00ec kh\u00f4ng v\u00e0 x\u00e2y d\u1ef1ng feature store nh\u01b0 th\u1ebf n\u00e0o, m\u1eddi b\u1ea1n \u0111\u1ebfn v\u1edbi n\u1ed9i dung b\u00e0i h\u1ecdc h\u00f4m nay.","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/data-pipeline/feature-store.html#moi-truong-phat-trien","text":"C\u00e1c b\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 c\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n: C\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng Python 3.9 m\u1edbi v\u1edbi c\u00e1c th\u01b0 vi\u1ec7n c\u1ea7n thi\u1ebft trong file data_pipeline/dev_requirements.txt Feast s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong b\u00e0i n\u00e0y. B\u1ea1n v\u00e0o repo mlops-crash-course-platform/ v\u00e0 ch\u1ea1y: bash run.sh feast up Note Trong qu\u00e1 tr\u00ecnh ch\u1ea1y code cho t\u1ea5t c\u1ea3 c\u00e1c ph\u1ea7n d\u01b0\u1edbi \u0111\u00e2y, ch\u00fang ta gi\u1ea3 s\u1eed r\u1eb1ng folder g\u1ed1c n\u01a1i ch\u00fang ta l\u00e0m vi\u1ec7c l\u00e0 folder data_pipeline .","title":"M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n"},{"location":"mlops-crash-course/data-pipeline/feature-store.html#feature-store","text":"Feature store l\u00e0 m\u1ed9t h\u1ec7 th\u1ed1ng gi\u00fap l\u01b0u tr\u1eef, t\u01b0\u01a1ng t\u00e1c v\u00e0 qu\u1ea3n l\u00fd feature. C\u00f4ng c\u1ee5 n\u00e0y sinh ra \u0111\u1ec3 gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1 v\u1ec1: Feature reuse: l\u01b0u tr\u1eef c\u00e1c feature \u0111\u00e3 \u0111\u01b0\u1ee3c t\u1ea1o ra \u0111\u1ec3 t\u00e1i s\u1eed d\u1ee5ng khi c\u1ea7n thi\u1ebft Feature sharing: chia s\u1ebb feature gi\u1eefa c\u00e1c th\u00e0nh vi\u00ean trong team ho\u1eb7c v\u1edbi nhi\u1ec1u team kh\u00e1c nhau Feature consistency: m\u1ed9t ngu\u1ed3n d\u1eef li\u1ec7u cho c\u1ea3 m\u1ee5c \u0111\u00edch training v\u00e0 serving Feature monitoring: theo d\u00f5i thay \u0111\u1ed5i (drift) v\u00e0 ch\u1ea5t l\u01b0\u1ee3ng d\u1eef li\u1ec7u tr\u01b0\u1edbc khi \u0111\u01b0a qua model s\u1eed d\u1ee5ng Data leakage: \u0111\u1ea3m b\u1ea3o kh\u00f4ng x\u1ea3y ra hi\u1ec7n t\u01b0\u1ee3ng r\u00f2 r\u1ec9 (leak) d\u1eef li\u1ec7u trong t\u1eadp training. V\u00ed d\u1ee5: d\u1eef li\u1ec7u training v\u00e0o th\u1eddi \u0111i\u1ec3m b\u1ea5t k\u1ef3 kh\u00f4ng \u0111\u01b0\u1ee3c bao g\u1ed3m d\u1eef li\u1ec7u m\u00e0 c\u00f3 timestamp sau \u0111\u00f3. C\u00f3 r\u1ea5t nhi\u1ec1u feature store \u1edf th\u1eddi \u0111i\u1ec3m hi\u1ec7n t\u1ea1i, c\u00f3 th\u1ec3 k\u1ec3 t\u1edbi m\u1ed9t s\u1ed1 nh\u01b0: Open-source: Feast, Hopsworks Tr\u1ea3 ph\u00ed: Tecton (Feast phi\u00ean b\u1ea3n enterprise), Hopworks (phi\u00ean b\u1ea3n enterprise), Amazon SageMaker Feature Store, Vertex AI Feature Store","title":"Feature store"},{"location":"mlops-crash-course/data-pipeline/feature-store.html#feast","text":"\u1ede series n\u00e0y ch\u00fang ta s\u1ebd t\u00ecm hi\u1ec3u v\u1ec1 feature store th\u00f4ng qua Feast . Feast c\u00f3 2 kh\u00e1i ni\u1ec7m stores l\u00e0: Offline store: l\u01b0u tr\u1eef d\u1eef li\u1ec7u l\u1ecbch s\u1eed \u0111\u1ec3 ph\u1ee5c v\u1ee5 m\u1ee5c \u0111\u00edch training ho\u1eb7c offline batch serving. Hi\u1ec7n t\u1ea1i Feast h\u1ed7 tr\u1ee3 ch\u1ecdn m\u1ed9t trong lo\u1ea1i data source sau \u0111\u1ec3 l\u00e0m offline store: File, Snowflake, Bigquery v\u00e0 Redshift. Ngo\u00e0i ra c\u00f2n c\u00e1c lo\u1ea1i kh\u00e1c \u0111\u01b0\u1ee3c contribute b\u1edfi c\u1ed9ng \u0111\u1ed3ng v\u00ed d\u1ee5 nh\u01b0 PostgreSQL, Spark, Trino, .v.v.., tuy nhi\u00ean n\u00ean h\u1ea1n ch\u1ebf d\u00f9ng v\u00ec ch\u01b0a \u0111\u1ea1t full test coverage. Online store: l\u01b0u tr\u1eef d\u1eef li\u1ec7u m\u1edbi nh\u1ea5t cho m\u1ed7i ID. Store n\u00e0y c\u1ea7n c\u00f3 kh\u1ea3 n\u0103ng serve v\u1edbi low latency \u0111\u1ec3 s\u1eed d\u1ee5ng cho online serving. C\u00e1c lo\u1ea1i data source m\u00e0 Feast h\u1ed7 tr\u1ee3 \u0111\u1ec3 l\u00e0m online store bao g\u1ed3m: SQLite, Snowflake, Redis, MongoDB v\u00e0 Datastore. C\u00e1c lo\u1ea1i kh\u00e1c contribute b\u1edfi c\u1ed9ng \u0111\u1ed3ng c\u00f3 th\u1ec3 k\u1ec3 \u0111\u1ebfn nh\u01b0 PostgreSQL v\u00e0 Cassandra + Astra DB. T\u1ea5t c\u1ea3 c\u00e1c config cho Feast bao g\u1ed3m data source cho m\u1ed7i lo\u1ea1i store, \u0111\u1ecbnh ngh\u0129a c\u00e1c feature v\u00e0 entity (ID) n\u1eb1m trong folder sau: data_pipeline/feature_repo \u251c\u2500\u2500 data_sources.py: \u0111\u1ecbnh ngh\u0129a c\u00e1c data source \u251c\u2500\u2500 entities.py: \u0111\u1ecbnh ngh\u0129a entity \u251c\u2500\u2500 features.py: \u0111\u1ecbnh ngh\u0129a c\u00e1c b\u1ea3ng feature v\u00e0 c\u00e1c feature c\u00f9ng ki\u1ec3u d\u1eef li\u1ec7u trong t\u1eebng b\u1ea3ng \u2514\u2500\u2500 feature_store.yaml: \u0111\u1ecbnh ngh\u0129a lo\u1ea1i data source v\u00e0 \u0111\u01b0\u1eddng d\u1eabn t\u1edbi feature definition object store C\u00e1c b\u1ea3ng feature (c\u00f2n g\u1ecdi l\u00e0 feature view) ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng bao g\u1ed3m: driver_stats_view: feature view v\u1edbi data source d\u1ea1ng file driver_stats_stream: stream feature view v\u1edbi data source l\u00e0 Kafka v\u00e0 x\u1eed l\u00fd d\u1eef li\u1ec7u b\u1eb1ng Spark. Do b\u1ea3ng n\u00e0y l\u1ea5y d\u1eef li\u1ec7u t\u1eeb stream source n\u00ean feature s\u1ebd m\u1edbi h\u01a1n so v\u1edbi driver_stats_view Code \u0111\u1ecbnh ngh\u0129a c\u00e1c data source nh\u01b0 sau: data_pipeline/feature_repo/data_sources.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 driver_stats_parquet_file = \"../data_sources/driver_stats.parquet\" # local Parquet file as data source driver_stats_batch_source = FileSource ( name = \"driver_stats\" , file_format = ParquetFormat (), path = driver_stats_parquet_file , timestamp_field = \"datetime\" , created_timestamp_column = \"created\" , ) # Kafka for stream source driver_stats_stream_source = KafkaSource ( name = \"driver_stats_stream\" , kafka_bootstrap_servers = \"localhost:29092\" , topic = \"drivers\" , timestamp_field = \"datetime\" , batch_source = driver_stats_batch_source , message_format = JsonFormat ( schema_json = \"driver_id integer, acc_rate double, conv_rate double, datetime timestamp, created timestamp\" ), watermark_delay_threshold = timedelta ( minutes = 5 ), # (1) description = \"The Kafka stream containing the driver stats\" , ) Kho\u1ea3ng th\u1eddi gian \u0111\u1ebfn mu\u1ed9n cho ph\u00e9p c\u1ee7a feature tr\u01b0\u1edbc khi n\u00f3 b\u1ecb lo\u1ea1i b\u1ecf Code \u0111\u1ecbnh ngh\u0129a c\u00e1c feature view nh\u01b0 d\u01b0\u1edbi \u0111\u00e2y: data_pipeline/feature_repo/features.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 driver_stats_view = FeatureView ( name = \"driver_stats\" , description = \"driver features\" , entities = [ driver ], # (1) ttl = timedelta ( days = 36500 ), # (2) schema = [ Field ( name = \"conv_rate\" , dtype = Float32 ), # (3) Field ( name = \"acc_rate\" , dtype = Float32 ), Field ( name = \"avg_daily_trips\" , dtype = Int32 ), ], online = True , # (4) source = driver_stats_batch_source , # (5) tags = {}, owner = \"batch_source_owner@gmail.com\" , ) @stream_feature_view ( entities = [ driver ], ttl = timedelta ( days = 36500 ), mode = \"spark\" , # (6) schema = [ Field ( name = \"conv_rate\" , dtype = Float32 ), Field ( name = \"acc_rate\" , dtype = Float32 ), ], timestamp_field = \"datetime\" , online = True , source = driver_stats_stream_source , tags = {}, owner = \"stream_source_owner@gmail.com\" , ) def driver_stats_stream ( df : DataFrame ): from pyspark.sql.functions import col return ( df . withColumn ( \"conv_percentage\" , col ( \"conv_rate\" ) * 100.0 ) . withColumn ( \"acc_percentage\" , col ( \"acc_rate\" ) * 100.0 ) . drop ( \"conv_rate\" , \"acc_rate\" ) . withColumnRenamed ( \"conv_percentage\" , \"conv_rate\" ) . withColumnRenamed ( \"acc_percentage\" , \"acc_rate\" ) ) \u0110\u1ecbnh ngh\u0129a entity cho b\u1ea3ng feature Time-to-live: Th\u1eddi gian s\u1eed d\u1ee5ng c\u1ee7a feature tr\u01b0\u1edbc khi b\u1ecb stale \u0110\u1ecbnh ngh\u0129a feature v\u00e0 ki\u1ec3u d\u1eef li\u1ec7u Cho ph\u00e9p online serving \u0110\u1ecbnh ngh\u0129a data source cho b\u1ea3ng feature S\u1eed d\u1ee5ng Spark \u0111\u1ec3 x\u1eed l\u00fd d\u1eef li\u1ec7u stream Sau khi config feature store b\u1eb1ng c\u00e1ch thay \u0111\u1ed5i c\u00e1c file trong repo feature_repo/ , ch\u00fang ta c\u1ea7n \u0111\u1ea3m b\u1ea3o c\u00e1c data source \u0111\u00e3 s\u1eb5n s\u00e0ng, bao g\u1ed3m: FileSource: \u0111\u1ea3m b\u1ea3o \u0111\u01b0\u1eddng d\u1eabn t\u1ed3n t\u1ea1i, file kh\u00f4ng b\u1ecb l\u1ed7i KafkaSource: \u0111\u1ea3m b\u1ea3o bootstrap servers \u0111ang ch\u1ea1y. \u0110\u1ec3 start bootstrap server n\u00e0y, c\u00e1c b\u1ea1n ch\u1ea1y: cd ../stream_emitting bash deploy.sh start cd ../data_pipeline N\u1ebfu c\u00e1c b\u1ea1n s\u1ebd th\u1ea5y console nh\u01b0 sau, t\u1ee9c l\u00e0 Kafka \u0111ang stream d\u1eef li\u1ec7u driver v\u1ec1 Tip \u0110\u1ec3 stop server, c\u00e1c b\u1ea1n ch\u1ea1y: bash deploy.sh stop cd ../stream_emitting bash deploy.sh stop cd ../data_pipeline \u0110\u1ec3 teardown server (stop v\u00e0 remove t\u1ea5t c\u1ea3 docker volume li\u00ean quan), c\u00e1c b\u1ea1n ch\u1ea1y: cd ../stream_emitting bash deploy.sh teardown cd ../data_pipeline V\u00e0 cu\u1ed1i c\u00f9ng ch\u00fang ta s\u1ebd c\u1eadp nh\u1eadt Offline Feature store b\u1eb1ng c\u00e1ch ch\u1ea1y: cd feature_repo feast apply Info feast apply ch\u1ec9 c\u1eadp nh\u1eadt \u0111\u1ecbnh ngh\u0129a c\u1ee7a c\u00e1c features. feast apply ch\u1ec9 c\u1ea7n ch\u1ea1y khi b\u1ea1n c\u1ea7n th\u00eam c\u1ed9t, s\u1eeda ki\u1ec3u d\u1eef li\u1ec7u c\u1ee7a c\u1ed9t, v.v...","title":"Feast"},{"location":"mlops-crash-course/data-pipeline/feature-store.html#tong-ket","text":"Ch\u00fang ta v\u1eeba l\u00e0m quen v\u1edbi m\u1ed9t s\u1ed1 kh\u00e1i ni\u1ec7m v\u1ec1 feature store th\u00f4ng qua Feast. \u1ede b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd: L\u1ea5y feature t\u1eeb Feast aterialize feature t\u1eeb offline qua online store \u0110\u1ea9y d\u1eef li\u1ec7u stream v\u1ec1 online store v\u00e0 offline store X\u00e2y d\u1ef1ng c\u00e1c Airflow pipeline \u0111\u1ec3 t\u1ef1 \u0111\u1ed9ng h\u00f3a c\u00e1c c\u00f4ng vi\u1ec7c tr\u00ean.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/data-pipeline/feature-store.html#tai-lieu-tham-khao","text":"https://feast.dev/","title":"T\u00e0i li\u1ec7u tham kh\u1ea3o"},{"location":"mlops-crash-course/data-pipeline/tong-quan-data-pipeline.html","text":"Photo by Barr Moses on Medium Gi\u1edbi thi\u1ec7u Trong khoa h\u1ecdc m\u00e1y t\u00ednh c\u00f3 kh\u00e1i ni\u1ec7m garbage in, garbage out , \u0111\u01b0\u1ee3c hi\u1ec3u r\u1eb1ng d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o m\u00e0 r\u00e1c th\u00ec k\u1ebft qu\u1ea3 \u0111\u1ea7u ra c\u0169ng kh\u00f4ng th\u1ec3 d\u00f9ng \u0111\u01b0\u1ee3c. Nh\u01b0 v\u1eady c\u00f4ng \u0111o\u1ea1n chu\u1ea9n b\u1ecb d\u1eef li\u1ec7u l\u00e0 c\u1ef1c k\u1ef3 quan tr\u1ecdng, nh\u1ea5t l\u00e0 \u0111\u1ed1i v\u1edbi c\u00e1c \u1ee9ng d\u1ee5ng c\u00f3 hi\u1ec7u n\u0103ng b\u1ecb chi ph\u1ed1i m\u1ea1nh m\u1ebd b\u1edfi d\u1eef li\u1ec7u nh\u01b0 ML. Theo th\u1ed1ng k\u00ea c\u1ee7a Forbes , c\u00e1c Data Scientist d\u00e0nh t\u1edbi 80% th\u1eddi gian cho c\u00e1c c\u00f4ng vi\u1ec7c li\u00ean quan t\u1edbi x\u1eed l\u00fd d\u1eef li\u1ec7u, \u0111\u1ee7 \u0111\u1ec3 hi\u1ec3u r\u1eb1ng data engineering l\u00e0 m\u1ed9t qu\u00e1 tr\u00ecnh r\u1ea5t ph\u1ee9c t\u1ea1p v\u00e0 t\u1ed1n nhi\u1ec1u th\u1eddi gian. \u1ede b\u00e0i h\u1ecdc n\u00e0y, ch\u00fang ta s\u1ebd c\u00f9ng nhau t\u00ecm hi\u1ec3u c\u00e1c c\u00f4ng vi\u1ec7c ph\u1ed5 bi\u1ebfn trong x\u1eed l\u00fd d\u1eef li\u1ec7u, kh\u00e1i ni\u1ec7m v\u1ec1 pipeline d\u1eef li\u1ec7u, t\u1eeb \u0111\u00f3 b\u1ea1n c\u00f3 th\u1ec3 r\u00fat ra \u0111\u01b0\u1ee3c nh\u1eefng vi\u1ec7c c\u1ea7n l\u00e0m cho b\u00e0i to\u00e1n c\u1ee7a m\u00ecnh v\u00e0 l\u00ean k\u1ebf ho\u1ea1ch tri\u1ec3n khai cho ph\u00f9 h\u1ee3p. C\u00e1c c\u00f4ng \u0111o\u1ea1n ch\u00ednh trong x\u1eed l\u00fd d\u1eef li\u1ec7u Th\u00f4ng th\u01b0\u1eddng c\u00f4ng vi\u1ec7c x\u1eed l\u00fd d\u1eef li\u1ec7u bao g\u1ed3m c\u00e1c c\u00f4ng \u0111o\u1ea1n ch\u00ednh nh\u01b0 sau: T\u00ean c\u00f4ng \u0111o\u1ea1n C\u00f4ng vi\u1ec7c c\u1ee5 th\u1ec3 Data ingestion Data provenance: l\u01b0u tr\u1eef th\u00f4ng tin v\u1ec1 c\u00e1c d\u1eef li\u1ec7u ngu\u1ed3n Metadata catalog: l\u01b0u tr\u1eef th\u00f4ng tin v\u1ec1 d\u1eef li\u1ec7u bao g\u1ed3m: k\u00edch th\u01b0\u1edbc, \u0111\u1ecbnh d\u1ea1ng, ng\u01b0\u1eddi s\u1edf h\u1eefu, ng\u01b0\u1eddi c\u00f3 quy\u1ec1n truy c\u1eadp, th\u1eddi gian s\u1eeda \u0111\u1ed5i g\u1ea7n nh\u1ea5t, .v.v. Data formatting: chuy\u1ec3n d\u1eef li\u1ec7u sang format kh\u00e1c \u0111\u1ec3 d\u1ec5 d\u00e0ng x\u1eed l\u00fd Privacy Compliance: \u0111\u1ea3m b\u1ea3o c\u00e1c d\u1eef li\u1ec7u nh\u1ea1y c\u1ea3m (PII), v\u00ed d\u1ee5 th\u00f4ng tin h\u1ecd t\u00ean kh\u00e1ch h\u00e0ng \u0111i k\u00e8m CMND/CCCD, \u0111\u00e3 \u0111\u01b0\u1ee3c \u1ea9n \u0111i Data cleaning X\u1eed l\u00fd outlier/missing values Lo\u1ea1i b\u1ecf c\u00e1c features kh\u00f4ng li\u00ean quan ho\u1eb7c c\u00e1c sample b\u1ecb l\u1eb7p l\u1ea1i Thay \u0111\u1ed5i th\u1ee9 t\u1ef1 c\u00e1c c\u1ed9t Th\u1ef1c hi\u1ec7n c\u00e1c ph\u00e9p bi\u1ebfn \u0111\u1ed5i Data exploration & validation Data profiling: hi\u1ec3n th\u1ecb th\u00f4ng tin c\u01a1 b\u1ea3n v\u1ec1 c\u00e1c feature nh\u01b0 ki\u1ec3u d\u1eef li\u1ec7u, t\u1ec9 l\u1ec7 missing value, ph\u00e2n b\u1ed1 d\u1eef li\u1ec7u, c\u00e1c con s\u1ed1 th\u1ed1ng k\u00ea nh\u01b0 min , max , mean , .v.v. Visualization: x\u00e2y d\u1ef1ng c\u00e1c dashboard v\u1ec1 ph\u00e2n b\u1ed1 ho\u1eb7c \u0111\u1ed9 skew c\u1ee7a d\u1eef li\u1ec7u Validation: s\u1eed d\u1ee5ng c\u00e1c user-defined rule (v\u00ed d\u1ee5 nh\u01b0 t\u1ec9 l\u1ec7 missing value < 80% ), ho\u1eb7c d\u1ef1a v\u00e0o th\u1ed1ng k\u00ea \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh \u0111\u1ed9 l\u1ec7ch ph\u00e2n b\u1ed1 Pipeline x\u1eed l\u00fd d\u1eef li\u1ec7u Sau khi \u0111\u00e3 n\u1eafm r\u00f5 c\u00e1c \u0111\u1ea7u vi\u1ec7c c\u1ea7n ph\u1ea3i l\u00e0m, ch\u00fang ta s\u1ebd chia c\u00e1c c\u00f4ng vi\u1ec7c \u0111\u00f3 th\u00e0nh c\u00e1c module \u0111\u1ec3 c\u00e1c th\u00e0nh vi\u00ean trong team c\u00f3 th\u1ec3 b\u1eaft \u0111\u1ea7u implement. Vi\u1ec7c chia module c\u00f3 th\u1ec3 d\u1ef1a theo c\u00f4ng \u0111o\u1ea1n nh\u01b0 \u1edf ph\u1ea7n tr\u00ean, \u0111\u00f3 l\u00e0 3 module: data ingestion , data cleaning , v\u00e0 data exploration & validation ho\u1eb7c chia nh\u1ecf th\u00eam n\u1eefa \u0111\u1ec3 d\u1ec5 maintain v\u00e0 scale h\u01a1n. C\u00e1c module x\u1eed l\u00fd d\u1eef li\u1ec7u ch\u1ea1y theo tu\u1ea7n t\u1ef1 t\u1ea1o th\u00e0nh m\u1ed9t pipeline x\u1eed l\u00fd d\u1eef li\u1ec7u, v\u00ed d\u1ee5 b\u00ean d\u01b0\u1edbi: flowchart LR n1[ingest_task] --> n2[clean_task] --> n3[explore_and_validate_task] Tip S\u1ed1 l\u01b0\u1ee3ng module qu\u00e1 nhi\u1ec1u c\u00f3 th\u1ec3 d\u1eabn t\u1edbi m\u1ed9t s\u1ed1 v\u1ea5n \u0111\u1ec1 nh\u01b0: Pipeline tr\u1edf n\u00ean ph\u1ee9c t\u1ea1p v\u00e0 kh\u00f3 debug Vi\u1ec7c pass d\u1eef li\u1ec7u qua l\u1ea1i gi\u1eefa c\u00e1c module x\u1ea3y ra nhi\u1ec1u l\u00ean l\u00e0m t\u0103ng th\u1eddi gian ho\u00e0n th\u00e0nh c\u1ee7a pipeline D\u1ec5 g\u00e2y l\u00e3ng ph\u00ed computing resource n\u1ebfu kh\u00f4ng x\u1eed l\u00fd scale h\u1ee3p l\u00fd T\u1ed5ng k\u1ebft \u1ede b\u00e0i h\u1ecdc v\u1eeba r\u1ed3i, ch\u00fang ta \u0111\u00e3 c\u00f9ng nhau t\u00ecm hi\u1ec3u v\u1ec1 c\u00e1c c\u00f4ng vi\u1ec7c x\u1eed l\u00fd d\u1eef li\u1ec7u cho model v\u00e0 \u00fd t\u01b0\u1edfng chia nh\u1ecf c\u00e1c c\u00f4ng vi\u1ec7c \u0111\u00f3 th\u00e0nh c\u00e1c th\u00e0nh ph\u1ea7n c\u1ee7a pipeline. \u1ede b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd t\u00ecm hi\u1ec3u v\u1ec1 Airflow, m\u1ed9t c\u00f4ng c\u1ee5 gi\u00fap x\u00e2y d\u1ef1ng pipeline. T\u00e0i li\u1ec7u tham kh\u1ea3o https://ml-ops.org/content/three-levels-of-ml-software https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning","title":"T\u1ed5ng quan pipeline"},{"location":"mlops-crash-course/data-pipeline/tong-quan-data-pipeline.html#gioi-thieu","text":"Trong khoa h\u1ecdc m\u00e1y t\u00ednh c\u00f3 kh\u00e1i ni\u1ec7m garbage in, garbage out , \u0111\u01b0\u1ee3c hi\u1ec3u r\u1eb1ng d\u1eef li\u1ec7u \u0111\u1ea7u v\u00e0o m\u00e0 r\u00e1c th\u00ec k\u1ebft qu\u1ea3 \u0111\u1ea7u ra c\u0169ng kh\u00f4ng th\u1ec3 d\u00f9ng \u0111\u01b0\u1ee3c. Nh\u01b0 v\u1eady c\u00f4ng \u0111o\u1ea1n chu\u1ea9n b\u1ecb d\u1eef li\u1ec7u l\u00e0 c\u1ef1c k\u1ef3 quan tr\u1ecdng, nh\u1ea5t l\u00e0 \u0111\u1ed1i v\u1edbi c\u00e1c \u1ee9ng d\u1ee5ng c\u00f3 hi\u1ec7u n\u0103ng b\u1ecb chi ph\u1ed1i m\u1ea1nh m\u1ebd b\u1edfi d\u1eef li\u1ec7u nh\u01b0 ML. Theo th\u1ed1ng k\u00ea c\u1ee7a Forbes , c\u00e1c Data Scientist d\u00e0nh t\u1edbi 80% th\u1eddi gian cho c\u00e1c c\u00f4ng vi\u1ec7c li\u00ean quan t\u1edbi x\u1eed l\u00fd d\u1eef li\u1ec7u, \u0111\u1ee7 \u0111\u1ec3 hi\u1ec3u r\u1eb1ng data engineering l\u00e0 m\u1ed9t qu\u00e1 tr\u00ecnh r\u1ea5t ph\u1ee9c t\u1ea1p v\u00e0 t\u1ed1n nhi\u1ec1u th\u1eddi gian. \u1ede b\u00e0i h\u1ecdc n\u00e0y, ch\u00fang ta s\u1ebd c\u00f9ng nhau t\u00ecm hi\u1ec3u c\u00e1c c\u00f4ng vi\u1ec7c ph\u1ed5 bi\u1ebfn trong x\u1eed l\u00fd d\u1eef li\u1ec7u, kh\u00e1i ni\u1ec7m v\u1ec1 pipeline d\u1eef li\u1ec7u, t\u1eeb \u0111\u00f3 b\u1ea1n c\u00f3 th\u1ec3 r\u00fat ra \u0111\u01b0\u1ee3c nh\u1eefng vi\u1ec7c c\u1ea7n l\u00e0m cho b\u00e0i to\u00e1n c\u1ee7a m\u00ecnh v\u00e0 l\u00ean k\u1ebf ho\u1ea1ch tri\u1ec3n khai cho ph\u00f9 h\u1ee3p.","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/data-pipeline/tong-quan-data-pipeline.html#cac-cong-oan-chinh-trong-xu-ly-du-lieu","text":"Th\u00f4ng th\u01b0\u1eddng c\u00f4ng vi\u1ec7c x\u1eed l\u00fd d\u1eef li\u1ec7u bao g\u1ed3m c\u00e1c c\u00f4ng \u0111o\u1ea1n ch\u00ednh nh\u01b0 sau: T\u00ean c\u00f4ng \u0111o\u1ea1n C\u00f4ng vi\u1ec7c c\u1ee5 th\u1ec3 Data ingestion Data provenance: l\u01b0u tr\u1eef th\u00f4ng tin v\u1ec1 c\u00e1c d\u1eef li\u1ec7u ngu\u1ed3n Metadata catalog: l\u01b0u tr\u1eef th\u00f4ng tin v\u1ec1 d\u1eef li\u1ec7u bao g\u1ed3m: k\u00edch th\u01b0\u1edbc, \u0111\u1ecbnh d\u1ea1ng, ng\u01b0\u1eddi s\u1edf h\u1eefu, ng\u01b0\u1eddi c\u00f3 quy\u1ec1n truy c\u1eadp, th\u1eddi gian s\u1eeda \u0111\u1ed5i g\u1ea7n nh\u1ea5t, .v.v. Data formatting: chuy\u1ec3n d\u1eef li\u1ec7u sang format kh\u00e1c \u0111\u1ec3 d\u1ec5 d\u00e0ng x\u1eed l\u00fd Privacy Compliance: \u0111\u1ea3m b\u1ea3o c\u00e1c d\u1eef li\u1ec7u nh\u1ea1y c\u1ea3m (PII), v\u00ed d\u1ee5 th\u00f4ng tin h\u1ecd t\u00ean kh\u00e1ch h\u00e0ng \u0111i k\u00e8m CMND/CCCD, \u0111\u00e3 \u0111\u01b0\u1ee3c \u1ea9n \u0111i Data cleaning X\u1eed l\u00fd outlier/missing values Lo\u1ea1i b\u1ecf c\u00e1c features kh\u00f4ng li\u00ean quan ho\u1eb7c c\u00e1c sample b\u1ecb l\u1eb7p l\u1ea1i Thay \u0111\u1ed5i th\u1ee9 t\u1ef1 c\u00e1c c\u1ed9t Th\u1ef1c hi\u1ec7n c\u00e1c ph\u00e9p bi\u1ebfn \u0111\u1ed5i Data exploration & validation Data profiling: hi\u1ec3n th\u1ecb th\u00f4ng tin c\u01a1 b\u1ea3n v\u1ec1 c\u00e1c feature nh\u01b0 ki\u1ec3u d\u1eef li\u1ec7u, t\u1ec9 l\u1ec7 missing value, ph\u00e2n b\u1ed1 d\u1eef li\u1ec7u, c\u00e1c con s\u1ed1 th\u1ed1ng k\u00ea nh\u01b0 min , max , mean , .v.v. Visualization: x\u00e2y d\u1ef1ng c\u00e1c dashboard v\u1ec1 ph\u00e2n b\u1ed1 ho\u1eb7c \u0111\u1ed9 skew c\u1ee7a d\u1eef li\u1ec7u Validation: s\u1eed d\u1ee5ng c\u00e1c user-defined rule (v\u00ed d\u1ee5 nh\u01b0 t\u1ec9 l\u1ec7 missing value < 80% ), ho\u1eb7c d\u1ef1a v\u00e0o th\u1ed1ng k\u00ea \u0111\u1ec3 x\u00e1c \u0111\u1ecbnh \u0111\u1ed9 l\u1ec7ch ph\u00e2n b\u1ed1","title":"C\u00e1c c\u00f4ng \u0111o\u1ea1n ch\u00ednh trong x\u1eed l\u00fd d\u1eef li\u1ec7u"},{"location":"mlops-crash-course/data-pipeline/tong-quan-data-pipeline.html#pipeline-xu-ly-du-lieu","text":"Sau khi \u0111\u00e3 n\u1eafm r\u00f5 c\u00e1c \u0111\u1ea7u vi\u1ec7c c\u1ea7n ph\u1ea3i l\u00e0m, ch\u00fang ta s\u1ebd chia c\u00e1c c\u00f4ng vi\u1ec7c \u0111\u00f3 th\u00e0nh c\u00e1c module \u0111\u1ec3 c\u00e1c th\u00e0nh vi\u00ean trong team c\u00f3 th\u1ec3 b\u1eaft \u0111\u1ea7u implement. Vi\u1ec7c chia module c\u00f3 th\u1ec3 d\u1ef1a theo c\u00f4ng \u0111o\u1ea1n nh\u01b0 \u1edf ph\u1ea7n tr\u00ean, \u0111\u00f3 l\u00e0 3 module: data ingestion , data cleaning , v\u00e0 data exploration & validation ho\u1eb7c chia nh\u1ecf th\u00eam n\u1eefa \u0111\u1ec3 d\u1ec5 maintain v\u00e0 scale h\u01a1n. C\u00e1c module x\u1eed l\u00fd d\u1eef li\u1ec7u ch\u1ea1y theo tu\u1ea7n t\u1ef1 t\u1ea1o th\u00e0nh m\u1ed9t pipeline x\u1eed l\u00fd d\u1eef li\u1ec7u, v\u00ed d\u1ee5 b\u00ean d\u01b0\u1edbi: flowchart LR n1[ingest_task] --> n2[clean_task] --> n3[explore_and_validate_task] Tip S\u1ed1 l\u01b0\u1ee3ng module qu\u00e1 nhi\u1ec1u c\u00f3 th\u1ec3 d\u1eabn t\u1edbi m\u1ed9t s\u1ed1 v\u1ea5n \u0111\u1ec1 nh\u01b0: Pipeline tr\u1edf n\u00ean ph\u1ee9c t\u1ea1p v\u00e0 kh\u00f3 debug Vi\u1ec7c pass d\u1eef li\u1ec7u qua l\u1ea1i gi\u1eefa c\u00e1c module x\u1ea3y ra nhi\u1ec1u l\u00ean l\u00e0m t\u0103ng th\u1eddi gian ho\u00e0n th\u00e0nh c\u1ee7a pipeline D\u1ec5 g\u00e2y l\u00e3ng ph\u00ed computing resource n\u1ebfu kh\u00f4ng x\u1eed l\u00fd scale h\u1ee3p l\u00fd","title":"Pipeline x\u1eed l\u00fd d\u1eef li\u1ec7u"},{"location":"mlops-crash-course/data-pipeline/tong-quan-data-pipeline.html#tong-ket","text":"\u1ede b\u00e0i h\u1ecdc v\u1eeba r\u1ed3i, ch\u00fang ta \u0111\u00e3 c\u00f9ng nhau t\u00ecm hi\u1ec3u v\u1ec1 c\u00e1c c\u00f4ng vi\u1ec7c x\u1eed l\u00fd d\u1eef li\u1ec7u cho model v\u00e0 \u00fd t\u01b0\u1edfng chia nh\u1ecf c\u00e1c c\u00f4ng vi\u1ec7c \u0111\u00f3 th\u00e0nh c\u00e1c th\u00e0nh ph\u1ea7n c\u1ee7a pipeline. \u1ede b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd t\u00ecm hi\u1ec3u v\u1ec1 Airflow, m\u1ed9t c\u00f4ng c\u1ee5 gi\u00fap x\u00e2y d\u1ef1ng pipeline.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/data-pipeline/tong-quan-data-pipeline.html#tai-lieu-tham-khao","text":"https://ml-ops.org/content/three-levels-of-ml-software https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning","title":"T\u00e0i li\u1ec7u tham kh\u1ea3o"},{"location":"mlops-crash-course/data-pipeline/xay-dung-data-pipeline.html","text":"Photo by Sneha Mehrin on Medium Gi\u1edbi thi\u1ec7u \u1ede b\u00e0i h\u1ecdc tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 l\u00e0m quen v\u1edbi feature store, Feast v\u00e0 d\u00f9ng command feast apply \u0111\u1ec3 t\u1ea1o ra feature definition \u1edf \u0111\u01b0\u1eddng d\u1eabn data_pipeline/feature_repo/registry/local_registry.db . Trong b\u00e0i h\u1ecdc n\u00e0y ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng folder n\u00e0y \u0111\u1ec3 c\u1ea5u h\u00ecnh client store giao ti\u1ebfp v\u1edbi feature store nh\u01b0 sau: 1 2 from feast import FeatureStore store = FeatureStore ( repo_path = \"../feature_repo\" ) # (1) Kh\u1edfi t\u1ea1o client store \u0111\u1ec3 giao ti\u1ebfp v\u1edbi feature store Client n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u1edf nhi\u1ec1u b\u01b0\u1edbc kh\u00e1c nhau bao g\u1ed3m 1 , 2 , 3 , 4 , 5 nh\u01b0 h\u00ecnh d\u01b0\u1edbi \u0111\u00e2y: M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n Ngo\u00e0i Feast, b\u00e0i h\u1ecdc n\u00e0y s\u1ebd s\u1eed d\u1ee5ng th\u00eam Airflow, b\u1ea1n v\u00e0o repo mlops-crash-course-platform/ v\u00e0 start service n\u00e0y nh\u01b0 sau: bash run.sh airflow up C\u00e1c t\u01b0\u01a1ng t\u00e1c ch\u00ednh v\u1edbi Feast Ch\u00fang ta c\u00f3 6 t\u01b0\u01a1ng t\u00e1c ch\u00ednh v\u1edbi Feast nh\u01b0 sau: 1. Materialize feature t\u1eeb offline sang online store \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o online store l\u01b0u tr\u1eef feature m\u1edbi nh\u1ea5t data_pipeline/scripts/feast_helper.sh 1 2 cd feature_repo feast materialize - incremental $ ( date +% Y -% m -% d ) Tip \u0110\u1ec3 hi\u1ec3u r\u00f5 h\u01a1n v\u1ec1 materialize , gi\u1ea3 s\u1eed r\u1eb1ng \u1edf offline store ch\u00fang ta c\u00f3 3 record c\u1ee7a ID 1001 nh\u01b0 sau: datetime driver_id conv_rate acc_rate avg_daily_trips created 2021-07-13 11:00:00+00:00 1001 0.852406 0.059147 340 2021-07-28 11:08:04.802 2021-08-10 12:00:00+00:00 1001 0.571599 0.244896 752 2021-07-28 11:08:04.802 2021-07-13 13:00:00+00:00 1001 0.929023 0.479821 716 2021-07-28 11:08:04.802 Khi ch\u00fang ta ch\u1ea1y command feast materialize 2021-08-07T00:00:00 , th\u00ec d\u1eef li\u1ec7u c\u00f3 datetime m\u1edbi nh\u1ea5t m\u00e0 tr\u01b0\u1edbc th\u1eddi \u0111i\u1ec3m 2021-08-07T00:00:00 s\u1ebd \u0111\u01b0\u1ee3c c\u1eadp nh\u1eadt v\u00e0o online store. \u0110\u00f3 ch\u00ednh l\u00e0 record th\u1ee9 3 \u1edf b\u1ea3ng tr\u00ean. datetime driver_id conv_rate acc_rate avg_daily_trips created 2021-07-13 13:00:00+00:00 1001 0.929023 0.479821 716 2021-07-28 11:08:04.802 2. Data scientist, training pipeline ho\u1eb7c offline batch serving pipeline k\u00e9o features v\u1ec1 \u0111\u1ec3 train model data_pipeline/examples/get_historical_features.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 entity_df = pd . DataFrame . from_dict ( { \"driver_id\" : [ 1001 , 1002 , 1003 ], \"datetime\" : [ datetime ( 2022 , 5 , 11 , 11 , 59 , 59 ), datetime ( 2022 , 6 , 12 , 1 , 15 , 10 ), datetime . now (), ], } ) training_df = store . get_historical_features ( entity_df = entity_df , features = [ \"driver_stats:acc_rate\" , \"driver_stats:conv_rate\" ], ) . to_df () print ( training_df . head ()) 3. K\u00e9o features m\u1edbi nh\u1ea5t t\u01b0\u01a1ng \u1ee9ng v\u1edbi c\u00e1c IDs trong request API \u0111\u1ec3 cho qua model d\u1ef1 \u0111o\u00e1n data_pipeline/examples/get_online_features.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 features = store . get_online_features ( features = [ \"driver_stats:acc_rate\" , \"driver_stats:conv_rate\" ], entity_rows = [ { \"driver_id\" : 1001 , } ], ) . to_dict ( include_event_timestamps = True ) def print_online_features ( features ): for key , value in sorted ( features . items ()): print ( key , \" : \" , value ) print_online_features ( features ) 4. \u0110\u1ea9y stream feature v\u00e0o offline store data_pipeline/src/stream_to_stores/processor.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def preprocess_fn ( rows : pd . DataFrame ): print ( f \"df columns: { rows . columns } \" ) print ( f \"df size: { rows . size } \" ) print ( f \"df preview: \\n { rows . head () } \" ) return rows ingestion_config = SparkProcessorConfig ( mode = \"spark\" , source = \"kafka\" , spark_session = spark , processing_time = \"30 seconds\" , query_timeout = 15 ) sfv = store . get_stream_feature_view ( \"driver_stats_stream\" ) processor = get_stream_processor_object ( config = ingestion_config , fs = store , sfv = sfv , preprocess_fn = preprocess_fn , ) processor . ingest_stream_feature_view ( PushMode . OFFLINE ) 5. \u0110\u1ea9y stream feature v\u00e0o online store 1 processor . ingest_stream_feature_view () 7. ETL (Extract, Transform, Load) pipeline c\u1eadp nh\u1eadt d\u1eef li\u1ec7u c\u1ee7a offline store Tip \u1ede t\u01b0\u01a1ng t\u00e1c 2., th\u00f4ng th\u01b0\u1eddng c\u00e1c Data Scientist s\u1ebd k\u00e9o d\u1eef li\u1ec7u t\u1eeb feature store \u0111\u1ec3: th\u1ef1c hi\u1ec7n POC th\u1eed nghi\u1ec7m v\u1edbi c\u00e1c feature kh\u00e1c nh\u1eb1m m\u1ee5c \u0111\u00edch c\u1ea3i thi\u1ec7n model \u1ede c\u00f4ng \u0111o\u1ea1n x\u00e2y d\u1ef1ng data pipeline, ch\u00fang ta s\u1ebd x\u00e2y d\u1ef1ng pipeline cho c\u00e1c t\u01b0\u01a1ng t\u00e1c 1., 4., 5., 7. X\u00e2y d\u1ef1ng c\u00e1c pipelines ETL pipeline \u0110\u1ec3 t\u1ea1o ra m\u1ed9t Airflow pipeline, th\u00f4ng th\u01b0\u1eddng ch\u00fang ta s\u1ebd l\u00e0m theo tr\u00ecnh t\u1ef1 sau: \u0110\u1ecbnh ngh\u0129a DAG cho pipeline (line 1-8) Vi\u1ebft c\u00e1c task cho pipeline, v\u00ed d\u1ee5: ingest_task , clean_task v\u00e0 explore_and_validate_task (line 9-25) Vi\u1ebft th\u1ee9 t\u1ef1 ch\u1ea1y c\u00e1c task (line 27) Ch\u1ea1y l\u1ec7nh sau \u0111\u1ec3 build Docker image cho c\u00e1c pipeline component, v\u00e0 copy file code DAG sang folder airflow/run_env/dags/data_pipeline c\u1ee7a repo clone t\u1eeb MLOps Crash course platform cd data_pipeline make build_image # \u0110\u1ea3m b\u1ea3o Airflow server \u0111\u00e3 ch\u1ea1y make deploy_dags # (1) Copy data_pipeline/dags/* v\u00e0o folder dags c\u1ee7a Airflow DAG d\u01b0\u1edbi \u0111\u00e2y th\u1ec3 hi\u1ec7n ETL pipeline. data_pipeline/dags/db_to_offline_store.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 with DAG ( dag_id = \"db_to_offline_store\" , # (1) default_args = DefaultConfig . DEFAULT_DAG_ARGS , # (2) schedule_interval = \"@once\" , # (3) start_date = pendulum . datetime ( 2022 , 1 , 1 , tz = \"UTC\" ), # (4) catchup = False , # (5) tags = [ \"data_pipeline\" ], ) as dag : ingest_task = DockerOperator ( task_id = \"ingest_task\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , command = \"/bin/bash -c 'cd src/db_to_offline_store && python ingest.py'\" , # (6) ) clean_task = DockerOperator ( task_id = \"clean_task\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , command = \"/bin/bash -c 'cd src/db_to_offline_store && python clean.py'\" , ) explore_and_validate_task = DockerOperator ( task_id = \"explore_and_validate_task\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , command = \"/bin/bash -c 'cd src/db_to_offline_store && python explore_and_validate.py'\" , ) ingest_task >> clean_task >> explore_and_validate_task # (7) \u0110\u1ecbnh ngh\u0129a t\u00ean pipeline hi\u1ec3n th\u1ecb \u1edf tr\u00ean Airflow dashboard \u0110\u1ecbnh ngh\u0129a pipeline owner, s\u1ed1 l\u1ea7n retry pipeline, v\u00e0 kho\u1ea3ng th\u1eddi gian gi\u1eefa c\u00e1c l\u1ea7n retry L\u1ecbch ch\u1ea1y pipeline, \u1edf \u0111\u00e2y @once l\u00e0 m\u1ed9t l\u1ea7n ch\u1ea1y, b\u1ea1n c\u00f3 th\u1ec3 thay b\u1eb1ng cron expression v\u00ed d\u1ee5 nh\u01b0 0 0 1 * * Ng\u00e0y b\u1eaft \u0111\u1ea7u ch\u1ea1y pipeline theo m\u00fai gi\u1edd UTC N\u1ebfu start_date l\u00e0 ng\u00e0y 01/01/2022, ng\u00e0y deploy/turn on pipeline l\u00e0 ng\u00e0y 02/02/2022, v\u00e0 schedule_interval l\u00e0 @daily th\u00ec s\u1ebd kh\u00f4ng ch\u1ea1y c\u00e1c ng\u00e0y tr\u01b0\u1edbc 02/02/2022 n\u1eefa Command ch\u1ea1y trong docker container cho b\u01b0\u1edbc n\u00e0y \u0110\u1ecbnh ngh\u0129a th\u1ee9 t\u1ef1 ch\u1ea1y c\u00e1c b\u01b0\u1edbc c\u1ee7a pipeline: \u0111\u1ea7u ti\u00ean l\u00e0 ingest sau \u0111\u00f3 t\u1edbi clean v\u00e0 cu\u1ed1i c\u00f9ng l\u00e0 explore_and_validate Info Do ch\u00fang ta d\u00f9ng DockerOperator \u0111\u1ec3 t\u1ea1o task n\u00ean c\u1ea7n ph\u1ea3i build image ch\u1ee9a code v\u00e0 m\u00f4i tr\u01b0\u1eddng tr\u01b0\u1edbc, sau \u0111\u00f3 s\u1ebd truy\u1ec1n t\u00ean image v\u00e0o DEFAULT_DOCKER_OPERATOR_ARGS trong t\u1eebng pipeline component (v\u00ed d\u1ee5 nh\u01b0 line 11). Dockerfile \u0111\u1ec3 build image b\u1ea1n c\u00f3 th\u1ec3 tham kh\u1ea3o t\u1ea1i data_pipeline/deployment/Dockerfile Bi\u1ebfn DefaultConfig.DEFAULT_DOCKER_OPERATOR_ARGS ch\u1ee9a c\u00e1c config nh\u01b0 sau: data_pipeline/dags/utils.py 1 2 3 4 5 6 7 8 9 10 11 12 DEFAULT_DOCKER_OPERATOR_ARGS = { \"image\" : f \" { AppConst . DOCKER_USER } /mlops_crash_course/data_pipeline:latest\" , # (1) \"api_version\" : \"auto\" , # (2) \"auto_remove\" : True , # (3) \"mounts\" : [ Mount ( source = AppPath . FEATURE_REPO . absolute () . as_posix (), # (4) target = \"/data_pipeline/feature_repo\" , # (5) type = \"bind\" , # (6) ), ], } Docker image d\u00f9ng cho task T\u1ef1 \u0111\u1ed9ng x\u00e1c \u0111\u1ecbnh Docker engine API version T\u1ef1 \u0111\u1ed9ng d\u1ecdn d\u1eb9p container sau khi exit Folder \u1edf m\u00e1y local, b\u1eaft bu\u1ed9c l\u00e0 \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i Folder n\u1eb1m trong docker container Ki\u1ec3u bind, \u0111\u1ecdc th\u00eam \u1edf \u0111\u00e2y \u0110\u0103ng nh\u1eadp v\u00e0o Airflow t\u1ea1i http://localhost:8088 , account airflow , password airflow , c\u00e1c b\u1ea1n s\u1ebd th\u1ea5y m\u1ed9t DAG v\u1edbi t\u00ean db_to_offline_store , 2 DAG b\u00ean d\u01b0\u1edbi ch\u00ednh l\u00e0 nh\u1eefng pipeline c\u00f2n l\u1ea1i trong data pipelines (\u0111\u1ec1 c\u1eadp \u1edf b\u00ean d\u01b0\u1edbi). \u0110\u1eb7t Airflow Variable MLOPS_CRASH_COURSE_CODE_DIR b\u1eb1ng \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i t\u1edbi folder mlops-crash-course-code/ . Tham kh\u1ea3o h\u01b0\u1edbng d\u1eabn n\u00e0y v\u1ec1 c\u00e1ch \u0111\u1eb7t Airflow Variable. Info Airflow Variable MLOPS_CRASH_COURSE_CODE_DIR \u0111\u01b0\u1ee3c d\u00f9ng trong file data_pipeline/dags/utils.py . Variable n\u00e0y ch\u1ee9a \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i t\u1edbi folder mlops-crash-course-code/ , v\u00ec DockerOperator y\u00eau c\u1ea7u Mount Source ph\u1ea3i l\u00e0 \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i. K\u00edch ho\u1ea1t data pipeline v\u00e0 \u0111\u1ee3i k\u1ebft qu\u1ea3 Xem th\u1ee9 t\u1ef1 c\u00e1c task c\u1ee7a pipeline n\u00e0y nh\u01b0 sau: T\u01b0\u01a1ng t\u1ef1 nh\u01b0 ETL pipeline, ch\u00fang ta s\u1ebd code ti\u1ebfp Feast materialize pipeline v\u00e0 Stream to stores pipeline nh\u01b0 b\u00ean d\u01b0\u1edbi. Feast materialize pipeline Materialize d\u1eef li\u1ec7u t\u1eeb offline qua online gi\u00fap l\u00e0m m\u1edbi d\u1eef li\u1ec7u \u1edf online store data_pipeline/dags/materialize_offline_to_online.py 1 2 3 4 5 6 7 8 9 10 11 12 13 with DAG ( dag_id = \"materlize_offline_to_online\" , default_args = DefaultConfig . DEFAULT_DAG_ARGS , schedule_interval = \"@once\" , start_date = pendulum . datetime ( 2022 , 1 , 1 , tz = \"UTC\" ), catchup = False , tags = [ \"data_pipeline\" ], ) as dag : materialize_task = DockerOperator ( task_id = \"materialize_task\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , command = \"/bin/bash ./scripts/feast_helper.sh materialize\" , ) Stream pipeline Trong ph\u1ea7n n\u00e0y, ch\u00fang ta s\u1ebd l\u00e0m m\u1edbi features b\u1eb1ng c\u00e1ch ghi d\u1eef li\u1ec7u tr\u1ef1c ti\u1ebfp t\u1eeb stream source v\u00e0o offline v\u00e0 online store . \u1ede b\u00e0i tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 ch\u1ea1y Kafka stream. \u0110o\u1ea1n code d\u01b0\u1edbi \u0111\u00e2y s\u1ebd th\u1ef1c hi\u1ec7n t\u00e1c v\u1ee5 \u0111\u1ecdc v\u00e0 x\u1eed l\u00fd data t\u1eeb Kafka stream v\u00e0 l\u01b0u v\u00e0o offline store v\u00e0 online store. Khi b\u1ea1n s\u1eed d\u1ee5ng th\u01b0 vi\u1ec7n Feast trong \u0111o\u1ea1n code training hay inference \u0111\u1ec3 \u0111\u1ecdc features, b\u1ea1n s\u1ebd th\u1ea5y features \u0111\u01b0\u1ee3c c\u1eadp nh\u1eadt m\u1edbi li\u00ean t\u1ee5c. C\u00e1c \u0111o\u1ea1n code training v\u00e0 inference n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c h\u01b0\u1edbng d\u1eabn trong c\u00e1c b\u00e0i ti\u1ebfp theo. data_pipeline/dags/stream_to_stores.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 with DAG ( dag_id = \"stream_to_stores\" , default_args = DefaultConfig . DEFAULT_DAG_ARGS , schedule_interval = \"@once\" , start_date = pendulum . datetime ( 2022 , 1 , 1 , tz = \"UTC\" ), catchup = False , tags = [ \"data_pipeline\" ], ) as dag : stream_to_online_task = DockerOperator ( task_id = \"stream_to_online_task\" , command = \"/bin/bash -c 'cd src/stream_to_stores && python ingest.py --store online'\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , ) stream_to_offline_task = DockerOperator ( task_id = \"stream_to_offline_task\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , command = \"/bin/bash -c 'cd src/stream_to_stores && python ingest.py --store offline'\" , ) T\u1ed5ng k\u1ebft \u1ede b\u00e0i h\u1ecdc n\u00e0y, ch\u00fang ta \u0111\u00e3 s\u1eed d\u1ee5ng Feast SDK \u0111\u1ec3 l\u01b0u tr\u1eef v\u00e0 l\u1ea5y feature t\u1eeb feature store. \u0110\u1ec3 \u0111\u1ea3m b\u1ea3o feature lu\u00f4n \u1edf tr\u1ea1ng th\u00e1i m\u1edbi nh\u1ea5t c\u00f3 th\u1ec3, ch\u00fang ta c\u0169ng \u0111\u00e3 x\u00e2y d\u1ef1ng c\u00e1c Airflow pipeline \u0111\u1ec3 c\u1eadp nh\u1eadt d\u1eef li\u1ec7u \u0111\u1ecbnh k\u1ef3 cho c\u00e1c store. Ch\u00fang ta c\u0169ng ho\u00e0n th\u00e0nh chu\u1ed7i b\u00e0i v\u1ec1 data pipeline, hy v\u1ecdng b\u1ea1n c\u00f3 th\u1ec3 v\u1eadn d\u1ee5ng c\u00e1c ki\u1ebfn th\u1ee9c \u0111\u00e3 h\u1ecdc \u0111\u1ec3 v\u1eadn h\u00e0nh hi\u1ec7u qu\u1ea3 c\u00e1c lu\u1ed3ng d\u1eef li\u1ec7u v\u00e0 lu\u1ed3ng feature c\u1ee7a m\u00ecnh. T\u00e0i li\u1ec7u tham kh\u1ea3o https://feast.dev/ https://airflow.apache.org/docs/apache-airflow/stable/tutorial/index.html","title":"X\u00e2y d\u1ef1ng pipeline"},{"location":"mlops-crash-course/data-pipeline/xay-dung-data-pipeline.html#gioi-thieu","text":"\u1ede b\u00e0i h\u1ecdc tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 l\u00e0m quen v\u1edbi feature store, Feast v\u00e0 d\u00f9ng command feast apply \u0111\u1ec3 t\u1ea1o ra feature definition \u1edf \u0111\u01b0\u1eddng d\u1eabn data_pipeline/feature_repo/registry/local_registry.db . Trong b\u00e0i h\u1ecdc n\u00e0y ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng folder n\u00e0y \u0111\u1ec3 c\u1ea5u h\u00ecnh client store giao ti\u1ebfp v\u1edbi feature store nh\u01b0 sau: 1 2 from feast import FeatureStore store = FeatureStore ( repo_path = \"../feature_repo\" ) # (1) Kh\u1edfi t\u1ea1o client store \u0111\u1ec3 giao ti\u1ebfp v\u1edbi feature store Client n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u1edf nhi\u1ec1u b\u01b0\u1edbc kh\u00e1c nhau bao g\u1ed3m 1 , 2 , 3 , 4 , 5 nh\u01b0 h\u00ecnh d\u01b0\u1edbi \u0111\u00e2y:","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/data-pipeline/xay-dung-data-pipeline.html#moi-truong-phat-trien","text":"Ngo\u00e0i Feast, b\u00e0i h\u1ecdc n\u00e0y s\u1ebd s\u1eed d\u1ee5ng th\u00eam Airflow, b\u1ea1n v\u00e0o repo mlops-crash-course-platform/ v\u00e0 start service n\u00e0y nh\u01b0 sau: bash run.sh airflow up","title":"M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n"},{"location":"mlops-crash-course/data-pipeline/xay-dung-data-pipeline.html#cac-tuong-tac-chinh-voi-feast","text":"Ch\u00fang ta c\u00f3 6 t\u01b0\u01a1ng t\u00e1c ch\u00ednh v\u1edbi Feast nh\u01b0 sau: 1. Materialize feature t\u1eeb offline sang online store \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o online store l\u01b0u tr\u1eef feature m\u1edbi nh\u1ea5t data_pipeline/scripts/feast_helper.sh 1 2 cd feature_repo feast materialize - incremental $ ( date +% Y -% m -% d ) Tip \u0110\u1ec3 hi\u1ec3u r\u00f5 h\u01a1n v\u1ec1 materialize , gi\u1ea3 s\u1eed r\u1eb1ng \u1edf offline store ch\u00fang ta c\u00f3 3 record c\u1ee7a ID 1001 nh\u01b0 sau: datetime driver_id conv_rate acc_rate avg_daily_trips created 2021-07-13 11:00:00+00:00 1001 0.852406 0.059147 340 2021-07-28 11:08:04.802 2021-08-10 12:00:00+00:00 1001 0.571599 0.244896 752 2021-07-28 11:08:04.802 2021-07-13 13:00:00+00:00 1001 0.929023 0.479821 716 2021-07-28 11:08:04.802 Khi ch\u00fang ta ch\u1ea1y command feast materialize 2021-08-07T00:00:00 , th\u00ec d\u1eef li\u1ec7u c\u00f3 datetime m\u1edbi nh\u1ea5t m\u00e0 tr\u01b0\u1edbc th\u1eddi \u0111i\u1ec3m 2021-08-07T00:00:00 s\u1ebd \u0111\u01b0\u1ee3c c\u1eadp nh\u1eadt v\u00e0o online store. \u0110\u00f3 ch\u00ednh l\u00e0 record th\u1ee9 3 \u1edf b\u1ea3ng tr\u00ean. datetime driver_id conv_rate acc_rate avg_daily_trips created 2021-07-13 13:00:00+00:00 1001 0.929023 0.479821 716 2021-07-28 11:08:04.802 2. Data scientist, training pipeline ho\u1eb7c offline batch serving pipeline k\u00e9o features v\u1ec1 \u0111\u1ec3 train model data_pipeline/examples/get_historical_features.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 entity_df = pd . DataFrame . from_dict ( { \"driver_id\" : [ 1001 , 1002 , 1003 ], \"datetime\" : [ datetime ( 2022 , 5 , 11 , 11 , 59 , 59 ), datetime ( 2022 , 6 , 12 , 1 , 15 , 10 ), datetime . now (), ], } ) training_df = store . get_historical_features ( entity_df = entity_df , features = [ \"driver_stats:acc_rate\" , \"driver_stats:conv_rate\" ], ) . to_df () print ( training_df . head ()) 3. K\u00e9o features m\u1edbi nh\u1ea5t t\u01b0\u01a1ng \u1ee9ng v\u1edbi c\u00e1c IDs trong request API \u0111\u1ec3 cho qua model d\u1ef1 \u0111o\u00e1n data_pipeline/examples/get_online_features.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 features = store . get_online_features ( features = [ \"driver_stats:acc_rate\" , \"driver_stats:conv_rate\" ], entity_rows = [ { \"driver_id\" : 1001 , } ], ) . to_dict ( include_event_timestamps = True ) def print_online_features ( features ): for key , value in sorted ( features . items ()): print ( key , \" : \" , value ) print_online_features ( features ) 4. \u0110\u1ea9y stream feature v\u00e0o offline store data_pipeline/src/stream_to_stores/processor.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def preprocess_fn ( rows : pd . DataFrame ): print ( f \"df columns: { rows . columns } \" ) print ( f \"df size: { rows . size } \" ) print ( f \"df preview: \\n { rows . head () } \" ) return rows ingestion_config = SparkProcessorConfig ( mode = \"spark\" , source = \"kafka\" , spark_session = spark , processing_time = \"30 seconds\" , query_timeout = 15 ) sfv = store . get_stream_feature_view ( \"driver_stats_stream\" ) processor = get_stream_processor_object ( config = ingestion_config , fs = store , sfv = sfv , preprocess_fn = preprocess_fn , ) processor . ingest_stream_feature_view ( PushMode . OFFLINE ) 5. \u0110\u1ea9y stream feature v\u00e0o online store 1 processor . ingest_stream_feature_view () 7. ETL (Extract, Transform, Load) pipeline c\u1eadp nh\u1eadt d\u1eef li\u1ec7u c\u1ee7a offline store Tip \u1ede t\u01b0\u01a1ng t\u00e1c 2., th\u00f4ng th\u01b0\u1eddng c\u00e1c Data Scientist s\u1ebd k\u00e9o d\u1eef li\u1ec7u t\u1eeb feature store \u0111\u1ec3: th\u1ef1c hi\u1ec7n POC th\u1eed nghi\u1ec7m v\u1edbi c\u00e1c feature kh\u00e1c nh\u1eb1m m\u1ee5c \u0111\u00edch c\u1ea3i thi\u1ec7n model \u1ede c\u00f4ng \u0111o\u1ea1n x\u00e2y d\u1ef1ng data pipeline, ch\u00fang ta s\u1ebd x\u00e2y d\u1ef1ng pipeline cho c\u00e1c t\u01b0\u01a1ng t\u00e1c 1., 4., 5., 7.","title":"C\u00e1c t\u01b0\u01a1ng t\u00e1c ch\u00ednh v\u1edbi Feast"},{"location":"mlops-crash-course/data-pipeline/xay-dung-data-pipeline.html#xay-dung-cac-pipelines","text":"","title":"X\u00e2y d\u1ef1ng c\u00e1c pipelines"},{"location":"mlops-crash-course/data-pipeline/xay-dung-data-pipeline.html#etl-pipeline","text":"\u0110\u1ec3 t\u1ea1o ra m\u1ed9t Airflow pipeline, th\u00f4ng th\u01b0\u1eddng ch\u00fang ta s\u1ebd l\u00e0m theo tr\u00ecnh t\u1ef1 sau: \u0110\u1ecbnh ngh\u0129a DAG cho pipeline (line 1-8) Vi\u1ebft c\u00e1c task cho pipeline, v\u00ed d\u1ee5: ingest_task , clean_task v\u00e0 explore_and_validate_task (line 9-25) Vi\u1ebft th\u1ee9 t\u1ef1 ch\u1ea1y c\u00e1c task (line 27) Ch\u1ea1y l\u1ec7nh sau \u0111\u1ec3 build Docker image cho c\u00e1c pipeline component, v\u00e0 copy file code DAG sang folder airflow/run_env/dags/data_pipeline c\u1ee7a repo clone t\u1eeb MLOps Crash course platform cd data_pipeline make build_image # \u0110\u1ea3m b\u1ea3o Airflow server \u0111\u00e3 ch\u1ea1y make deploy_dags # (1) Copy data_pipeline/dags/* v\u00e0o folder dags c\u1ee7a Airflow DAG d\u01b0\u1edbi \u0111\u00e2y th\u1ec3 hi\u1ec7n ETL pipeline. data_pipeline/dags/db_to_offline_store.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 with DAG ( dag_id = \"db_to_offline_store\" , # (1) default_args = DefaultConfig . DEFAULT_DAG_ARGS , # (2) schedule_interval = \"@once\" , # (3) start_date = pendulum . datetime ( 2022 , 1 , 1 , tz = \"UTC\" ), # (4) catchup = False , # (5) tags = [ \"data_pipeline\" ], ) as dag : ingest_task = DockerOperator ( task_id = \"ingest_task\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , command = \"/bin/bash -c 'cd src/db_to_offline_store && python ingest.py'\" , # (6) ) clean_task = DockerOperator ( task_id = \"clean_task\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , command = \"/bin/bash -c 'cd src/db_to_offline_store && python clean.py'\" , ) explore_and_validate_task = DockerOperator ( task_id = \"explore_and_validate_task\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , command = \"/bin/bash -c 'cd src/db_to_offline_store && python explore_and_validate.py'\" , ) ingest_task >> clean_task >> explore_and_validate_task # (7) \u0110\u1ecbnh ngh\u0129a t\u00ean pipeline hi\u1ec3n th\u1ecb \u1edf tr\u00ean Airflow dashboard \u0110\u1ecbnh ngh\u0129a pipeline owner, s\u1ed1 l\u1ea7n retry pipeline, v\u00e0 kho\u1ea3ng th\u1eddi gian gi\u1eefa c\u00e1c l\u1ea7n retry L\u1ecbch ch\u1ea1y pipeline, \u1edf \u0111\u00e2y @once l\u00e0 m\u1ed9t l\u1ea7n ch\u1ea1y, b\u1ea1n c\u00f3 th\u1ec3 thay b\u1eb1ng cron expression v\u00ed d\u1ee5 nh\u01b0 0 0 1 * * Ng\u00e0y b\u1eaft \u0111\u1ea7u ch\u1ea1y pipeline theo m\u00fai gi\u1edd UTC N\u1ebfu start_date l\u00e0 ng\u00e0y 01/01/2022, ng\u00e0y deploy/turn on pipeline l\u00e0 ng\u00e0y 02/02/2022, v\u00e0 schedule_interval l\u00e0 @daily th\u00ec s\u1ebd kh\u00f4ng ch\u1ea1y c\u00e1c ng\u00e0y tr\u01b0\u1edbc 02/02/2022 n\u1eefa Command ch\u1ea1y trong docker container cho b\u01b0\u1edbc n\u00e0y \u0110\u1ecbnh ngh\u0129a th\u1ee9 t\u1ef1 ch\u1ea1y c\u00e1c b\u01b0\u1edbc c\u1ee7a pipeline: \u0111\u1ea7u ti\u00ean l\u00e0 ingest sau \u0111\u00f3 t\u1edbi clean v\u00e0 cu\u1ed1i c\u00f9ng l\u00e0 explore_and_validate Info Do ch\u00fang ta d\u00f9ng DockerOperator \u0111\u1ec3 t\u1ea1o task n\u00ean c\u1ea7n ph\u1ea3i build image ch\u1ee9a code v\u00e0 m\u00f4i tr\u01b0\u1eddng tr\u01b0\u1edbc, sau \u0111\u00f3 s\u1ebd truy\u1ec1n t\u00ean image v\u00e0o DEFAULT_DOCKER_OPERATOR_ARGS trong t\u1eebng pipeline component (v\u00ed d\u1ee5 nh\u01b0 line 11). Dockerfile \u0111\u1ec3 build image b\u1ea1n c\u00f3 th\u1ec3 tham kh\u1ea3o t\u1ea1i data_pipeline/deployment/Dockerfile Bi\u1ebfn DefaultConfig.DEFAULT_DOCKER_OPERATOR_ARGS ch\u1ee9a c\u00e1c config nh\u01b0 sau: data_pipeline/dags/utils.py 1 2 3 4 5 6 7 8 9 10 11 12 DEFAULT_DOCKER_OPERATOR_ARGS = { \"image\" : f \" { AppConst . DOCKER_USER } /mlops_crash_course/data_pipeline:latest\" , # (1) \"api_version\" : \"auto\" , # (2) \"auto_remove\" : True , # (3) \"mounts\" : [ Mount ( source = AppPath . FEATURE_REPO . absolute () . as_posix (), # (4) target = \"/data_pipeline/feature_repo\" , # (5) type = \"bind\" , # (6) ), ], } Docker image d\u00f9ng cho task T\u1ef1 \u0111\u1ed9ng x\u00e1c \u0111\u1ecbnh Docker engine API version T\u1ef1 \u0111\u1ed9ng d\u1ecdn d\u1eb9p container sau khi exit Folder \u1edf m\u00e1y local, b\u1eaft bu\u1ed9c l\u00e0 \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i Folder n\u1eb1m trong docker container Ki\u1ec3u bind, \u0111\u1ecdc th\u00eam \u1edf \u0111\u00e2y \u0110\u0103ng nh\u1eadp v\u00e0o Airflow t\u1ea1i http://localhost:8088 , account airflow , password airflow , c\u00e1c b\u1ea1n s\u1ebd th\u1ea5y m\u1ed9t DAG v\u1edbi t\u00ean db_to_offline_store , 2 DAG b\u00ean d\u01b0\u1edbi ch\u00ednh l\u00e0 nh\u1eefng pipeline c\u00f2n l\u1ea1i trong data pipelines (\u0111\u1ec1 c\u1eadp \u1edf b\u00ean d\u01b0\u1edbi). \u0110\u1eb7t Airflow Variable MLOPS_CRASH_COURSE_CODE_DIR b\u1eb1ng \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i t\u1edbi folder mlops-crash-course-code/ . Tham kh\u1ea3o h\u01b0\u1edbng d\u1eabn n\u00e0y v\u1ec1 c\u00e1ch \u0111\u1eb7t Airflow Variable. Info Airflow Variable MLOPS_CRASH_COURSE_CODE_DIR \u0111\u01b0\u1ee3c d\u00f9ng trong file data_pipeline/dags/utils.py . Variable n\u00e0y ch\u1ee9a \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i t\u1edbi folder mlops-crash-course-code/ , v\u00ec DockerOperator y\u00eau c\u1ea7u Mount Source ph\u1ea3i l\u00e0 \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i. K\u00edch ho\u1ea1t data pipeline v\u00e0 \u0111\u1ee3i k\u1ebft qu\u1ea3 Xem th\u1ee9 t\u1ef1 c\u00e1c task c\u1ee7a pipeline n\u00e0y nh\u01b0 sau: T\u01b0\u01a1ng t\u1ef1 nh\u01b0 ETL pipeline, ch\u00fang ta s\u1ebd code ti\u1ebfp Feast materialize pipeline v\u00e0 Stream to stores pipeline nh\u01b0 b\u00ean d\u01b0\u1edbi.","title":"ETL pipeline"},{"location":"mlops-crash-course/data-pipeline/xay-dung-data-pipeline.html#feast-materialize-pipeline","text":"Materialize d\u1eef li\u1ec7u t\u1eeb offline qua online gi\u00fap l\u00e0m m\u1edbi d\u1eef li\u1ec7u \u1edf online store data_pipeline/dags/materialize_offline_to_online.py 1 2 3 4 5 6 7 8 9 10 11 12 13 with DAG ( dag_id = \"materlize_offline_to_online\" , default_args = DefaultConfig . DEFAULT_DAG_ARGS , schedule_interval = \"@once\" , start_date = pendulum . datetime ( 2022 , 1 , 1 , tz = \"UTC\" ), catchup = False , tags = [ \"data_pipeline\" ], ) as dag : materialize_task = DockerOperator ( task_id = \"materialize_task\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , command = \"/bin/bash ./scripts/feast_helper.sh materialize\" , )","title":"Feast materialize pipeline"},{"location":"mlops-crash-course/data-pipeline/xay-dung-data-pipeline.html#stream-pipeline","text":"Trong ph\u1ea7n n\u00e0y, ch\u00fang ta s\u1ebd l\u00e0m m\u1edbi features b\u1eb1ng c\u00e1ch ghi d\u1eef li\u1ec7u tr\u1ef1c ti\u1ebfp t\u1eeb stream source v\u00e0o offline v\u00e0 online store . \u1ede b\u00e0i tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 ch\u1ea1y Kafka stream. \u0110o\u1ea1n code d\u01b0\u1edbi \u0111\u00e2y s\u1ebd th\u1ef1c hi\u1ec7n t\u00e1c v\u1ee5 \u0111\u1ecdc v\u00e0 x\u1eed l\u00fd data t\u1eeb Kafka stream v\u00e0 l\u01b0u v\u00e0o offline store v\u00e0 online store. Khi b\u1ea1n s\u1eed d\u1ee5ng th\u01b0 vi\u1ec7n Feast trong \u0111o\u1ea1n code training hay inference \u0111\u1ec3 \u0111\u1ecdc features, b\u1ea1n s\u1ebd th\u1ea5y features \u0111\u01b0\u1ee3c c\u1eadp nh\u1eadt m\u1edbi li\u00ean t\u1ee5c. C\u00e1c \u0111o\u1ea1n code training v\u00e0 inference n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c h\u01b0\u1edbng d\u1eabn trong c\u00e1c b\u00e0i ti\u1ebfp theo. data_pipeline/dags/stream_to_stores.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 with DAG ( dag_id = \"stream_to_stores\" , default_args = DefaultConfig . DEFAULT_DAG_ARGS , schedule_interval = \"@once\" , start_date = pendulum . datetime ( 2022 , 1 , 1 , tz = \"UTC\" ), catchup = False , tags = [ \"data_pipeline\" ], ) as dag : stream_to_online_task = DockerOperator ( task_id = \"stream_to_online_task\" , command = \"/bin/bash -c 'cd src/stream_to_stores && python ingest.py --store online'\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , ) stream_to_offline_task = DockerOperator ( task_id = \"stream_to_offline_task\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , command = \"/bin/bash -c 'cd src/stream_to_stores && python ingest.py --store offline'\" , )","title":"Stream pipeline"},{"location":"mlops-crash-course/data-pipeline/xay-dung-data-pipeline.html#tong-ket","text":"\u1ede b\u00e0i h\u1ecdc n\u00e0y, ch\u00fang ta \u0111\u00e3 s\u1eed d\u1ee5ng Feast SDK \u0111\u1ec3 l\u01b0u tr\u1eef v\u00e0 l\u1ea5y feature t\u1eeb feature store. \u0110\u1ec3 \u0111\u1ea3m b\u1ea3o feature lu\u00f4n \u1edf tr\u1ea1ng th\u00e1i m\u1edbi nh\u1ea5t c\u00f3 th\u1ec3, ch\u00fang ta c\u0169ng \u0111\u00e3 x\u00e2y d\u1ef1ng c\u00e1c Airflow pipeline \u0111\u1ec3 c\u1eadp nh\u1eadt d\u1eef li\u1ec7u \u0111\u1ecbnh k\u1ef3 cho c\u00e1c store. Ch\u00fang ta c\u0169ng ho\u00e0n th\u00e0nh chu\u1ed7i b\u00e0i v\u1ec1 data pipeline, hy v\u1ecdng b\u1ea1n c\u00f3 th\u1ec3 v\u1eadn d\u1ee5ng c\u00e1c ki\u1ebfn th\u1ee9c \u0111\u00e3 h\u1ecdc \u0111\u1ec3 v\u1eadn h\u00e0nh hi\u1ec7u qu\u1ea3 c\u00e1c lu\u1ed3ng d\u1eef li\u1ec7u v\u00e0 lu\u1ed3ng feature c\u1ee7a m\u00ecnh.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/data-pipeline/xay-dung-data-pipeline.html#tai-lieu-tham-khao","text":"https://feast.dev/ https://airflow.apache.org/docs/apache-airflow/stable/tutorial/index.html","title":"T\u00e0i li\u1ec7u tham kh\u1ea3o"},{"location":"mlops-crash-course/model-serving/trien-khai-model-serving.html","text":"Photo by Jay Wennington on Unsplash Gi\u1edbi thi\u1ec7u Sau khi train \u0111\u01b0\u1ee3c m\u1ed9t model t\u1ed1t, ch\u00fang ta c\u1ea7n tri\u1ec3n khai model \u0111\u00f3 \u0111\u1ec3 th\u1ef1c hi\u1ec7n inference. C\u00f3 hai h\u00ecnh th\u1ee9c tri\u1ec3n khai model ph\u1ed5 bi\u1ebfn l\u00e0 batch serving v\u00e0 online serving . C\u1ea3 batch serving v\u00e0 online serving \u0111\u1ec1u c\u00f3 th\u1ec3 x\u1eed l\u00fd m\u1ed9t ho\u1eb7c nhi\u1ec1u requests. Trong khi batch serving \u0111\u01b0\u1ee3c t\u1ed1i \u01b0u \u0111\u1ec3 x\u1eed l\u00fd s\u1ed1 l\u01b0\u1ee3ng l\u1edbn c\u00e1c requests, th\u01b0\u1eddng \u0111\u1ec3 ch\u1ea1y c\u00e1c model ph\u1ee9c t\u1ea1p, th\u00ec online serving \u0111\u01b0\u1ee3c t\u1ed1i \u01b0u \u0111\u1ec3 gi\u1ea3m th\u1eddi gian x\u1eed l\u00fd trong m\u1ed9t l\u1ea7n th\u1ef1c thi. Batch serving th\u01b0\u1eddng \u0111\u01b0\u1ee3c l\u00ean l\u1ecbch theo chu k\u00ec v\u00e0 ch\u1ea1y offline. Online serving th\u01b0\u1eddng \u0111\u01b0\u1ee3c tri\u1ec3n khai l\u00ean m\u1ed9t server d\u01b0\u1edbi d\u1ea1ng RESTful APIs \u0111\u1ec3 ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 g\u1ecdi t\u1edbi. Trong b\u00e0i n\u00e0y, ch\u00fang ta s\u1ebd t\u00ecm hi\u1ec3u c\u00e1ch tri\u1ec3n khai model \u1edf c\u1ea3 hai h\u00ecnh th\u1ee9c batch serving v\u00e0 online serving. M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n C\u00e1c b\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 c\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n: C\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng Python 3.9 m\u1edbi v\u1edbi c\u00e1c th\u01b0 vi\u1ec7n c\u1ea7n thi\u1ebft trong file model_serving/dev_requirements.txt \u0110\u1eb7t environment variable MODEL_SERVING_DIR \u1edf terminal b\u1ea1n d\u00f9ng b\u1eb1ng \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i t\u1edbi folder model_serving , v\u00e0 MLFLOW_TRACKING_URI b\u1eb1ng URL c\u1ee7a MLflow server. Hai env var n\u00e0y h\u1ed7 tr\u1ee3 ch\u1ea1y python code \u1edf folder model_serving/src trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n. cd mlops-crash-course-code/model_serving export MODEL_SERVING_DIR = $( pwd ) export MLFLOW_TRACKING_URI = \"http://localhost:5000\" C\u00e1c MLOps tools \u0111\u01b0\u1ee3c d\u00f9ng trong b\u00e0i n\u00e0y bao g\u1ed3m: Feast: truy xu\u1ea5t Feature Store MLflow: ML Metadata Store, Model Registry Airflow: \u0111i\u1ec1u ph\u1ed1i batch serving pipeline Note Trong qu\u00e1 tr\u00ecnh ch\u1ea1y code cho t\u1ea5t c\u1ea3 c\u00e1c ph\u1ea7n d\u01b0\u1edbi \u0111\u00e2y, gi\u1ea3 s\u1eed r\u1eb1ng folder g\u1ed1c n\u01a1i ch\u00fang ta l\u00e0m vi\u1ec7c l\u00e0 folder model_serving . Batch serving Batch serving \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf v\u1edbi input l\u00e0 data file \u1edf local ho\u1eb7c cloud. B\u1ea1n c\u00f3 th\u1ec3 ch\u1ec9 c\u1ea7n vi\u1ebft v\u00e0i script \u0111\u1ec3 load input, load model, ch\u1ea1y predictions v\u00e0 l\u01b0u l\u1ea1i ch\u00fang. Tuy nhi\u00ean, ch\u00fang ta c\u0169ng c\u00f3 th\u1ec3 coi batch serving l\u00e0 m\u1ed9t pipeline, s\u1eed d\u1ee5ng Airflow \u0111\u1ec3 qu\u1ea3n l\u00fd v\u00e0 l\u00ean l\u1ecbch cho qu\u00e1 tr\u00ecnh ch\u1ea1y batch serving. Batch serving pipeline g\u1ed3m c\u00e1c tasks nh\u01b0 h\u00ecnh d\u01b0\u1edbi: flowchart LR n1[1. C\u1eadp nh\u1eadt<br>Feature Store] --> n2[2. Data<br>extraction] --> n3[3. Batch<br>prediction] C\u1eadp nh\u1eadt Feature Store Gi\u1ea3 s\u1eed n\u01a1i ch\u1ea1y Batch serving l\u00e0 \u1edf m\u1ed9t server v\u1edbi infrastructure \u0111\u1ee7 m\u1ea1nh cho vi\u1ec7c t\u1ed1i \u01b0u batch serving. Khi ch\u1ea1y batch serving, data \u0111\u01b0\u1ee3c l\u1ea5y t\u1eeb Feature Store \u0111\u1ec3 ph\u1ee5c v\u1ee5 cho inference. Do \u0111\u00f3, Feature Store c\u1ea7n \u0111\u01b0\u1ee3c c\u1eadp nh\u1eadt tr\u00ean server n\u01a1i batch serving \u0111\u01b0\u1ee3c tri\u1ec3n khai. Task n\u00e0y \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n gi\u1ed1ng nh\u01b0 task C\u1eadp nh\u1eadt Feature Store \u1edf training pipeline. B\u1ea1n c\u00f3 th\u1ec3 xem l\u1ea1i b\u00e0i X\u00e2y d\u1ef1ng training pipeline . B\u1ea1n h\u00e3y l\u00e0m theo c\u00e1c b\u01b0\u1edbc d\u01b0\u1edbi \u0111\u00e2y \u0111\u1ec3 c\u1eadp nh\u1eadt Feature Store. Code c\u1ee7a Feature Store n\u1eb1m t\u1ea1i data_pipeline/feature_repo . \u0110\u1ec3 tri\u1ec3n khai sang batch serving pipeline, ch\u00fang ta s\u1ebd copy code t\u1eeb data_pipeline/feature_repo sang model_serving/feature_repo . B\u1ea1n h\u00e3y ch\u1ea1y c\u00e1c l\u1ec7nh sau. cd ../data_pipeline make deploy_feature_repo # (1) cd ../model_serving cd feature_repo feast apply # (2) cd .. Tri\u1ec3n khai code c\u1ee7a Feature Store C\u1eadp nh\u1eadt Feature Registry v\u00e0 Offline Feature Store c\u1ee7a Feast Data extraction Task Data extraction c\u00f3 \u0111\u1ea7u v\u00e0o v\u00e0 \u0111\u1ea7u ra nh\u01b0 sau: \u0110\u1ea7u v\u00e0o: data \u0111\u01b0\u1ee3c \u0111\u1ecdc t\u1eeb Offline Feature Store. Data s\u1ebd \u0111\u01b0\u1ee3c x\u1eed l\u00fd theo format m\u00e0 model y\u00eau c\u1ea7u \u0111\u1ec3 ti\u1ec7n cho task Batch prediction ti\u1ebfp theo \u0110\u1ea7u ra: data \u0111\u00e3 \u0111\u01b0\u1ee3c x\u1eed l\u00fd v\u00e0 \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o disk Code c\u1ee7a task n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i model_serving/src/data_extraction.py . model_serving/src/data_extraction.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 fs = feast . FeatureStore ( repo_path = AppPath . FEATURE_REPO ) # (1) orders = pd . read_csv ( batch_input_file , sep = \" \\t \" ) # (2) orders [ \"event_timestamp\" ] = pd . to_datetime ( orders [ \"event_timestamp\" ]) batch_input_df = fs . get_historical_features ( # (3) entity_df = orders , features = [ \"driver_stats:conv_rate\" , # (4) \"driver_stats:acc_rate\" , \"driver_stats:avg_daily_trips\" , ], ) . to_df () batch_input_df = batch_input_df . drop ([ \"event_timestamp\" , \"driver_id\" ], axis = 1 ) # (5) to_parquet ( batch_input_df , AppPath . BATCH_INPUT_PQ ) # (6) Kh\u1edfi t\u1ea1o k\u1ebft n\u1ed1i t\u1edbi Feature Store \u0110\u1ecdc file data n\u1eb1m t\u1ea1i model_serving/data/batch_request.csv ch\u1ee9a c\u00e1c records m\u00e0 ch\u00fang ta mu\u1ed1n ch\u1ea1y prediction L\u1ea5y ra c\u00e1c features conv_rate , acc_rate v\u00e0 avg_daily_trips driver_stats l\u00e0 t\u00ean FeatureView m\u00e0 ch\u00fang ta \u0111\u00e3 \u0111\u1ecbnh ngh\u0129a t\u1ea1i data_pipeline/feature_repo/features.py B\u1ecf c\u00e1c c\u1ed9t kh\u00f4ng c\u1ea7n thi\u1ebft L\u01b0u batch_input_df v\u00e0o disk B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 test th\u1eed code. Ch\u1ea1y code cd src python data_extraction.py cd .. Ki\u1ec3m tra folder model_serving/artifacts , b\u1ea1n s\u1ebd th\u1ea5y file batch_input.parquet Batch prediction Task Batch prediction c\u00f3 \u0111\u1ea7u v\u00e0o v\u00e0 \u0111\u1ea7u ra nh\u01b0 sau: \u0110\u1ea7u v\u00e0o: config file ch\u1ee9a th\u00f4ng tin v\u1ec1 model \u0111\u01b0\u1ee3c d\u00f9ng \u0110\u1ea7u ra: k\u1ebft qu\u1ea3 predictions \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o disk Model \u0111\u01b0\u1ee3c d\u00f9ng l\u00e0 model \u0111\u00e3 \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o MLflow Model Registry \u1edf task Model validation trong b\u00e0i X\u00e2y d\u1ef1ng training pipeline . Trong task Model validation \u0111\u00f3, th\u00f4ng tin v\u1ec1 model \u0111\u00e3 \u0111\u0103ng k\u00fd \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i file training_pipeline/artifacts/registered_model_version.json . File n\u00e0y c\u1ea7n \u0111\u01b0\u1ee3c upload v\u00e0o m\u1ed9t Storage n\u00e0o \u0111\u00f3 trong t\u1ed5 ch\u1ee9c \u0111\u1ec3 c\u00e1c task kh\u00e1c, c\u1ee5 th\u1ec3 l\u00e0 cho batch serving v\u00e0 online serving \u1edf trong b\u00e0i n\u00e0y, c\u00f3 th\u1ec3 bi\u1ebft \u0111\u01b0\u1ee3c model n\u00e0o l\u00e0 t\u1ed1t nh\u1ea5t. V\u00ec ch\u00fang ta \u0111ang ph\u00e1t tri\u1ec3n c\u1ea3 training pipeline v\u00e0 model serving \u1edf local, n\u00ean b\u1ea1n ch\u1ec9 c\u1ea7n copy file training_pipeline/artifacts/registered_model_version.json sang model_serving/artifacts/registered_model_version.json . \u0110\u1ec3 l\u00e0m \u0111i\u1ec1u n\u00e0y, b\u1ea1n h\u00e3y ch\u1ea1y l\u1ec7nh sau. cd ../training_pipeline make deploy_registered_model_file cd ../model_serving Ti\u1ebfp theo, ch\u00fang ta s\u1ebd vi\u1ebft code cho task batch prediction. \u0110o\u1ea1n code n\u00e0y gi\u1ed1ng nh\u01b0 \u1edf task Model evaluation trong b\u00e0i X\u00e2y d\u1ef1ng training pipeline . Code c\u1ee7a task n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i model_serving/src/batch_prediction.py . model_serving/src/batch_prediction.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 mlflow_model = mlflow . pyfunc . load_model ( model_uri = model_uri ) # (1) batch_df = load_df ( AppPath . BATCH_INPUT_PQ ) # (2) model_signature = mlflow_model . metadata . signature # (3) feature_list = [] for name in model_signature . inputs . input_names (): feature_list . append ( name ) batch_df = batch_df [ feature_list ] # (4) preds = mlflow_model . predict ( batch_df ) # (5) batch_df [ \"pred\" ] = preds to_parquet ( batch_df , AppPath . BATCH_OUTPUT_PQ ) # (6) model_uri ch\u1ee9a URI c\u1ee7a model \u0111\u1ecdc t\u1eeb file model_serving/artifacts/registered_model_version.json Load batch input file \u0111\u01b0\u1ee3c l\u01b0u \u1edf task tr\u01b0\u1edbc, n\u1eb1m t\u1ea1i model_serving/artifacts/batch_input.parquet Load model signature S\u1eafp x\u1ebfp c\u00e1c features theo \u0111\u00fang th\u1ee9 t\u1ef1 m\u00e0 model y\u00eau c\u1ea7u Ch\u1ea1y inference L\u01b0u output v\u00e0o disk B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 test th\u1eed code. Ch\u1ea1y code cd src python batch_prediction.py cd .. Ki\u1ec3m tra folder model_serving/artifacts , b\u1ea1n s\u1ebd th\u1ea5y file batch_output.parquet Airflow DAG \u1ede ph\u1ea7n n\u00e0y, Airflow DAG s\u1ebd k\u1ebft n\u1ed1i c\u00e1c task tr\u00ean th\u00e0nh m\u1ed9t pipeline. Code \u0111\u1ecbnh ngh\u0129a Airflow DAG \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i model_serving/dags/batch_serving_dag.py . model_serving/dags/batch_serving_dag.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 with DAG ( dag_id = \"batch_serving_pipeline\" , # (1) # c\u00e1c argument kh\u00e1c ) as dag : feature_store_init_task = DockerOperator ( task_id = \"feature_store_init_task\" , command = \"bash -c 'cd feature_repo && feast apply'\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , ) data_extraction_task = DockerOperator ( task_id = \"data_extraction_task\" , command = \"bash -c 'cd src && python data_extraction.py'\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , ) # c\u00e1c task kh\u00e1c Chi ti\u1ebft v\u1ec1 nh\u1eefng \u0111i\u1ec3m quan tr\u1ecdng c\u1ea7n l\u01b0u \u00fd, m\u1eddi b\u1ea1n xem l\u1ea1i b\u00e0i X\u00e2y d\u1ef1ng training pipeline . Ti\u1ebfp theo, ch\u00fang ta c\u1ea7n build docker image mlopsvn/mlops_crash_course/model_serving:latest v\u00e0 tri\u1ec3n khai Airflow DAGs b\u1eb1ng c\u00e1ch c\u00e1c b\u01b0\u1edbc sau. \u0110\u0103ng nh\u1eadp v\u00e0o Airflow UI v\u1edbi t\u00e0i kho\u1ea3n v\u00e0 m\u1eadt kh\u1ea9u l\u00e0 airflow . \u0110\u1eb7t Airflow Variable MLOPS_CRASH_COURSE_CODE_DIR b\u1eb1ng \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i t\u1edbi folder mlops-crash-course-code/ Ch\u1ea1y l\u1ec7nh make build_image make deploy_dags # (1) Copy model_serving/dags/* v\u00e0o folder dags c\u1ee7a Airflow Tip \u0110\u1ecbnh ngh\u0129a v\u1ec1 c\u00e1c env vars \u0111\u01b0\u1ee3c d\u00f9ng trong qu\u00e1 tr\u00ecnh ch\u1ea1y Airflow DAG \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i model_serving/.env . B\u1ea1n c\u00f3 th\u1ec3 thay \u0111\u1ed5i n\u1ebfu c\u1ea7n. K\u00edch ho\u1ea1t batch serving pipeline v\u00e0 \u0111\u1ee3i k\u1ebft qu\u1ea3 Online serving Khi tri\u1ec3n khai Online serving hay Online serving service , th\u01b0\u1eddng th\u00ec b\u1ea1n s\u1ebd d\u00f9ng m\u1ed9t library \u0111\u1ec3 x\u00e2y d\u1ef1ng RESTful API, v\u00ed d\u1ee5 nh\u01b0 Flask ho\u1eb7c FastAPI trong Python. Trong ph\u1ea7n n\u00e0y, ch\u00fang ta s\u1ebd d\u00f9ng m\u1ed9t library chuy\u00ean \u0111\u01b0\u1ee3c d\u00f9ng cho vi\u1ec7c x\u00e2y d\u1ef1ng online serving cho ML models, \u0111\u00f3 l\u00e0 BentoML . Code c\u1ee7a online serving \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i model_serving/src/bentoml_service.py . model_serving/src/bentoml_service.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 mlflow_model = mlflow . pyfunc . load_model ( model_uri = model_uri ) # (1) model = mlflow_model . _model_impl # (2) bentoml_model = bentoml . sklearn . save_model ( # (3) model_name , # (4) model , signatures = { # (5) \"predict\" : { # (6) \"batchable\" : False , # (7) }, }, custom_objects = { # (8) \"feature_list\" : feature_list , # (9) }, ) feature_list = bentoml_model . custom_objects [ \"feature_list\" ] bentoml_runner = bentoml . sklearn . get ( bentoml_model . tag ) . to_runner () # (10) svc = bentoml . Service ( bentoml_model . tag . name , runners = [ bentoml_runner ]) fs = feast . FeatureStore ( repo_path = AppPath . FEATURE_REPO ) # (11) def predict ( request : np . ndarray ) -> np . ndarray : # (12) result = bentoml_runner . predict . run ( request ) return result class InferenceRequest ( BaseModel ): # (13) driver_ids : List [ int ] class InferenceResponse ( BaseModel ): # (14) prediction : Optional [ float ] error : Optional [ str ] @svc . api ( input = JSON ( pydantic_model = InferenceRequest ), # (15) output = JSON ( pydantic_model = InferenceResponse ), ) def inference ( request : InferenceRequest , ctx : bentoml . Context ) -> Dict [ str , Any ]: try : driver_ids = request . driver_ids online_features = fs . get_online_features ( # (16) entity_rows = [{ \"driver_id\" : driver_id } for driver_id in driver_ids ], features = [ f \"driver_stats: { name } \" for name in feature_list ], ) df = pd . DataFrame . from_dict ( online_features . to_dict ()) input_features = df . drop ([ \"driver_id\" ], axis = 1 ) # (17) input_features = input_features [ feature_list ] # (18) result = predict ( input_features ) df [ \"prediction\" ] = result best_idx = df [ \"prediction\" ] . argmax () best_driver_id = df [ \"driver_id\" ] . iloc [ best_idx ] # (19) ... # (20) except Exception as e : ... Download model t\u1eeb MLflow server L\u1ea5y ra sklearn model L\u01b0u model v\u1ec1 d\u1ea1ng m\u00e0 BentoML y\u00eau c\u1ea7u model_name \u0111\u01b0\u1ee3c l\u1ea5y t\u1eeb file model_serving/artifacts/registered_model_version.json Signature c\u1ee7a model , th\u1ec3 hi\u1ec7n h\u00e0m m\u00e0 model object s\u1ebd g\u1ecdi Key predict l\u00e0 t\u00ean h\u00e0m m\u00e0 model s\u1ebd g\u1ecdi. V\u00ec sklearn model d\u00f9ng h\u00e0m predict \u0111\u1ec3 ch\u1ea1y inference n\u00ean signatures c\u1ee7a BentoML s\u1ebd ch\u1ee9a key predict Th\u00f4ng tin th\u00eam v\u1ec1 key batchable . \u0110\u1ecdc th\u00eam t\u1ea1i \u0111\u00e2y . L\u01b0u b\u1ea5t k\u00ec Python object n\u00e0o \u0111i k\u00e8m v\u1edbi model. \u0110\u1ecdc th\u00eam t\u1ea1i \u0111\u00e2y L\u01b0u th\u1ee9 t\u1ef1 c\u00e1c features model y\u00eau c\u1ea7u. feature_list \u0111\u01b0\u1ee3c l\u1ea5y ra t\u1eeb metadata c\u1ee7a model \u0111\u00e3 l\u01b0u \u1edf MLflow T\u1ea1o BentoML Runner v\u00e0 BentoML Service . Qu\u00e1 tr\u00ecnh ch\u1ea1y inference th\u00f4ng qua m\u1ed9t BentoML Runner. BentoML Service ch\u1ee9a object BentoML Runner, gi\u00fap \u0111\u1ecbnh ngh\u0129a API m\u1ed9t c\u00e1ch thu\u1eadn ti\u1ec7n Kh\u1edfi t\u1ea1o k\u1ebft n\u1ed1i t\u1edbi Feature Store H\u00e0m predict \u0111\u1ec3 th\u1ef1c hi\u1ec7n inference \u0110\u1ecbnh ngh\u0129a input class cho API \u0110\u1ecbnh ngh\u0129a output class cho API \u0110\u1ecbnh ngh\u0129a input v\u00e0 output \u1edf d\u1ea1ng json cho API \u0110\u1ecdc features t\u1eeb Online Feature Store Lo\u1ea1i b\u1ecf c\u1ed9t kh\u00f4ng c\u1ea7n thi\u1ebft S\u1eafp x\u1ebfp th\u1ee9 t\u1ef1 features L\u1ea5y ra ID c\u1ee7a t\u00e0i x\u1ebf c\u00f3 kh\u1ea3 n\u0103ng cao nh\u1ea5t s\u1ebd ho\u00e0n th\u00e0nh cu\u1ed1c xe. ID n\u00e0y \u0111\u01b0\u1ee3c tr\u1ea3 v\u1ec1 trong response \u0110o\u1ea1n code li\u00ean quan t\u1edbi monitoring s\u1ebd \u0111\u01b0\u1ee3c gi\u1ea3i th\u00edch trong b\u00e0i ti\u1ebfp theo. B\u1ea1n h\u00e3y t\u1ea1m th\u1eddi b\u1ecf qua \u0111o\u1ea1n code n\u00e0y \u0110\u1ec3 tri\u1ec3n khai online serving API tr\u00ean m\u00e1y local, docker compose s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng. Online serving API s\u1ebd \u0111\u01b0\u1ee3c g\u1ecdi qua port 8172 . Info Port 8172 \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a t\u1ea1i model_serving/deployment/.env . B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 tri\u1ec3n khai Online serving service. Ch\u1ea1y Online Feature Store b\u1eb1ng c\u00e1ch v\u00e0o repo mlops-crash-course-platform v\u00e0 ch\u1ea1y l\u1ec7nh sau bash run.sh feast up Info Online Feature Store th\u1ef1c ch\u1ea5t l\u00e0 m\u1ed9t Redis database. C\u00e1c b\u1ea1n xem file feast/feast-docker-compose.yml trong repo mlops-crash-course-platform C\u1eadp nh\u1eadt Online Feature Store. Xem l\u1ea1i b\u00e0i X\u00e2y d\u1ef1ng data pipeline cd feature_repo feast apply feast materialize-incremental $( date +%Y-%m-%d ) cd .. Build docker image v\u00e0 ch\u1ea1y docker compose make build_image make compose_up Tip \u0110\u1ecbnh ngh\u0129a v\u1ec1 c\u00e1c env vars \u0111\u01b0\u1ee3c d\u00f9ng trong qu\u00e1 tr\u00ecnh build image \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i model_serving/deployment/.env . B\u1ea1n c\u00f3 th\u1ec3 thay \u0111\u1ed5i n\u1ebfu c\u1ea7n. Truy c\u1eadp http://localhost:8172/ , m\u1edf API /inference , click Try it out . \u1ede ph\u1ea7n Request body , b\u1ea1n g\u00f5 n\u1ed9i dung sau: { \"request_id\" : \"uuid-1\" , \"driver_ids\" : [ 1001 , 1002 , 1003 , 1004 , 1005 ] } K\u1ebft qu\u1ea3 c\u1ee7a response tr\u1ea3 v\u1ec1 s\u1ebd gi\u1ed1ng nh\u01b0 sau. T\u1ed5ng k\u1ebft Ch\u00fang ta v\u1eeba th\u1ef1c hi\u1ec7n m\u1ed9t lo\u1ea1t c\u00e1c quy tr\u00ecnh \u0111i\u1ec3n h\u00ecnh \u0111\u1ec3 tri\u1ec3n khai batch serving v\u00e0 online serving. Code \u0111\u1ec3 ch\u1ea1y c\u1ea3 batch serving v\u00e0 online serving s\u1ebd ph\u1ee5 thu\u1ed9c v\u00e0o model m\u00e0 Data Scientist \u0111\u00e3 train v\u00e0 c\u00e1c features \u0111\u01b0\u1ee3c y\u00eau c\u1ea7u cho model \u0111\u00f3. Do \u0111\u00f3, batch serving v\u00e0 online serving code c\u0169ng s\u1ebd \u0111\u01b0\u1ee3c c\u1eadp nh\u1eadt theo y\u00eau c\u1ea7u c\u1ee7a Data Scientist. Sau khi t\u1ef1 \u0111\u1ed9ng ho\u00e1 batch serving pipeline v\u00e0 tri\u1ec3n khai online serving service, trong b\u00e0i ti\u1ebfp theo ch\u00fang ta s\u1ebd x\u00e2y d\u1ef1ng h\u1ec7 th\u1ed1ng gi\u00e1m s\u00e1t online serving service. H\u1ec7 th\u1ed1ng n\u00e0y r\u1ea5t quan tr\u1ecdng trong vi\u1ec7c theo d\u00f5i system performance v\u00e0 model performance, gi\u00fap ch\u00fang ta gi\u1ea3i quy\u1ebft c\u00e1c v\u1ea5n \u0111\u1ec1 \u1edf production nhanh h\u01a1n v\u00e0 c\u1ea3nh b\u00e1o khi c\u00f3 c\u00e1c s\u1ef1 c\u1ed1 v\u1ec1 h\u1ec7 th\u1ed1ng v\u00e0 model performance. T\u00e0i li\u1ec7u tham kh\u1ea3o BentoML","title":"Model serving"},{"location":"mlops-crash-course/model-serving/trien-khai-model-serving.html#gioi-thieu","text":"Sau khi train \u0111\u01b0\u1ee3c m\u1ed9t model t\u1ed1t, ch\u00fang ta c\u1ea7n tri\u1ec3n khai model \u0111\u00f3 \u0111\u1ec3 th\u1ef1c hi\u1ec7n inference. C\u00f3 hai h\u00ecnh th\u1ee9c tri\u1ec3n khai model ph\u1ed5 bi\u1ebfn l\u00e0 batch serving v\u00e0 online serving . C\u1ea3 batch serving v\u00e0 online serving \u0111\u1ec1u c\u00f3 th\u1ec3 x\u1eed l\u00fd m\u1ed9t ho\u1eb7c nhi\u1ec1u requests. Trong khi batch serving \u0111\u01b0\u1ee3c t\u1ed1i \u01b0u \u0111\u1ec3 x\u1eed l\u00fd s\u1ed1 l\u01b0\u1ee3ng l\u1edbn c\u00e1c requests, th\u01b0\u1eddng \u0111\u1ec3 ch\u1ea1y c\u00e1c model ph\u1ee9c t\u1ea1p, th\u00ec online serving \u0111\u01b0\u1ee3c t\u1ed1i \u01b0u \u0111\u1ec3 gi\u1ea3m th\u1eddi gian x\u1eed l\u00fd trong m\u1ed9t l\u1ea7n th\u1ef1c thi. Batch serving th\u01b0\u1eddng \u0111\u01b0\u1ee3c l\u00ean l\u1ecbch theo chu k\u00ec v\u00e0 ch\u1ea1y offline. Online serving th\u01b0\u1eddng \u0111\u01b0\u1ee3c tri\u1ec3n khai l\u00ean m\u1ed9t server d\u01b0\u1edbi d\u1ea1ng RESTful APIs \u0111\u1ec3 ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 g\u1ecdi t\u1edbi. Trong b\u00e0i n\u00e0y, ch\u00fang ta s\u1ebd t\u00ecm hi\u1ec3u c\u00e1ch tri\u1ec3n khai model \u1edf c\u1ea3 hai h\u00ecnh th\u1ee9c batch serving v\u00e0 online serving.","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/model-serving/trien-khai-model-serving.html#moi-truong-phat-trien","text":"C\u00e1c b\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 c\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n: C\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng Python 3.9 m\u1edbi v\u1edbi c\u00e1c th\u01b0 vi\u1ec7n c\u1ea7n thi\u1ebft trong file model_serving/dev_requirements.txt \u0110\u1eb7t environment variable MODEL_SERVING_DIR \u1edf terminal b\u1ea1n d\u00f9ng b\u1eb1ng \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i t\u1edbi folder model_serving , v\u00e0 MLFLOW_TRACKING_URI b\u1eb1ng URL c\u1ee7a MLflow server. Hai env var n\u00e0y h\u1ed7 tr\u1ee3 ch\u1ea1y python code \u1edf folder model_serving/src trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n. cd mlops-crash-course-code/model_serving export MODEL_SERVING_DIR = $( pwd ) export MLFLOW_TRACKING_URI = \"http://localhost:5000\" C\u00e1c MLOps tools \u0111\u01b0\u1ee3c d\u00f9ng trong b\u00e0i n\u00e0y bao g\u1ed3m: Feast: truy xu\u1ea5t Feature Store MLflow: ML Metadata Store, Model Registry Airflow: \u0111i\u1ec1u ph\u1ed1i batch serving pipeline Note Trong qu\u00e1 tr\u00ecnh ch\u1ea1y code cho t\u1ea5t c\u1ea3 c\u00e1c ph\u1ea7n d\u01b0\u1edbi \u0111\u00e2y, gi\u1ea3 s\u1eed r\u1eb1ng folder g\u1ed1c n\u01a1i ch\u00fang ta l\u00e0m vi\u1ec7c l\u00e0 folder model_serving .","title":"M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n"},{"location":"mlops-crash-course/model-serving/trien-khai-model-serving.html#batch-serving","text":"Batch serving \u0111\u01b0\u1ee3c thi\u1ebft k\u1ebf v\u1edbi input l\u00e0 data file \u1edf local ho\u1eb7c cloud. B\u1ea1n c\u00f3 th\u1ec3 ch\u1ec9 c\u1ea7n vi\u1ebft v\u00e0i script \u0111\u1ec3 load input, load model, ch\u1ea1y predictions v\u00e0 l\u01b0u l\u1ea1i ch\u00fang. Tuy nhi\u00ean, ch\u00fang ta c\u0169ng c\u00f3 th\u1ec3 coi batch serving l\u00e0 m\u1ed9t pipeline, s\u1eed d\u1ee5ng Airflow \u0111\u1ec3 qu\u1ea3n l\u00fd v\u00e0 l\u00ean l\u1ecbch cho qu\u00e1 tr\u00ecnh ch\u1ea1y batch serving. Batch serving pipeline g\u1ed3m c\u00e1c tasks nh\u01b0 h\u00ecnh d\u01b0\u1edbi: flowchart LR n1[1. C\u1eadp nh\u1eadt<br>Feature Store] --> n2[2. Data<br>extraction] --> n3[3. Batch<br>prediction]","title":"Batch serving"},{"location":"mlops-crash-course/model-serving/trien-khai-model-serving.html#cap-nhat-feature-store","text":"Gi\u1ea3 s\u1eed n\u01a1i ch\u1ea1y Batch serving l\u00e0 \u1edf m\u1ed9t server v\u1edbi infrastructure \u0111\u1ee7 m\u1ea1nh cho vi\u1ec7c t\u1ed1i \u01b0u batch serving. Khi ch\u1ea1y batch serving, data \u0111\u01b0\u1ee3c l\u1ea5y t\u1eeb Feature Store \u0111\u1ec3 ph\u1ee5c v\u1ee5 cho inference. Do \u0111\u00f3, Feature Store c\u1ea7n \u0111\u01b0\u1ee3c c\u1eadp nh\u1eadt tr\u00ean server n\u01a1i batch serving \u0111\u01b0\u1ee3c tri\u1ec3n khai. Task n\u00e0y \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n gi\u1ed1ng nh\u01b0 task C\u1eadp nh\u1eadt Feature Store \u1edf training pipeline. B\u1ea1n c\u00f3 th\u1ec3 xem l\u1ea1i b\u00e0i X\u00e2y d\u1ef1ng training pipeline . B\u1ea1n h\u00e3y l\u00e0m theo c\u00e1c b\u01b0\u1edbc d\u01b0\u1edbi \u0111\u00e2y \u0111\u1ec3 c\u1eadp nh\u1eadt Feature Store. Code c\u1ee7a Feature Store n\u1eb1m t\u1ea1i data_pipeline/feature_repo . \u0110\u1ec3 tri\u1ec3n khai sang batch serving pipeline, ch\u00fang ta s\u1ebd copy code t\u1eeb data_pipeline/feature_repo sang model_serving/feature_repo . B\u1ea1n h\u00e3y ch\u1ea1y c\u00e1c l\u1ec7nh sau. cd ../data_pipeline make deploy_feature_repo # (1) cd ../model_serving cd feature_repo feast apply # (2) cd .. Tri\u1ec3n khai code c\u1ee7a Feature Store C\u1eadp nh\u1eadt Feature Registry v\u00e0 Offline Feature Store c\u1ee7a Feast","title":"C\u1eadp nh\u1eadt Feature Store"},{"location":"mlops-crash-course/model-serving/trien-khai-model-serving.html#data-extraction","text":"Task Data extraction c\u00f3 \u0111\u1ea7u v\u00e0o v\u00e0 \u0111\u1ea7u ra nh\u01b0 sau: \u0110\u1ea7u v\u00e0o: data \u0111\u01b0\u1ee3c \u0111\u1ecdc t\u1eeb Offline Feature Store. Data s\u1ebd \u0111\u01b0\u1ee3c x\u1eed l\u00fd theo format m\u00e0 model y\u00eau c\u1ea7u \u0111\u1ec3 ti\u1ec7n cho task Batch prediction ti\u1ebfp theo \u0110\u1ea7u ra: data \u0111\u00e3 \u0111\u01b0\u1ee3c x\u1eed l\u00fd v\u00e0 \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o disk Code c\u1ee7a task n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i model_serving/src/data_extraction.py . model_serving/src/data_extraction.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 fs = feast . FeatureStore ( repo_path = AppPath . FEATURE_REPO ) # (1) orders = pd . read_csv ( batch_input_file , sep = \" \\t \" ) # (2) orders [ \"event_timestamp\" ] = pd . to_datetime ( orders [ \"event_timestamp\" ]) batch_input_df = fs . get_historical_features ( # (3) entity_df = orders , features = [ \"driver_stats:conv_rate\" , # (4) \"driver_stats:acc_rate\" , \"driver_stats:avg_daily_trips\" , ], ) . to_df () batch_input_df = batch_input_df . drop ([ \"event_timestamp\" , \"driver_id\" ], axis = 1 ) # (5) to_parquet ( batch_input_df , AppPath . BATCH_INPUT_PQ ) # (6) Kh\u1edfi t\u1ea1o k\u1ebft n\u1ed1i t\u1edbi Feature Store \u0110\u1ecdc file data n\u1eb1m t\u1ea1i model_serving/data/batch_request.csv ch\u1ee9a c\u00e1c records m\u00e0 ch\u00fang ta mu\u1ed1n ch\u1ea1y prediction L\u1ea5y ra c\u00e1c features conv_rate , acc_rate v\u00e0 avg_daily_trips driver_stats l\u00e0 t\u00ean FeatureView m\u00e0 ch\u00fang ta \u0111\u00e3 \u0111\u1ecbnh ngh\u0129a t\u1ea1i data_pipeline/feature_repo/features.py B\u1ecf c\u00e1c c\u1ed9t kh\u00f4ng c\u1ea7n thi\u1ebft L\u01b0u batch_input_df v\u00e0o disk B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 test th\u1eed code. Ch\u1ea1y code cd src python data_extraction.py cd .. Ki\u1ec3m tra folder model_serving/artifacts , b\u1ea1n s\u1ebd th\u1ea5y file batch_input.parquet","title":"Data extraction"},{"location":"mlops-crash-course/model-serving/trien-khai-model-serving.html#batch-prediction","text":"Task Batch prediction c\u00f3 \u0111\u1ea7u v\u00e0o v\u00e0 \u0111\u1ea7u ra nh\u01b0 sau: \u0110\u1ea7u v\u00e0o: config file ch\u1ee9a th\u00f4ng tin v\u1ec1 model \u0111\u01b0\u1ee3c d\u00f9ng \u0110\u1ea7u ra: k\u1ebft qu\u1ea3 predictions \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o disk Model \u0111\u01b0\u1ee3c d\u00f9ng l\u00e0 model \u0111\u00e3 \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o MLflow Model Registry \u1edf task Model validation trong b\u00e0i X\u00e2y d\u1ef1ng training pipeline . Trong task Model validation \u0111\u00f3, th\u00f4ng tin v\u1ec1 model \u0111\u00e3 \u0111\u0103ng k\u00fd \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i file training_pipeline/artifacts/registered_model_version.json . File n\u00e0y c\u1ea7n \u0111\u01b0\u1ee3c upload v\u00e0o m\u1ed9t Storage n\u00e0o \u0111\u00f3 trong t\u1ed5 ch\u1ee9c \u0111\u1ec3 c\u00e1c task kh\u00e1c, c\u1ee5 th\u1ec3 l\u00e0 cho batch serving v\u00e0 online serving \u1edf trong b\u00e0i n\u00e0y, c\u00f3 th\u1ec3 bi\u1ebft \u0111\u01b0\u1ee3c model n\u00e0o l\u00e0 t\u1ed1t nh\u1ea5t. V\u00ec ch\u00fang ta \u0111ang ph\u00e1t tri\u1ec3n c\u1ea3 training pipeline v\u00e0 model serving \u1edf local, n\u00ean b\u1ea1n ch\u1ec9 c\u1ea7n copy file training_pipeline/artifacts/registered_model_version.json sang model_serving/artifacts/registered_model_version.json . \u0110\u1ec3 l\u00e0m \u0111i\u1ec1u n\u00e0y, b\u1ea1n h\u00e3y ch\u1ea1y l\u1ec7nh sau. cd ../training_pipeline make deploy_registered_model_file cd ../model_serving Ti\u1ebfp theo, ch\u00fang ta s\u1ebd vi\u1ebft code cho task batch prediction. \u0110o\u1ea1n code n\u00e0y gi\u1ed1ng nh\u01b0 \u1edf task Model evaluation trong b\u00e0i X\u00e2y d\u1ef1ng training pipeline . Code c\u1ee7a task n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i model_serving/src/batch_prediction.py . model_serving/src/batch_prediction.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 mlflow_model = mlflow . pyfunc . load_model ( model_uri = model_uri ) # (1) batch_df = load_df ( AppPath . BATCH_INPUT_PQ ) # (2) model_signature = mlflow_model . metadata . signature # (3) feature_list = [] for name in model_signature . inputs . input_names (): feature_list . append ( name ) batch_df = batch_df [ feature_list ] # (4) preds = mlflow_model . predict ( batch_df ) # (5) batch_df [ \"pred\" ] = preds to_parquet ( batch_df , AppPath . BATCH_OUTPUT_PQ ) # (6) model_uri ch\u1ee9a URI c\u1ee7a model \u0111\u1ecdc t\u1eeb file model_serving/artifacts/registered_model_version.json Load batch input file \u0111\u01b0\u1ee3c l\u01b0u \u1edf task tr\u01b0\u1edbc, n\u1eb1m t\u1ea1i model_serving/artifacts/batch_input.parquet Load model signature S\u1eafp x\u1ebfp c\u00e1c features theo \u0111\u00fang th\u1ee9 t\u1ef1 m\u00e0 model y\u00eau c\u1ea7u Ch\u1ea1y inference L\u01b0u output v\u00e0o disk B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 test th\u1eed code. Ch\u1ea1y code cd src python batch_prediction.py cd .. Ki\u1ec3m tra folder model_serving/artifacts , b\u1ea1n s\u1ebd th\u1ea5y file batch_output.parquet","title":"Batch prediction"},{"location":"mlops-crash-course/model-serving/trien-khai-model-serving.html#airflow-dag","text":"\u1ede ph\u1ea7n n\u00e0y, Airflow DAG s\u1ebd k\u1ebft n\u1ed1i c\u00e1c task tr\u00ean th\u00e0nh m\u1ed9t pipeline. Code \u0111\u1ecbnh ngh\u0129a Airflow DAG \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i model_serving/dags/batch_serving_dag.py . model_serving/dags/batch_serving_dag.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 with DAG ( dag_id = \"batch_serving_pipeline\" , # (1) # c\u00e1c argument kh\u00e1c ) as dag : feature_store_init_task = DockerOperator ( task_id = \"feature_store_init_task\" , command = \"bash -c 'cd feature_repo && feast apply'\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , ) data_extraction_task = DockerOperator ( task_id = \"data_extraction_task\" , command = \"bash -c 'cd src && python data_extraction.py'\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , ) # c\u00e1c task kh\u00e1c Chi ti\u1ebft v\u1ec1 nh\u1eefng \u0111i\u1ec3m quan tr\u1ecdng c\u1ea7n l\u01b0u \u00fd, m\u1eddi b\u1ea1n xem l\u1ea1i b\u00e0i X\u00e2y d\u1ef1ng training pipeline . Ti\u1ebfp theo, ch\u00fang ta c\u1ea7n build docker image mlopsvn/mlops_crash_course/model_serving:latest v\u00e0 tri\u1ec3n khai Airflow DAGs b\u1eb1ng c\u00e1ch c\u00e1c b\u01b0\u1edbc sau. \u0110\u0103ng nh\u1eadp v\u00e0o Airflow UI v\u1edbi t\u00e0i kho\u1ea3n v\u00e0 m\u1eadt kh\u1ea9u l\u00e0 airflow . \u0110\u1eb7t Airflow Variable MLOPS_CRASH_COURSE_CODE_DIR b\u1eb1ng \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i t\u1edbi folder mlops-crash-course-code/ Ch\u1ea1y l\u1ec7nh make build_image make deploy_dags # (1) Copy model_serving/dags/* v\u00e0o folder dags c\u1ee7a Airflow Tip \u0110\u1ecbnh ngh\u0129a v\u1ec1 c\u00e1c env vars \u0111\u01b0\u1ee3c d\u00f9ng trong qu\u00e1 tr\u00ecnh ch\u1ea1y Airflow DAG \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i model_serving/.env . B\u1ea1n c\u00f3 th\u1ec3 thay \u0111\u1ed5i n\u1ebfu c\u1ea7n. K\u00edch ho\u1ea1t batch serving pipeline v\u00e0 \u0111\u1ee3i k\u1ebft qu\u1ea3","title":"Airflow DAG"},{"location":"mlops-crash-course/model-serving/trien-khai-model-serving.html#online-serving","text":"Khi tri\u1ec3n khai Online serving hay Online serving service , th\u01b0\u1eddng th\u00ec b\u1ea1n s\u1ebd d\u00f9ng m\u1ed9t library \u0111\u1ec3 x\u00e2y d\u1ef1ng RESTful API, v\u00ed d\u1ee5 nh\u01b0 Flask ho\u1eb7c FastAPI trong Python. Trong ph\u1ea7n n\u00e0y, ch\u00fang ta s\u1ebd d\u00f9ng m\u1ed9t library chuy\u00ean \u0111\u01b0\u1ee3c d\u00f9ng cho vi\u1ec7c x\u00e2y d\u1ef1ng online serving cho ML models, \u0111\u00f3 l\u00e0 BentoML . Code c\u1ee7a online serving \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i model_serving/src/bentoml_service.py . model_serving/src/bentoml_service.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 mlflow_model = mlflow . pyfunc . load_model ( model_uri = model_uri ) # (1) model = mlflow_model . _model_impl # (2) bentoml_model = bentoml . sklearn . save_model ( # (3) model_name , # (4) model , signatures = { # (5) \"predict\" : { # (6) \"batchable\" : False , # (7) }, }, custom_objects = { # (8) \"feature_list\" : feature_list , # (9) }, ) feature_list = bentoml_model . custom_objects [ \"feature_list\" ] bentoml_runner = bentoml . sklearn . get ( bentoml_model . tag ) . to_runner () # (10) svc = bentoml . Service ( bentoml_model . tag . name , runners = [ bentoml_runner ]) fs = feast . FeatureStore ( repo_path = AppPath . FEATURE_REPO ) # (11) def predict ( request : np . ndarray ) -> np . ndarray : # (12) result = bentoml_runner . predict . run ( request ) return result class InferenceRequest ( BaseModel ): # (13) driver_ids : List [ int ] class InferenceResponse ( BaseModel ): # (14) prediction : Optional [ float ] error : Optional [ str ] @svc . api ( input = JSON ( pydantic_model = InferenceRequest ), # (15) output = JSON ( pydantic_model = InferenceResponse ), ) def inference ( request : InferenceRequest , ctx : bentoml . Context ) -> Dict [ str , Any ]: try : driver_ids = request . driver_ids online_features = fs . get_online_features ( # (16) entity_rows = [{ \"driver_id\" : driver_id } for driver_id in driver_ids ], features = [ f \"driver_stats: { name } \" for name in feature_list ], ) df = pd . DataFrame . from_dict ( online_features . to_dict ()) input_features = df . drop ([ \"driver_id\" ], axis = 1 ) # (17) input_features = input_features [ feature_list ] # (18) result = predict ( input_features ) df [ \"prediction\" ] = result best_idx = df [ \"prediction\" ] . argmax () best_driver_id = df [ \"driver_id\" ] . iloc [ best_idx ] # (19) ... # (20) except Exception as e : ... Download model t\u1eeb MLflow server L\u1ea5y ra sklearn model L\u01b0u model v\u1ec1 d\u1ea1ng m\u00e0 BentoML y\u00eau c\u1ea7u model_name \u0111\u01b0\u1ee3c l\u1ea5y t\u1eeb file model_serving/artifacts/registered_model_version.json Signature c\u1ee7a model , th\u1ec3 hi\u1ec7n h\u00e0m m\u00e0 model object s\u1ebd g\u1ecdi Key predict l\u00e0 t\u00ean h\u00e0m m\u00e0 model s\u1ebd g\u1ecdi. V\u00ec sklearn model d\u00f9ng h\u00e0m predict \u0111\u1ec3 ch\u1ea1y inference n\u00ean signatures c\u1ee7a BentoML s\u1ebd ch\u1ee9a key predict Th\u00f4ng tin th\u00eam v\u1ec1 key batchable . \u0110\u1ecdc th\u00eam t\u1ea1i \u0111\u00e2y . L\u01b0u b\u1ea5t k\u00ec Python object n\u00e0o \u0111i k\u00e8m v\u1edbi model. \u0110\u1ecdc th\u00eam t\u1ea1i \u0111\u00e2y L\u01b0u th\u1ee9 t\u1ef1 c\u00e1c features model y\u00eau c\u1ea7u. feature_list \u0111\u01b0\u1ee3c l\u1ea5y ra t\u1eeb metadata c\u1ee7a model \u0111\u00e3 l\u01b0u \u1edf MLflow T\u1ea1o BentoML Runner v\u00e0 BentoML Service . Qu\u00e1 tr\u00ecnh ch\u1ea1y inference th\u00f4ng qua m\u1ed9t BentoML Runner. BentoML Service ch\u1ee9a object BentoML Runner, gi\u00fap \u0111\u1ecbnh ngh\u0129a API m\u1ed9t c\u00e1ch thu\u1eadn ti\u1ec7n Kh\u1edfi t\u1ea1o k\u1ebft n\u1ed1i t\u1edbi Feature Store H\u00e0m predict \u0111\u1ec3 th\u1ef1c hi\u1ec7n inference \u0110\u1ecbnh ngh\u0129a input class cho API \u0110\u1ecbnh ngh\u0129a output class cho API \u0110\u1ecbnh ngh\u0129a input v\u00e0 output \u1edf d\u1ea1ng json cho API \u0110\u1ecdc features t\u1eeb Online Feature Store Lo\u1ea1i b\u1ecf c\u1ed9t kh\u00f4ng c\u1ea7n thi\u1ebft S\u1eafp x\u1ebfp th\u1ee9 t\u1ef1 features L\u1ea5y ra ID c\u1ee7a t\u00e0i x\u1ebf c\u00f3 kh\u1ea3 n\u0103ng cao nh\u1ea5t s\u1ebd ho\u00e0n th\u00e0nh cu\u1ed1c xe. ID n\u00e0y \u0111\u01b0\u1ee3c tr\u1ea3 v\u1ec1 trong response \u0110o\u1ea1n code li\u00ean quan t\u1edbi monitoring s\u1ebd \u0111\u01b0\u1ee3c gi\u1ea3i th\u00edch trong b\u00e0i ti\u1ebfp theo. B\u1ea1n h\u00e3y t\u1ea1m th\u1eddi b\u1ecf qua \u0111o\u1ea1n code n\u00e0y \u0110\u1ec3 tri\u1ec3n khai online serving API tr\u00ean m\u00e1y local, docker compose s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng. Online serving API s\u1ebd \u0111\u01b0\u1ee3c g\u1ecdi qua port 8172 . Info Port 8172 \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a t\u1ea1i model_serving/deployment/.env . B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 tri\u1ec3n khai Online serving service. Ch\u1ea1y Online Feature Store b\u1eb1ng c\u00e1ch v\u00e0o repo mlops-crash-course-platform v\u00e0 ch\u1ea1y l\u1ec7nh sau bash run.sh feast up Info Online Feature Store th\u1ef1c ch\u1ea5t l\u00e0 m\u1ed9t Redis database. C\u00e1c b\u1ea1n xem file feast/feast-docker-compose.yml trong repo mlops-crash-course-platform C\u1eadp nh\u1eadt Online Feature Store. Xem l\u1ea1i b\u00e0i X\u00e2y d\u1ef1ng data pipeline cd feature_repo feast apply feast materialize-incremental $( date +%Y-%m-%d ) cd .. Build docker image v\u00e0 ch\u1ea1y docker compose make build_image make compose_up Tip \u0110\u1ecbnh ngh\u0129a v\u1ec1 c\u00e1c env vars \u0111\u01b0\u1ee3c d\u00f9ng trong qu\u00e1 tr\u00ecnh build image \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i model_serving/deployment/.env . B\u1ea1n c\u00f3 th\u1ec3 thay \u0111\u1ed5i n\u1ebfu c\u1ea7n. Truy c\u1eadp http://localhost:8172/ , m\u1edf API /inference , click Try it out . \u1ede ph\u1ea7n Request body , b\u1ea1n g\u00f5 n\u1ed9i dung sau: { \"request_id\" : \"uuid-1\" , \"driver_ids\" : [ 1001 , 1002 , 1003 , 1004 , 1005 ] } K\u1ebft qu\u1ea3 c\u1ee7a response tr\u1ea3 v\u1ec1 s\u1ebd gi\u1ed1ng nh\u01b0 sau.","title":"Online serving"},{"location":"mlops-crash-course/model-serving/trien-khai-model-serving.html#tong-ket","text":"Ch\u00fang ta v\u1eeba th\u1ef1c hi\u1ec7n m\u1ed9t lo\u1ea1t c\u00e1c quy tr\u00ecnh \u0111i\u1ec3n h\u00ecnh \u0111\u1ec3 tri\u1ec3n khai batch serving v\u00e0 online serving. Code \u0111\u1ec3 ch\u1ea1y c\u1ea3 batch serving v\u00e0 online serving s\u1ebd ph\u1ee5 thu\u1ed9c v\u00e0o model m\u00e0 Data Scientist \u0111\u00e3 train v\u00e0 c\u00e1c features \u0111\u01b0\u1ee3c y\u00eau c\u1ea7u cho model \u0111\u00f3. Do \u0111\u00f3, batch serving v\u00e0 online serving code c\u0169ng s\u1ebd \u0111\u01b0\u1ee3c c\u1eadp nh\u1eadt theo y\u00eau c\u1ea7u c\u1ee7a Data Scientist. Sau khi t\u1ef1 \u0111\u1ed9ng ho\u00e1 batch serving pipeline v\u00e0 tri\u1ec3n khai online serving service, trong b\u00e0i ti\u1ebfp theo ch\u00fang ta s\u1ebd x\u00e2y d\u1ef1ng h\u1ec7 th\u1ed1ng gi\u00e1m s\u00e1t online serving service. H\u1ec7 th\u1ed1ng n\u00e0y r\u1ea5t quan tr\u1ecdng trong vi\u1ec7c theo d\u00f5i system performance v\u00e0 model performance, gi\u00fap ch\u00fang ta gi\u1ea3i quy\u1ebft c\u00e1c v\u1ea5n \u0111\u1ec1 \u1edf production nhanh h\u01a1n v\u00e0 c\u1ea3nh b\u00e1o khi c\u00f3 c\u00e1c s\u1ef1 c\u1ed1 v\u1ec1 h\u1ec7 th\u1ed1ng v\u00e0 model performance.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/model-serving/trien-khai-model-serving.html#tai-lieu-tham-khao","text":"BentoML","title":"T\u00e0i li\u1ec7u tham kh\u1ea3o"},{"location":"mlops-crash-course/monitoring/metrics-he-thong.html","text":"Photo by Chris Liverani on Unsplash Gi\u1edbi thi\u1ec7u Trong b\u00e0i tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 t\u00ecm hi\u1ec3u v\u1ec1 theo d\u00f5i m\u1ed9t h\u1ec7 th\u1ed1ng ML n\u00f3i chung, v\u1edbi c\u00e1c metrics \u0111i\u1ec3n h\u00ecnh v\u00e0 c\u00e1c b\u1ed9 c\u00f4ng c\u1ee5 \u0111\u01b0\u1ee3c d\u00f9ng trong qu\u00e1 tr\u00ecnh theo d\u00f5i. Trong b\u00e0i n\u00e0y, ch\u00fang ta s\u1ebd tri\u1ec3n khai c\u00e1c gi\u1ea3i ph\u00e1p \u0111\u1ec3 theo d\u00f5i h\u1ec7 th\u1ed1ng ML trong kho\u00e1 h\u1ecdc n\u00e0y, c\u1ee5 th\u1ec3 l\u00e0 nh\u1eefng c\u00f4ng vi\u1ec7c sau: Tri\u1ec3n khai ELK Stack \u0111\u1ec3 theo d\u00f5i logs c\u1ee7a h\u1ec7 th\u1ed1ng Tri\u1ec3n khai Prometheus v\u00e0 Grafana servers \u0111\u1ec3 theo d\u00f5i metrics h\u1ec7 th\u1ed1ng M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n \u1ede b\u00e0i n\u00e0y, ch\u00fang ta kh\u00f4ng vi\u1ebft code, m\u00e0 s\u1ebd tri\u1ec3n khai ELK Stack, Prometheus v\u00e0 Grafana servers. Do \u0111\u00f3, b\u1ea1n kh\u00f4ng c\u1ea7n c\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n. C\u00e1c MLOps tools \u0111\u01b0\u1ee3c d\u00f9ng trong b\u00e0i n\u00e0y bao g\u1ed3m: Elasticsearch, Kibana v\u00e0 Filebeat: thu th\u1eadp v\u00e0 hi\u1ec3n th\u1ecb logs t\u1eadp trung t\u1eeb Online serving service Prometheus v\u00e0 Grafana: theo d\u00f5i v\u00e0 hi\u1ec3n th\u1ecb metrics Logs Vi\u1ec7c s\u1eed d\u1ee5ng c\u00f4ng ngh\u1ec7 container c\u00f3 nhi\u1ec1u \u01b0u \u0111i\u1ec3m, nh\u01b0ng c\u0169ng xu\u1ea5t hi\u1ec7n th\u00eam nhi\u1ec1u th\u00e1ch th\u1ee9c cho c\u00e1c k\u0129 s\u01b0. M\u1ed9t trong nh\u1eefng th\u00e1ch th\u1ee9c \u0111\u00f3 l\u00e0 vi\u1ec7c thu th\u1eadp v\u00e0 x\u1eed l\u00fd logs c\u1ee7a m\u1ed7i container m\u1ed9t c\u00e1ch hi\u1ec7u qu\u1ea3. May m\u1eafn thay, ELK Stack l\u00e0 m\u1ed9t trong nh\u1eefng gi\u1ea3i ph\u00e1p \u0111\u01b0\u1ee3c c\u1ed9ng \u0111\u1ed3ng \u01b0a chu\u1ed9ng \u0111\u1ec3 x\u1eed l\u00fd v\u1ea5n \u0111\u1ec1 n\u00e0y. C\u00e1ch ELK Stack ho\u1ea1t \u0111\u1ed9ng H\u00ecnh d\u01b0\u1edbi l\u00e0 m\u1ed9t pipeline \u0111i\u1ec3n h\u00ecnh cho vi\u1ec7c thu th\u1eadp v\u00e0 x\u1eed l\u00fd logs t\u1eadp trung s\u1eed d\u1ee5ng ELK Stack. \u0110\u1ea7u ti\u00ean, Logstash thu th\u1eadp logs t\u1eeb containers v\u00e0 l\u1ecdc logs. C\u00e1c c\u00e1ch \u0111\u1ec3 l\u1ecdc logs \u0111\u01b0\u1ee3c ng\u01b0\u1eddi d\u00f9ng \u0111\u1ecbnh ngh\u0129a. Sau \u0111\u00f3, Logstash \u0111\u1ea9y logs t\u1edbi Elasticsearch \u0111\u1ec3 \u0111\u00e1nh index, ti\u1ec7n cho vi\u1ec7c t\u00ecm ki\u1ebfm. Kibana l\u1ea5y logs ra, ph\u00e2n t\u00edch, hi\u1ec3n th\u1ecb data l\u00ean Kibana dashboard. C\u00f3 kh\u00e1 nhi\u1ec1u bi\u1ebfn th\u1ec3 c\u1ee7a pipeline tr\u00ean, v\u00ed d\u1ee5 nh\u01b0 d\u00f9ng Filebeat \u0111\u1ec3 thu th\u1eadp logs t\u1eeb containers v\u00e0 g\u1eedi logs t\u1edbi Elasticsearch. Trong b\u00e0i n\u00e0y, Logstash s\u1ebd \u0111\u01b0\u1ee3c thay th\u1ebf b\u1eb1ng Filebeat \u0111\u1ec3 thu th\u1eadp logs t\u1eeb containers v\u00e0 g\u1eedi t\u1edbi Elasticsearch. Info ELK Stack \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng l\u00e0m t\u00ean chung cho gi\u1ea3i ph\u00e1p, m\u1eb7c d\u00f9 Filebeat s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng thay th\u1ebf cho Logstash trong b\u00e0i n\u00e0y. Tri\u1ec3n khai ELK Stack \u0110\u1ec3 tri\u1ec3n khai ELK Stack, \u1edf trong repo mlops-crash-course-platform , b\u1ea1n h\u00e3y l\u00e0m c\u00e1c b\u01b0\u1edbc sau: Tri\u1ec3n khai c\u00e1c servers c\u1ea7n thi\u1ebft bash run.sh elk up C\u00e2u l\u1ec7nh tr\u00ean s\u1ebd ch\u1ea1y c\u00e1c servers v\u1edbi c\u00e1c file config sau: Filebeat server elk/extensions/filebeat/filebeat-compose.yml : File docker-compose \u0111\u1ec3 ch\u1ea1y Filebeat server elk/extensions/filebeat/config/filebeat.yml : Config c\u1ee7a Filebeat server Elasticsearch server elk/elk-docker-compose.yml : File docker-compose \u0111\u1ec3 ch\u1ea1y Elasticsearch server elk/elasticsearch/config/elasticsearch.yml : Config c\u1ee7a Elasticsearch server Kibana server elk/elk-docker-compose.yml : File docker-compose \u0111\u1ec3 ch\u1ea1y Kibana server elk/kibana/config/kibana.yml : Config c\u1ee7a Kibana server \u0110\u1ee3i 20s \u0111\u1ec3 vi\u1ec7c kh\u1edfi t\u1ea1o c\u00e1c servers ho\u00e0n th\u00e0nh Ki\u1ec3m tra Elasticsearch server \u0111\u01b0\u1ee3c tri\u1ec3n khai th\u00e0nh c\u00f4ng ch\u01b0a: curl -X GET http://localhost:9200 -u elastic:changeme N\u1ebfu Elasticsearch server \u0111\u01b0\u1ee3c tri\u1ec3n khai th\u00e0nh c\u00f4ng, \u1edf terminal s\u1ebd hi\u1ec3n th\u1ecb t\u01b0\u01a1ng t\u1ef1 nh\u01b0 sau: { \"name\" : \"ee711e6d1977\" , \"cluster_name\" : \"docker-cluster\" , \"cluster_uuid\" : \"sG38FtFuQSedHb68U_Uv5Q\" , \"version\" : { \"number\" : \"8.4.1\" , \"build_flavor\" : \"default\" , \"build_type\" : \"docker\" , \"build_hash\" : \"2bd229c8e56650b42e40992322a76e7914258f0c\" , \"build_date\" : \"2022-08-26T12:11:43.232597118Z\" , \"build_snapshot\" : false, \"lucene_version\" : \"9.3.0\" , \"minimum_wire_compatibility_version\" : \"7.17.0\" , \"minimum_index_compatibility_version\" : \"7.0.0\" } , \"tagline\" : \"You Know, for Search\" } Ki\u1ec3m tra Kibana server \u0111\u01b0\u1ee3c tri\u1ec3n khai th\u00e0nh c\u00f4ng ch\u01b0a: Tr\u00ean browser, truy c\u1eadp v\u00e0o Kibana server t\u1ea1i http://localhost:5601 \u0110\u0103ng nh\u1eadp v\u1edbi t\u00ean user l\u00e0 elastic v\u00e0 m\u1eadt kh\u1ea9u l\u00e0 changeme Vi\u1ec7c \u0111\u0103ng nh\u1eadp th\u00e0nh c\u00f4ng ch\u1ee9ng t\u1ecf Kibana server \u0111\u00e3 tri\u1ec3n khai th\u00e0nh c\u00f4ng. Truy v\u1ea5n logs Sau khi \u0111\u00e3 tri\u1ec3n khai ELK Stack, h\u00e3y th\u1eed truy v\u1ea5n logs \u1edf ELK Stack xem logs \u0111\u00e3 \u0111\u01b0\u1ee3c thu th\u1eadp th\u00e0nh c\u00f4ng t\u1eeb Online serving service hay ch\u01b0a. G\u1eedi v\u00e0i requests t\u1edbi Online serving API b\u1eb1ng c\u00e1ch truy c\u1eadp http://localhost:8172 , m\u1edf API /inference , click Try it out . \u1ede ph\u1ea7n Request body , b\u1ea1n g\u00f5 n\u1ed9i dung sau: { \"request_id\" : \"uuid-1\" , \"driver_ids\" : [ 1001 , 1002 , 1003 , 1004 , 1005 ] } \u0110\u0103ng nh\u1eadp v\u00e0o Kibana server http://localhost:5601 . \u1ede sidebar b\u00ean ph\u1ea3i, ch\u1ecdn Discover . Tr\u00ean UI c\u1ee7a page Discover , trong ph\u1ea7n g\u00f5 c\u00e2u truy v\u1ea5n, g\u00f5 truy v\u1ea5n sau: container.name:\"online_serving\" Info C\u00e2u truy v\u1ea5n tr\u00ean s\u1eed d\u1ee5ng ng\u00f4n ng\u1eef truy v\u1ea5n KQL. B\u1ea1n c\u00f3 th\u1ec3 tham kh\u1ea3o th\u00eam t\u1ea1i \u0111\u00e2y . B\u1ea3ng hi\u1ec3n th\u1ecb logs c\u1ee7a Online Serving service s\u1ebd gi\u1ed1ng nh\u01b0 sau B\u1ea1n c\u00f3 th\u1ec3 l\u01b0u l\u1ea1i l\u1ea7n discover n\u00e0y b\u1eb1ng c\u00e1ch click v\u00e0o n\u00fat Save \u1edf g\u00f3c tr\u00ean b\u00ean ph\u1ea3i. Question L\u00e0m th\u1ebf n\u00e0o ELK stack c\u00f3 th\u1ec3 bi\u1ebft \u0111\u01b0\u1ee3c n\u00ean thu th\u1eadp logs t\u1eeb containers n\u00e0o? N\u1ebfu b\u1ea1n n\u00e0o \u0111\u00e3 \u0111\u1ecdc file config c\u1ee7a Filebeat t\u1ea1i elk/extensions/filebeat/config/filebeat.yml , b\u1ea1n s\u1ebd th\u1ea5y m\u1ed9t \u0111o\u1ea1n config nh\u01b0 sau: elk/extensions/filebeat/config/filebeat.yml 1 2 3 4 5 6 filebeat.autodiscover : providers : # The Docker autodiscover provider automatically retrieves logs from Docker # containers as they start and stop. - type : docker hints.enabled : true \u0110o\u1ea1n config n\u00e0y c\u1ea5u h\u00ecnh \u0111\u1ec3 Filebeat t\u1ef1 \u0111\u1ed9ng thu th\u1eadp logs t\u1eeb c\u00e1c containers v\u00e0 g\u1eedi v\u1ec1 Elasticsearch. Trong th\u1ef1c t\u1ebf, ch\u00fang ta kh\u00f4ng mu\u1ed1n thu th\u1eadp logs t\u1eeb m\u1ecdi containers v\u00e0 c\u0169ng mu\u1ed1n l\u1ecdc ra nh\u1eefng d\u00f2ng log nh\u1ea5t \u0111\u1ecbnh t\u1eeb service. \u0110\u1ec3 l\u00e0m \u0111i\u1ec1u n\u00e0y, b\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc th\u00eam t\u1ea1i \u0111\u00e2y . Metrics h\u1ec7 th\u1ed1ng Trong ph\u1ea7n n\u00e0y, Prometheus s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 thu th\u1eadp c\u00e1c metrics h\u1ec7 th\u1ed1ng v\u00e0 Grafana s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 hi\u1ec3n th\u1ecb c\u00e1c metrics \u0111\u00f3. Prometheus v\u00e0 Grafana servers \u0110\u1ec3 tri\u1ec3n khai Prometheus v\u00e0 Grafana servers, \u1edf trong repo mlops-crash-course-platform , b\u1ea1n h\u00e3y l\u00e0m c\u00e1c b\u01b0\u1edbc sau: Tri\u1ec3n khai c\u00e1c servers c\u1ea7n thi\u1ebft bash run.sh prom-graf up C\u00e2u l\u1ec7nh tr\u00ean s\u1ebd ch\u1ea1y c\u00e1c servers sau: Prometheus server prom-graf/prom-graf-docker-compose.yml : File docker-compose \u0111\u1ec3 ch\u1ea1y Prometheus server prom-graf/prometheus/config/prometheus.yml : Config c\u1ee7a Prometheus server Grafana server prom-graf/prom-graf-docker-compose.yml : File docker-compose \u0111\u1ec3 ch\u1ea1y Grafana server prom-graf/grafana/config/dashboards.yaml : Grafana dashboard config prom-graf/grafana/config/datasources.yaml . Grafana datasource config. File n\u00e0y \u0111\u1ecbnh ngh\u0129a s\u1eb5n datasource l\u00e0 Prometheus server \u0111\u01b0\u1ee3c tri\u1ec3n khai \u1edf tr\u00ean Node exporter server prom-graf/prom-graf-docker-compose.yml : File docker-compose \u0111\u1ec3 ch\u1ea1y Node exporter server Node exporter server \u0111\u01b0\u1ee3c c\u00e0i \u0111\u1eb7t th\u00eam v\u00e0o \u0111\u1ec3 t\u00ednh to\u00e1n c\u00e1c metrics li\u00ean quan t\u1edbi node (ch\u00ednh l\u00e0 m\u00e1y local hi\u1ec7n t\u1ea1i c\u1ee7a b\u1ea1n), v\u00ed d\u1ee5 nh\u01b0 c\u00e1c metrics li\u00ean quan t\u1edbi CPU, memory, v.v. Ch\u00fang ta s\u1ebd h\u1ecdc c\u00e1ch l\u1ea5y ra c\u00e1c metrics n\u00e0y t\u1eeb Node exporter server v\u00e0 hi\u1ec3n th\u1ecb l\u00ean Grafana dashboard \u1edf ph\u1ea7n d\u01b0\u1edbi. Ki\u1ec3m tra Prometheus server \u0111\u01b0\u1ee3c tri\u1ec3n khai th\u00e0nh c\u00f4ng ch\u01b0a: Truy c\u1eadp Prometheus server t\u1ea1i http://localhost:9090 Tr\u00ean Navbar, click Status , ch\u1ecdn Targets Ki\u1ec3m tra xem c\u00e1c endpoints c\u1ee7a c\u00e1c job prometheus , node , online_serving c\u00f3 \u1edf tr\u1ea1ng th\u00e1i UP kh\u00f4ng. B\u1ea1n c\u00f3 th\u1ec3 c\u1ea7n \u0111\u1ee3i 30s cho t\u1edbi khi c\u00e1c endpoints \u0111\u1ea1t tr\u1ea1ng th\u00e1i n\u00e0y. H\u00ecnh d\u01b0\u1edbi cho th\u1ea5y endpoints c\u1ee7a c\u00e1c targets tr\u00ean \u0111\u00e3 \u1edf tr\u1ea1ng th\u00e1i UP . Info M\u1ed9t endpoint ho\u1eb7c m\u1ed9t instance , trong Prometheus \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 \u0111\u1ecba ch\u1ec9 c\u1ee7a service m\u00e0 Prometheus thu th\u1eadp metrics. M\u1ed9t job l\u00e0 m\u1ed9t process l\u00e0m nhi\u1ec7m v\u1ee5 thu th\u1eadp metrics t\u1eeb m\u1ed9t t\u1eadp h\u1ee3p c\u00e1c instance c\u00f3 chung m\u1ee5c \u0111\u00edch. B\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc th\u00eam t\u1ea1i \u0111\u00e2y . Ki\u1ec3m tra xem Grafana server \u0111\u01b0\u1ee3c tri\u1ec3n khai th\u00e0nh c\u00f4ng ch\u01b0a Truy c\u1eadp v\u00e0o Grafana server t\u1ea1i http://localhost:3000 \u0110\u0103ng nh\u1eadp v\u1edbi t\u00ean user l\u00e0 admin , v\u00e0 m\u1eadt kh\u1ea9u l\u00e0 admin . Vi\u1ec7c \u0111\u0103ng nh\u1eadp th\u00e0nh c\u00f4ng ch\u1ee9ng t\u1ecf Grafana server \u0111\u00e3 \u0111\u01b0\u1ee3c tri\u1ec3n khai th\u00e0nh c\u00f4ng. Info Grafana c\u1ea7n m\u1ed9t datasource \u0111\u1ec3 c\u00f3 th\u1ec3 l\u1ea5y metrics v\u1ec1 v\u00e0 hi\u1ec3n th\u1ecb. Prometheus \u0111\u00e3 \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh l\u00e0m datasource m\u1eb7c \u0111\u1ecbnh c\u1ee7a Grafana. C\u1ea5u h\u00ecnh n\u00e0y \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u1ea1i prom-graf/grafana/config/datasources.yaml . Question L\u00e0m th\u1ebf n\u00e0o \u0111\u1ec3 t\u1ea1o m\u1ed9t job hay m\u1ed9t instance trong Prometheus? Trong config file prom-graf/prometheus/config/prometheus.yml c\u1ee7a Prometheus server, job online_serving \u0111\u00e3 \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp s\u1eb5n \u0111\u1ec3 thu th\u1eadp metrics t\u1eeb Online serving service. prom-graf/prometheus/config/prometheus.yml 1 2 3 4 5 - job_name : \"online_serving\" scrape_interval : 5s static_configs : - targets : - \"localhost:8172\" Thi\u1ebft l\u1eadp n\u00e0y b\u00e1o cho Prometheus bi\u1ebft r\u1eb1ng, m\u1ed7i 5s n\u00f3 c\u1ea7n ph\u1ea3i thu th\u1eadp metrics t\u1eeb URI http://localhost:8172/metrics , v\u1edbi /metrics l\u00e0 route m\u1eb7c \u0111\u1ecbnh \u0111\u1ec3 Prometheus \u0111\u1ecdc c\u00e1c metrics. B\u1ea1n c\u00f3 th\u1ec3 m\u1edf URI n\u00e0y tr\u00ean browser v\u00e0 s\u1ebd th\u1ea5y n\u1ed9i dung t\u01b0\u01a1ng t\u1ef1 nh\u01b0 sau. Node Exporter Full dashboard \u1ede ph\u1ea7n n\u00e0y, ch\u00fang ta s\u1ebd tri\u1ec3n khai Grafana dashboard t\u00ean l\u00e0 Node Exporter Full . Dashboard n\u00e0y \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng s\u1eb5n b\u1edfi c\u1ed9ng \u0111\u1ed3ng s\u1eed d\u1ee5ng Prometheus v\u00e0 Grafana. N\u00f3 hi\u1ec3n th\u1ecb c\u00e1c th\u00f4ng tin quan tr\u1ecdng c\u1ee7a h\u1ec7 th\u1ed1ng v\u1ec1 m\u00e1y local m\u00e0 b\u1ea1n \u0111ang ch\u1ea1y. B\u1ea1n h\u00e3y l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 tri\u1ec3n khai. \u0110\u1ea3m b\u1ea3o config file prom-graf/prometheus/config/prometheus.yml c\u1ee7a Prometheus server ch\u1ee9a config sau: prom-graf/prometheus/config/prometheus.yml 1 2 3 4 - job_name : \"node\" static_configs : - targets : - \"localhost:9100\" Tr\u00ean giao di\u1ec7n c\u1ee7a Grafana Web UI, \u1edf menu b\u00ean tr\u00e1i ch\u1ecdn Dashboards > Browse Click Import , nh\u1eadp v\u00e0o ID c\u1ee7a Node Exporter Full dashboard l\u00e0 1860 , click Load Ch\u1ecdn datasource l\u00e0 Prometheus, click Import . B\u1ea1n s\u1ebd nh\u00ecn th\u1ea5y dashboard gi\u1ed1ng nh\u01b0 sau Tu\u1ef3 thu\u1ed9c v\u00e0o c\u00e0i \u0111\u1eb7t c\u1ee7a Node Exporter service trong file docker-compose prom-graf/prom-graf-docker-compose.yml m\u00e0 m\u1ed9t v\u00e0i ph\u1ea7n c\u1ee7a dashboard s\u1ebd kh\u00f4ng \u0111\u01b0\u1ee3c hi\u1ec3n th\u1ecb h\u1ebft. B\u1ea1n c\u00f3 th\u1ec3 xem th\u00eam t\u1ea1i \u0111\u00e2y n\u1ebfu c\u1ea7n bi\u1ebft th\u00eam chi ti\u1ebft v\u1ec1 c\u00e1ch c\u1ea5u h\u00ecnh Node Exporter service. BentoML dashboard BentoML dashboard \u0111\u00e3 \u0111\u01b0\u1ee3c chu\u1ea9n b\u1ecb s\u1eb5n t\u1ea1i mlops-crash-course-code/monitoring_service/dashboards/bentoml_dashboard.json . B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 tri\u1ec3n khai BentoML dashboard tr\u00ean Grafana. Copy file dashboard tr\u00ean v\u00e0o mlops-crash-course-platform/prom-graf/run_env/grafana/dashboards Truy c\u1eadp v\u00e0o Grafana server t\u1ea1i http://localhost:3000 \u1ede sidebar b\u00ean ph\u1ea3i ch\u1ecdn Dashboards \u1ede giao di\u1ec7n c\u1ee7a trang Dashboards, b\u1ea1n s\u1ebd th\u1ea5y BentoML Dashboard , click ch\u1ecdn \u0111\u1ec3 m\u1edf. BentoML dashboard s\u1ebd gi\u1ed1ng nh\u01b0 sau. Dashboard n\u00e0y bao g\u1ed3m 2 panel: request_in_progress : Hi\u1ec3n th\u1ecb s\u1ed1 l\u01b0\u1ee3ng requests \u0111ang \u0111\u01b0\u1ee3c x\u1eed l\u00fd request_total : Hi\u1ec3n th\u1ecb s\u1ed1 l\u01b0\u1ee3ng requests trong 1s, \u0111\u01b0\u1ee3c \u0111o trong th\u1eddi gian m\u1ed7i 5 ph\u00fat Click v\u00e0o t\u00ean c\u1ee7a panel, ch\u1ecdn Explore \u0111\u1ec3 xem c\u00e2u truy v\u1ea5n PromQL \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 \u0111\u1ecdc data t\u1eeb Prometheus. Info PromQL l\u00e0 ng\u00f4n ng\u1eef truy v\u1ea5n \u0111\u01b0\u1ee3c d\u00f9ng trong Prometheus \u0111\u1ec3 t\u1ed5ng h\u1ee3p data d\u1ea1ng time-series trong th\u1eddi gian th\u1ef1c. B\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc th\u00eam t\u1ea1i \u0111\u00e2y . Question L\u00e0m th\u1ebf n\u00e0o m\u00e0 Grafana t\u1ef1 \u0111\u1ed9ng \u0111\u1ecdc \u0111\u01b0\u1ee3c file bentoml_dashboard.json ? Trong config prom-graf/grafana/config/dashboards.yaml c\u1ee7a Grafana, b\u1ea1n s\u1ebd th\u1ea5y m\u1ed9t s\u1ed1 config nh\u01b0 sau: prom-graf/grafana/config/dashboards.yaml 1 2 3 updateIntervalSeconds : 10 # (1) options : path : /opt/grafana/dashboards # (2) Chu k\u00ec m\u00e0 Grafana \u0111\u1ecdc v\u00e0 c\u1eadp nh\u1eadt dashboard n\u1eb1m trong folder ch\u1ee9a dashboard Folder ch\u1ee9a Grafana dashboard Ngo\u00e0i ra, trong file docker-compose c\u1ee7a Grafana server t\u1ea1i prom-graf/prom-graf-docker-compose.yml , ch\u00fang ta \u0111\u00e3 mount folder mlops-crash-course-platform/prom-graf/run_env/grafana/dashboards \u1edf m\u00e1y local v\u00e0o folder /opt/grafana/dashboards \u1edf trong docker container. \u0110i\u1ec1u n\u00e0y gi\u00fap Grafana t\u1ef1 \u0111\u1ed9ng \u0111\u1ecdc c\u00e1c file dashboard trong folder mlops-crash-course-platform/prom-graf/run_env/grafana/dashboards . T\u1ed5ng k\u1ebft Ch\u00fang ta v\u1eeba tri\u1ec3n khai ELK Stack \u0111\u1ec3 thu th\u1eadp logs t\u1eadp trung l\u1ea1i m\u1ed9t ch\u1ed7, truy v\u1ea5n v\u00e0 hi\u1ec3n th\u1ecb logs. Ch\u00fang ta c\u0169ng v\u1eeba tri\u1ec3n khai Prometheus, Grafana servers \u0111\u1ec3 thu th\u1eadp c\u00e1c metrics h\u1ec7 th\u1ed1ng v\u00e0 hi\u1ec3n th\u1ecb ch\u00fang. Trong th\u1ef1c t\u1ebf v\u1edbi ELK Stack, b\u1ea1n s\u1ebd c\u1ea7n thi\u1ebft l\u1eadp c\u00e1c b\u1ed9 l\u1ecdc \u0111\u1ec3 truy v\u1ea5n v\u00e0 hi\u1ec3n th\u1ecb logs hi\u1ec7u qu\u1ea3 h\u01a1n, d\u1ec5 d\u00e0ng t\u00ecm ra logs ch\u1ee9a l\u1ed7i \u0111\u1ec3 k\u1ecbp th\u1eddi x\u1eed l\u00fd. V\u1edbi Prometheus, Grafana, b\u1ea1n s\u1ebd c\u1ea7n t\u00ecm hi\u1ec3u th\u00eam v\u1ec1 c\u00e1ch vi\u1ebft c\u00e1c c\u00e2u l\u1ec7nh truy v\u1ea5n s\u1eed dung PromQL \u0111\u1ec3 c\u00f3 th\u1ec3 ch\u1ecdn l\u1ecdc v\u00e0 t\u1ed5ng h\u1ee3p metrics data hi\u1ec7u qu\u1ea3. B\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc th\u00eam t\u1ea1i Querying Prometheus . T\u1eadp trung logs l\u1ea1i m\u1ed9t n\u01a1i, theo d\u00f5i c\u00e1c metrics h\u1ec7 th\u1ed1ng c\u1ee7a Online serving service l\u00e0 ch\u01b0a \u0111\u1ee7 trong m\u1ed9t h\u1ec7 th\u1ed1ng ML. Ngo\u00e0i c\u00e1c metrics \u0111\u00f3, c\u00e1c metrics v\u1ec1 data v\u00e0 model c\u0169ng c\u1ea7n \u0111\u01b0\u1ee3c quan t\u00e2m, v\u00ed d\u1ee5 nh\u01b0 data \u1edf production c\u00f3 b\u1ecb drift kh\u00f4ng, model performance nh\u01b0 th\u1ebf n\u00e0o, v.v. Vi\u1ec7c theo d\u00f5i c\u00e1c metrics li\u00ean quan t\u1edbi data, model s\u1ebd gi\u00fap k\u1ecbp th\u1eddi c\u1eadp nh\u1eadt data v\u00e0 train l\u1ea1i model. Trong b\u00e0i sau, ch\u00fang ta s\u1ebd th\u1ef1c hi\u1ec7n tri\u1ec3n khai m\u1ed9t service kh\u00e1 ph\u1ee9c t\u1ea1p, \u0111\u00f3 l\u00e0 Monitoring service. T\u00e0i li\u1ec7u tham kh\u1ea3o Docker Logs with the ELK Stack Monitoring a Linux host with Prometheus, Node Exporter, and Docker Compose BentoML - Monitoring with Prometheus","title":"Metrics h\u1ec7 th\u1ed1ng"},{"location":"mlops-crash-course/monitoring/metrics-he-thong.html#gioi-thieu","text":"Trong b\u00e0i tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 t\u00ecm hi\u1ec3u v\u1ec1 theo d\u00f5i m\u1ed9t h\u1ec7 th\u1ed1ng ML n\u00f3i chung, v\u1edbi c\u00e1c metrics \u0111i\u1ec3n h\u00ecnh v\u00e0 c\u00e1c b\u1ed9 c\u00f4ng c\u1ee5 \u0111\u01b0\u1ee3c d\u00f9ng trong qu\u00e1 tr\u00ecnh theo d\u00f5i. Trong b\u00e0i n\u00e0y, ch\u00fang ta s\u1ebd tri\u1ec3n khai c\u00e1c gi\u1ea3i ph\u00e1p \u0111\u1ec3 theo d\u00f5i h\u1ec7 th\u1ed1ng ML trong kho\u00e1 h\u1ecdc n\u00e0y, c\u1ee5 th\u1ec3 l\u00e0 nh\u1eefng c\u00f4ng vi\u1ec7c sau: Tri\u1ec3n khai ELK Stack \u0111\u1ec3 theo d\u00f5i logs c\u1ee7a h\u1ec7 th\u1ed1ng Tri\u1ec3n khai Prometheus v\u00e0 Grafana servers \u0111\u1ec3 theo d\u00f5i metrics h\u1ec7 th\u1ed1ng","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/monitoring/metrics-he-thong.html#moi-truong-phat-trien","text":"\u1ede b\u00e0i n\u00e0y, ch\u00fang ta kh\u00f4ng vi\u1ebft code, m\u00e0 s\u1ebd tri\u1ec3n khai ELK Stack, Prometheus v\u00e0 Grafana servers. Do \u0111\u00f3, b\u1ea1n kh\u00f4ng c\u1ea7n c\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n. C\u00e1c MLOps tools \u0111\u01b0\u1ee3c d\u00f9ng trong b\u00e0i n\u00e0y bao g\u1ed3m: Elasticsearch, Kibana v\u00e0 Filebeat: thu th\u1eadp v\u00e0 hi\u1ec3n th\u1ecb logs t\u1eadp trung t\u1eeb Online serving service Prometheus v\u00e0 Grafana: theo d\u00f5i v\u00e0 hi\u1ec3n th\u1ecb metrics","title":"M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n"},{"location":"mlops-crash-course/monitoring/metrics-he-thong.html#logs","text":"Vi\u1ec7c s\u1eed d\u1ee5ng c\u00f4ng ngh\u1ec7 container c\u00f3 nhi\u1ec1u \u01b0u \u0111i\u1ec3m, nh\u01b0ng c\u0169ng xu\u1ea5t hi\u1ec7n th\u00eam nhi\u1ec1u th\u00e1ch th\u1ee9c cho c\u00e1c k\u0129 s\u01b0. M\u1ed9t trong nh\u1eefng th\u00e1ch th\u1ee9c \u0111\u00f3 l\u00e0 vi\u1ec7c thu th\u1eadp v\u00e0 x\u1eed l\u00fd logs c\u1ee7a m\u1ed7i container m\u1ed9t c\u00e1ch hi\u1ec7u qu\u1ea3. May m\u1eafn thay, ELK Stack l\u00e0 m\u1ed9t trong nh\u1eefng gi\u1ea3i ph\u00e1p \u0111\u01b0\u1ee3c c\u1ed9ng \u0111\u1ed3ng \u01b0a chu\u1ed9ng \u0111\u1ec3 x\u1eed l\u00fd v\u1ea5n \u0111\u1ec1 n\u00e0y.","title":"Logs"},{"location":"mlops-crash-course/monitoring/metrics-he-thong.html#cach-elk-stack-hoat-ong","text":"H\u00ecnh d\u01b0\u1edbi l\u00e0 m\u1ed9t pipeline \u0111i\u1ec3n h\u00ecnh cho vi\u1ec7c thu th\u1eadp v\u00e0 x\u1eed l\u00fd logs t\u1eadp trung s\u1eed d\u1ee5ng ELK Stack. \u0110\u1ea7u ti\u00ean, Logstash thu th\u1eadp logs t\u1eeb containers v\u00e0 l\u1ecdc logs. C\u00e1c c\u00e1ch \u0111\u1ec3 l\u1ecdc logs \u0111\u01b0\u1ee3c ng\u01b0\u1eddi d\u00f9ng \u0111\u1ecbnh ngh\u0129a. Sau \u0111\u00f3, Logstash \u0111\u1ea9y logs t\u1edbi Elasticsearch \u0111\u1ec3 \u0111\u00e1nh index, ti\u1ec7n cho vi\u1ec7c t\u00ecm ki\u1ebfm. Kibana l\u1ea5y logs ra, ph\u00e2n t\u00edch, hi\u1ec3n th\u1ecb data l\u00ean Kibana dashboard. C\u00f3 kh\u00e1 nhi\u1ec1u bi\u1ebfn th\u1ec3 c\u1ee7a pipeline tr\u00ean, v\u00ed d\u1ee5 nh\u01b0 d\u00f9ng Filebeat \u0111\u1ec3 thu th\u1eadp logs t\u1eeb containers v\u00e0 g\u1eedi logs t\u1edbi Elasticsearch. Trong b\u00e0i n\u00e0y, Logstash s\u1ebd \u0111\u01b0\u1ee3c thay th\u1ebf b\u1eb1ng Filebeat \u0111\u1ec3 thu th\u1eadp logs t\u1eeb containers v\u00e0 g\u1eedi t\u1edbi Elasticsearch. Info ELK Stack \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng l\u00e0m t\u00ean chung cho gi\u1ea3i ph\u00e1p, m\u1eb7c d\u00f9 Filebeat s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng thay th\u1ebf cho Logstash trong b\u00e0i n\u00e0y.","title":"C\u00e1ch ELK Stack ho\u1ea1t \u0111\u1ed9ng"},{"location":"mlops-crash-course/monitoring/metrics-he-thong.html#trien-khai-elk-stack","text":"\u0110\u1ec3 tri\u1ec3n khai ELK Stack, \u1edf trong repo mlops-crash-course-platform , b\u1ea1n h\u00e3y l\u00e0m c\u00e1c b\u01b0\u1edbc sau: Tri\u1ec3n khai c\u00e1c servers c\u1ea7n thi\u1ebft bash run.sh elk up C\u00e2u l\u1ec7nh tr\u00ean s\u1ebd ch\u1ea1y c\u00e1c servers v\u1edbi c\u00e1c file config sau: Filebeat server elk/extensions/filebeat/filebeat-compose.yml : File docker-compose \u0111\u1ec3 ch\u1ea1y Filebeat server elk/extensions/filebeat/config/filebeat.yml : Config c\u1ee7a Filebeat server Elasticsearch server elk/elk-docker-compose.yml : File docker-compose \u0111\u1ec3 ch\u1ea1y Elasticsearch server elk/elasticsearch/config/elasticsearch.yml : Config c\u1ee7a Elasticsearch server Kibana server elk/elk-docker-compose.yml : File docker-compose \u0111\u1ec3 ch\u1ea1y Kibana server elk/kibana/config/kibana.yml : Config c\u1ee7a Kibana server \u0110\u1ee3i 20s \u0111\u1ec3 vi\u1ec7c kh\u1edfi t\u1ea1o c\u00e1c servers ho\u00e0n th\u00e0nh Ki\u1ec3m tra Elasticsearch server \u0111\u01b0\u1ee3c tri\u1ec3n khai th\u00e0nh c\u00f4ng ch\u01b0a: curl -X GET http://localhost:9200 -u elastic:changeme N\u1ebfu Elasticsearch server \u0111\u01b0\u1ee3c tri\u1ec3n khai th\u00e0nh c\u00f4ng, \u1edf terminal s\u1ebd hi\u1ec3n th\u1ecb t\u01b0\u01a1ng t\u1ef1 nh\u01b0 sau: { \"name\" : \"ee711e6d1977\" , \"cluster_name\" : \"docker-cluster\" , \"cluster_uuid\" : \"sG38FtFuQSedHb68U_Uv5Q\" , \"version\" : { \"number\" : \"8.4.1\" , \"build_flavor\" : \"default\" , \"build_type\" : \"docker\" , \"build_hash\" : \"2bd229c8e56650b42e40992322a76e7914258f0c\" , \"build_date\" : \"2022-08-26T12:11:43.232597118Z\" , \"build_snapshot\" : false, \"lucene_version\" : \"9.3.0\" , \"minimum_wire_compatibility_version\" : \"7.17.0\" , \"minimum_index_compatibility_version\" : \"7.0.0\" } , \"tagline\" : \"You Know, for Search\" } Ki\u1ec3m tra Kibana server \u0111\u01b0\u1ee3c tri\u1ec3n khai th\u00e0nh c\u00f4ng ch\u01b0a: Tr\u00ean browser, truy c\u1eadp v\u00e0o Kibana server t\u1ea1i http://localhost:5601 \u0110\u0103ng nh\u1eadp v\u1edbi t\u00ean user l\u00e0 elastic v\u00e0 m\u1eadt kh\u1ea9u l\u00e0 changeme Vi\u1ec7c \u0111\u0103ng nh\u1eadp th\u00e0nh c\u00f4ng ch\u1ee9ng t\u1ecf Kibana server \u0111\u00e3 tri\u1ec3n khai th\u00e0nh c\u00f4ng.","title":"Tri\u1ec3n khai ELK Stack"},{"location":"mlops-crash-course/monitoring/metrics-he-thong.html#truy-van-logs","text":"Sau khi \u0111\u00e3 tri\u1ec3n khai ELK Stack, h\u00e3y th\u1eed truy v\u1ea5n logs \u1edf ELK Stack xem logs \u0111\u00e3 \u0111\u01b0\u1ee3c thu th\u1eadp th\u00e0nh c\u00f4ng t\u1eeb Online serving service hay ch\u01b0a. G\u1eedi v\u00e0i requests t\u1edbi Online serving API b\u1eb1ng c\u00e1ch truy c\u1eadp http://localhost:8172 , m\u1edf API /inference , click Try it out . \u1ede ph\u1ea7n Request body , b\u1ea1n g\u00f5 n\u1ed9i dung sau: { \"request_id\" : \"uuid-1\" , \"driver_ids\" : [ 1001 , 1002 , 1003 , 1004 , 1005 ] } \u0110\u0103ng nh\u1eadp v\u00e0o Kibana server http://localhost:5601 . \u1ede sidebar b\u00ean ph\u1ea3i, ch\u1ecdn Discover . Tr\u00ean UI c\u1ee7a page Discover , trong ph\u1ea7n g\u00f5 c\u00e2u truy v\u1ea5n, g\u00f5 truy v\u1ea5n sau: container.name:\"online_serving\" Info C\u00e2u truy v\u1ea5n tr\u00ean s\u1eed d\u1ee5ng ng\u00f4n ng\u1eef truy v\u1ea5n KQL. B\u1ea1n c\u00f3 th\u1ec3 tham kh\u1ea3o th\u00eam t\u1ea1i \u0111\u00e2y . B\u1ea3ng hi\u1ec3n th\u1ecb logs c\u1ee7a Online Serving service s\u1ebd gi\u1ed1ng nh\u01b0 sau B\u1ea1n c\u00f3 th\u1ec3 l\u01b0u l\u1ea1i l\u1ea7n discover n\u00e0y b\u1eb1ng c\u00e1ch click v\u00e0o n\u00fat Save \u1edf g\u00f3c tr\u00ean b\u00ean ph\u1ea3i. Question L\u00e0m th\u1ebf n\u00e0o ELK stack c\u00f3 th\u1ec3 bi\u1ebft \u0111\u01b0\u1ee3c n\u00ean thu th\u1eadp logs t\u1eeb containers n\u00e0o? N\u1ebfu b\u1ea1n n\u00e0o \u0111\u00e3 \u0111\u1ecdc file config c\u1ee7a Filebeat t\u1ea1i elk/extensions/filebeat/config/filebeat.yml , b\u1ea1n s\u1ebd th\u1ea5y m\u1ed9t \u0111o\u1ea1n config nh\u01b0 sau: elk/extensions/filebeat/config/filebeat.yml 1 2 3 4 5 6 filebeat.autodiscover : providers : # The Docker autodiscover provider automatically retrieves logs from Docker # containers as they start and stop. - type : docker hints.enabled : true \u0110o\u1ea1n config n\u00e0y c\u1ea5u h\u00ecnh \u0111\u1ec3 Filebeat t\u1ef1 \u0111\u1ed9ng thu th\u1eadp logs t\u1eeb c\u00e1c containers v\u00e0 g\u1eedi v\u1ec1 Elasticsearch. Trong th\u1ef1c t\u1ebf, ch\u00fang ta kh\u00f4ng mu\u1ed1n thu th\u1eadp logs t\u1eeb m\u1ecdi containers v\u00e0 c\u0169ng mu\u1ed1n l\u1ecdc ra nh\u1eefng d\u00f2ng log nh\u1ea5t \u0111\u1ecbnh t\u1eeb service. \u0110\u1ec3 l\u00e0m \u0111i\u1ec1u n\u00e0y, b\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc th\u00eam t\u1ea1i \u0111\u00e2y .","title":"Truy v\u1ea5n logs"},{"location":"mlops-crash-course/monitoring/metrics-he-thong.html#metrics-he-thong","text":"Trong ph\u1ea7n n\u00e0y, Prometheus s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 thu th\u1eadp c\u00e1c metrics h\u1ec7 th\u1ed1ng v\u00e0 Grafana s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 hi\u1ec3n th\u1ecb c\u00e1c metrics \u0111\u00f3.","title":"Metrics h\u1ec7 th\u1ed1ng"},{"location":"mlops-crash-course/monitoring/metrics-he-thong.html#prometheus-va-grafana-servers","text":"\u0110\u1ec3 tri\u1ec3n khai Prometheus v\u00e0 Grafana servers, \u1edf trong repo mlops-crash-course-platform , b\u1ea1n h\u00e3y l\u00e0m c\u00e1c b\u01b0\u1edbc sau: Tri\u1ec3n khai c\u00e1c servers c\u1ea7n thi\u1ebft bash run.sh prom-graf up C\u00e2u l\u1ec7nh tr\u00ean s\u1ebd ch\u1ea1y c\u00e1c servers sau: Prometheus server prom-graf/prom-graf-docker-compose.yml : File docker-compose \u0111\u1ec3 ch\u1ea1y Prometheus server prom-graf/prometheus/config/prometheus.yml : Config c\u1ee7a Prometheus server Grafana server prom-graf/prom-graf-docker-compose.yml : File docker-compose \u0111\u1ec3 ch\u1ea1y Grafana server prom-graf/grafana/config/dashboards.yaml : Grafana dashboard config prom-graf/grafana/config/datasources.yaml . Grafana datasource config. File n\u00e0y \u0111\u1ecbnh ngh\u0129a s\u1eb5n datasource l\u00e0 Prometheus server \u0111\u01b0\u1ee3c tri\u1ec3n khai \u1edf tr\u00ean Node exporter server prom-graf/prom-graf-docker-compose.yml : File docker-compose \u0111\u1ec3 ch\u1ea1y Node exporter server Node exporter server \u0111\u01b0\u1ee3c c\u00e0i \u0111\u1eb7t th\u00eam v\u00e0o \u0111\u1ec3 t\u00ednh to\u00e1n c\u00e1c metrics li\u00ean quan t\u1edbi node (ch\u00ednh l\u00e0 m\u00e1y local hi\u1ec7n t\u1ea1i c\u1ee7a b\u1ea1n), v\u00ed d\u1ee5 nh\u01b0 c\u00e1c metrics li\u00ean quan t\u1edbi CPU, memory, v.v. Ch\u00fang ta s\u1ebd h\u1ecdc c\u00e1ch l\u1ea5y ra c\u00e1c metrics n\u00e0y t\u1eeb Node exporter server v\u00e0 hi\u1ec3n th\u1ecb l\u00ean Grafana dashboard \u1edf ph\u1ea7n d\u01b0\u1edbi. Ki\u1ec3m tra Prometheus server \u0111\u01b0\u1ee3c tri\u1ec3n khai th\u00e0nh c\u00f4ng ch\u01b0a: Truy c\u1eadp Prometheus server t\u1ea1i http://localhost:9090 Tr\u00ean Navbar, click Status , ch\u1ecdn Targets Ki\u1ec3m tra xem c\u00e1c endpoints c\u1ee7a c\u00e1c job prometheus , node , online_serving c\u00f3 \u1edf tr\u1ea1ng th\u00e1i UP kh\u00f4ng. B\u1ea1n c\u00f3 th\u1ec3 c\u1ea7n \u0111\u1ee3i 30s cho t\u1edbi khi c\u00e1c endpoints \u0111\u1ea1t tr\u1ea1ng th\u00e1i n\u00e0y. H\u00ecnh d\u01b0\u1edbi cho th\u1ea5y endpoints c\u1ee7a c\u00e1c targets tr\u00ean \u0111\u00e3 \u1edf tr\u1ea1ng th\u00e1i UP . Info M\u1ed9t endpoint ho\u1eb7c m\u1ed9t instance , trong Prometheus \u0111\u01b0\u1ee3c hi\u1ec3u l\u00e0 \u0111\u1ecba ch\u1ec9 c\u1ee7a service m\u00e0 Prometheus thu th\u1eadp metrics. M\u1ed9t job l\u00e0 m\u1ed9t process l\u00e0m nhi\u1ec7m v\u1ee5 thu th\u1eadp metrics t\u1eeb m\u1ed9t t\u1eadp h\u1ee3p c\u00e1c instance c\u00f3 chung m\u1ee5c \u0111\u00edch. B\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc th\u00eam t\u1ea1i \u0111\u00e2y . Ki\u1ec3m tra xem Grafana server \u0111\u01b0\u1ee3c tri\u1ec3n khai th\u00e0nh c\u00f4ng ch\u01b0a Truy c\u1eadp v\u00e0o Grafana server t\u1ea1i http://localhost:3000 \u0110\u0103ng nh\u1eadp v\u1edbi t\u00ean user l\u00e0 admin , v\u00e0 m\u1eadt kh\u1ea9u l\u00e0 admin . Vi\u1ec7c \u0111\u0103ng nh\u1eadp th\u00e0nh c\u00f4ng ch\u1ee9ng t\u1ecf Grafana server \u0111\u00e3 \u0111\u01b0\u1ee3c tri\u1ec3n khai th\u00e0nh c\u00f4ng. Info Grafana c\u1ea7n m\u1ed9t datasource \u0111\u1ec3 c\u00f3 th\u1ec3 l\u1ea5y metrics v\u1ec1 v\u00e0 hi\u1ec3n th\u1ecb. Prometheus \u0111\u00e3 \u0111\u01b0\u1ee3c c\u1ea5u h\u00ecnh l\u00e0m datasource m\u1eb7c \u0111\u1ecbnh c\u1ee7a Grafana. C\u1ea5u h\u00ecnh n\u00e0y \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u1ea1i prom-graf/grafana/config/datasources.yaml . Question L\u00e0m th\u1ebf n\u00e0o \u0111\u1ec3 t\u1ea1o m\u1ed9t job hay m\u1ed9t instance trong Prometheus? Trong config file prom-graf/prometheus/config/prometheus.yml c\u1ee7a Prometheus server, job online_serving \u0111\u00e3 \u0111\u01b0\u1ee3c thi\u1ebft l\u1eadp s\u1eb5n \u0111\u1ec3 thu th\u1eadp metrics t\u1eeb Online serving service. prom-graf/prometheus/config/prometheus.yml 1 2 3 4 5 - job_name : \"online_serving\" scrape_interval : 5s static_configs : - targets : - \"localhost:8172\" Thi\u1ebft l\u1eadp n\u00e0y b\u00e1o cho Prometheus bi\u1ebft r\u1eb1ng, m\u1ed7i 5s n\u00f3 c\u1ea7n ph\u1ea3i thu th\u1eadp metrics t\u1eeb URI http://localhost:8172/metrics , v\u1edbi /metrics l\u00e0 route m\u1eb7c \u0111\u1ecbnh \u0111\u1ec3 Prometheus \u0111\u1ecdc c\u00e1c metrics. B\u1ea1n c\u00f3 th\u1ec3 m\u1edf URI n\u00e0y tr\u00ean browser v\u00e0 s\u1ebd th\u1ea5y n\u1ed9i dung t\u01b0\u01a1ng t\u1ef1 nh\u01b0 sau.","title":"Prometheus v\u00e0 Grafana servers"},{"location":"mlops-crash-course/monitoring/metrics-he-thong.html#node-exporter-full-dashboard","text":"\u1ede ph\u1ea7n n\u00e0y, ch\u00fang ta s\u1ebd tri\u1ec3n khai Grafana dashboard t\u00ean l\u00e0 Node Exporter Full . Dashboard n\u00e0y \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng s\u1eb5n b\u1edfi c\u1ed9ng \u0111\u1ed3ng s\u1eed d\u1ee5ng Prometheus v\u00e0 Grafana. N\u00f3 hi\u1ec3n th\u1ecb c\u00e1c th\u00f4ng tin quan tr\u1ecdng c\u1ee7a h\u1ec7 th\u1ed1ng v\u1ec1 m\u00e1y local m\u00e0 b\u1ea1n \u0111ang ch\u1ea1y. B\u1ea1n h\u00e3y l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 tri\u1ec3n khai. \u0110\u1ea3m b\u1ea3o config file prom-graf/prometheus/config/prometheus.yml c\u1ee7a Prometheus server ch\u1ee9a config sau: prom-graf/prometheus/config/prometheus.yml 1 2 3 4 - job_name : \"node\" static_configs : - targets : - \"localhost:9100\" Tr\u00ean giao di\u1ec7n c\u1ee7a Grafana Web UI, \u1edf menu b\u00ean tr\u00e1i ch\u1ecdn Dashboards > Browse Click Import , nh\u1eadp v\u00e0o ID c\u1ee7a Node Exporter Full dashboard l\u00e0 1860 , click Load Ch\u1ecdn datasource l\u00e0 Prometheus, click Import . B\u1ea1n s\u1ebd nh\u00ecn th\u1ea5y dashboard gi\u1ed1ng nh\u01b0 sau Tu\u1ef3 thu\u1ed9c v\u00e0o c\u00e0i \u0111\u1eb7t c\u1ee7a Node Exporter service trong file docker-compose prom-graf/prom-graf-docker-compose.yml m\u00e0 m\u1ed9t v\u00e0i ph\u1ea7n c\u1ee7a dashboard s\u1ebd kh\u00f4ng \u0111\u01b0\u1ee3c hi\u1ec3n th\u1ecb h\u1ebft. B\u1ea1n c\u00f3 th\u1ec3 xem th\u00eam t\u1ea1i \u0111\u00e2y n\u1ebfu c\u1ea7n bi\u1ebft th\u00eam chi ti\u1ebft v\u1ec1 c\u00e1ch c\u1ea5u h\u00ecnh Node Exporter service.","title":"Node Exporter Full dashboard"},{"location":"mlops-crash-course/monitoring/metrics-he-thong.html#bentoml-dashboard","text":"BentoML dashboard \u0111\u00e3 \u0111\u01b0\u1ee3c chu\u1ea9n b\u1ecb s\u1eb5n t\u1ea1i mlops-crash-course-code/monitoring_service/dashboards/bentoml_dashboard.json . B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 tri\u1ec3n khai BentoML dashboard tr\u00ean Grafana. Copy file dashboard tr\u00ean v\u00e0o mlops-crash-course-platform/prom-graf/run_env/grafana/dashboards Truy c\u1eadp v\u00e0o Grafana server t\u1ea1i http://localhost:3000 \u1ede sidebar b\u00ean ph\u1ea3i ch\u1ecdn Dashboards \u1ede giao di\u1ec7n c\u1ee7a trang Dashboards, b\u1ea1n s\u1ebd th\u1ea5y BentoML Dashboard , click ch\u1ecdn \u0111\u1ec3 m\u1edf. BentoML dashboard s\u1ebd gi\u1ed1ng nh\u01b0 sau. Dashboard n\u00e0y bao g\u1ed3m 2 panel: request_in_progress : Hi\u1ec3n th\u1ecb s\u1ed1 l\u01b0\u1ee3ng requests \u0111ang \u0111\u01b0\u1ee3c x\u1eed l\u00fd request_total : Hi\u1ec3n th\u1ecb s\u1ed1 l\u01b0\u1ee3ng requests trong 1s, \u0111\u01b0\u1ee3c \u0111o trong th\u1eddi gian m\u1ed7i 5 ph\u00fat Click v\u00e0o t\u00ean c\u1ee7a panel, ch\u1ecdn Explore \u0111\u1ec3 xem c\u00e2u truy v\u1ea5n PromQL \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 \u0111\u1ecdc data t\u1eeb Prometheus. Info PromQL l\u00e0 ng\u00f4n ng\u1eef truy v\u1ea5n \u0111\u01b0\u1ee3c d\u00f9ng trong Prometheus \u0111\u1ec3 t\u1ed5ng h\u1ee3p data d\u1ea1ng time-series trong th\u1eddi gian th\u1ef1c. B\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc th\u00eam t\u1ea1i \u0111\u00e2y . Question L\u00e0m th\u1ebf n\u00e0o m\u00e0 Grafana t\u1ef1 \u0111\u1ed9ng \u0111\u1ecdc \u0111\u01b0\u1ee3c file bentoml_dashboard.json ? Trong config prom-graf/grafana/config/dashboards.yaml c\u1ee7a Grafana, b\u1ea1n s\u1ebd th\u1ea5y m\u1ed9t s\u1ed1 config nh\u01b0 sau: prom-graf/grafana/config/dashboards.yaml 1 2 3 updateIntervalSeconds : 10 # (1) options : path : /opt/grafana/dashboards # (2) Chu k\u00ec m\u00e0 Grafana \u0111\u1ecdc v\u00e0 c\u1eadp nh\u1eadt dashboard n\u1eb1m trong folder ch\u1ee9a dashboard Folder ch\u1ee9a Grafana dashboard Ngo\u00e0i ra, trong file docker-compose c\u1ee7a Grafana server t\u1ea1i prom-graf/prom-graf-docker-compose.yml , ch\u00fang ta \u0111\u00e3 mount folder mlops-crash-course-platform/prom-graf/run_env/grafana/dashboards \u1edf m\u00e1y local v\u00e0o folder /opt/grafana/dashboards \u1edf trong docker container. \u0110i\u1ec1u n\u00e0y gi\u00fap Grafana t\u1ef1 \u0111\u1ed9ng \u0111\u1ecdc c\u00e1c file dashboard trong folder mlops-crash-course-platform/prom-graf/run_env/grafana/dashboards .","title":"BentoML dashboard"},{"location":"mlops-crash-course/monitoring/metrics-he-thong.html#tong-ket","text":"Ch\u00fang ta v\u1eeba tri\u1ec3n khai ELK Stack \u0111\u1ec3 thu th\u1eadp logs t\u1eadp trung l\u1ea1i m\u1ed9t ch\u1ed7, truy v\u1ea5n v\u00e0 hi\u1ec3n th\u1ecb logs. Ch\u00fang ta c\u0169ng v\u1eeba tri\u1ec3n khai Prometheus, Grafana servers \u0111\u1ec3 thu th\u1eadp c\u00e1c metrics h\u1ec7 th\u1ed1ng v\u00e0 hi\u1ec3n th\u1ecb ch\u00fang. Trong th\u1ef1c t\u1ebf v\u1edbi ELK Stack, b\u1ea1n s\u1ebd c\u1ea7n thi\u1ebft l\u1eadp c\u00e1c b\u1ed9 l\u1ecdc \u0111\u1ec3 truy v\u1ea5n v\u00e0 hi\u1ec3n th\u1ecb logs hi\u1ec7u qu\u1ea3 h\u01a1n, d\u1ec5 d\u00e0ng t\u00ecm ra logs ch\u1ee9a l\u1ed7i \u0111\u1ec3 k\u1ecbp th\u1eddi x\u1eed l\u00fd. V\u1edbi Prometheus, Grafana, b\u1ea1n s\u1ebd c\u1ea7n t\u00ecm hi\u1ec3u th\u00eam v\u1ec1 c\u00e1ch vi\u1ebft c\u00e1c c\u00e2u l\u1ec7nh truy v\u1ea5n s\u1eed dung PromQL \u0111\u1ec3 c\u00f3 th\u1ec3 ch\u1ecdn l\u1ecdc v\u00e0 t\u1ed5ng h\u1ee3p metrics data hi\u1ec7u qu\u1ea3. B\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc th\u00eam t\u1ea1i Querying Prometheus . T\u1eadp trung logs l\u1ea1i m\u1ed9t n\u01a1i, theo d\u00f5i c\u00e1c metrics h\u1ec7 th\u1ed1ng c\u1ee7a Online serving service l\u00e0 ch\u01b0a \u0111\u1ee7 trong m\u1ed9t h\u1ec7 th\u1ed1ng ML. Ngo\u00e0i c\u00e1c metrics \u0111\u00f3, c\u00e1c metrics v\u1ec1 data v\u00e0 model c\u0169ng c\u1ea7n \u0111\u01b0\u1ee3c quan t\u00e2m, v\u00ed d\u1ee5 nh\u01b0 data \u1edf production c\u00f3 b\u1ecb drift kh\u00f4ng, model performance nh\u01b0 th\u1ebf n\u00e0o, v.v. Vi\u1ec7c theo d\u00f5i c\u00e1c metrics li\u00ean quan t\u1edbi data, model s\u1ebd gi\u00fap k\u1ecbp th\u1eddi c\u1eadp nh\u1eadt data v\u00e0 train l\u1ea1i model. Trong b\u00e0i sau, ch\u00fang ta s\u1ebd th\u1ef1c hi\u1ec7n tri\u1ec3n khai m\u1ed9t service kh\u00e1 ph\u1ee9c t\u1ea1p, \u0111\u00f3 l\u00e0 Monitoring service.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/monitoring/metrics-he-thong.html#tai-lieu-tham-khao","text":"Docker Logs with the ELK Stack Monitoring a Linux host with Prometheus, Node Exporter, and Docker Compose BentoML - Monitoring with Prometheus","title":"T\u00e0i li\u1ec7u tham kh\u1ea3o"},{"location":"mlops-crash-course/monitoring/thiet-ke-monitoring-service.html","text":"Photo by Ibrahim Boran on Unsplash Gi\u1edbi thi\u1ec7u Trong b\u00e0i tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 tri\u1ec3n khai ELK Stack thu th\u1eadp, theo d\u00f5i logs t\u1eeb c\u00e1c services, Prometheus v\u00e0 Grafana server \u0111\u1ec3 theo d\u00f5i c\u00e1c metrics h\u1ec7 th\u1ed1ng nh\u01b0 CPU, memory, network, v.v. Trong m\u1ed9t h\u1ec7 th\u1ed1ng ML, ch\u00fang ta c\u0169ng c\u1ea7n theo d\u00f5i metrics li\u00ean quan t\u1edbi data, model \u0111\u1ec3 k\u1ecbp th\u1eddi ph\u00e1t hi\u1ec7n s\u1ef1 thay \u0111\u1ed5i c\u1ee7a ch\u00fang \u1edf production, \u0111\u1ec3 c\u1eadp nh\u1eadt data hay train l\u1ea1i model k\u1ecbp th\u1eddi. Trong b\u00e0i n\u00e0y, ch\u00fang ta s\u1ebd thi\u1ebft k\u1ebf monitoring service v\u1edbi c\u00e1c c\u00f4ng vi\u1ec7c c\u1ee5 th\u1ec3 sau: T\u1ea1o ra dataset ch\u1ee9a feature b\u1ecb drift Tri\u1ec3n khai monitoring service \u0111\u1ec3 theo d\u00f5i data v\u00e0 model performance Thi\u1ebft l\u1eadp Grafana dashboards \u0111\u1ec3 hi\u1ec3n th\u1ecb metrics v\u1ec1 data v\u00e0 model M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n C\u00e1c b\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 c\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n: C\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng Python 3.9 m\u1edbi v\u1edbi c\u00e1c th\u01b0 vi\u1ec7n c\u1ea7n thi\u1ebft trong file monitoring_service/dev_requirements.txt \u0110\u1eb7t environment variable MONITORING_SERVICE_DIR \u1edf terminal b\u1ea1n d\u00f9ng b\u1eb1ng \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i t\u1edbi folder monitoring_service . Env var n\u00e0y h\u1ed7 tr\u1ee3 ch\u1ea1y python code \u1edf folder monitoring_service/src trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n. cd mlops-crash-course-code/monitoring_service export MONITORING_SERVICE_DIR = $( pwd ) C\u00e1c tools s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong b\u00e0i n\u00e0y bao g\u1ed3m: Feast: truy xu\u1ea5t Feature Store Flask: vi\u1ebft API cho monitoring service Evidently: ki\u1ec3m tra ch\u1ea5t l\u01b0\u1ee3ng data v\u00e0 model performance Note Trong qu\u00e1 tr\u00ecnh ch\u1ea1y code cho t\u1ea5t c\u1ea3 c\u00e1c ph\u1ea7n d\u01b0\u1edbi \u0111\u00e2y, gi\u1ea3 s\u1eed r\u1eb1ng folder g\u1ed1c n\u01a1i ch\u00fang ta l\u00e0m vi\u1ec7c l\u00e0 folder monitoring_service . Architecture Theo d\u00f5i metrics li\u00ean quan t\u1edbi ch\u1ea5t l\u01b0\u1ee3ng data v\u00e0 model performance, l\u00e0 qu\u00e1 tr\u00ecnh ki\u1ec3m tra xem data v\u00e0 model performance thay \u0111\u1ed5i nh\u01b0 th\u1ebf n\u00e0o theo th\u1eddi gian. \u0110\u00e2y c\u0169ng l\u00e0 y\u00eau c\u1ea7u \u0111\u1ea7u ra c\u1ee7a monitoring service. C\u00e1c ch\u1ee9c n\u0103ng ch\u00ednh c\u1ee7a monitoring service \u0111\u01b0\u1ee3c th\u1ec3 hi\u1ec7n nh\u01b0 h\u00ecnh d\u01b0\u1edbi graph LR n00[ ]--Training data-->n1[Ph\u00e1t hi\u1ec7n<br>data drift]--Data metrics-->n01[ ] n02[ ]--Production data-->n1 n10[ ]--Prediction-->n2[Theo d\u00f5i model<br>performance]--Model performance-->n11[ ] n12[ ]--Label-->n2 style n00 height:0px; style n01 height:0px; style n02 height:0px; style n10 height:0px; style n11 height:0px; style n12 height:0px; \u0110\u1ec3 bi\u1ebft data thay \u0111\u1ed5i th\u1ebf n\u00e0o, training data s\u1ebd \u0111\u01b0\u1ee3c so s\u00e1nh v\u1edbi production data d\u1ef1a tr\u00ean m\u1ed9t thu\u1eadt to\u00e1n so s\u00e1nh. Thu\u1eadt to\u00e1n n\u00e0y xem x\u00e9t c\u00e1c thu\u1ed9c t\u00ednh v\u1ec1 th\u1ed1ng k\u00ea c\u1ee7a data b\u1ecb thay \u0111\u1ed5i nhi\u1ec1u hay \u00edt th\u1ebf n\u00e0o. Nh\u01b0 v\u1eady, \u0111\u1ea7u v\u00e0o c\u1ee7a ch\u1ee9c n\u0103ng Ph\u00e1t hi\u1ec7n data drift l\u00e0 features \u1edf khi training v\u00e0 features \u1edf production. \u0110\u1ec3 bi\u1ebft model performance thay \u0111\u1ed5i th\u1ebf n\u00e0o, label \u1edf production s\u1ebd \u0111\u01b0\u1ee3c so s\u00e1nh v\u1edbi prediction m\u00e0 model t\u1ea1o ra. Model performance \u1edf production c\u0169ng c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c so s\u00e1nh v\u1edbi model performance \u1edf khi training. \u0110\u1ec3 \u0111\u01a1n gi\u1ea3n, monitoring service s\u1ebd ch\u1ec9 theo d\u00f5i model performance \u1edf production. Nh\u01b0 v\u1eady, \u0111\u1ea7u v\u00e0o c\u1ee7a ch\u1ee9c n\u0103ng Theo d\u00f5i model performance l\u00e0 d\u1ef1 \u0111o\u00e1n c\u1ee7a model v\u00e0 label \u1edf production. Trong b\u00e0i n\u00e0y, th\u01b0 vi\u1ec7n Evidently \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 ph\u00e1t hi\u1ec7n data drift, t\u00ednh to\u00e1n model performance metrics. Evidently l\u00e0 m\u1ed9t th\u01b0 vi\u1ec7n open-source \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 \u0111\u00e1nh gi\u00e1, ki\u1ec3m tra v\u00e0 gi\u00e1m s\u00e1t data, model performance. Evidently \u0111\u00e3 t\u00edch h\u1ee3p s\u1eb5n c\u00e1c thu\u1eadt to\u00e1n \u0111\u1ec3 theo d\u00f5i c\u00e1c thu\u1ed9c t\u00ednh th\u1ed1ng k\u00ea c\u1ee7a data nh\u01b0 PSI , K-L divergence , Jensen-Shannon distance , Wasserstein distance v\u00e0 c\u00e1c metrics ph\u1ed5 bi\u1ebfn c\u1ee7a model performance nh\u01b0 Accuracy , F1 score , RMSE , MAE , v.v. B\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc th\u00eam \u1edf document c\u1ee7a Evidently \u0111\u1ec3 t\u00ecm hi\u1ec3u v\u1ec1 c\u00e1ch m\u00e0 Evidently l\u1ef1a ch\u1ecdn thu\u1eadt to\u00e1n t\u1ef1 \u0111\u1ed9ng khi ph\u00e1t hi\u1ec7n data drift. C\u00e1ch test Tr\u01b0\u1edbc khi code, ch\u00fang ta s\u1ebd ph\u00e2n t\u00edch xem l\u00e0m th\u1ebf n\u00e0o \u0111\u1ec3 test c\u00e1c ch\u1ee9c n\u0103ng c\u1ee7a monitoring service. Quote Before you start anything, learn how to finish it. Ph\u00e1t hi\u1ec7n data drift \u0110\u1ec3 test ch\u1ee9c n\u0103ng Ph\u00e1t hi\u1ec7n data drift , 2 b\u1ed9 datasets c\u1ea7n \u0111\u01b0\u1ee3c t\u1ea1o ra: # T\u00ean dataset Gi\u00e1 tr\u1ecb 1 normal_data Trong \u0111o\u1ea1n [A, B] 2 drift_data Trong \u0111o\u1ea1n [C, D] ; C , D n\u1eb1m \u0111\u1ee7 xa A , B \u0111\u1ec3 g\u00e2y ra data drift Hai t\u00ecnh hu\u1ed1ng nh\u01b0 b\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y c\u0169ng c\u1ea7n \u0111\u01b0\u1ee3c s\u1eafp \u0111\u1eb7t. # T\u00ecnh hu\u1ed1ng Data \u0111\u1ea7u v\u00e0o Dataset \u0111\u01b0\u1ee3c d\u00f9ng 1 Production data kh\u00f4ng b\u1ecb drift Training data normal_data Production data normal_data 2 Production data b\u1ecb drift Training data normal_data Production data drift_data \u1ede t\u00ecnh hu\u1ed1ng 1, production data kh\u00f4ng b\u1ecb drift normal_data v\u1eeba l\u00e0 training data, v\u1eeba l\u00e0 production data v\u00e0 \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o Online Feature Store. Data \u0111\u01b0\u1ee3c l\u1ea5y ra \u1edf Online Feature Store s\u1ebd gi\u1ed1ng v\u1edbi prodution data, t\u1ee9c l\u00e0 s\u1ebd kh\u00f4ng x\u1ea3y ra data drift. \u1ede t\u00ecnh hu\u1ed1ng 2, production data b\u1ecb drift normal_data \u1edf tr\u00ean v\u1eabn l\u00e0 training data, c\u00f2n drift_data l\u00e0 production data. drift_data \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o Online Feature Store. Data \u0111\u01b0\u1ee3c l\u1ea5y ra \u1edf Online Feature Store ( drift_data ) \u0111\u1ec3 model d\u1ef1 \u0111o\u00e1n c\u00f3 gi\u00e1 tr\u1ecb n\u1eb1m xa training data ( normal_data ), t\u1ee9c l\u00e0 s\u1ebd x\u1ea3y ra data drift. Question C\u1ea7n l\u1ea5y ra bao nhi\u00eau records t\u1eeb training data v\u00e0 t\u00edch lu\u1ef9 bao nhi\u00eau records c\u1ee7a production data th\u00ec m\u1edbi b\u1eaft \u0111\u1ea7u th\u1ef1c hi\u1ec7n qu\u00e1 tr\u00ecnh so s\u00e1nh? Khi training dataset qu\u00e1 l\u1edbn, ch\u00fang ta kh\u00f4ng th\u1ec3 l\u1ea5y h\u1ebft c\u00e1c records ra \u0111\u1ec3 so s\u00e1nh \u0111\u01b0\u1ee3c. Th\u00f4ng th\u01b0\u1eddng, m\u1ed9t con s\u1ed1 \u0111\u1ee7 nh\u1ecf s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 vi\u1ec7c theo d\u00f5i data \u0111\u01b0\u1ee3c di\u1ec5n ra li\u00ean t\u1ee5c v\u00e0 g\u1ea7n v\u1edbi th\u1eddi gian th\u1ef1c (near real-time). \u0110\u1ed3ng th\u1eddi, con s\u1ed1 n\u00e0y c\u0169ng ph\u1ea3i \u0111\u1ee7 l\u1edbn, \u0111\u1ec3 c\u00e1c t\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a data kh\u00f4ng qu\u00e1 kh\u00e1c bi\u1ec7t \u1edf c\u00e1c ph\u1ea7n c\u1ee7a dataset. Ph\u01b0\u01a1ng ph\u00e1p l\u1ef1a ch\u1ecdn v\u00e0 s\u1ed1 records c\u1ea7n l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o nhu c\u1ea7u v\u00e0 t\u1ea7n su\u1ea5t theo d\u00f5i production data c\u1ee7a m\u1ed7i d\u1ef1 \u00e1n. Tip Thu\u1eadt ng\u1eef reference window ch\u1ec9 t\u1eadp h\u1ee3p c\u00e1c records \u0111\u1ec3 so s\u00e1nh v\u1edbi production data. Thu\u1eadt ng\u1eef test window ch\u1ec9 t\u1eadp h\u1ee3p c\u00e1c records \u0111\u1ec3 so s\u00e1nh v\u1edbi reference window \u0110\u1ec3 \u0111\u01a1n gi\u1ea3n, ch\u00fang ta s\u1ebd t\u1ea1o ra 5 records cho m\u1ed7i dataset v\u00e0 ch\u1ec9 t\u00edch lu\u1ef9 5 records c\u1ee7a production data \u0111\u1ec3 th\u1ef1c hi\u1ec7n vi\u1ec7c so s\u00e1nh data. M\u1ed9t l\u00fd do n\u1eefa cho con s\u1ed1 5 l\u00e0 v\u00ec \u1edf Online serving API, features \u0111\u01b0\u1ee3c l\u1ea5y ra s\u1ebd l\u00e0 features m\u1edbi nh\u1ea5t trong dataset. Do \u0111\u00f3, vi\u1ec7c t\u1ea1o ra nhi\u1ec1u records \u1edf nhi\u1ec1u th\u1eddi \u0111i\u1ec3m l\u00e0 kh\u00f4ng c\u1ea7n thi\u1ebft. Ch\u1ec9 c\u1ea7n \u0111\u1ea3m b\u1ea3o r\u1eb1ng trong Feature Store, t\u1ed3n t\u1ea1i \u00edt nh\u1ea5t 1 record cho m\u1ed7i ID c\u1ee7a t\u00e0i x\u1ebf \u1edf request g\u1eedi \u0111\u1ebfn. V\u00ec dataset g\u1ed1c ch\u1ec9 ch\u1ee9a ID c\u1ee7a 5 t\u00e0i x\u1ebf bao g\u1ed3m [1001, 1002, 1003, 1004, 1005] , n\u00ean ch\u1ec9 c\u1ea7n 5 records cho m\u1ed7i dataset. T\u00f3m l\u1ea1i, ch\u00fang ta c\u1ea7n t\u1ea1o ra 2 datasets c\u00f3 kho\u1ea3ng gi\u00e1 tr\u1ecb n\u1eb1m xa nhau, m\u1ed7i dataset c\u00f3 5 records t\u01b0\u01a1ng \u1ee9ng v\u1edbi 5 ID c\u1ee7a c\u00e1c t\u00e0i x\u1ebf. \u0110\u1ec3 \u0111\u01a1n gi\u1ea3n ho\u00e1 qu\u00e1 tr\u00ecnh test, ph\u00e2n ph\u1ed1i chu\u1ea9n s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng cho c\u00e1c gi\u00e1 tr\u1ecb c\u1ee7a features trong c\u1ea3 2 datasets. B\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y l\u00e0 m\u1ed9t v\u00ed d\u1ee5 c\u1ee7a normal_data . index datetime driver_id conv_rate acc_rate avg_daily_trips 0 2021-07-19 23:00:00+00:00 1001 0.186341 0.226879 107 1 2021-07-18 06:00:00+00:00 1002 0.071032 0.229490 250 2 2021-07-28 09:00:00+00:00 1003 0.050000 0.192864 103 3 2021-07-27 10:00:00+00:00 1004 0.184332 0.050000 49 4 2021-07-23 05:00:00+00:00 1005 0.250000 0.250000 246 B\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y l\u00e0 m\u1ed9t v\u00ed d\u1ee5 c\u1ee7a drift_data . index datetime driver_id conv_rate acc_rate avg_daily_trips 0 2021-07-19 23:00:00+00:00 1001 0.886341 0.926879 807 1 2021-07-18 06:00:00+00:00 1002 0.771032 0.929490 950 2 2021-07-28 09:00:00+00:00 1003 0.750000 0.892864 803 3 2021-07-27 10:00:00+00:00 1004 0.884332 0.750000 750 4 2021-07-23 05:00:00+00:00 1005 0.950000 0.950000 946 Theo d\u00f5i model performance \u0110\u1ec3 test ch\u1ee9c n\u0103ng Theo d\u00f5i model performance , label c\u1ee7a m\u1ed7i request \u0111\u01b0\u1ee3c g\u1eedi t\u1edbi Online serving API c\u1ea7n \u0111\u01b0\u1ee3c bi\u1ebft, th\u00ec m\u1edbi \u0111\u00e1nh gi\u00e1 \u0111\u01b0\u1ee3c d\u1ef1 \u0111o\u00e1n c\u1ee7a model l\u00e0 \u0111\u00fang hay sai. \u1ede ph\u1ea7n Online serving c\u1ee7a b\u00e0i Tri\u1ec3n khai model serving , request v\u00e0 response \u0111\u01b0\u1ee3c g\u1eedi t\u1edbi Online serving API c\u00f3 d\u1ea1ng nh\u01b0 sau. // Request { \"request_id\" : \"uuid-1\" , \"driver_ids\" : [ 1001 , 1002 , 1003 , 1004 , 1005 ] } // Response { \"prediction\" : 1001 , \"error\" : null } V\u1edbi m\u1ed7i ID c\u1ee7a t\u00e0i x\u1ebf, model tr\u1ea3 v\u1ec1 1 s\u1ed1 th\u1ef1c. S\u1ed1 th\u1ef1c n\u00e0y th\u1ec3 hi\u1ec7n kh\u1ea3 n\u0103ng m\u00e0 t\u00e0i x\u1ebf c\u00f3 ho\u00e0n th\u00e0nh cu\u1ed1c xe hay kh\u00f4ng. Tuy nhi\u00ean \u1edf production, ch\u00fang ta kh\u00f4ng bi\u1ebft ch\u00ednh x\u00e1c s\u1ed1 th\u1ef1c n\u00e0y l\u00e0 bao nhi\u00eau. Ch\u00fang ta ch\u1ec9 bi\u1ebft r\u1eb1ng, khi model tr\u1ea3 v\u1ec1 ID t\u00e0i x\u1ebf c\u00f3 kh\u1ea3 n\u0103ng cao nh\u1ea5t ho\u00e0n th\u00e0nh cu\u1ed1c xe l\u00e0 1001 , th\u00ec t\u1ee9c l\u00e0 model \u0111ang d\u1ef1 \u0111o\u00e1n t\u00e0i x\u1ebf c\u00f3 ID 1001 s\u1ebd ho\u00e0n th\u00e0nh cu\u1ed1c xe. B\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y th\u1ec3 hi\u1ec7n k\u1ebft qu\u1ea3 d\u1ef1 \u0111o\u00e1n c\u1ee7a model v\u00e0 ID c\u1ee7a t\u00e0i x\u1ebf \u0111\u01b0\u1ee3c ch\u1ecdn, th\u00f4ng tin cu\u1ed1c xe c\u00f3 ho\u00e0n th\u00e0nh kh\u00f4ng, v\u1edbi m\u1ed7i request \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn Online serving API. request_id driver_ids D\u1ef1 \u0111o\u00e1n c\u1ee7a model T\u00e0i x\u1ebf \u0111\u01b0\u1ee3c ch\u1ecdn Ho\u00e0n th\u00e0nh uuid-1 [1001, 1002, 1003] 0.1234 1001 1 uuid-2 [1001, 1002, 1003] 1.2345 1001 0 uuid-3 [1001, 1002, 1003] -1.5678 1002 1 Nh\u01b0 b\u1ea1n th\u1ea5y, m\u1eb7c d\u00f9 c\u00f3 d\u1ef1 \u0111o\u00e1n c\u1ee7a model, nh\u01b0ng b\u1ea1n s\u1ebd kh\u00f4ng c\u00f3 label \u1edf d\u1ea1ng s\u1ed1 th\u1ef1c n\u00e0y \u0111\u1ec3 so s\u00e1nh. B\u1ea1n ch\u1ec9 bi\u1ebft t\u00e0i x\u1ebf \u0111\u01b0\u1ee3c ch\u1ecdn \u0111\u01b0\u1ee3c d\u1ef1 \u0111o\u00e1n l\u00e0 s\u1ebd ho\u00e0n th\u00e0nh cu\u1ed1c xe, t\u1ee9c l\u00e0 d\u1ef1 \u0111o\u00e1n lu\u00f4n l\u00e0 1 cho t\u00e0i x\u1ebf \u0111\u01b0\u1ee3c ch\u1ecdn \u0111\u00f3. Nh\u01b0 v\u1eady, \u0111\u1ec3 test ch\u1ee9c n\u0103ng theo d\u00f5i model performance c\u1ee7a monitoring service, b\u1ea1n ch\u1ec9 c\u1ea7n t\u1ea1o ra labels cho m\u1ed7i request \u0111\u01b0\u1ee3c g\u1eedi t\u1edbi \u1edf d\u1ea1ng 1/0 ch\u1ee9 kh\u00f4ng ph\u1ea3i \u1edf d\u1ea1ng s\u1ed1 th\u1ef1c m\u00e0 model tr\u1ea3 v\u1ec1. Question C\u1ea7n t\u1ea1o ra bao nhi\u00eau request v\u00e0 label t\u01b0\u01a1ng \u1ee9ng? \u1ede ph\u1ea7n tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 ph\u00e2n t\u00edch r\u1eb1ng ch\u1ec9 c\u1ea7n t\u00edch lu\u1ef9 5 records l\u00e0 \u0111\u1ee7 \u0111\u1ec3 th\u1ef1c hi\u1ec7n qu\u00e1 tr\u00ecnh so s\u00e1nh data, n\u00ean s\u1ed1 l\u01b0\u1ee3ng request v\u00e0 label t\u01b0\u01a1ng \u1ee9ng c\u0169ng ch\u1ec9 c\u1ea7n 5 records. Dataset ch\u1ee9a 5 records n\u00e0y \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 request_data , g\u1ed3m 3 c\u1ed9t: request_id : request id driver_ids : danh s\u00e1ch ID c\u00e1c t\u00e0i x\u1ebf \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn trong request trip_completed : label cho request C\u00f3 m\u1ed9t v\u1ea5n \u0111\u1ec1 nh\u01b0 sau. N\u1ebfu t\u00e0i x\u1ebf 1001 lu\u00f4n \u0111\u01b0\u1ee3c d\u1ef1 \u0111o\u00e1n l\u00e0 t\u00e0i x\u1ebf c\u00f3 kh\u1ea3 n\u0103ng cao nh\u1ea5t s\u1ebd ho\u00e0n th\u00e0nh cu\u1ed1c xe, th\u00ec b\u1ed9 features c\u1ee7a t\u00e0i x\u1ebf 1001 s\u1ebd lu\u00f4n \u0111\u01b0\u1ee3c g\u1eedi v\u1ec1 monitoring service, khi\u1ebfn cho t\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a production data s\u1ebd kh\u00f4ng gi\u1ed1ng v\u1edbi t\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a normal_data ho\u1eb7c drift_data . \u0110\u1ec3 kh\u1eafc ph\u1ee5c, b\u1ea1n c\u1ea7n \u0111\u1ea3m b\u1ea3o c\u1ea3 5 b\u1ed9 features c\u1ee7a 5 t\u00e0i x\u1ebf trong dataset m\u00e0 ch\u00fang ta d\u00f9ng ( normal_data ho\u1eb7c drift_data ) \u0111\u1ec1u \u0111\u01b0\u1ee3c g\u1eedi t\u1edbi monitoring service. B\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y l\u00e0 m\u1ed9t v\u00ed d\u1ee5 cho dataset request_data . request_id driver_ids trip_completed uuid-1 [1001] 1 uuid-2 [1002] 0 uuid-3 [1003] 1 uuid-4 [1004] 0 uuid-5 [1005] 1 Nh\u01b0 c\u00e1c b\u1ea1n th\u1ea5y, khi driver_ids ch\u1ec9 ch\u1ee9a 1 ID, th\u00ec ch\u1eafc ch\u1eafc ID n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c ch\u1ecdn l\u00e0m d\u1ef1 \u0111o\u00e1n c\u1ee7a model. Nh\u01b0 v\u1eady l\u00e0 ch\u00fang ta \u0111\u00e3 ph\u00e2n t\u00edch xong c\u00e1ch test monitoring service, v\u1edbi c\u00e1c b\u1ed9 dataset c\u1ea7n \u0111\u01b0\u1ee3c t\u1ea1o ra bao g\u1ed3m normal_data , drift_data v\u00e0 request_data . C\u00e1c ph\u1ea7n d\u01b0\u1edbi \u0111\u00e2y s\u1ebd t\u1eadp trung v\u00e0o vi\u1ebft code. T\u1ea1o datasets Trong ph\u1ea7n n\u00e0y, ch\u00fang ta s\u1ebd t\u1ea1o ra 2 datasets c\u00f3 t\u00ednh ch\u1ea5t v\u00e0 m\u1ee5c \u0111\u00edch nh\u01b0 b\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y. Dataset Ph\u00e2n ph\u1ed1i S\u1ed1 records normal_data Ph\u00e2n ph\u1ed1i chu\u1ea9n, gi\u00e1 tr\u1ecb thu\u1ed9c [0.05, 0.25] 5 drift_data Ph\u00e2n ph\u1ed1i chu\u1ea9n, gi\u00e1 tr\u1ecb thu\u1ed9c [0.75, 0.95] 5 Code \u0111\u1ec3 t\u1ea1o ra 2 datasets n\u00e0y n\u1eb1m t\u1ea1i monitoring_service/nbs/prepare_datasets.ipynb . monitoring_service/nbs/prepare_datasets.ipynb 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 df_orig = pd . read_parquet ( DATA_PATH , engine = 'fastparquet' ) driver_ids = np . unique ( df_orig [ 'driver_id' ]) # (1) N_SAMPLES = driver_ids . shape [ 0 ] X , _ = make_classification ( n_samples = N_SAMPLES , random_state = random_seed ) # (2) scaler = MinMaxScaler ( feature_range = ( 0.05 , 0.25 )) X = scaler . fit_transform ( X ) # (3) scaler = MinMaxScaler ( feature_range = ( 0.75 , 0.95 )) X_shift = scaler . fit_transform ( X ) # (4) def create_dataset ( generated_X ): df = pd . DataFrame () df [ 'conv_rate' ] = generated_X [:, 0 ] # (5) df [ 'acc_rate' ] = generated_X [:, 1 ] df [ 'avg_daily_trips' ] = np . array (( generated_X [:, 2 ] * 1000 ), dtype = int ) # (6) return df # T\u1ea1o normal_data v\u00e0 drift_data normal_df = create_dataset ( X ) drift_df = create_dataset ( X ) # T\u1ea1o request_data request_id_list = [] # (7) driver_ids_list = [] for i in range ( N_SAMPLES ): request_id = f \"uuid- { i } \" request_id_list . append ( request_id ) driver_id = driver_ids [ i % len ( driver_ids )] # (8) driver_ids_list . append ([ driver_id ]) y = np . random . choice ([ 0 , 1 ], size = N_SAMPLES , p = [ 0.3 , 0.7 ]) # (9) request_df = pd . DataFrame () # (10) request_df [ 'request_id' ] = request_id_list request_df [ 'driver_ids' ] = driver_ids_list request_df [ 'trip_completed' ] = y L\u1ea5y ra ID c\u00e1c t\u00e0i x\u1ebf t\u1eeb dataset g\u1ed1c T\u1ea1o ra 1 dataset d\u1ea1ng classification theo ph\u00e2n ph\u1ed1i chu\u1ea9n d\u00f9ng h\u00e0m make_classification c\u1ee7a scikit-learn Bi\u1ebfn \u0111\u1ed5i X v\u1ec1 \u0111o\u1ea1n [0.05, 0.25]. X s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 t\u1ea1o normal_data Bi\u1ebfn \u0111\u1ed5i X v\u1ec1 \u0111o\u1ea1n [0.75, 0.95], l\u01b0u v\u00e0o X_shift . X_shift s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 t\u1ea1o drift_data S\u1eed d\u1ee5ng 3 c\u1ed9t \u0111\u1ea7u ti\u00ean c\u1ee7a X v\u00e0 X_shift \u0111\u1ec3 l\u00e0m features cho normal_data v\u00e0 drift_data Feature avg_daily_trips n\u1eb1m trong kho\u1ea3ng t\u1eeb 0 t\u1edbi 1000 Kh\u1edfi t\u1ea1o list ch\u1ee9a request ID v\u00e0 list ch\u1ee9a ID c\u00e1c t\u00e0i x\u1ebf cho m\u1ed7i request L\u1ea7n l\u01b0\u1ee3t l\u1ea5y ra ID c\u00e1c t\u00e0i x\u1ebf T\u1ea1o ra label cho m\u1ed7i request v\u1edbi x\u00e1c su\u1ea5t 0.3 cho label 0 v\u00e0 0.7 cho label 1 . 2 con s\u1ed1 n\u00e0y \u0111\u01b0\u1ee3c l\u1ea5y b\u1ea5t k\u00ec T\u1ea1o DataFrame ch\u1ee9a request_data \u0110o\u1ea1n code tr\u00ean t\u1ea1o ra request_data ch\u1ee9a th\u00f4ng tin v\u1ec1 request \u0111\u01b0\u1ee3c g\u1eedi t\u1edbi Online serving API. Th\u00f4ng tin v\u1ec1 request c\u0169ng s\u1ebd ch\u1ee9a label t\u01b0\u01a1ng \u1ee9ng c\u1ee7a m\u1ed7i request. Ti\u1ebfp theo, ch\u00fang ta s\u1ebd test c\u00e1c datasets \u0111\u01b0\u1ee3c t\u1ea1o ra b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng Evidently \u0111\u1ec3 ph\u00e1t hi\u1ec7n data drift v\u00e0 \u0111\u00e1nh gi\u00e1 model performance. Test datasets Code c\u1ee7a ph\u1ea7n n\u00e0y \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u1ea1i monitoring_service/nbs/test_datasets.ipynb . monitoring_service/nbs/test_datasets.ipynb 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 normal_df = pd . read_parquet ( ORIG_DATA_PATH , engine = 'fastparquet' ) # (1) drift_df = pd . read_parquet ( DRIFT_DATA_PATH , engine = 'fastparquet' ) request_df = pd . read_csv ( REQUEST_DATA_PATH ) column_mapping = ColumnMapping ( # (2) target = \"trip_completed\" , # (3) prediction = \"prediction\" , # (4) numerical_features = [ \"conv_rate\" , \"acc_rate\" , \"avg_daily_trips\" ], # (5) categorical_features = [], # (6) ) features_and_target_monitor = ModelMonitoring ( monitors = [ DataDriftMonitor ()]) # (7) model_performance_monitor = ModelMonitoring ( monitors = [ ClassificationPerformanceMonitor ()]) # (8) # Ch\u1ea1y ki\u1ec3m tra data drift features_and_target_monitor . execute ( # (9) reference_data = normal_df , # (10) current_data = drift_df , # (11) column_mapping = column_mapping , ) # Ch\u1ea1y ki\u1ec3m tra model performance predictions = [ 1 ] * drift_df . shape [ 0 ] drift_df = drift_df . assign ( prediction = predictions ) # (12) drift_df = drift_df . assign ( trip_completed = request_df [ \"trip_completed\" ]) # (13) model_performance_monitor . execute ( # (14) reference_data = drift_df , current_data = drift_df , column_mapping = column_mapping , ) \u0110\u1ecdc normal_data , drift_data v\u00e0 request_data ColumnMapping l\u00e0 1 class trong Evidently \u0111\u1ecbnh ngh\u0129a \u00fd ngh\u0129a c\u1ee7a c\u00e1c c\u1ed9t trong b\u1ed9 data \u0110\u1ecbnh ngh\u0129a c\u1ed9t target hay ch\u00ednh l\u00e0 label \u0110\u1ecbnh ngh\u0129a c\u1ed9t prediction hay ch\u00ednh l\u00e0 d\u1ef1 \u0111o\u00e1n c\u1ee7a model \u0110\u1ecbnh ngh\u0129a c\u00e1c c\u1ed9t l\u00e0 features \u1edf d\u1ea1ng s\u1ed1 \u0110\u1ecbnh ngh\u0129a c\u00e1c c\u1ed9t l\u00e0 features \u1edf d\u1ea1ng categorical \u0110\u1ecbnh ngh\u0129a object ModelMonitoring \u0111\u1ec3 theo d\u00f5i data drift. ModelMonitoring l\u00e0 1 class trong Evidently \u0111\u1ecbnh ngh\u0129a c\u00e1c lo\u1ea1i monitoring m\u00e0 ch\u00fang ta mu\u1ed1n ch\u1ea1y. C\u00f3 nhi\u1ec1u lo\u1ea1i monitoring nh\u01b0 DataDriftMonitor , CatTargetDriftMonitor , NumTargetDriftMonitor , v.v. \u0110\u1ecbnh ngh\u0129a object ModelMonitoring \u0111\u1ec3 theo d\u00f5i model performance Ki\u1ec3m tra data drift, so s\u00e1nh drift_data v\u1edbi normal_data D\u00f9ng normal_data l\u00e0m reference window hay training data. Trong Evidently, reference window \u0111\u01b0\u1ee3c g\u00e1n v\u00e0o tham s\u1ed1 reference_data D\u00f9ng drift_data l\u00e0m test window hay production data \u0111\u1ec3 so s\u00e1nh v\u1edbi training data. Trong Evidently, test window \u0111\u01b0\u1ee3c g\u00e1n v\u00e0o tham s\u1ed1 current_data Th\u00eam c\u1ed9t prediction v\u00e0o drift_data , hay ch\u00ednh l\u00e0 d\u1ef1 \u0111o\u00e1n c\u1ee7a model. Nh\u01b0 \u0111\u00e3 ph\u00e2n t\u00edch \u1edf ph\u1ea7n tr\u01b0\u1edbc, predictions c\u1ee7a model lu\u00f4n l\u00e0 1 Th\u00eam c\u1ed9t trip_completed v\u00e0o drift_data hay ch\u00ednh l\u00e0 label c\u1ee7a m\u1ed7i record Ki\u1ec3m tra model performance so s\u00e1nh drift_data v\u1edbi ch\u00ednh n\u00f3 Question T\u1ea1i sao l\u1ea1i c\u1ea7n ki\u1ec3m tra model performance b\u1eb1ng c\u00e1ch so s\u00e1nh drift_data hay production data v\u1edbi ch\u00ednh n\u00f3? Trong Evidently, v\u1edbi lo\u1ea1i monitoring l\u00e0 ClassificationPerformanceMonitor n\u1ebfu c\u1ea3 reference window , test window \u0111\u1ec1u ch\u1ee9a prediction v\u00e0 label th\u00ec Evidently s\u1ebd t\u00ednh to\u00e1n c\u00e1c metrics c\u1ee7a model performance tr\u00ean c\u1ea3 2 datasets n\u00e0y, vi\u1ec7c th\u1ef1c hi\u1ec7n so s\u00e1nh xem c\u00e1c metrics \u0111\u00f3 kh\u00e1c nhau th\u1ebf n\u00e0o. Tuy nhi\u00ean \u0111\u1ec3 \u0111\u01a1n gi\u1ea3n ho\u00e1, ch\u00fang ta ch\u1ec9 c\u1ea7n bi\u1ebft model performance c\u1ee7a model v\u1edbi production data, ch\u1ee9 kh\u00f4ng c\u1ea7n so s\u00e1nh model performance gi\u1eefa reference window , test window . V\u00ec v\u1eady, ch\u00fang ta s\u1ebd truy\u1ec1n v\u00e0o drift_data v\u00e0o c\u1ea3 reference_data v\u00e0 current_data . B\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc th\u00eam t\u1ea1i \u0111\u00e2y \u0111\u1ec3 hi\u1ec3u r\u00f5 h\u01a1n v\u1ec1 c\u00e1ch Evidently t\u00ednh model performance. K\u1ebft qu\u1ea3 \u0111\u01b0\u1ee3c in ra sau khi ch\u1ea1y gi\u1ed1ng nh\u01b0 sau. data_drift:n_drifted_features | 3 | None # (1) data_drift:dataset_drift | True | None # (2) ... classification_performance:quality | 0 .4 | { 'dataset' : 'reference' , 'metric' : 'accuracy' } # (3) classification_performance:class_quality | 0 .0 | { 'dataset' : 'reference' , 'class_name' : '0' , 'metric' : 'precision' } # (4) ... S\u1ed1 features b\u1ecb drift current_data , hay test window , c\u00f3 b\u1ecb drift kh\u00f4ng accuracy c\u1ee7a model precision c\u1ee7a model cho class 0 \u0110\u1ec3 t\u00ecm hi\u1ec3u th\u00eam v\u1ec1 c\u00e1c lo\u1ea1i monitoring kh\u00e1c hay c\u00e1c ch\u1ee9c n\u0103ng kh\u00e1c c\u1ee7a Evidently, b\u1ea1n c\u00f3 th\u1ec3 xem th\u00eam c\u00e1c v\u00ed d\u1ee5 t\u1ea1i website c\u1ee7a Evidently . T\u1ed5ng k\u1ebft Trong b\u00e0i n\u00e0y ch\u00fang ta \u0111\u00e3 ph\u00e2n t\u00edch, thi\u1ebft k\u1ebf m\u1ed9t service kh\u00e1 ph\u1ee9c t\u1ea1p l\u00e0 Monitoring service. B\u1ea1n \u0111\u00e3 hi\u1ec3u c\u00e1c y\u00eau c\u1ea7u v\u1ec1 c\u00e1c ch\u1ee9c n\u0103ng c\u1ee7a m\u1ed9t Monitoring service \u0111\u1ec3 theo d\u00f5i c\u00e1c metrics c\u1ee7a data, model nh\u01b0 Ph\u00e1t hi\u1ec7n Data drift , Theo d\u00f5i model performance . Trong b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd h\u1ecdc c\u00e1ch tri\u1ec3n khai v\u00e0 thi\u1ebft l\u1eadp c\u1ea3nh b\u00e1o tr\u00ean Grafana. T\u00e0i li\u1ec7u tham kh\u1ea3o Evidently","title":"Thi\u1ebft k\u1ebf monitoring service"},{"location":"mlops-crash-course/monitoring/thiet-ke-monitoring-service.html#gioi-thieu","text":"Trong b\u00e0i tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 tri\u1ec3n khai ELK Stack thu th\u1eadp, theo d\u00f5i logs t\u1eeb c\u00e1c services, Prometheus v\u00e0 Grafana server \u0111\u1ec3 theo d\u00f5i c\u00e1c metrics h\u1ec7 th\u1ed1ng nh\u01b0 CPU, memory, network, v.v. Trong m\u1ed9t h\u1ec7 th\u1ed1ng ML, ch\u00fang ta c\u0169ng c\u1ea7n theo d\u00f5i metrics li\u00ean quan t\u1edbi data, model \u0111\u1ec3 k\u1ecbp th\u1eddi ph\u00e1t hi\u1ec7n s\u1ef1 thay \u0111\u1ed5i c\u1ee7a ch\u00fang \u1edf production, \u0111\u1ec3 c\u1eadp nh\u1eadt data hay train l\u1ea1i model k\u1ecbp th\u1eddi. Trong b\u00e0i n\u00e0y, ch\u00fang ta s\u1ebd thi\u1ebft k\u1ebf monitoring service v\u1edbi c\u00e1c c\u00f4ng vi\u1ec7c c\u1ee5 th\u1ec3 sau: T\u1ea1o ra dataset ch\u1ee9a feature b\u1ecb drift Tri\u1ec3n khai monitoring service \u0111\u1ec3 theo d\u00f5i data v\u00e0 model performance Thi\u1ebft l\u1eadp Grafana dashboards \u0111\u1ec3 hi\u1ec3n th\u1ecb metrics v\u1ec1 data v\u00e0 model","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/monitoring/thiet-ke-monitoring-service.html#moi-truong-phat-trien","text":"C\u00e1c b\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 c\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n: C\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng Python 3.9 m\u1edbi v\u1edbi c\u00e1c th\u01b0 vi\u1ec7n c\u1ea7n thi\u1ebft trong file monitoring_service/dev_requirements.txt \u0110\u1eb7t environment variable MONITORING_SERVICE_DIR \u1edf terminal b\u1ea1n d\u00f9ng b\u1eb1ng \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i t\u1edbi folder monitoring_service . Env var n\u00e0y h\u1ed7 tr\u1ee3 ch\u1ea1y python code \u1edf folder monitoring_service/src trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n. cd mlops-crash-course-code/monitoring_service export MONITORING_SERVICE_DIR = $( pwd ) C\u00e1c tools s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong b\u00e0i n\u00e0y bao g\u1ed3m: Feast: truy xu\u1ea5t Feature Store Flask: vi\u1ebft API cho monitoring service Evidently: ki\u1ec3m tra ch\u1ea5t l\u01b0\u1ee3ng data v\u00e0 model performance Note Trong qu\u00e1 tr\u00ecnh ch\u1ea1y code cho t\u1ea5t c\u1ea3 c\u00e1c ph\u1ea7n d\u01b0\u1edbi \u0111\u00e2y, gi\u1ea3 s\u1eed r\u1eb1ng folder g\u1ed1c n\u01a1i ch\u00fang ta l\u00e0m vi\u1ec7c l\u00e0 folder monitoring_service .","title":"M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n"},{"location":"mlops-crash-course/monitoring/thiet-ke-monitoring-service.html#architecture","text":"Theo d\u00f5i metrics li\u00ean quan t\u1edbi ch\u1ea5t l\u01b0\u1ee3ng data v\u00e0 model performance, l\u00e0 qu\u00e1 tr\u00ecnh ki\u1ec3m tra xem data v\u00e0 model performance thay \u0111\u1ed5i nh\u01b0 th\u1ebf n\u00e0o theo th\u1eddi gian. \u0110\u00e2y c\u0169ng l\u00e0 y\u00eau c\u1ea7u \u0111\u1ea7u ra c\u1ee7a monitoring service. C\u00e1c ch\u1ee9c n\u0103ng ch\u00ednh c\u1ee7a monitoring service \u0111\u01b0\u1ee3c th\u1ec3 hi\u1ec7n nh\u01b0 h\u00ecnh d\u01b0\u1edbi graph LR n00[ ]--Training data-->n1[Ph\u00e1t hi\u1ec7n<br>data drift]--Data metrics-->n01[ ] n02[ ]--Production data-->n1 n10[ ]--Prediction-->n2[Theo d\u00f5i model<br>performance]--Model performance-->n11[ ] n12[ ]--Label-->n2 style n00 height:0px; style n01 height:0px; style n02 height:0px; style n10 height:0px; style n11 height:0px; style n12 height:0px; \u0110\u1ec3 bi\u1ebft data thay \u0111\u1ed5i th\u1ebf n\u00e0o, training data s\u1ebd \u0111\u01b0\u1ee3c so s\u00e1nh v\u1edbi production data d\u1ef1a tr\u00ean m\u1ed9t thu\u1eadt to\u00e1n so s\u00e1nh. Thu\u1eadt to\u00e1n n\u00e0y xem x\u00e9t c\u00e1c thu\u1ed9c t\u00ednh v\u1ec1 th\u1ed1ng k\u00ea c\u1ee7a data b\u1ecb thay \u0111\u1ed5i nhi\u1ec1u hay \u00edt th\u1ebf n\u00e0o. Nh\u01b0 v\u1eady, \u0111\u1ea7u v\u00e0o c\u1ee7a ch\u1ee9c n\u0103ng Ph\u00e1t hi\u1ec7n data drift l\u00e0 features \u1edf khi training v\u00e0 features \u1edf production. \u0110\u1ec3 bi\u1ebft model performance thay \u0111\u1ed5i th\u1ebf n\u00e0o, label \u1edf production s\u1ebd \u0111\u01b0\u1ee3c so s\u00e1nh v\u1edbi prediction m\u00e0 model t\u1ea1o ra. Model performance \u1edf production c\u0169ng c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c so s\u00e1nh v\u1edbi model performance \u1edf khi training. \u0110\u1ec3 \u0111\u01a1n gi\u1ea3n, monitoring service s\u1ebd ch\u1ec9 theo d\u00f5i model performance \u1edf production. Nh\u01b0 v\u1eady, \u0111\u1ea7u v\u00e0o c\u1ee7a ch\u1ee9c n\u0103ng Theo d\u00f5i model performance l\u00e0 d\u1ef1 \u0111o\u00e1n c\u1ee7a model v\u00e0 label \u1edf production. Trong b\u00e0i n\u00e0y, th\u01b0 vi\u1ec7n Evidently \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 ph\u00e1t hi\u1ec7n data drift, t\u00ednh to\u00e1n model performance metrics. Evidently l\u00e0 m\u1ed9t th\u01b0 vi\u1ec7n open-source \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 \u0111\u00e1nh gi\u00e1, ki\u1ec3m tra v\u00e0 gi\u00e1m s\u00e1t data, model performance. Evidently \u0111\u00e3 t\u00edch h\u1ee3p s\u1eb5n c\u00e1c thu\u1eadt to\u00e1n \u0111\u1ec3 theo d\u00f5i c\u00e1c thu\u1ed9c t\u00ednh th\u1ed1ng k\u00ea c\u1ee7a data nh\u01b0 PSI , K-L divergence , Jensen-Shannon distance , Wasserstein distance v\u00e0 c\u00e1c metrics ph\u1ed5 bi\u1ebfn c\u1ee7a model performance nh\u01b0 Accuracy , F1 score , RMSE , MAE , v.v. B\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc th\u00eam \u1edf document c\u1ee7a Evidently \u0111\u1ec3 t\u00ecm hi\u1ec3u v\u1ec1 c\u00e1ch m\u00e0 Evidently l\u1ef1a ch\u1ecdn thu\u1eadt to\u00e1n t\u1ef1 \u0111\u1ed9ng khi ph\u00e1t hi\u1ec7n data drift.","title":"Architecture"},{"location":"mlops-crash-course/monitoring/thiet-ke-monitoring-service.html#cach-test","text":"Tr\u01b0\u1edbc khi code, ch\u00fang ta s\u1ebd ph\u00e2n t\u00edch xem l\u00e0m th\u1ebf n\u00e0o \u0111\u1ec3 test c\u00e1c ch\u1ee9c n\u0103ng c\u1ee7a monitoring service. Quote Before you start anything, learn how to finish it.","title":"C\u00e1ch test"},{"location":"mlops-crash-course/monitoring/thiet-ke-monitoring-service.html#phat-hien-data-drift","text":"\u0110\u1ec3 test ch\u1ee9c n\u0103ng Ph\u00e1t hi\u1ec7n data drift , 2 b\u1ed9 datasets c\u1ea7n \u0111\u01b0\u1ee3c t\u1ea1o ra: # T\u00ean dataset Gi\u00e1 tr\u1ecb 1 normal_data Trong \u0111o\u1ea1n [A, B] 2 drift_data Trong \u0111o\u1ea1n [C, D] ; C , D n\u1eb1m \u0111\u1ee7 xa A , B \u0111\u1ec3 g\u00e2y ra data drift Hai t\u00ecnh hu\u1ed1ng nh\u01b0 b\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y c\u0169ng c\u1ea7n \u0111\u01b0\u1ee3c s\u1eafp \u0111\u1eb7t. # T\u00ecnh hu\u1ed1ng Data \u0111\u1ea7u v\u00e0o Dataset \u0111\u01b0\u1ee3c d\u00f9ng 1 Production data kh\u00f4ng b\u1ecb drift Training data normal_data Production data normal_data 2 Production data b\u1ecb drift Training data normal_data Production data drift_data \u1ede t\u00ecnh hu\u1ed1ng 1, production data kh\u00f4ng b\u1ecb drift normal_data v\u1eeba l\u00e0 training data, v\u1eeba l\u00e0 production data v\u00e0 \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o Online Feature Store. Data \u0111\u01b0\u1ee3c l\u1ea5y ra \u1edf Online Feature Store s\u1ebd gi\u1ed1ng v\u1edbi prodution data, t\u1ee9c l\u00e0 s\u1ebd kh\u00f4ng x\u1ea3y ra data drift. \u1ede t\u00ecnh hu\u1ed1ng 2, production data b\u1ecb drift normal_data \u1edf tr\u00ean v\u1eabn l\u00e0 training data, c\u00f2n drift_data l\u00e0 production data. drift_data \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o Online Feature Store. Data \u0111\u01b0\u1ee3c l\u1ea5y ra \u1edf Online Feature Store ( drift_data ) \u0111\u1ec3 model d\u1ef1 \u0111o\u00e1n c\u00f3 gi\u00e1 tr\u1ecb n\u1eb1m xa training data ( normal_data ), t\u1ee9c l\u00e0 s\u1ebd x\u1ea3y ra data drift. Question C\u1ea7n l\u1ea5y ra bao nhi\u00eau records t\u1eeb training data v\u00e0 t\u00edch lu\u1ef9 bao nhi\u00eau records c\u1ee7a production data th\u00ec m\u1edbi b\u1eaft \u0111\u1ea7u th\u1ef1c hi\u1ec7n qu\u00e1 tr\u00ecnh so s\u00e1nh? Khi training dataset qu\u00e1 l\u1edbn, ch\u00fang ta kh\u00f4ng th\u1ec3 l\u1ea5y h\u1ebft c\u00e1c records ra \u0111\u1ec3 so s\u00e1nh \u0111\u01b0\u1ee3c. Th\u00f4ng th\u01b0\u1eddng, m\u1ed9t con s\u1ed1 \u0111\u1ee7 nh\u1ecf s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 vi\u1ec7c theo d\u00f5i data \u0111\u01b0\u1ee3c di\u1ec5n ra li\u00ean t\u1ee5c v\u00e0 g\u1ea7n v\u1edbi th\u1eddi gian th\u1ef1c (near real-time). \u0110\u1ed3ng th\u1eddi, con s\u1ed1 n\u00e0y c\u0169ng ph\u1ea3i \u0111\u1ee7 l\u1edbn, \u0111\u1ec3 c\u00e1c t\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a data kh\u00f4ng qu\u00e1 kh\u00e1c bi\u1ec7t \u1edf c\u00e1c ph\u1ea7n c\u1ee7a dataset. Ph\u01b0\u01a1ng ph\u00e1p l\u1ef1a ch\u1ecdn v\u00e0 s\u1ed1 records c\u1ea7n l\u1ef1a ch\u1ecdn tu\u1ef3 thu\u1ed9c v\u00e0o nhu c\u1ea7u v\u00e0 t\u1ea7n su\u1ea5t theo d\u00f5i production data c\u1ee7a m\u1ed7i d\u1ef1 \u00e1n. Tip Thu\u1eadt ng\u1eef reference window ch\u1ec9 t\u1eadp h\u1ee3p c\u00e1c records \u0111\u1ec3 so s\u00e1nh v\u1edbi production data. Thu\u1eadt ng\u1eef test window ch\u1ec9 t\u1eadp h\u1ee3p c\u00e1c records \u0111\u1ec3 so s\u00e1nh v\u1edbi reference window \u0110\u1ec3 \u0111\u01a1n gi\u1ea3n, ch\u00fang ta s\u1ebd t\u1ea1o ra 5 records cho m\u1ed7i dataset v\u00e0 ch\u1ec9 t\u00edch lu\u1ef9 5 records c\u1ee7a production data \u0111\u1ec3 th\u1ef1c hi\u1ec7n vi\u1ec7c so s\u00e1nh data. M\u1ed9t l\u00fd do n\u1eefa cho con s\u1ed1 5 l\u00e0 v\u00ec \u1edf Online serving API, features \u0111\u01b0\u1ee3c l\u1ea5y ra s\u1ebd l\u00e0 features m\u1edbi nh\u1ea5t trong dataset. Do \u0111\u00f3, vi\u1ec7c t\u1ea1o ra nhi\u1ec1u records \u1edf nhi\u1ec1u th\u1eddi \u0111i\u1ec3m l\u00e0 kh\u00f4ng c\u1ea7n thi\u1ebft. Ch\u1ec9 c\u1ea7n \u0111\u1ea3m b\u1ea3o r\u1eb1ng trong Feature Store, t\u1ed3n t\u1ea1i \u00edt nh\u1ea5t 1 record cho m\u1ed7i ID c\u1ee7a t\u00e0i x\u1ebf \u1edf request g\u1eedi \u0111\u1ebfn. V\u00ec dataset g\u1ed1c ch\u1ec9 ch\u1ee9a ID c\u1ee7a 5 t\u00e0i x\u1ebf bao g\u1ed3m [1001, 1002, 1003, 1004, 1005] , n\u00ean ch\u1ec9 c\u1ea7n 5 records cho m\u1ed7i dataset. T\u00f3m l\u1ea1i, ch\u00fang ta c\u1ea7n t\u1ea1o ra 2 datasets c\u00f3 kho\u1ea3ng gi\u00e1 tr\u1ecb n\u1eb1m xa nhau, m\u1ed7i dataset c\u00f3 5 records t\u01b0\u01a1ng \u1ee9ng v\u1edbi 5 ID c\u1ee7a c\u00e1c t\u00e0i x\u1ebf. \u0110\u1ec3 \u0111\u01a1n gi\u1ea3n ho\u00e1 qu\u00e1 tr\u00ecnh test, ph\u00e2n ph\u1ed1i chu\u1ea9n s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng cho c\u00e1c gi\u00e1 tr\u1ecb c\u1ee7a features trong c\u1ea3 2 datasets. B\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y l\u00e0 m\u1ed9t v\u00ed d\u1ee5 c\u1ee7a normal_data . index datetime driver_id conv_rate acc_rate avg_daily_trips 0 2021-07-19 23:00:00+00:00 1001 0.186341 0.226879 107 1 2021-07-18 06:00:00+00:00 1002 0.071032 0.229490 250 2 2021-07-28 09:00:00+00:00 1003 0.050000 0.192864 103 3 2021-07-27 10:00:00+00:00 1004 0.184332 0.050000 49 4 2021-07-23 05:00:00+00:00 1005 0.250000 0.250000 246 B\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y l\u00e0 m\u1ed9t v\u00ed d\u1ee5 c\u1ee7a drift_data . index datetime driver_id conv_rate acc_rate avg_daily_trips 0 2021-07-19 23:00:00+00:00 1001 0.886341 0.926879 807 1 2021-07-18 06:00:00+00:00 1002 0.771032 0.929490 950 2 2021-07-28 09:00:00+00:00 1003 0.750000 0.892864 803 3 2021-07-27 10:00:00+00:00 1004 0.884332 0.750000 750 4 2021-07-23 05:00:00+00:00 1005 0.950000 0.950000 946","title":"Ph\u00e1t hi\u1ec7n data drift"},{"location":"mlops-crash-course/monitoring/thiet-ke-monitoring-service.html#theo-doi-model-performance","text":"\u0110\u1ec3 test ch\u1ee9c n\u0103ng Theo d\u00f5i model performance , label c\u1ee7a m\u1ed7i request \u0111\u01b0\u1ee3c g\u1eedi t\u1edbi Online serving API c\u1ea7n \u0111\u01b0\u1ee3c bi\u1ebft, th\u00ec m\u1edbi \u0111\u00e1nh gi\u00e1 \u0111\u01b0\u1ee3c d\u1ef1 \u0111o\u00e1n c\u1ee7a model l\u00e0 \u0111\u00fang hay sai. \u1ede ph\u1ea7n Online serving c\u1ee7a b\u00e0i Tri\u1ec3n khai model serving , request v\u00e0 response \u0111\u01b0\u1ee3c g\u1eedi t\u1edbi Online serving API c\u00f3 d\u1ea1ng nh\u01b0 sau. // Request { \"request_id\" : \"uuid-1\" , \"driver_ids\" : [ 1001 , 1002 , 1003 , 1004 , 1005 ] } // Response { \"prediction\" : 1001 , \"error\" : null } V\u1edbi m\u1ed7i ID c\u1ee7a t\u00e0i x\u1ebf, model tr\u1ea3 v\u1ec1 1 s\u1ed1 th\u1ef1c. S\u1ed1 th\u1ef1c n\u00e0y th\u1ec3 hi\u1ec7n kh\u1ea3 n\u0103ng m\u00e0 t\u00e0i x\u1ebf c\u00f3 ho\u00e0n th\u00e0nh cu\u1ed1c xe hay kh\u00f4ng. Tuy nhi\u00ean \u1edf production, ch\u00fang ta kh\u00f4ng bi\u1ebft ch\u00ednh x\u00e1c s\u1ed1 th\u1ef1c n\u00e0y l\u00e0 bao nhi\u00eau. Ch\u00fang ta ch\u1ec9 bi\u1ebft r\u1eb1ng, khi model tr\u1ea3 v\u1ec1 ID t\u00e0i x\u1ebf c\u00f3 kh\u1ea3 n\u0103ng cao nh\u1ea5t ho\u00e0n th\u00e0nh cu\u1ed1c xe l\u00e0 1001 , th\u00ec t\u1ee9c l\u00e0 model \u0111ang d\u1ef1 \u0111o\u00e1n t\u00e0i x\u1ebf c\u00f3 ID 1001 s\u1ebd ho\u00e0n th\u00e0nh cu\u1ed1c xe. B\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y th\u1ec3 hi\u1ec7n k\u1ebft qu\u1ea3 d\u1ef1 \u0111o\u00e1n c\u1ee7a model v\u00e0 ID c\u1ee7a t\u00e0i x\u1ebf \u0111\u01b0\u1ee3c ch\u1ecdn, th\u00f4ng tin cu\u1ed1c xe c\u00f3 ho\u00e0n th\u00e0nh kh\u00f4ng, v\u1edbi m\u1ed7i request \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn Online serving API. request_id driver_ids D\u1ef1 \u0111o\u00e1n c\u1ee7a model T\u00e0i x\u1ebf \u0111\u01b0\u1ee3c ch\u1ecdn Ho\u00e0n th\u00e0nh uuid-1 [1001, 1002, 1003] 0.1234 1001 1 uuid-2 [1001, 1002, 1003] 1.2345 1001 0 uuid-3 [1001, 1002, 1003] -1.5678 1002 1 Nh\u01b0 b\u1ea1n th\u1ea5y, m\u1eb7c d\u00f9 c\u00f3 d\u1ef1 \u0111o\u00e1n c\u1ee7a model, nh\u01b0ng b\u1ea1n s\u1ebd kh\u00f4ng c\u00f3 label \u1edf d\u1ea1ng s\u1ed1 th\u1ef1c n\u00e0y \u0111\u1ec3 so s\u00e1nh. B\u1ea1n ch\u1ec9 bi\u1ebft t\u00e0i x\u1ebf \u0111\u01b0\u1ee3c ch\u1ecdn \u0111\u01b0\u1ee3c d\u1ef1 \u0111o\u00e1n l\u00e0 s\u1ebd ho\u00e0n th\u00e0nh cu\u1ed1c xe, t\u1ee9c l\u00e0 d\u1ef1 \u0111o\u00e1n lu\u00f4n l\u00e0 1 cho t\u00e0i x\u1ebf \u0111\u01b0\u1ee3c ch\u1ecdn \u0111\u00f3. Nh\u01b0 v\u1eady, \u0111\u1ec3 test ch\u1ee9c n\u0103ng theo d\u00f5i model performance c\u1ee7a monitoring service, b\u1ea1n ch\u1ec9 c\u1ea7n t\u1ea1o ra labels cho m\u1ed7i request \u0111\u01b0\u1ee3c g\u1eedi t\u1edbi \u1edf d\u1ea1ng 1/0 ch\u1ee9 kh\u00f4ng ph\u1ea3i \u1edf d\u1ea1ng s\u1ed1 th\u1ef1c m\u00e0 model tr\u1ea3 v\u1ec1. Question C\u1ea7n t\u1ea1o ra bao nhi\u00eau request v\u00e0 label t\u01b0\u01a1ng \u1ee9ng? \u1ede ph\u1ea7n tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 ph\u00e2n t\u00edch r\u1eb1ng ch\u1ec9 c\u1ea7n t\u00edch lu\u1ef9 5 records l\u00e0 \u0111\u1ee7 \u0111\u1ec3 th\u1ef1c hi\u1ec7n qu\u00e1 tr\u00ecnh so s\u00e1nh data, n\u00ean s\u1ed1 l\u01b0\u1ee3ng request v\u00e0 label t\u01b0\u01a1ng \u1ee9ng c\u0169ng ch\u1ec9 c\u1ea7n 5 records. Dataset ch\u1ee9a 5 records n\u00e0y \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 request_data , g\u1ed3m 3 c\u1ed9t: request_id : request id driver_ids : danh s\u00e1ch ID c\u00e1c t\u00e0i x\u1ebf \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn trong request trip_completed : label cho request C\u00f3 m\u1ed9t v\u1ea5n \u0111\u1ec1 nh\u01b0 sau. N\u1ebfu t\u00e0i x\u1ebf 1001 lu\u00f4n \u0111\u01b0\u1ee3c d\u1ef1 \u0111o\u00e1n l\u00e0 t\u00e0i x\u1ebf c\u00f3 kh\u1ea3 n\u0103ng cao nh\u1ea5t s\u1ebd ho\u00e0n th\u00e0nh cu\u1ed1c xe, th\u00ec b\u1ed9 features c\u1ee7a t\u00e0i x\u1ebf 1001 s\u1ebd lu\u00f4n \u0111\u01b0\u1ee3c g\u1eedi v\u1ec1 monitoring service, khi\u1ebfn cho t\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a production data s\u1ebd kh\u00f4ng gi\u1ed1ng v\u1edbi t\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a normal_data ho\u1eb7c drift_data . \u0110\u1ec3 kh\u1eafc ph\u1ee5c, b\u1ea1n c\u1ea7n \u0111\u1ea3m b\u1ea3o c\u1ea3 5 b\u1ed9 features c\u1ee7a 5 t\u00e0i x\u1ebf trong dataset m\u00e0 ch\u00fang ta d\u00f9ng ( normal_data ho\u1eb7c drift_data ) \u0111\u1ec1u \u0111\u01b0\u1ee3c g\u1eedi t\u1edbi monitoring service. B\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y l\u00e0 m\u1ed9t v\u00ed d\u1ee5 cho dataset request_data . request_id driver_ids trip_completed uuid-1 [1001] 1 uuid-2 [1002] 0 uuid-3 [1003] 1 uuid-4 [1004] 0 uuid-5 [1005] 1 Nh\u01b0 c\u00e1c b\u1ea1n th\u1ea5y, khi driver_ids ch\u1ec9 ch\u1ee9a 1 ID, th\u00ec ch\u1eafc ch\u1eafc ID n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c ch\u1ecdn l\u00e0m d\u1ef1 \u0111o\u00e1n c\u1ee7a model. Nh\u01b0 v\u1eady l\u00e0 ch\u00fang ta \u0111\u00e3 ph\u00e2n t\u00edch xong c\u00e1ch test monitoring service, v\u1edbi c\u00e1c b\u1ed9 dataset c\u1ea7n \u0111\u01b0\u1ee3c t\u1ea1o ra bao g\u1ed3m normal_data , drift_data v\u00e0 request_data . C\u00e1c ph\u1ea7n d\u01b0\u1edbi \u0111\u00e2y s\u1ebd t\u1eadp trung v\u00e0o vi\u1ebft code.","title":"Theo d\u00f5i model performance"},{"location":"mlops-crash-course/monitoring/thiet-ke-monitoring-service.html#tao-datasets","text":"Trong ph\u1ea7n n\u00e0y, ch\u00fang ta s\u1ebd t\u1ea1o ra 2 datasets c\u00f3 t\u00ednh ch\u1ea5t v\u00e0 m\u1ee5c \u0111\u00edch nh\u01b0 b\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y. Dataset Ph\u00e2n ph\u1ed1i S\u1ed1 records normal_data Ph\u00e2n ph\u1ed1i chu\u1ea9n, gi\u00e1 tr\u1ecb thu\u1ed9c [0.05, 0.25] 5 drift_data Ph\u00e2n ph\u1ed1i chu\u1ea9n, gi\u00e1 tr\u1ecb thu\u1ed9c [0.75, 0.95] 5 Code \u0111\u1ec3 t\u1ea1o ra 2 datasets n\u00e0y n\u1eb1m t\u1ea1i monitoring_service/nbs/prepare_datasets.ipynb . monitoring_service/nbs/prepare_datasets.ipynb 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 df_orig = pd . read_parquet ( DATA_PATH , engine = 'fastparquet' ) driver_ids = np . unique ( df_orig [ 'driver_id' ]) # (1) N_SAMPLES = driver_ids . shape [ 0 ] X , _ = make_classification ( n_samples = N_SAMPLES , random_state = random_seed ) # (2) scaler = MinMaxScaler ( feature_range = ( 0.05 , 0.25 )) X = scaler . fit_transform ( X ) # (3) scaler = MinMaxScaler ( feature_range = ( 0.75 , 0.95 )) X_shift = scaler . fit_transform ( X ) # (4) def create_dataset ( generated_X ): df = pd . DataFrame () df [ 'conv_rate' ] = generated_X [:, 0 ] # (5) df [ 'acc_rate' ] = generated_X [:, 1 ] df [ 'avg_daily_trips' ] = np . array (( generated_X [:, 2 ] * 1000 ), dtype = int ) # (6) return df # T\u1ea1o normal_data v\u00e0 drift_data normal_df = create_dataset ( X ) drift_df = create_dataset ( X ) # T\u1ea1o request_data request_id_list = [] # (7) driver_ids_list = [] for i in range ( N_SAMPLES ): request_id = f \"uuid- { i } \" request_id_list . append ( request_id ) driver_id = driver_ids [ i % len ( driver_ids )] # (8) driver_ids_list . append ([ driver_id ]) y = np . random . choice ([ 0 , 1 ], size = N_SAMPLES , p = [ 0.3 , 0.7 ]) # (9) request_df = pd . DataFrame () # (10) request_df [ 'request_id' ] = request_id_list request_df [ 'driver_ids' ] = driver_ids_list request_df [ 'trip_completed' ] = y L\u1ea5y ra ID c\u00e1c t\u00e0i x\u1ebf t\u1eeb dataset g\u1ed1c T\u1ea1o ra 1 dataset d\u1ea1ng classification theo ph\u00e2n ph\u1ed1i chu\u1ea9n d\u00f9ng h\u00e0m make_classification c\u1ee7a scikit-learn Bi\u1ebfn \u0111\u1ed5i X v\u1ec1 \u0111o\u1ea1n [0.05, 0.25]. X s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 t\u1ea1o normal_data Bi\u1ebfn \u0111\u1ed5i X v\u1ec1 \u0111o\u1ea1n [0.75, 0.95], l\u01b0u v\u00e0o X_shift . X_shift s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 t\u1ea1o drift_data S\u1eed d\u1ee5ng 3 c\u1ed9t \u0111\u1ea7u ti\u00ean c\u1ee7a X v\u00e0 X_shift \u0111\u1ec3 l\u00e0m features cho normal_data v\u00e0 drift_data Feature avg_daily_trips n\u1eb1m trong kho\u1ea3ng t\u1eeb 0 t\u1edbi 1000 Kh\u1edfi t\u1ea1o list ch\u1ee9a request ID v\u00e0 list ch\u1ee9a ID c\u00e1c t\u00e0i x\u1ebf cho m\u1ed7i request L\u1ea7n l\u01b0\u1ee3t l\u1ea5y ra ID c\u00e1c t\u00e0i x\u1ebf T\u1ea1o ra label cho m\u1ed7i request v\u1edbi x\u00e1c su\u1ea5t 0.3 cho label 0 v\u00e0 0.7 cho label 1 . 2 con s\u1ed1 n\u00e0y \u0111\u01b0\u1ee3c l\u1ea5y b\u1ea5t k\u00ec T\u1ea1o DataFrame ch\u1ee9a request_data \u0110o\u1ea1n code tr\u00ean t\u1ea1o ra request_data ch\u1ee9a th\u00f4ng tin v\u1ec1 request \u0111\u01b0\u1ee3c g\u1eedi t\u1edbi Online serving API. Th\u00f4ng tin v\u1ec1 request c\u0169ng s\u1ebd ch\u1ee9a label t\u01b0\u01a1ng \u1ee9ng c\u1ee7a m\u1ed7i request. Ti\u1ebfp theo, ch\u00fang ta s\u1ebd test c\u00e1c datasets \u0111\u01b0\u1ee3c t\u1ea1o ra b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng Evidently \u0111\u1ec3 ph\u00e1t hi\u1ec7n data drift v\u00e0 \u0111\u00e1nh gi\u00e1 model performance.","title":"T\u1ea1o datasets"},{"location":"mlops-crash-course/monitoring/thiet-ke-monitoring-service.html#test-datasets","text":"Code c\u1ee7a ph\u1ea7n n\u00e0y \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u1ea1i monitoring_service/nbs/test_datasets.ipynb . monitoring_service/nbs/test_datasets.ipynb 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 normal_df = pd . read_parquet ( ORIG_DATA_PATH , engine = 'fastparquet' ) # (1) drift_df = pd . read_parquet ( DRIFT_DATA_PATH , engine = 'fastparquet' ) request_df = pd . read_csv ( REQUEST_DATA_PATH ) column_mapping = ColumnMapping ( # (2) target = \"trip_completed\" , # (3) prediction = \"prediction\" , # (4) numerical_features = [ \"conv_rate\" , \"acc_rate\" , \"avg_daily_trips\" ], # (5) categorical_features = [], # (6) ) features_and_target_monitor = ModelMonitoring ( monitors = [ DataDriftMonitor ()]) # (7) model_performance_monitor = ModelMonitoring ( monitors = [ ClassificationPerformanceMonitor ()]) # (8) # Ch\u1ea1y ki\u1ec3m tra data drift features_and_target_monitor . execute ( # (9) reference_data = normal_df , # (10) current_data = drift_df , # (11) column_mapping = column_mapping , ) # Ch\u1ea1y ki\u1ec3m tra model performance predictions = [ 1 ] * drift_df . shape [ 0 ] drift_df = drift_df . assign ( prediction = predictions ) # (12) drift_df = drift_df . assign ( trip_completed = request_df [ \"trip_completed\" ]) # (13) model_performance_monitor . execute ( # (14) reference_data = drift_df , current_data = drift_df , column_mapping = column_mapping , ) \u0110\u1ecdc normal_data , drift_data v\u00e0 request_data ColumnMapping l\u00e0 1 class trong Evidently \u0111\u1ecbnh ngh\u0129a \u00fd ngh\u0129a c\u1ee7a c\u00e1c c\u1ed9t trong b\u1ed9 data \u0110\u1ecbnh ngh\u0129a c\u1ed9t target hay ch\u00ednh l\u00e0 label \u0110\u1ecbnh ngh\u0129a c\u1ed9t prediction hay ch\u00ednh l\u00e0 d\u1ef1 \u0111o\u00e1n c\u1ee7a model \u0110\u1ecbnh ngh\u0129a c\u00e1c c\u1ed9t l\u00e0 features \u1edf d\u1ea1ng s\u1ed1 \u0110\u1ecbnh ngh\u0129a c\u00e1c c\u1ed9t l\u00e0 features \u1edf d\u1ea1ng categorical \u0110\u1ecbnh ngh\u0129a object ModelMonitoring \u0111\u1ec3 theo d\u00f5i data drift. ModelMonitoring l\u00e0 1 class trong Evidently \u0111\u1ecbnh ngh\u0129a c\u00e1c lo\u1ea1i monitoring m\u00e0 ch\u00fang ta mu\u1ed1n ch\u1ea1y. C\u00f3 nhi\u1ec1u lo\u1ea1i monitoring nh\u01b0 DataDriftMonitor , CatTargetDriftMonitor , NumTargetDriftMonitor , v.v. \u0110\u1ecbnh ngh\u0129a object ModelMonitoring \u0111\u1ec3 theo d\u00f5i model performance Ki\u1ec3m tra data drift, so s\u00e1nh drift_data v\u1edbi normal_data D\u00f9ng normal_data l\u00e0m reference window hay training data. Trong Evidently, reference window \u0111\u01b0\u1ee3c g\u00e1n v\u00e0o tham s\u1ed1 reference_data D\u00f9ng drift_data l\u00e0m test window hay production data \u0111\u1ec3 so s\u00e1nh v\u1edbi training data. Trong Evidently, test window \u0111\u01b0\u1ee3c g\u00e1n v\u00e0o tham s\u1ed1 current_data Th\u00eam c\u1ed9t prediction v\u00e0o drift_data , hay ch\u00ednh l\u00e0 d\u1ef1 \u0111o\u00e1n c\u1ee7a model. Nh\u01b0 \u0111\u00e3 ph\u00e2n t\u00edch \u1edf ph\u1ea7n tr\u01b0\u1edbc, predictions c\u1ee7a model lu\u00f4n l\u00e0 1 Th\u00eam c\u1ed9t trip_completed v\u00e0o drift_data hay ch\u00ednh l\u00e0 label c\u1ee7a m\u1ed7i record Ki\u1ec3m tra model performance so s\u00e1nh drift_data v\u1edbi ch\u00ednh n\u00f3 Question T\u1ea1i sao l\u1ea1i c\u1ea7n ki\u1ec3m tra model performance b\u1eb1ng c\u00e1ch so s\u00e1nh drift_data hay production data v\u1edbi ch\u00ednh n\u00f3? Trong Evidently, v\u1edbi lo\u1ea1i monitoring l\u00e0 ClassificationPerformanceMonitor n\u1ebfu c\u1ea3 reference window , test window \u0111\u1ec1u ch\u1ee9a prediction v\u00e0 label th\u00ec Evidently s\u1ebd t\u00ednh to\u00e1n c\u00e1c metrics c\u1ee7a model performance tr\u00ean c\u1ea3 2 datasets n\u00e0y, vi\u1ec7c th\u1ef1c hi\u1ec7n so s\u00e1nh xem c\u00e1c metrics \u0111\u00f3 kh\u00e1c nhau th\u1ebf n\u00e0o. Tuy nhi\u00ean \u0111\u1ec3 \u0111\u01a1n gi\u1ea3n ho\u00e1, ch\u00fang ta ch\u1ec9 c\u1ea7n bi\u1ebft model performance c\u1ee7a model v\u1edbi production data, ch\u1ee9 kh\u00f4ng c\u1ea7n so s\u00e1nh model performance gi\u1eefa reference window , test window . V\u00ec v\u1eady, ch\u00fang ta s\u1ebd truy\u1ec1n v\u00e0o drift_data v\u00e0o c\u1ea3 reference_data v\u00e0 current_data . B\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc th\u00eam t\u1ea1i \u0111\u00e2y \u0111\u1ec3 hi\u1ec3u r\u00f5 h\u01a1n v\u1ec1 c\u00e1ch Evidently t\u00ednh model performance. K\u1ebft qu\u1ea3 \u0111\u01b0\u1ee3c in ra sau khi ch\u1ea1y gi\u1ed1ng nh\u01b0 sau. data_drift:n_drifted_features | 3 | None # (1) data_drift:dataset_drift | True | None # (2) ... classification_performance:quality | 0 .4 | { 'dataset' : 'reference' , 'metric' : 'accuracy' } # (3) classification_performance:class_quality | 0 .0 | { 'dataset' : 'reference' , 'class_name' : '0' , 'metric' : 'precision' } # (4) ... S\u1ed1 features b\u1ecb drift current_data , hay test window , c\u00f3 b\u1ecb drift kh\u00f4ng accuracy c\u1ee7a model precision c\u1ee7a model cho class 0 \u0110\u1ec3 t\u00ecm hi\u1ec3u th\u00eam v\u1ec1 c\u00e1c lo\u1ea1i monitoring kh\u00e1c hay c\u00e1c ch\u1ee9c n\u0103ng kh\u00e1c c\u1ee7a Evidently, b\u1ea1n c\u00f3 th\u1ec3 xem th\u00eam c\u00e1c v\u00ed d\u1ee5 t\u1ea1i website c\u1ee7a Evidently .","title":"Test datasets"},{"location":"mlops-crash-course/monitoring/thiet-ke-monitoring-service.html#tong-ket","text":"Trong b\u00e0i n\u00e0y ch\u00fang ta \u0111\u00e3 ph\u00e2n t\u00edch, thi\u1ebft k\u1ebf m\u1ed9t service kh\u00e1 ph\u1ee9c t\u1ea1p l\u00e0 Monitoring service. B\u1ea1n \u0111\u00e3 hi\u1ec3u c\u00e1c y\u00eau c\u1ea7u v\u1ec1 c\u00e1c ch\u1ee9c n\u0103ng c\u1ee7a m\u1ed9t Monitoring service \u0111\u1ec3 theo d\u00f5i c\u00e1c metrics c\u1ee7a data, model nh\u01b0 Ph\u00e1t hi\u1ec7n Data drift , Theo d\u00f5i model performance . Trong b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd h\u1ecdc c\u00e1ch tri\u1ec3n khai v\u00e0 thi\u1ebft l\u1eadp c\u1ea3nh b\u00e1o tr\u00ean Grafana.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/monitoring/thiet-ke-monitoring-service.html#tai-lieu-tham-khao","text":"Evidently","title":"T\u00e0i li\u1ec7u tham kh\u1ea3o"},{"location":"mlops-crash-course/monitoring/tong-quan-monitoring.html","text":"Photo by Milada Vigerova on Unsplash Gi\u1edbi thi\u1ec7u Trong b\u00e0i tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 tri\u1ec3n khai model l\u00ean batch serving pipeline v\u00e0 online serving service; tuy v\u1eady, tri\u1ec3n khai model xong ch\u01b0a ph\u1ea3i l\u00e0 k\u1ebft th\u00fac d\u1ef1 \u00e1n. Model performance c\u1ea7n \u0111\u01b0\u1ee3c theo d\u00f5i sau khi tri\u1ec3n khai \u0111\u1ec3 c\u1ea3i thi\u1ec7n model k\u1ecbp th\u1eddi. C\u00f3 kh\u00e1 nhi\u1ec1u l\u00fd do g\u00e2y ra \u1ea3nh h\u01b0\u1edfng t\u1edbi model performance, ti\u00eau bi\u1ec3u nh\u01b0: T\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a features, labels \u1edf production kh\u00e1c v\u1edbi khi training T\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a labels \u1edf production kh\u00f4ng \u0111\u1ed5i so v\u1edbi khi training, nh\u01b0ng c\u00e1ch data \u0111\u01b0\u1ee3c label b\u1ecb thay \u0111\u1ed5i Qu\u00e1 tr\u00ecnh thu th\u1eadp data v\u00e0 c\u1eadp nh\u1eadt Feature Store b\u1ecb l\u1ed7i Data b\u1ecb c\u1eadp nh\u1eadt sai Qu\u00e1 tr\u00ecnh feature engineering l\u00fac training v\u00e0 l\u00fac inference kh\u00f4ng kh\u1edbp v.v. Ngo\u00e0i model performance, logs, t\u00e0i nguy\u00ean t\u00ednh to\u00e1n v\u00e0 c\u00e1c th\u00f4ng s\u1ed1 kh\u00e1c c\u1ee7a h\u1ec7 th\u1ed1ng c\u0169ng c\u1ea7n \u0111\u01b0\u1ee3c theo d\u00f5i theo th\u1eddi gian th\u1ef1c, \u0111\u1ec3 x\u1eed l\u00fd c\u00e1c v\u1ea5n \u0111\u1ec1 c\u1ee7a h\u1ec7 th\u1ed1ng k\u1ecbp th\u1eddi \u1edf production. M\u1ed9t s\u1ed1 l\u1ed7i c\u00f3 th\u1ec3 k\u1ec3 \u0111\u1ebfn nh\u01b0: Phi\u00ean b\u1ea3n c\u1ee7a c\u00e1c th\u01b0 vi\u1ec7n, tools kh\u00f4ng t\u01b0\u01a1ng th\u00edch L\u1ed7i li\u00ean quan t\u1edbi quy\u1ec1n truy c\u1eadp v\u00e0o file CPU c\u1ee7a m\u1ed9t server b\u1ecb qu\u00e1 n\u00f3ng S\u1ed1 requests trung b\u00ecnh trong m\u1ed9t gi\u00e2y Trong b\u00e0i n\u00e0y, ch\u00fang ta s\u1ebd t\u00ecm hi\u1ec3u c\u00e1c metrics \u0111i\u1ec3n h\u00ecnh c\u1ea7n \u0111\u01b0\u1ee3c theo d\u00f5i trong m\u1ed9t h\u1ec7 th\u1ed1ng ML v\u00e0 c\u00e1ch tri\u1ec3n khai h\u1ec7 th\u1ed1ng theo d\u00f5i c\u00e1c metrics n\u00e0y. Theo d\u00f5i h\u1ec7 th\u1ed1ng Th\u00f4ng th\u01b0\u1eddng, c\u00f3 ba m\u1ea3ng sau c\u1ea7n \u0111\u01b0\u1ee3c theo d\u00f5i trong m\u1ed9t h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m: M\u1ea1ng m\u00e1y t\u00ednh T\u00e0i nguy\u00ean t\u00ednh to\u00e1n \u1ee8ng d\u1ee5ng M\u1ed9t s\u1ed1 v\u00ed d\u1ee5 v\u1ec1 metrics trong c\u00e1c m\u1ea3ng tr\u00ean nh\u01b0: \u0110\u1ed9 tr\u1ec5, th\u00f4ng l\u01b0\u1ee3ng S\u1ed1 requests trong m\u1ed9t ph\u00fat, t\u1ec9 l\u1ec7 s\u1ed1 requests c\u00f3 status code l\u00e0 200 M\u1ee9c \u0111\u1ed9 s\u1eed d\u1ee5ng CPU, GPU v\u00e0 memory, v.v. Nh\u1eefng metrics n\u00e0y \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 operational metrics , t\u1ea1m d\u1ecbch l\u00e0 metrics v\u1eadn h\u00e0nh h\u1ec7 th\u1ed1ng . Trong b\u00e0i sau, ch\u00fang ta s\u1ebd d\u00f9ng Prometheus \u0111\u1ec3 thu th\u1eadp c\u00e1c metrics tr\u00ean t\u1eeb m\u00e1y local v\u00e0 BentoML \u0111\u1ec3 thu th\u1eadp c\u00e1c metrics li\u00ean quan t\u1edbi Online serving API. Theo d\u00f5i data v\u00e0 model Trong m\u1ed9t h\u1ec7 th\u1ed1ng ML, metrics v\u1ec1 data, model c\u0169ng c\u1ea7n \u0111\u01b0\u1ee3c theo d\u00f5i. C\u00e1c metrics n\u00e0y \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 ML metrics, \u0111\u01b0\u1ee3c chia th\u00e0nh b\u1ed1n nh\u00f3m. B\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y ch\u1ec9 ra th\u00f4ng tin v\u1ec1 b\u1ed1n nh\u00f3m metrics v\u00e0 v\u00ed d\u1ee5 v\u1ec1 c\u00e1c metrics trong c\u00e1c nh\u00f3m \u0111\u00f3. # Nh\u00f3m Metrics 1 Input th\u00f4 \u0110\u1ea7u v\u00e0o nh\u1eadn \u0111\u01b0\u1ee3c t\u1eeb requests g\u1eedi t\u1edbi Online serving API 2 Feature \u0110\u1ec3 theo d\u00f5i s\u1ef1 thay \u0111\u1ed5i c\u00e1c thu\u1ed9c t\u00ednh th\u1ed1ng k\u00ea c\u1ee7a features 3 D\u1ef1 \u0111o\u00e1n D\u1ef1 \u0111o\u00e1n c\u1ee7a model, \u0111\u1ec3 theo d\u00f5i model performance v\u00e0 s\u1ef1 thay \u0111\u1ed5i c\u00e1c thu\u1ed9c t\u00ednh th\u1ed1ng k\u00ea c\u1ee7a d\u1ef1 \u0111o\u00e1n c\u1ee7a model 4 Label L\u01b0\u1ee3t click chu\u1ed9t, mua h\u00e0ng, y\u00eau th\u00edch, chia s\u1ebb, v.v, \u0111\u1ec3 theo d\u00f5i model performance v\u00e0 s\u1ef1 thay \u0111\u1ed5i c\u00e1c thu\u1ed9c t\u00ednh th\u1ed1ng k\u00ea c\u1ee7a label Metrics \u1edf c\u00e1c nh\u00f3m sau ch\u00ednh l\u00e0 s\u1ef1 bi\u1ebfn \u0111\u1ed5i c\u1ee7a c\u00e1c metrics t\u1eeb c\u00e1c nh\u00f3m tr\u01b0\u1edbc \u0111\u00f3. Metrics c\u00e0ng \u1edf c\u00e1c nh\u00f3m sau th\u00ec c\u00e0ng c\u00f3 \u00fd ngh\u0129a g\u1ea7n v\u1edbi m\u1ee5c ti\u00eau c\u1ee7a d\u1ef1 \u00e1n. C\u00f4ng c\u1ee5 theo d\u00f5i M\u1ed9t b\u1ed9 c\u00f4ng c\u1ee5 ph\u00f9 h\u1ee3p gi\u00fap ch\u00fang ta \u0111o l\u01b0\u1eddng, theo d\u00f5i v\u00e0 hi\u1ec3u \u00fd ngh\u0129a c\u1ee7a c\u00e1c metrics trong m\u1ed9t h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m. C\u00e1c c\u00f4ng c\u1ee5 ph\u1ed5 bi\u1ebfn \u0111\u01b0\u1ee3c k\u1ec3 \u0111\u1ebfn nh\u01b0 logs, dashboards, alerts. Logs Logs l\u00e0 m\u1ed9t th\u00e0nh ph\u1ea7n kh\u00f4ng th\u1ec3 thi\u1ebfu trong c\u00e1c h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m. Logs gi\u00fap b\u1ea1n debug nhanh h\u01a1n trong l\u00fac ph\u00e1t tri\u1ec3n v\u00e0 \u0111\u1eb7c bi\u1ec7t khi h\u1ec7 th\u1ed1ng \u0111\u01b0\u1ee3c tri\u1ec3n khai ra production. Trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n h\u1ec7 th\u1ed1ng, logs c\u00f3 th\u1ec3 ch\u1ec9 c\u1ea7n ghi ra bash terminal. Nh\u01b0ng \u1edf production, kh\u1ea3 n\u0103ng cao l\u00e0 logs s\u1ebd \u0111\u01b0\u1ee3c in ra \u1edf trong m\u1ed9t Docker container. \u0110\u1ec3 ki\u1ec3m tra \u0111\u01b0\u1ee3c logs trong m\u1ed9t Docker container, b\u1ea1n s\u1ebd d\u00f9ng l\u1ec7nh docker logs <container-id> ho\u1eb7c kubectl logs <pod-name> -c <container-name> . Vi\u1ec7c n\u00e0y r\u1ea5t m\u1ea5t th\u1eddi gian, v\u00ec b\u1ea1n c\u1ea7n ki\u1ec3m tra xem container-id l\u00e0 g\u00ec hay pod-name l\u00e0 g\u00ec. Kh\u00f4ng ch\u1ec9 v\u1eady \u1edf production, c\u00f3 r\u1ea5t nhi\u1ec1u replicas c\u1ee7a m\u1ed9t service, khi\u1ebfn cho vi\u1ec7c ki\u1ec3m tra logs b\u1eb1ng tay s\u1ebd r\u1ea5t kh\u00f3 kh\u0103n trong m\u1ed9t h\u1ec7 th\u1ed1ng l\u1edbn. Thay v\u00e0o \u0111\u00f3, logs c\u1ee7a c\u00e1c services s\u1ebd \u0111\u01b0\u1ee3c t\u1eadp trung v\u00e0o m\u1ed9t n\u01a1i \u0111\u1ec3 thu\u1eadn ti\u1ec7n t\u00ecm ki\u1ebfm, gi\u00fap cho vi\u1ec7c debug tr\u1edf n\u00ean thu\u1eadn ti\u1ec7n h\u01a1n r\u1ea5t nhi\u1ec1u. Trong b\u00e0i sau, ch\u00fang ta s\u1ebd d\u00f9ng ELK Stack (Elasticsearch, Logstash v\u00e0 Kibana) l\u00e0m gi\u1ea3i ph\u00e1p theo d\u00f5i logs c\u1ee7a Online serving service. Dashboards Dashboards hi\u1ec3n th\u1ecb m\u1ed9t b\u1ee9c tranh to\u00e0n c\u1ea3nh v\u1ec1 c\u00e1c metrics trong m\u1ed9t h\u1ec7 th\u1ed1ng, \u1edf d\u1ea1ng m\u00e0 con ng\u01b0\u1eddi d\u1ec5 hi\u1ec3u nh\u1ea5t v\u00e0 s\u1eafp x\u1ebfp h\u1ee3p l\u00fd g\u1ecdn g\u00e0ng tu\u1ef3 thu\u1ed9c v\u00e0o y\u00eau c\u1ea7u c\u1ee7a m\u1ed7i ch\u1ee9c n\u0103ng trong h\u1ec7 th\u1ed1ng. D\u1ef1a v\u00e0o nh\u1eefng g\u00ec \u0111\u01b0\u1ee3c hi\u1ec3n th\u1ecb tr\u00ean dashboards, ch\u00fang ta c\u00f2n bi\u1ebft \u0111\u01b0\u1ee3c m\u1ed1i quan h\u1ec7 gi\u1eefa c\u00e1c metrics, t\u00ecm ra nguy\u00ean nh\u00e2n c\u1ee7a v\u1ea5n \u0111\u1ec1 \u0111ang g\u1eb7p ph\u1ea3i \u1edf production m\u00e0 kh\u00f4ng c\u1ea7n ph\u1ea3i ki\u1ec3m tra data, code hay logs. Trong b\u00e0i sau, ch\u00fang ta s\u1ebd d\u00f9ng Grafana \u0111\u1ec3 l\u00e0m dashboards hi\u1ec3n th\u1ecb c\u00e1c metrics h\u1ec7 th\u1ed1ng v\u00e0 ML metrics. Alerts Alerts gi\u00fap c\u1ea3nh b\u00e1o t\u1edbi \u0111\u00fang ng\u01b0\u1eddi, \u0111\u00fang th\u1eddi \u0111i\u1ec3m, khi m\u1ed9t metrics \u1edf tr\u1ea1ng th\u00e1i b\u1ea5t th\u01b0\u1eddng. V\u00ed d\u1ee5 khi m\u1ed9t metric v\u01b0\u1ee3t qu\u00e1 m\u1ed9t threshold hay khi data b\u1ecb drift (c\u00e1c t\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a data b\u1ecb thay \u0111\u1ed5i). M\u1ed9t alert th\u01b0\u1eddng g\u1ed3m ba th\u00e0nh ph\u1ea7n: Ch\u00ednh s\u00e1ch (Policy): \u0111i\u1ec1u ki\u1ec7n \u0111\u1ec3 x\u1ea3y ra alert K\u00eanh th\u00f4ng b\u00e1o (Channel): khi c\u1ea3nh b\u00e1o x\u1ea3y ra, ai s\u1ebd \u0111\u01b0\u1ee3c th\u00f4ng b\u00e1o, b\u1eb1ng c\u00e1ch n\u00e0o M\u00f4 t\u1ea3 (Description): m\u00f4 t\u1ea3 c\u1ea3nh b\u00e1o v\u1ec1 chuy\u1ec7n g\u00ec \u0111ang x\u1ea3y ra Trong b\u00e0i sau, ch\u00fang ta s\u1ebd d\u00f9ng Grafana \u0111\u1ec3 thi\u1ebft l\u1eadp m\u1ed9t alert khi dataset b\u1ecb drift. T\u1ed5ng k\u1ebft \u0110\u1ec3 x\u00e2y d\u1ef1ng m\u1ed9t h\u1ec7 th\u1ed1ng ML th\u00e0nh c\u00f4ng, monitoring platform l\u00e0 y\u1ebfu t\u1ed1 quan tr\u1ecdng. B\u1ea1n s\u1ebd kh\u00f4ng bi\u1ebft tr\u01b0\u1edbc \u0111\u01b0\u1ee3c chuy\u1ec7n g\u00ec hay bug n\u00e0o s\u1ebd x\u1ea3y ra. V\u00ec v\u1eady, h\u00e3y chu\u1ea9n b\u1ecb cho n\u00f3! Trong b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd tri\u1ec3n khai ELK Stack, Prometheus server, Grafana server v\u00e0 vi\u1ebft Monitoring service \u0111\u1ec3 theo d\u00f5i c\u00e1c metrics li\u00ean quan t\u1edbi ho\u1ea1t \u0111\u1ed9ng c\u1ee7a h\u1ec7 th\u1ed1ng, data, ML model. T\u00e0i li\u1ec7u tham kh\u1ea3o CS 329S. Lecture 10. Data Distribution Shifts and Monitoring","title":"T\u1ed5ng quan monitoring"},{"location":"mlops-crash-course/monitoring/tong-quan-monitoring.html#gioi-thieu","text":"Trong b\u00e0i tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 tri\u1ec3n khai model l\u00ean batch serving pipeline v\u00e0 online serving service; tuy v\u1eady, tri\u1ec3n khai model xong ch\u01b0a ph\u1ea3i l\u00e0 k\u1ebft th\u00fac d\u1ef1 \u00e1n. Model performance c\u1ea7n \u0111\u01b0\u1ee3c theo d\u00f5i sau khi tri\u1ec3n khai \u0111\u1ec3 c\u1ea3i thi\u1ec7n model k\u1ecbp th\u1eddi. C\u00f3 kh\u00e1 nhi\u1ec1u l\u00fd do g\u00e2y ra \u1ea3nh h\u01b0\u1edfng t\u1edbi model performance, ti\u00eau bi\u1ec3u nh\u01b0: T\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a features, labels \u1edf production kh\u00e1c v\u1edbi khi training T\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a labels \u1edf production kh\u00f4ng \u0111\u1ed5i so v\u1edbi khi training, nh\u01b0ng c\u00e1ch data \u0111\u01b0\u1ee3c label b\u1ecb thay \u0111\u1ed5i Qu\u00e1 tr\u00ecnh thu th\u1eadp data v\u00e0 c\u1eadp nh\u1eadt Feature Store b\u1ecb l\u1ed7i Data b\u1ecb c\u1eadp nh\u1eadt sai Qu\u00e1 tr\u00ecnh feature engineering l\u00fac training v\u00e0 l\u00fac inference kh\u00f4ng kh\u1edbp v.v. Ngo\u00e0i model performance, logs, t\u00e0i nguy\u00ean t\u00ednh to\u00e1n v\u00e0 c\u00e1c th\u00f4ng s\u1ed1 kh\u00e1c c\u1ee7a h\u1ec7 th\u1ed1ng c\u0169ng c\u1ea7n \u0111\u01b0\u1ee3c theo d\u00f5i theo th\u1eddi gian th\u1ef1c, \u0111\u1ec3 x\u1eed l\u00fd c\u00e1c v\u1ea5n \u0111\u1ec1 c\u1ee7a h\u1ec7 th\u1ed1ng k\u1ecbp th\u1eddi \u1edf production. M\u1ed9t s\u1ed1 l\u1ed7i c\u00f3 th\u1ec3 k\u1ec3 \u0111\u1ebfn nh\u01b0: Phi\u00ean b\u1ea3n c\u1ee7a c\u00e1c th\u01b0 vi\u1ec7n, tools kh\u00f4ng t\u01b0\u01a1ng th\u00edch L\u1ed7i li\u00ean quan t\u1edbi quy\u1ec1n truy c\u1eadp v\u00e0o file CPU c\u1ee7a m\u1ed9t server b\u1ecb qu\u00e1 n\u00f3ng S\u1ed1 requests trung b\u00ecnh trong m\u1ed9t gi\u00e2y Trong b\u00e0i n\u00e0y, ch\u00fang ta s\u1ebd t\u00ecm hi\u1ec3u c\u00e1c metrics \u0111i\u1ec3n h\u00ecnh c\u1ea7n \u0111\u01b0\u1ee3c theo d\u00f5i trong m\u1ed9t h\u1ec7 th\u1ed1ng ML v\u00e0 c\u00e1ch tri\u1ec3n khai h\u1ec7 th\u1ed1ng theo d\u00f5i c\u00e1c metrics n\u00e0y.","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/monitoring/tong-quan-monitoring.html#theo-doi-he-thong","text":"Th\u00f4ng th\u01b0\u1eddng, c\u00f3 ba m\u1ea3ng sau c\u1ea7n \u0111\u01b0\u1ee3c theo d\u00f5i trong m\u1ed9t h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m: M\u1ea1ng m\u00e1y t\u00ednh T\u00e0i nguy\u00ean t\u00ednh to\u00e1n \u1ee8ng d\u1ee5ng M\u1ed9t s\u1ed1 v\u00ed d\u1ee5 v\u1ec1 metrics trong c\u00e1c m\u1ea3ng tr\u00ean nh\u01b0: \u0110\u1ed9 tr\u1ec5, th\u00f4ng l\u01b0\u1ee3ng S\u1ed1 requests trong m\u1ed9t ph\u00fat, t\u1ec9 l\u1ec7 s\u1ed1 requests c\u00f3 status code l\u00e0 200 M\u1ee9c \u0111\u1ed9 s\u1eed d\u1ee5ng CPU, GPU v\u00e0 memory, v.v. Nh\u1eefng metrics n\u00e0y \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 operational metrics , t\u1ea1m d\u1ecbch l\u00e0 metrics v\u1eadn h\u00e0nh h\u1ec7 th\u1ed1ng . Trong b\u00e0i sau, ch\u00fang ta s\u1ebd d\u00f9ng Prometheus \u0111\u1ec3 thu th\u1eadp c\u00e1c metrics tr\u00ean t\u1eeb m\u00e1y local v\u00e0 BentoML \u0111\u1ec3 thu th\u1eadp c\u00e1c metrics li\u00ean quan t\u1edbi Online serving API.","title":"Theo d\u00f5i h\u1ec7 th\u1ed1ng"},{"location":"mlops-crash-course/monitoring/tong-quan-monitoring.html#theo-doi-data-va-model","text":"Trong m\u1ed9t h\u1ec7 th\u1ed1ng ML, metrics v\u1ec1 data, model c\u0169ng c\u1ea7n \u0111\u01b0\u1ee3c theo d\u00f5i. C\u00e1c metrics n\u00e0y \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 ML metrics, \u0111\u01b0\u1ee3c chia th\u00e0nh b\u1ed1n nh\u00f3m. B\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y ch\u1ec9 ra th\u00f4ng tin v\u1ec1 b\u1ed1n nh\u00f3m metrics v\u00e0 v\u00ed d\u1ee5 v\u1ec1 c\u00e1c metrics trong c\u00e1c nh\u00f3m \u0111\u00f3. # Nh\u00f3m Metrics 1 Input th\u00f4 \u0110\u1ea7u v\u00e0o nh\u1eadn \u0111\u01b0\u1ee3c t\u1eeb requests g\u1eedi t\u1edbi Online serving API 2 Feature \u0110\u1ec3 theo d\u00f5i s\u1ef1 thay \u0111\u1ed5i c\u00e1c thu\u1ed9c t\u00ednh th\u1ed1ng k\u00ea c\u1ee7a features 3 D\u1ef1 \u0111o\u00e1n D\u1ef1 \u0111o\u00e1n c\u1ee7a model, \u0111\u1ec3 theo d\u00f5i model performance v\u00e0 s\u1ef1 thay \u0111\u1ed5i c\u00e1c thu\u1ed9c t\u00ednh th\u1ed1ng k\u00ea c\u1ee7a d\u1ef1 \u0111o\u00e1n c\u1ee7a model 4 Label L\u01b0\u1ee3t click chu\u1ed9t, mua h\u00e0ng, y\u00eau th\u00edch, chia s\u1ebb, v.v, \u0111\u1ec3 theo d\u00f5i model performance v\u00e0 s\u1ef1 thay \u0111\u1ed5i c\u00e1c thu\u1ed9c t\u00ednh th\u1ed1ng k\u00ea c\u1ee7a label Metrics \u1edf c\u00e1c nh\u00f3m sau ch\u00ednh l\u00e0 s\u1ef1 bi\u1ebfn \u0111\u1ed5i c\u1ee7a c\u00e1c metrics t\u1eeb c\u00e1c nh\u00f3m tr\u01b0\u1edbc \u0111\u00f3. Metrics c\u00e0ng \u1edf c\u00e1c nh\u00f3m sau th\u00ec c\u00e0ng c\u00f3 \u00fd ngh\u0129a g\u1ea7n v\u1edbi m\u1ee5c ti\u00eau c\u1ee7a d\u1ef1 \u00e1n.","title":"Theo d\u00f5i data v\u00e0 model"},{"location":"mlops-crash-course/monitoring/tong-quan-monitoring.html#cong-cu-theo-doi","text":"M\u1ed9t b\u1ed9 c\u00f4ng c\u1ee5 ph\u00f9 h\u1ee3p gi\u00fap ch\u00fang ta \u0111o l\u01b0\u1eddng, theo d\u00f5i v\u00e0 hi\u1ec3u \u00fd ngh\u0129a c\u1ee7a c\u00e1c metrics trong m\u1ed9t h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m. C\u00e1c c\u00f4ng c\u1ee5 ph\u1ed5 bi\u1ebfn \u0111\u01b0\u1ee3c k\u1ec3 \u0111\u1ebfn nh\u01b0 logs, dashboards, alerts.","title":"C\u00f4ng c\u1ee5 theo d\u00f5i"},{"location":"mlops-crash-course/monitoring/tong-quan-monitoring.html#logs","text":"Logs l\u00e0 m\u1ed9t th\u00e0nh ph\u1ea7n kh\u00f4ng th\u1ec3 thi\u1ebfu trong c\u00e1c h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m. Logs gi\u00fap b\u1ea1n debug nhanh h\u01a1n trong l\u00fac ph\u00e1t tri\u1ec3n v\u00e0 \u0111\u1eb7c bi\u1ec7t khi h\u1ec7 th\u1ed1ng \u0111\u01b0\u1ee3c tri\u1ec3n khai ra production. Trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n h\u1ec7 th\u1ed1ng, logs c\u00f3 th\u1ec3 ch\u1ec9 c\u1ea7n ghi ra bash terminal. Nh\u01b0ng \u1edf production, kh\u1ea3 n\u0103ng cao l\u00e0 logs s\u1ebd \u0111\u01b0\u1ee3c in ra \u1edf trong m\u1ed9t Docker container. \u0110\u1ec3 ki\u1ec3m tra \u0111\u01b0\u1ee3c logs trong m\u1ed9t Docker container, b\u1ea1n s\u1ebd d\u00f9ng l\u1ec7nh docker logs <container-id> ho\u1eb7c kubectl logs <pod-name> -c <container-name> . Vi\u1ec7c n\u00e0y r\u1ea5t m\u1ea5t th\u1eddi gian, v\u00ec b\u1ea1n c\u1ea7n ki\u1ec3m tra xem container-id l\u00e0 g\u00ec hay pod-name l\u00e0 g\u00ec. Kh\u00f4ng ch\u1ec9 v\u1eady \u1edf production, c\u00f3 r\u1ea5t nhi\u1ec1u replicas c\u1ee7a m\u1ed9t service, khi\u1ebfn cho vi\u1ec7c ki\u1ec3m tra logs b\u1eb1ng tay s\u1ebd r\u1ea5t kh\u00f3 kh\u0103n trong m\u1ed9t h\u1ec7 th\u1ed1ng l\u1edbn. Thay v\u00e0o \u0111\u00f3, logs c\u1ee7a c\u00e1c services s\u1ebd \u0111\u01b0\u1ee3c t\u1eadp trung v\u00e0o m\u1ed9t n\u01a1i \u0111\u1ec3 thu\u1eadn ti\u1ec7n t\u00ecm ki\u1ebfm, gi\u00fap cho vi\u1ec7c debug tr\u1edf n\u00ean thu\u1eadn ti\u1ec7n h\u01a1n r\u1ea5t nhi\u1ec1u. Trong b\u00e0i sau, ch\u00fang ta s\u1ebd d\u00f9ng ELK Stack (Elasticsearch, Logstash v\u00e0 Kibana) l\u00e0m gi\u1ea3i ph\u00e1p theo d\u00f5i logs c\u1ee7a Online serving service.","title":"Logs"},{"location":"mlops-crash-course/monitoring/tong-quan-monitoring.html#dashboards","text":"Dashboards hi\u1ec3n th\u1ecb m\u1ed9t b\u1ee9c tranh to\u00e0n c\u1ea3nh v\u1ec1 c\u00e1c metrics trong m\u1ed9t h\u1ec7 th\u1ed1ng, \u1edf d\u1ea1ng m\u00e0 con ng\u01b0\u1eddi d\u1ec5 hi\u1ec3u nh\u1ea5t v\u00e0 s\u1eafp x\u1ebfp h\u1ee3p l\u00fd g\u1ecdn g\u00e0ng tu\u1ef3 thu\u1ed9c v\u00e0o y\u00eau c\u1ea7u c\u1ee7a m\u1ed7i ch\u1ee9c n\u0103ng trong h\u1ec7 th\u1ed1ng. D\u1ef1a v\u00e0o nh\u1eefng g\u00ec \u0111\u01b0\u1ee3c hi\u1ec3n th\u1ecb tr\u00ean dashboards, ch\u00fang ta c\u00f2n bi\u1ebft \u0111\u01b0\u1ee3c m\u1ed1i quan h\u1ec7 gi\u1eefa c\u00e1c metrics, t\u00ecm ra nguy\u00ean nh\u00e2n c\u1ee7a v\u1ea5n \u0111\u1ec1 \u0111ang g\u1eb7p ph\u1ea3i \u1edf production m\u00e0 kh\u00f4ng c\u1ea7n ph\u1ea3i ki\u1ec3m tra data, code hay logs. Trong b\u00e0i sau, ch\u00fang ta s\u1ebd d\u00f9ng Grafana \u0111\u1ec3 l\u00e0m dashboards hi\u1ec3n th\u1ecb c\u00e1c metrics h\u1ec7 th\u1ed1ng v\u00e0 ML metrics.","title":"Dashboards"},{"location":"mlops-crash-course/monitoring/tong-quan-monitoring.html#alerts","text":"Alerts gi\u00fap c\u1ea3nh b\u00e1o t\u1edbi \u0111\u00fang ng\u01b0\u1eddi, \u0111\u00fang th\u1eddi \u0111i\u1ec3m, khi m\u1ed9t metrics \u1edf tr\u1ea1ng th\u00e1i b\u1ea5t th\u01b0\u1eddng. V\u00ed d\u1ee5 khi m\u1ed9t metric v\u01b0\u1ee3t qu\u00e1 m\u1ed9t threshold hay khi data b\u1ecb drift (c\u00e1c t\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a data b\u1ecb thay \u0111\u1ed5i). M\u1ed9t alert th\u01b0\u1eddng g\u1ed3m ba th\u00e0nh ph\u1ea7n: Ch\u00ednh s\u00e1ch (Policy): \u0111i\u1ec1u ki\u1ec7n \u0111\u1ec3 x\u1ea3y ra alert K\u00eanh th\u00f4ng b\u00e1o (Channel): khi c\u1ea3nh b\u00e1o x\u1ea3y ra, ai s\u1ebd \u0111\u01b0\u1ee3c th\u00f4ng b\u00e1o, b\u1eb1ng c\u00e1ch n\u00e0o M\u00f4 t\u1ea3 (Description): m\u00f4 t\u1ea3 c\u1ea3nh b\u00e1o v\u1ec1 chuy\u1ec7n g\u00ec \u0111ang x\u1ea3y ra Trong b\u00e0i sau, ch\u00fang ta s\u1ebd d\u00f9ng Grafana \u0111\u1ec3 thi\u1ebft l\u1eadp m\u1ed9t alert khi dataset b\u1ecb drift.","title":"Alerts"},{"location":"mlops-crash-course/monitoring/tong-quan-monitoring.html#tong-ket","text":"\u0110\u1ec3 x\u00e2y d\u1ef1ng m\u1ed9t h\u1ec7 th\u1ed1ng ML th\u00e0nh c\u00f4ng, monitoring platform l\u00e0 y\u1ebfu t\u1ed1 quan tr\u1ecdng. B\u1ea1n s\u1ebd kh\u00f4ng bi\u1ebft tr\u01b0\u1edbc \u0111\u01b0\u1ee3c chuy\u1ec7n g\u00ec hay bug n\u00e0o s\u1ebd x\u1ea3y ra. V\u00ec v\u1eady, h\u00e3y chu\u1ea9n b\u1ecb cho n\u00f3! Trong b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd tri\u1ec3n khai ELK Stack, Prometheus server, Grafana server v\u00e0 vi\u1ebft Monitoring service \u0111\u1ec3 theo d\u00f5i c\u00e1c metrics li\u00ean quan t\u1edbi ho\u1ea1t \u0111\u1ed9ng c\u1ee7a h\u1ec7 th\u1ed1ng, data, ML model.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/monitoring/tong-quan-monitoring.html#tai-lieu-tham-khao","text":"CS 329S. Lecture 10. Data Distribution Shifts and Monitoring","title":"T\u00e0i li\u1ec7u tham kh\u1ea3o"},{"location":"mlops-crash-course/monitoring/trien-khai-monitoring-service.html","text":"Photo by Stephen Dawson on Unsplash Gi\u1edbi thi\u1ec7u Trong b\u00e0i tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 thi\u1ebft k\u1ebf monitoring service v\u1edbi c\u00e1c c\u00f4ng vi\u1ec7c: T\u1ea1o ra dataset ch\u1ee9a feature b\u1ecb drift Tri\u1ec3n khai monitoring service \u0111\u1ec3 theo d\u00f5i data v\u00e0 model performance Thi\u1ebft l\u1eadp Grafana dashboards \u0111\u1ec3 hi\u1ec3n th\u1ecb metrics v\u1ec1 data v\u00e0 model Trong b\u00e0i n\u00e0y, ch\u00fang ta s\u1ebd th\u1ef1c hi\u1ec7n code \u0111\u1ec3 tri\u1ec3n khai service n\u00e0y. M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n C\u00e1c b\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 c\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n: C\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng Python 3.9 m\u1edbi v\u1edbi c\u00e1c th\u01b0 vi\u1ec7n c\u1ea7n thi\u1ebft trong file monitoring_service/dev_requirements.txt \u0110\u1eb7t environment variable MONITORING_SERVICE_DIR \u1edf terminal b\u1ea1n d\u00f9ng b\u1eb1ng \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i t\u1edbi folder monitoring_service . Env var n\u00e0y h\u1ed7 tr\u1ee3 ch\u1ea1y python code \u1edf folder monitoring_service/src trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n. cd mlops-crash-course-code/monitoring_service export MONITORING_SERVICE_DIR = $( pwd ) C\u00e1c tools s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong b\u00e0i n\u00e0y bao g\u1ed3m: Feast: truy xu\u1ea5t Feature Store Flask: vi\u1ebft API cho monitoring service Evidently: ki\u1ec3m tra ch\u1ea5t l\u01b0\u1ee3ng data v\u00e0 model performance Note Trong qu\u00e1 tr\u00ecnh ch\u1ea1y code cho t\u1ea5t c\u1ea3 c\u00e1c ph\u1ea7n d\u01b0\u1edbi \u0111\u00e2y, gi\u1ea3 s\u1eed r\u1eb1ng folder g\u1ed1c n\u01a1i ch\u00fang ta l\u00e0m vi\u1ec7c l\u00e0 folder monitoring_service . Monitoring service Trong ph\u1ea7n n\u00e0y, ch\u00fang ta s\u1ebd th\u1ef1c hi\u1ec7n code monitoring service. H\u00ecnh d\u01b0\u1edbi \u0111\u00e2y th\u1ec3 hi\u1ec7n c\u00e1c lu\u1ed3ng data c\u1ee7a monitoring service. flowchart LR n01[ ] --Label--> n2 n0[Client] --Request--> n1[Online serving<br>service] --Features &<br>prediction--> n2[Monitoring<br>service] --Metrics--> n3[Prometheus<br>& Grafana] n1 --Response--> n0 style n01 height:0px; Qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n monitoring service g\u1ed3m c\u00e1c b\u01b0\u1edbc ch\u00ednh sau. Vi\u1ebft code g\u1eedi request v\u00e0 response data t\u1eeb Online serving API sang Monitoring API (m\u1ed9t RESTful API) c\u1ee7a monitoring service Vi\u1ebft Monitoring API \u1edf monitoring service, nh\u1eadn data t\u1eeb Online serving API, d\u00f9ng data n\u00e0y \u0111\u1ec3 theo d\u00f5i data drift v\u00e0 model performance Thi\u1ebft l\u1eadp Prometheus server v\u00e0 Grafana dashboards \u0111\u1ec3 hi\u1ec3n th\u1ecb c\u00e1c metrics v\u1ec1 data drift v\u00e0 model performance Monitoring API \u0110\u1ea7u ti\u00ean, ch\u00fang ta s\u1ebd vi\u1ebft Monitoring API \u1edf monitoring service. Code c\u1ee7a monitoring service \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u1ea1i monitoring_service/src/monitoring_service.py . B\u1ea1n h\u00e3y \u0111\u1ec3 \u00fd t\u1edbi h\u00e0m iterate c\u1ee7a class MonitoringService v\u1edbi lu\u1ed3ng x\u1eed l\u00fd data nh\u01b0 sau. monitoring_service/src/monitoring_service.py 1 2 3 4 5 6 7 8 def iterate ( self , new_rows : pd . DataFrame ): # (1) if not self . _process_curr_data ( new_rows ): # (2) return if not self . _process_next_run (): # (3) return self . _execute_monitoring () # (4) self . _process_metrics ( self . features_and_target_monitor . metrics ()) # (5) self . _process_metrics ( self . model_performance_monitor . metrics ()) # (6) H\u00e0m iterate nh\u1eadn v\u00e0o new_rows , ch\u00ednh l\u00e0 data \u0111\u01b0\u1ee3c Online serving API g\u1eedi t\u1edbi X\u1eed l\u00fd data nh\u1eadn \u0111\u01b0\u1ee3c Ki\u1ec3m tra xem \u0111\u00e3 \u0111\u1ebfn th\u1eddi \u0111i\u1ec3m ch\u1ea1y qu\u00e1 tr\u00ecnh \u0111\u00e1nh gi\u00e1 data drift v\u00e0 model performance ch\u01b0a Th\u1ef1c hi\u1ec7n ph\u00e2n t\u00edch \u0111\u00e1nh gi\u00e1 data drift v\u00e0 model performance G\u1eedi metrics v\u1ec1 data drift t\u1edbi Prometheus server G\u1eedi metrics v\u1ec1 model performance t\u1edbi Prometheus server Data nh\u1eadn \u0111\u01b0\u1ee3c t\u1eeb Online serving API g\u1ed3m c\u00e1c c\u1ed9t ch\u00ednh sau. C\u1ed9t \u00dd ngh\u0129a request_id Request ID conv_rate Feature acc_rate Feature avg_daily_trips Feature best_driver_id ID t\u00e0i x\u1ebf \u0111\u01b0\u1ee3c ch\u1ecdn prediction D\u1ef1 \u0111o\u00e1n c\u1ee7a model cho driver ID \u0111\u01b0\u1ee3c ch\u1ecdn H\u00e3y c\u00f9ng xem h\u00e0m _process_curr_data l\u00e0m c\u00f4ng vi\u1ec7c g\u00ec. monitoring_service/src/monitoring_service.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def _process_curr_data ( self , new_rows : pd . DataFrame ): # (1) label_data = read_label_data () # (2) if label_data is None : return False merged_data = merge_request_with_label ( new_rows , label_data ) # (3) if not self . current_data is None : # (4) curr_data : pd . DataFrame = pd . concat ([ self . current_data , merged_data ], ignore_index = True ) else : curr_data = merged_data curr_size = curr_data . shape [ 0 ] if curr_size > self . WINDOW_SIZE : # (5) curr_data . drop ( index = list ( range ( 0 , curr_size - self . WINDOW_SIZE )), inplace = True ) curr_data . reset_index ( drop = True , inplace = True ) self . current_data = curr_data # (6) if curr_size < self . WINDOW_SIZE : # (7) Log () . log . info ( f \"Not enough data for measurement: { curr_size } / { self . WINDOW_SIZE } rows. Waiting for more data\" ) return False return True H\u00e0m _process_curr_data nh\u1eadn v\u00e0o data m\u1edbi \u0111\u01b0\u1ee3c g\u1eedi t\u1eeb Online serving API sang \u0110\u1ecdc label data hay ch\u00ednh l\u00e0 request_data K\u1ebft h\u1ee3p data m\u1edbi v\u1edbi label data theo request_id T\u00edch lu\u1ef9 data m\u1edbi v\u1edbi data hi\u1ec7n t\u1ea1i B\u1ecf b\u1edbt records n\u1ebfu nh\u01b0 s\u1ed1 records v\u01b0\u1ee3t qu\u00e1 WINDOW_SIZE ch\u00ednh l\u00e0 k\u00edch th\u01b0\u1edbc c\u1ee7a test window L\u01b0u data m\u1edbi \u0111\u00e3 \u0111\u01b0\u1ee3c x\u1eed l\u00fd v\u00e0o l\u00e0m data hi\u1ec7n t\u1ea1i Ki\u1ec3m tra xem \u0111\u00e3 \u0111\u1ee7 s\u1ed1 records c\u1ea7n thi\u1ebft ch\u01b0a Question T\u1ea1i sao c\u1ea7n \u0111\u1ecdc label data hay request_data m\u1ed7i khi c\u00f3 records m\u1edbi \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn t\u1eeb Online serving API? Ch\u00fang ta kh\u00f4ng c\u1ea7n ph\u1ea3i \u0111\u1ecdc l\u1ea1i request_data m\u1ed7i khi c\u00f3 records m\u1edbi v\u00ec request_data l\u00e0 kh\u00f4ng \u0111\u1ed5i. S\u1edf d\u0129 code \u0111\u01b0\u1ee3c vi\u1ebft nh\u01b0 v\u1eady l\u00e0 \u0111\u1ec3 gi\u1ea3 s\u1eed r\u1eb1ng kh\u00f4ng ph\u1ea3i l\u00fac n\u00e0o label c\u0169ng c\u00f3 s\u1eb5n \u1edf production. Sau khi k\u1ebft h\u1ee3p data m\u1edbi v\u1edbi label data theo request_id data \u0111\u01b0\u1ee3c t\u1ed5ng h\u1ee3p ch\u1ee9a c\u00e1c c\u1ed9t sau: C\u00e1c c\u1ed9t features: d\u00f9ng \u0111\u1ec3 theo d\u00f5i data drift C\u1ed9t prediction v\u00e0 c\u1ed9t label trip_completed : d\u00f9ng \u0111\u1ec3 theo d\u00f5i model performance. L\u01b0u \u00fd, c\u1ed9t prediction \u0111\u01b0\u1ee3c bi\u1ebfn \u0111\u1ed5i trong h\u00e0m merge_request_with_label \u0111\u1ec3 lu\u00f4n c\u00f3 gi\u00e1 tr\u1ecb l\u00e0 1 Ti\u1ebfp \u0111\u1ebfn, h\u00e3y xem h\u00e0m _process_next_run v\u00e0 _execute_monitoring . monitoring_service/src/monitoring_service.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def _process_next_run ( self ): if not self . next_run is None and self . next_run > datetime . now (): # (1) return False self . next_run = datetime . now () + timedelta ( seconds = self . RUN_PERIOD_SEC ) # (2) return True def _execute_monitoring ( self ): self . features_and_target_monitor . execute ( # (3) self . reference_data , self . current_data , self . column_mapping , ) self . model_performance_monitor . execute ( # (4) self . current_data , self . current_data , self . column_mapping , ) Ki\u1ec3m tra xem th\u1eddi \u0111i\u1ec3m hi\u1ec7n t\u1ea1i c\u00f3 ch\u1ea1y monitoring kh\u00f4ng T\u00ednh th\u1eddi \u0111i\u1ec3m ti\u1ebfp theo s\u1ebd ch\u1ea1y monitoring Th\u1ef1c hi\u1ec7n \u0111\u00e1nh gi\u00e1 data drift, gi\u1ed1ng nh\u01b0 ch\u00fang ta \u0111\u00e3 th\u1ef1c hi\u1ec7n \u1edf file notebook monitoring_service/nbs/test_datasets.ipynb Th\u1ef1c hi\u1ec7n \u0111\u00e1nh gi\u00e1 model performance Cu\u1ed1i c\u00f9ng, \u0111o\u1ea1n code d\u01b0\u1edbi \u0111\u00e2y c\u1ee7a h\u00e0m _process_metrics s\u1ebd g\u1eedi metrics c\u1ee7a data drift v\u00e0 model performance t\u1edbi Prometheus server. monitoring_service/src/monitoring_service.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def _process_metrics ( self , evidently_metrics ): for metric , value , labels in evidently_metrics : metric_key = f \"evidently: { metric . name } \" # (1) if not labels : labels = {} labels [ \"dataset_name\" ] = MonitoringService . DATASET_NAME # (2) if isinstance ( value , str ): continue found = self . metrics . get ( metric_key ) # (3) if found is None : found = prometheus_client . Gauge ( metric_key , \"\" , list ( sorted ( labels . keys ())) ) self . metrics [ metric_key ] = found try : found . labels ( ** labels ) . set ( value ) # (4) except ValueError as error : ... T\u1ea1o t\u00ean metric, ph\u1ea3i gi\u1ed1ng v\u1edbi metric \u0111\u01b0\u1ee3c d\u00f9ng trong Prometheus query tr\u00ean Grafana dashboards labels l\u00e0 m\u1ed9t dict v\u1edbi key, value l\u00e0 t\u00ean v\u00e0 gi\u00e1 tr\u1ecb c\u1ee7a c\u00e1c label \u0111\u01b0\u1ee3c quy \u01b0\u1edbc b\u1edfi Evidently, v\u00ed d\u1ee5 {'dataset': 'reference', 'metric': 'accuracy'} . labels n\u00e0y c\u00f3 \u00fd ngh\u0129a t\u01b0\u01a1ng \u0111\u01b0\u01a1ng v\u1edbi Prometheus labels self.metrics l\u01b0u c\u00e1c object Gauge c\u1ee7a Prometheus. Gauge g\u1eedi metrics t\u1edbi Prometheus server. Bi\u1ebfn found l\u00e0 m\u1ed9t object Gauge , t\u01b0\u01a1ng \u1ee9ng v\u1edbi m\u1ed7i metric l\u1ea5y ra t\u1eeb Evidently G\u00e1n Prometheus labels v\u00e0 gi\u00e1 tr\u1ecb cho Gauge object. Gauge object s\u1ebd g\u1eedi labels, gi\u00e1 tr\u1ecb c\u1ee7a c\u00e1c metrics l\u00ean Prometheus server Ngo\u00e0i c\u00e1c \u0111o\u1ea1n code quan tr\u1ecdng nh\u1ea5t c\u1ee7a monitoring service \u1edf tr\u00ean, c\u00e1c \u0111o\u1ea1n code c\u00f2n l\u1ea1i kh\u00e1c m\u00e0 b\u1ea1n c\u1ea7n l\u01b0u \u00fd nh\u01b0 d\u01b0\u1edbi \u0111\u00e2y. monitoring_service/src/monitoring_service.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 app = Flask ( AppConst . MONITORING_SERVICE ) # (1) ... app . wsgi_app = DispatcherMiddleware ( app . wsgi_app , { \"/metrics\" : prometheus_client . make_wsgi_app ()}) # (2) ... SERVICE = MonitoringService () # (3) ... @app . route ( \"/iterate\" , methods = [ \"POST\" ]) # (4) def iterate (): item = flask . request . json df = pd . DataFrame . from_dict ( item ) # (5) SERVICE . iterate ( new_rows = df ) # (6) return \"ok\" ... app . run ( host = \"0.0.0.0\" , port = 8309 , debug = True ) # (7) T\u1ea1o Flask app. Flask l\u00e0 m\u1ed9t th\u01b0 vi\u1ec7n ph\u1ed5 bi\u1ebfn \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 vi\u1ebft RESTful API trong Python T\u1ef1 \u0111\u1ed9ng t\u1ea1o endpoint /metrics \u0111\u1ec3 Prometheus thu th\u1eadp metrics Kh\u1edfi t\u1ea1o MonitoringService class T\u1ea1o endpoint /iterate \u0111\u1ec3 Online serving API g\u1eedi data t\u1edbi Bi\u1ebfn \u0111\u1ed5i data nh\u1eadn v\u00e0o th\u00e0nh DataFrame G\u1ecdi h\u00e0m iterate \u0111\u1ec3 th\u1ef1c hi\u1ec7n \u0111\u00e1nh gi\u00e1 data drift v\u00e0 model performance Ch\u1ea1y Flask app t\u1ea1i port 8309 \u1edf m\u00e1y local \u0110\u1ec3 Prometheus thu th\u1eadp \u0111\u01b0\u1ee3c metrics g\u1eedi qua endpoint /metrics , b\u1ea1n c\u1ea7n t\u1ea1o 1 Prometheus Job trong file config c\u1ee7a Prometheus server \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u1ea1i prom-graf/prometheus/config/prometheus.yml trong repo mlops-crash-course-platform . Prometheus Job n\u00e0y \u0111\u00e3 \u0111\u01b0\u1ee3c t\u1ea1o s\u1eb5n nh\u01b0 d\u01b0\u1edbi \u0111\u00e2y. prom-graf/prometheus/config/prometheus.yml 1 2 3 4 5 - job_name : \"monitoring_service\" scrape_interval : 5s static_configs : - targets : - \"localhost:8309\" Sau khi code xong monitoring service, ch\u00fang ta s\u1ebd c\u1eadp nh\u1eadt code trong Online serving API \u0111\u1ec3 g\u1eedi data t\u1edbi Monitoring API sau khi model th\u1ef1c hi\u1ec7n d\u1ef1 \u0111o\u00e1n. T\u00edch h\u1ee3p Online serving B\u1ea1n m\u1edf file code c\u1ee7a Online serving API t\u1ea1i model_serving/src/bentoml_service.py trong repo mlops-crash-course-code . H\u00e3y ch\u00fa \u00fd t\u1edbi \u0111o\u1ea1n code trong h\u00e0m inference . model_serving/src/bentoml_service.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 @svc . api ( ... ) def inference ( request : InferenceRequest , ctx : bentoml . Context ) -> Dict [ str , Any ]: try : ... result = predict ( input_features [ sorted ( input_features )]) df [ \"prediction\" ] = result best_idx = df [ \"prediction\" ] . argmax () # (1) best_driver_id = df [ \"driver_id\" ] . iloc [ best_idx ] # (2) # monitor monitor_df = df . iloc [[ best_idx ]] # (3) monitor_df = monitor_df . assign ( request_id = [ request . request_id ]) # (4) monitor_df = monitor_df . assign ( best_driver_id = [ best_driver_id ]) # (5) monitor_request ( monitor_df ) # (6) except Exception as e : ... def monitor_request ( df : pd . DataFrame ): try : data = json . dumps ( df . to_dict (), cls = NumpyEncoder ) # (7) response = requests . post ( # (8) MONITORING_SERVICE_API , data = data , headers = { \"content-type\" : \"application/json\" }, ) ... except Exception as error : ... L\u1ea5y ra index c\u1ee7a t\u00e0i x\u1ebf c\u00f3 kh\u1ea3 n\u0103ng cao nh\u1ea5t s\u1ebd ho\u00e0n th\u00e0nh cu\u1ed1c xe L\u1ea5y ra ID c\u1ee7a t\u00e0i x\u1ebf \u0111\u01b0\u1ee3c ch\u1ecdn L\u1ea5y ra record trong DataFrame g\u1ed1c c\u1ee7a t\u00e0i x\u1ebf \u0111\u01b0\u1ee3c ch\u1ecdn Th\u00eam c\u1ed9t request_id v\u00e0o monitor_df v\u1edbi gi\u00e1 tr\u1ecb l\u00e0 request_id \u0111\u01b0\u1ee3c g\u1eedi t\u1edbi trong request Th\u00eam c\u1ed9t best_driver_id v\u00e0o monitor_df . Vi\u1ec7c l\u01b0u tr\u1eef l\u1ea1i th\u00f4ng tin v\u1ec1 d\u1ef1 \u0111o\u00e1n c\u1ee7a model l\u00e0 c\u1ea7n thi\u1ebft, gi\u00fap cho vi\u1ec7c theo d\u00f5i data v\u00e0 debug \u1edf production d\u1ec5 d\u00e0ng h\u01a1n G\u1ecdi t\u1edbi h\u00e0m monitor_request \u0111\u1ec3 g\u1eedi data t\u1edbi Monitoring API. Data \u0111\u01b0\u1ee3c g\u1eedi bao g\u1ed3m c\u00e1c c\u1ed9t ch\u00ednh: request_id , c\u00e1c c\u1ed9t features, prediction v\u00e0 best_driver_id Bi\u1ebfn \u0111\u1ed5i DataFrame th\u00e0nh d\u1ea1ng JSON v\u1edbi s\u1ef1 h\u1ed7 tr\u1ee3 c\u1ee7a NumpyEncoder class, gi\u00fap cho vi\u1ec7c bi\u1ebfn \u0111\u1ed5i JSON tr\u1edf l\u1ea1i th\u00e0nh DataFrame \u1edf ph\u00eda Monitoring API d\u1ec5 d\u00e0ng h\u01a1n G\u1eedi POST request t\u1edbi Monitoring API Nh\u01b0 v\u1eady l\u00e0 ch\u00fang ta v\u1eeba t\u00edch h\u1ee3p Online serving API v\u1edbi Monitoring API c\u1ee7a Monitoring service. Sau khi model th\u1ef1c hi\u1ec7n d\u1ef1 \u0111o\u00e1n \u1edf Online serving API, data \u0111\u01b0\u1ee3c t\u1ed5ng h\u1ee3p t\u1eeb requests v\u00e0 prediction c\u1ee7a model s\u1ebd \u0111\u01b0\u1ee3c g\u1eedi sang Monitoring API \u0111\u1ec3 \u0111\u01b0\u1ee3c theo d\u00f5i v\u00e0 \u0111\u00e1nh gi\u00e1. Monitoring API s\u1ebd th\u1ef1c hi\u1ec7n vi\u1ec7c \u0111\u00e1nh gi\u00e1 data drift, model performance, r\u1ed3i g\u1eedi c\u00e1c metrics sau khi \u0111\u00e1nh gi\u00e1 ra API endpoint /metrics . Prometheus server s\u1ebd \u0111\u1ecbnh k\u00ec thu th\u1eadp c\u00e1c metrics qua endpoint /metrics n\u00e0y. Grafana s\u1ebd \u0111\u1ecdc c\u00e1c metrics t\u1eeb Prometheus server v\u00e0 hi\u1ec3n th\u1ecb l\u00ean dashboards. Trong ph\u1ea7n ti\u1ebfp theo, ch\u00fang ta s\u1ebd thi\u1ebft l\u1eadp Grafana dashboards \u0111\u1ec3 hi\u1ec3n th\u1ecb c\u00e1c metrics. Grafana dashboards v\u00e0 Alerts C\u00f3 2 dashboards ch\u00fang ta c\u1ea7n thi\u1ebft l\u1eadp, bao g\u1ed3m: monitoring_service/dashboards/data_drift.json : Dashboard cho metrics v\u1ec1 data drift monitoring_service/dashboards/classification_performance.json : Dashboard cho metrics v\u1ec1 model performance B\u1ea1n c\u1ea7n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 tri\u1ec3n khai c\u00e1c dashboards n\u00e0y l\u00ean Grafana. Copy 2 file dashboards tr\u00ean v\u00e0o mlops-crash-course-platform/prom-graf/run_env/grafana/dashboards Truy c\u1eadp v\u00e0o Grafana server t\u1ea1i http://localhost:3000 M\u1edf 2 dashboards c\u00f3 t\u00ean Evidently Data Drift Dashboard v\u00e0 Evidently Classification Performance Dashboard Data Drift Dashboard Dashboard Evidently Data Drift Dashboard s\u1ebd gi\u1ed1ng nh\u01b0 h\u00ecnh d\u01b0\u1edbi \u0111\u00e2y. Dashboard n\u00e0y ch\u1ee9a c\u00e1c panels v\u1ec1 data drift bao g\u1ed3m: General information Dataset drift : Dataset c\u00f3 b\u1ecb drift hay kh\u00f4ng Share of drifted features : T\u1ec9 l\u1ec7 s\u1ed1 features b\u1ecb drift tr\u00ean t\u1ed5ng s\u1ed1 features # of drifted features : S\u1ed1 features b\u1ecb drift # of features : T\u1ed5ng s\u1ed1 features Detailed information P-value of features : p-value c\u1ee7a c\u00e1c features Model Performance Dashboard Dashboard Evidently Classification Performance Dashboard s\u1ebd gi\u1ed1ng nh\u01b0 h\u00ecnh d\u01b0\u1edbi \u0111\u00e2y. Dashboard n\u00e0y ch\u1ee9a c\u00e1c panels v\u1ec1 model performance bao g\u1ed3m: Reference dataset data Quality : T\u1ed5ng h\u1ee3p model performance metrics theo th\u1eddi gian accuracy , f1 , precision , recall : Model performance metrics Prediction class representation : S\u1ed1 l\u01b0\u1ee3ng c\u00e1c d\u1ef1 \u0111o\u00e1n theo class Target class representation : S\u1ed1 l\u01b0\u1ee3ng c\u00e1c label theo class Class 0 information : Th\u00f4ng tin v\u1ec1 class 0 Confusion 0 : Confusion matrix cho class 0 Confusion in time : Gi\u00e1 tr\u1ecb c\u1ee7a confusion matrix theo th\u1eddi gian Quality : T\u1ed5ng h\u1ee3p model performance metrics cho class 0 theo th\u1eddi gian Class 1 information : T\u01b0\u01a1ng t\u1ef1 class 0 Alerts Grafana Alerts cho ph\u00e9p k\u00edch ho\u1ea1t c\u1ea3nh b\u00e1o khi m\u1ed9t v\u1ea5n \u0111\u1ec1 v\u1ec1 metrics x\u1ea3y ra. Trong b\u00e0i n\u00e0y, ch\u00fang ta s\u1ebd t\u1ea1o m\u1ed9t c\u1ea3nh b\u00e1o \u0111\u01a1n gi\u1ea3n \u0111\u1ec3 c\u1ea3nh b\u00e1o khi dataset b\u1ecb drift. \u1ede sidebar b\u00ean ph\u1ea3i c\u1ee7a Grafana, click Dashabords . \u1ede trang Dashboard, t\u1ea1o Folder t\u00ean l\u00e0 Alerts . Folder n\u00e0y \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 l\u01b0u c\u1ea3nh b\u00e1o ch\u00fang ta s\u1ebd t\u1ea1o \u1ede sidebar b\u00ean ph\u1ea3i c\u1ee7a Grafana, b\u1ea1n click v\u00e0o Alerting . \u1ede trang Alerting , tab Alert rules , click n\u00fat New alert rule . Trong trang t\u1ea1o c\u1ea3nh b\u00e1o, t\u1ea1o c\u1ea3nh b\u00e1o m\u1edbi t\u00ean l\u00e0 Data drift detection , \u0111i\u1ec1n c\u00e1c th\u00f4ng tin trong ph\u1ea7n 1. Set a query and alert condition nh\u01b0 \u1ea3nh d\u01b0\u1edbi, v\u1edbi query A l\u00e0: 1 evidently : data_drift : dataset_drift { dataset_name = \" drivers \"} Ph\u1ea7n 2. Alert evaluation behavior v\u00e0 3. Add details for your alert Click Save and exit Info \u0110\u1ec3 c\u1ea5u h\u00ecnh c\u00e1ch m\u00e0 Alert \u0111\u01b0\u1ee3c g\u1eedi \u0111i, b\u1ea1n v\u00e0o tab Notification polices v\u00e0 th\u00eam policy m\u1edbi. Trong b\u00e0i n\u00e0y, \u0111\u1ec3 \u0111\u01a1n gi\u1ea3n h\u01a1n ch\u00fang ta s\u1ebd gi\u1eef nguy\u00ean policy m\u1eb7c \u0111\u1ecbnh c\u1ee7a Grafana. Th\u1eed nghi\u1ec7m Data b\u1ecb drift Sau khi thi\u1ebft l\u1eadp xong dashboards, ch\u00fang ta s\u1ebd vi\u1ebft code \u0111\u1ec3 g\u1eedi request gi\u1ea3 t\u1edbi Online serving API. Code \u0111\u1ec3 g\u1eedi requests \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u1ea1i monitoring_service/src/mock_request.py . monitoring_service/src/mock_request.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def construct_request ( row : pd . Series ) -> dict : # (1) request_id = row [ \"request_id\" ] driver_ids = ast . literal_eval ( row [ \"driver_ids\" ]) return { \"request_id\" : request_id , \"driver_ids\" : driver_ids , } def send_request ( request : dict ) -> None : # (2) try : data = json . dumps ( request ) response = requests . post ( ONLINE_SERVING_API , data = data , headers = { \"content-type\" : \"application/json\" }, ) ... except Exception as error : ... def main ( data_type : str , n_request : int = 1 ): # (3) data_path = AppPath . NORMAL_DATA if data_type == DataType . DRIFT : data_path = AppPath . DRIFT_DATA data_source = pd . read_parquet ( data_path , engine = \"fastparquet\" ) # (4) request_data = pd . read_csv ( AppPath . REQUEST_DATA ) # (5) ... data_source . to_parquet ( AppPath . FEAST_DATA_SOURCE , engine = \"fastparquet\" ) # (6) result = subprocess . run ([ \"make\" , \"feast_teardown\" ]) # (7) ... result = subprocess . run ([ \"make\" , \"feast_apply\" ]) # (8) ... result = subprocess . run ([ \"make\" , \"feast_materialize\" ]) # (9) ... total_request = request_data . shape [ 0 ] for idx in range ( n_request ): row = request_data . iloc [ idx % total_request ] request = construct_request ( row ) send_request ( request ) # (10) ... H\u00e0m construct_request t\u1ea1o payload d\u1ea1ng JSON \u0111\u1ec3 g\u1eedi t\u1edbi Online serving API H\u00e0m send_request g\u1eedi payload tr\u00ean t\u1edbi Online serving API H\u00e0m main th\u1ef1c hi\u1ec7n qu\u00e1 tr\u00ecnh g\u1eedi data \u0110\u1ecdc dataset ch\u1ee9a c\u00e1c features tu\u1ef3 thu\u1ed9c v\u00e0o lo\u1ea1i data l\u00e0 normal_data hay drift_data \u0110\u1ecdc request_data Ghi \u0111\u00e8 dataset ch\u1ee9a c\u00e1c features v\u00e0o file data source c\u1ee7a Feast Xo\u00e1 data \u1edf c\u1ea3 Offline Feature Store v\u00e0 Online Feature Store Ghi data t\u1eeb file data source c\u1ee7a Feast v\u00e0o Offline Feature Store Ghi data t\u1eeb Offline Feature Store v\u00e0o Online Feature Store G\u1eedi l\u1ea7n l\u01b0\u1ee3t c\u00e1c request trong request_data t\u1edbi Online serving API \u0110\u1ec3 ti\u1ebfn h\u00e0nh th\u1eed nghi\u1ec7m, b\u1ea1n l\u00e0m theo c\u00e1c b\u01b0\u1edbc sau. \u0110\u1ea3m b\u1ea3o Online serving service \u0111\u00e3 ch\u1ea1y C\u1eadp nh\u1eadt Feature Store cd ../data_pipeline make deploy_feature_repo # (1) cd ../monitoring_service Tri\u1ec3n khai code c\u1ee7a Feature Store Build docker image v\u00e0 ch\u1ea1y docker compose cho monitoring service make build_image make compose_up Tip \u0110\u1ecbnh ngh\u0129a v\u1ec1 c\u00e1c env vars \u0111\u01b0\u1ee3c d\u00f9ng trong qu\u00e1 tr\u00ecnh build image \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i monitoring_service/deployment/.env . B\u1ea1n c\u00f3 th\u1ec3 thay \u0111\u1ed5i n\u1ebfu c\u1ea7n. G\u1eedi 5 requests gi\u1ea3 ch\u1ee9a drift_data python src/mock_request.py -d drift -n 5 \u0110\u1ee3i 30s, ki\u1ec3m tra Evidently Data Drift Dashboard v\u00e0 Evidently Classification Performance Dashboard , k\u1ebft qu\u1ea3 s\u1ebd gi\u1ed1ng nh\u01b0 sau. Evidently Data Drift Dashboard - Dataset drift Evidently Classification Performance Dashboard M\u1edf trang Grafana Alerting, b\u1ea1n s\u1ebd th\u1ea5y c\u1ea3nh b\u00e1o Data drift detection \u0111ang \u1edf tr\u1ea1ng th\u00e1i Firing Click n\u00fat Show state history \u0111\u1ec3 xem th\u1eddi \u0111i\u1ec3m c\u1ee7a c\u00e1c tr\u1ea1ng th\u00e1i trong c\u1ea3nh b\u00e1o n\u00e0y. Data kh\u00f4ng b\u1ecb drift Ti\u1ebfp theo, ch\u00fang ta s\u1ebd test tr\u01b0\u1eddng h\u1ee3p data kh\u00f4ng b\u1ecb drift. B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau. G\u1eedi 5 requests gi\u1ea3 ch\u1ee9a normal_data t\u1edbi Online serving API python src/mock_request.py -d normal -n 5 Ki\u1ec3m tra Evidently Data Drift Dashboard , b\u1ea1n s\u1ebd th\u1ea5y th\u00f4ng tin Dataset kh\u00f4ng b\u1ecb drift s\u1ed1 features b\u1ecb drift l\u00e0 0. Ngo\u00e0i ra, c\u1ea3nh b\u00e1o Data drift detection c\u0169ng \u0111\u00e3 \u1edf tr\u1ea1ng th\u00e1i Normal Evidently Data Drift Dashboard - Dataset kh\u00f4ng drift Alert Data drift detection \u1edf tr\u1ea1ng th\u00e1i Normal Tip N\u1ebfu m\u1edf Kibana ra, b\u1ea1n c\u0169ng s\u1ebd th\u1ea5y logs c\u1ee7a Monitoring service \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng thu th\u1eadp nh\u1edd ch\u1ee9c n\u0103ng t\u1ef1 \u0111\u1ed9ng thu th\u1eadp logs t\u1eeb c\u00e1c containers c\u1ee7a Filebeat T\u1ed5ng k\u1ebft Theo d\u00f5i v\u00e0 b\u1ea3o tr\u00ec lu\u00f4n l\u00e0 m\u1ed9t ph\u1ea7n quan tr\u1ecdng trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n m\u1ed9t h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m n\u00f3i chung, \u0111\u1eb7c bi\u1ec7t l\u00e0 trong m\u1ed9t h\u1ec7 th\u1ed1ng ML n\u00f3i ri\u00eang. Trong b\u00e0i Monitoring n\u00e0y, ch\u00fang ta \u0111\u00e3 bi\u1ebft v\u1ec1 c\u00e1c metrics \u0111i\u1ec3n h\u00ecnh c\u1ee7a h\u1ec7 th\u1ed1ng v\u1ec1 data v\u00e0 v\u1ec1 model m\u00e0 m\u1ed9t h\u1ec7 th\u1ed1ng ML th\u01b0\u1eddng theo d\u00f5i. Ch\u00fang ta c\u0169ng \u0111\u00e3 ph\u00e2n t\u00edch v\u00e0 thi\u1ebft k\u1ebf m\u1ed9t service kh\u00e1 ph\u1ee9c t\u1ea1p l\u00e0 Monitoring service. B\u1ea1n \u0111\u00e3 bi\u1ebft c\u00e1ch theo d\u00f5i c\u00e1c metrics c\u1ee7a data, model nh\u01b0 Ph\u00e1t hi\u1ec7n Data drift , Theo d\u00f5i model performance , tri\u1ec3n khai v\u00e0 thi\u1ebft l\u1eadp c\u1ea3nh b\u00e1o tr\u00ean Grafana. Trong th\u1ef1c t\u1ebf, b\u1ea1n c\u00f3 th\u1ec3 s\u1ebd c\u1ea7n d\u00f9ng Grafana alert \u0111\u1ec3 k\u00edch ho\u1ea1t m\u1ed9t t\u00e1c v\u1ee5 n\u00e0o \u0111\u00f3, v\u00ed d\u1ee5 nh\u01b0 k\u00edch ho\u1ea1t training pipeline t\u1ef1 \u0111\u1ed9ng khi ph\u00e1t hi\u1ec7n dataset b\u1ecb drift hay \u0111\u01a1n gi\u1ea3n l\u00e0 g\u1eedi email th\u00f4ng b\u00e1o v\u1ec1 model performance t\u1edbi Data Scientist, v.v. Trong b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd thi\u1ebft l\u1eadp v\u00e0 tri\u1ec3n khai CI/CD cho c\u00e1c ph\u1ea7n trong h\u1ec7 th\u1ed1ng ML. CI/CD gi\u00fap ch\u00fang ta t\u1ef1 \u0111\u1ed9ng test v\u00e0 t\u1ef1 \u0111\u1ed9ng tri\u1ec3n khai c\u00e1c Airflow DAGs, c\u0169ng nh\u01b0 l\u00e0 c\u00e1c services nh\u01b0 Online serving service hay Monitoring service, thay v\u00ec g\u00f5 c\u00e1c l\u1ec7nh th\u1ee7 c\u00f4ng trong terminal. T\u00e0i li\u1ec7u tham kh\u1ea3o Flask Grafana Alerting","title":"Tri\u1ec3n khai monitoring service"},{"location":"mlops-crash-course/monitoring/trien-khai-monitoring-service.html#gioi-thieu","text":"Trong b\u00e0i tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 thi\u1ebft k\u1ebf monitoring service v\u1edbi c\u00e1c c\u00f4ng vi\u1ec7c: T\u1ea1o ra dataset ch\u1ee9a feature b\u1ecb drift Tri\u1ec3n khai monitoring service \u0111\u1ec3 theo d\u00f5i data v\u00e0 model performance Thi\u1ebft l\u1eadp Grafana dashboards \u0111\u1ec3 hi\u1ec3n th\u1ecb metrics v\u1ec1 data v\u00e0 model Trong b\u00e0i n\u00e0y, ch\u00fang ta s\u1ebd th\u1ef1c hi\u1ec7n code \u0111\u1ec3 tri\u1ec3n khai service n\u00e0y.","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/monitoring/trien-khai-monitoring-service.html#moi-truong-phat-trien","text":"C\u00e1c b\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 c\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n: C\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng Python 3.9 m\u1edbi v\u1edbi c\u00e1c th\u01b0 vi\u1ec7n c\u1ea7n thi\u1ebft trong file monitoring_service/dev_requirements.txt \u0110\u1eb7t environment variable MONITORING_SERVICE_DIR \u1edf terminal b\u1ea1n d\u00f9ng b\u1eb1ng \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i t\u1edbi folder monitoring_service . Env var n\u00e0y h\u1ed7 tr\u1ee3 ch\u1ea1y python code \u1edf folder monitoring_service/src trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n. cd mlops-crash-course-code/monitoring_service export MONITORING_SERVICE_DIR = $( pwd ) C\u00e1c tools s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong b\u00e0i n\u00e0y bao g\u1ed3m: Feast: truy xu\u1ea5t Feature Store Flask: vi\u1ebft API cho monitoring service Evidently: ki\u1ec3m tra ch\u1ea5t l\u01b0\u1ee3ng data v\u00e0 model performance Note Trong qu\u00e1 tr\u00ecnh ch\u1ea1y code cho t\u1ea5t c\u1ea3 c\u00e1c ph\u1ea7n d\u01b0\u1edbi \u0111\u00e2y, gi\u1ea3 s\u1eed r\u1eb1ng folder g\u1ed1c n\u01a1i ch\u00fang ta l\u00e0m vi\u1ec7c l\u00e0 folder monitoring_service .","title":"M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n"},{"location":"mlops-crash-course/monitoring/trien-khai-monitoring-service.html#monitoring-service","text":"Trong ph\u1ea7n n\u00e0y, ch\u00fang ta s\u1ebd th\u1ef1c hi\u1ec7n code monitoring service. H\u00ecnh d\u01b0\u1edbi \u0111\u00e2y th\u1ec3 hi\u1ec7n c\u00e1c lu\u1ed3ng data c\u1ee7a monitoring service. flowchart LR n01[ ] --Label--> n2 n0[Client] --Request--> n1[Online serving<br>service] --Features &<br>prediction--> n2[Monitoring<br>service] --Metrics--> n3[Prometheus<br>& Grafana] n1 --Response--> n0 style n01 height:0px; Qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n monitoring service g\u1ed3m c\u00e1c b\u01b0\u1edbc ch\u00ednh sau. Vi\u1ebft code g\u1eedi request v\u00e0 response data t\u1eeb Online serving API sang Monitoring API (m\u1ed9t RESTful API) c\u1ee7a monitoring service Vi\u1ebft Monitoring API \u1edf monitoring service, nh\u1eadn data t\u1eeb Online serving API, d\u00f9ng data n\u00e0y \u0111\u1ec3 theo d\u00f5i data drift v\u00e0 model performance Thi\u1ebft l\u1eadp Prometheus server v\u00e0 Grafana dashboards \u0111\u1ec3 hi\u1ec3n th\u1ecb c\u00e1c metrics v\u1ec1 data drift v\u00e0 model performance","title":"Monitoring service"},{"location":"mlops-crash-course/monitoring/trien-khai-monitoring-service.html#monitoring-api","text":"\u0110\u1ea7u ti\u00ean, ch\u00fang ta s\u1ebd vi\u1ebft Monitoring API \u1edf monitoring service. Code c\u1ee7a monitoring service \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u1ea1i monitoring_service/src/monitoring_service.py . B\u1ea1n h\u00e3y \u0111\u1ec3 \u00fd t\u1edbi h\u00e0m iterate c\u1ee7a class MonitoringService v\u1edbi lu\u1ed3ng x\u1eed l\u00fd data nh\u01b0 sau. monitoring_service/src/monitoring_service.py 1 2 3 4 5 6 7 8 def iterate ( self , new_rows : pd . DataFrame ): # (1) if not self . _process_curr_data ( new_rows ): # (2) return if not self . _process_next_run (): # (3) return self . _execute_monitoring () # (4) self . _process_metrics ( self . features_and_target_monitor . metrics ()) # (5) self . _process_metrics ( self . model_performance_monitor . metrics ()) # (6) H\u00e0m iterate nh\u1eadn v\u00e0o new_rows , ch\u00ednh l\u00e0 data \u0111\u01b0\u1ee3c Online serving API g\u1eedi t\u1edbi X\u1eed l\u00fd data nh\u1eadn \u0111\u01b0\u1ee3c Ki\u1ec3m tra xem \u0111\u00e3 \u0111\u1ebfn th\u1eddi \u0111i\u1ec3m ch\u1ea1y qu\u00e1 tr\u00ecnh \u0111\u00e1nh gi\u00e1 data drift v\u00e0 model performance ch\u01b0a Th\u1ef1c hi\u1ec7n ph\u00e2n t\u00edch \u0111\u00e1nh gi\u00e1 data drift v\u00e0 model performance G\u1eedi metrics v\u1ec1 data drift t\u1edbi Prometheus server G\u1eedi metrics v\u1ec1 model performance t\u1edbi Prometheus server Data nh\u1eadn \u0111\u01b0\u1ee3c t\u1eeb Online serving API g\u1ed3m c\u00e1c c\u1ed9t ch\u00ednh sau. C\u1ed9t \u00dd ngh\u0129a request_id Request ID conv_rate Feature acc_rate Feature avg_daily_trips Feature best_driver_id ID t\u00e0i x\u1ebf \u0111\u01b0\u1ee3c ch\u1ecdn prediction D\u1ef1 \u0111o\u00e1n c\u1ee7a model cho driver ID \u0111\u01b0\u1ee3c ch\u1ecdn H\u00e3y c\u00f9ng xem h\u00e0m _process_curr_data l\u00e0m c\u00f4ng vi\u1ec7c g\u00ec. monitoring_service/src/monitoring_service.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def _process_curr_data ( self , new_rows : pd . DataFrame ): # (1) label_data = read_label_data () # (2) if label_data is None : return False merged_data = merge_request_with_label ( new_rows , label_data ) # (3) if not self . current_data is None : # (4) curr_data : pd . DataFrame = pd . concat ([ self . current_data , merged_data ], ignore_index = True ) else : curr_data = merged_data curr_size = curr_data . shape [ 0 ] if curr_size > self . WINDOW_SIZE : # (5) curr_data . drop ( index = list ( range ( 0 , curr_size - self . WINDOW_SIZE )), inplace = True ) curr_data . reset_index ( drop = True , inplace = True ) self . current_data = curr_data # (6) if curr_size < self . WINDOW_SIZE : # (7) Log () . log . info ( f \"Not enough data for measurement: { curr_size } / { self . WINDOW_SIZE } rows. Waiting for more data\" ) return False return True H\u00e0m _process_curr_data nh\u1eadn v\u00e0o data m\u1edbi \u0111\u01b0\u1ee3c g\u1eedi t\u1eeb Online serving API sang \u0110\u1ecdc label data hay ch\u00ednh l\u00e0 request_data K\u1ebft h\u1ee3p data m\u1edbi v\u1edbi label data theo request_id T\u00edch lu\u1ef9 data m\u1edbi v\u1edbi data hi\u1ec7n t\u1ea1i B\u1ecf b\u1edbt records n\u1ebfu nh\u01b0 s\u1ed1 records v\u01b0\u1ee3t qu\u00e1 WINDOW_SIZE ch\u00ednh l\u00e0 k\u00edch th\u01b0\u1edbc c\u1ee7a test window L\u01b0u data m\u1edbi \u0111\u00e3 \u0111\u01b0\u1ee3c x\u1eed l\u00fd v\u00e0o l\u00e0m data hi\u1ec7n t\u1ea1i Ki\u1ec3m tra xem \u0111\u00e3 \u0111\u1ee7 s\u1ed1 records c\u1ea7n thi\u1ebft ch\u01b0a Question T\u1ea1i sao c\u1ea7n \u0111\u1ecdc label data hay request_data m\u1ed7i khi c\u00f3 records m\u1edbi \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn t\u1eeb Online serving API? Ch\u00fang ta kh\u00f4ng c\u1ea7n ph\u1ea3i \u0111\u1ecdc l\u1ea1i request_data m\u1ed7i khi c\u00f3 records m\u1edbi v\u00ec request_data l\u00e0 kh\u00f4ng \u0111\u1ed5i. S\u1edf d\u0129 code \u0111\u01b0\u1ee3c vi\u1ebft nh\u01b0 v\u1eady l\u00e0 \u0111\u1ec3 gi\u1ea3 s\u1eed r\u1eb1ng kh\u00f4ng ph\u1ea3i l\u00fac n\u00e0o label c\u0169ng c\u00f3 s\u1eb5n \u1edf production. Sau khi k\u1ebft h\u1ee3p data m\u1edbi v\u1edbi label data theo request_id data \u0111\u01b0\u1ee3c t\u1ed5ng h\u1ee3p ch\u1ee9a c\u00e1c c\u1ed9t sau: C\u00e1c c\u1ed9t features: d\u00f9ng \u0111\u1ec3 theo d\u00f5i data drift C\u1ed9t prediction v\u00e0 c\u1ed9t label trip_completed : d\u00f9ng \u0111\u1ec3 theo d\u00f5i model performance. L\u01b0u \u00fd, c\u1ed9t prediction \u0111\u01b0\u1ee3c bi\u1ebfn \u0111\u1ed5i trong h\u00e0m merge_request_with_label \u0111\u1ec3 lu\u00f4n c\u00f3 gi\u00e1 tr\u1ecb l\u00e0 1 Ti\u1ebfp \u0111\u1ebfn, h\u00e3y xem h\u00e0m _process_next_run v\u00e0 _execute_monitoring . monitoring_service/src/monitoring_service.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def _process_next_run ( self ): if not self . next_run is None and self . next_run > datetime . now (): # (1) return False self . next_run = datetime . now () + timedelta ( seconds = self . RUN_PERIOD_SEC ) # (2) return True def _execute_monitoring ( self ): self . features_and_target_monitor . execute ( # (3) self . reference_data , self . current_data , self . column_mapping , ) self . model_performance_monitor . execute ( # (4) self . current_data , self . current_data , self . column_mapping , ) Ki\u1ec3m tra xem th\u1eddi \u0111i\u1ec3m hi\u1ec7n t\u1ea1i c\u00f3 ch\u1ea1y monitoring kh\u00f4ng T\u00ednh th\u1eddi \u0111i\u1ec3m ti\u1ebfp theo s\u1ebd ch\u1ea1y monitoring Th\u1ef1c hi\u1ec7n \u0111\u00e1nh gi\u00e1 data drift, gi\u1ed1ng nh\u01b0 ch\u00fang ta \u0111\u00e3 th\u1ef1c hi\u1ec7n \u1edf file notebook monitoring_service/nbs/test_datasets.ipynb Th\u1ef1c hi\u1ec7n \u0111\u00e1nh gi\u00e1 model performance Cu\u1ed1i c\u00f9ng, \u0111o\u1ea1n code d\u01b0\u1edbi \u0111\u00e2y c\u1ee7a h\u00e0m _process_metrics s\u1ebd g\u1eedi metrics c\u1ee7a data drift v\u00e0 model performance t\u1edbi Prometheus server. monitoring_service/src/monitoring_service.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def _process_metrics ( self , evidently_metrics ): for metric , value , labels in evidently_metrics : metric_key = f \"evidently: { metric . name } \" # (1) if not labels : labels = {} labels [ \"dataset_name\" ] = MonitoringService . DATASET_NAME # (2) if isinstance ( value , str ): continue found = self . metrics . get ( metric_key ) # (3) if found is None : found = prometheus_client . Gauge ( metric_key , \"\" , list ( sorted ( labels . keys ())) ) self . metrics [ metric_key ] = found try : found . labels ( ** labels ) . set ( value ) # (4) except ValueError as error : ... T\u1ea1o t\u00ean metric, ph\u1ea3i gi\u1ed1ng v\u1edbi metric \u0111\u01b0\u1ee3c d\u00f9ng trong Prometheus query tr\u00ean Grafana dashboards labels l\u00e0 m\u1ed9t dict v\u1edbi key, value l\u00e0 t\u00ean v\u00e0 gi\u00e1 tr\u1ecb c\u1ee7a c\u00e1c label \u0111\u01b0\u1ee3c quy \u01b0\u1edbc b\u1edfi Evidently, v\u00ed d\u1ee5 {'dataset': 'reference', 'metric': 'accuracy'} . labels n\u00e0y c\u00f3 \u00fd ngh\u0129a t\u01b0\u01a1ng \u0111\u01b0\u01a1ng v\u1edbi Prometheus labels self.metrics l\u01b0u c\u00e1c object Gauge c\u1ee7a Prometheus. Gauge g\u1eedi metrics t\u1edbi Prometheus server. Bi\u1ebfn found l\u00e0 m\u1ed9t object Gauge , t\u01b0\u01a1ng \u1ee9ng v\u1edbi m\u1ed7i metric l\u1ea5y ra t\u1eeb Evidently G\u00e1n Prometheus labels v\u00e0 gi\u00e1 tr\u1ecb cho Gauge object. Gauge object s\u1ebd g\u1eedi labels, gi\u00e1 tr\u1ecb c\u1ee7a c\u00e1c metrics l\u00ean Prometheus server Ngo\u00e0i c\u00e1c \u0111o\u1ea1n code quan tr\u1ecdng nh\u1ea5t c\u1ee7a monitoring service \u1edf tr\u00ean, c\u00e1c \u0111o\u1ea1n code c\u00f2n l\u1ea1i kh\u00e1c m\u00e0 b\u1ea1n c\u1ea7n l\u01b0u \u00fd nh\u01b0 d\u01b0\u1edbi \u0111\u00e2y. monitoring_service/src/monitoring_service.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 app = Flask ( AppConst . MONITORING_SERVICE ) # (1) ... app . wsgi_app = DispatcherMiddleware ( app . wsgi_app , { \"/metrics\" : prometheus_client . make_wsgi_app ()}) # (2) ... SERVICE = MonitoringService () # (3) ... @app . route ( \"/iterate\" , methods = [ \"POST\" ]) # (4) def iterate (): item = flask . request . json df = pd . DataFrame . from_dict ( item ) # (5) SERVICE . iterate ( new_rows = df ) # (6) return \"ok\" ... app . run ( host = \"0.0.0.0\" , port = 8309 , debug = True ) # (7) T\u1ea1o Flask app. Flask l\u00e0 m\u1ed9t th\u01b0 vi\u1ec7n ph\u1ed5 bi\u1ebfn \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 vi\u1ebft RESTful API trong Python T\u1ef1 \u0111\u1ed9ng t\u1ea1o endpoint /metrics \u0111\u1ec3 Prometheus thu th\u1eadp metrics Kh\u1edfi t\u1ea1o MonitoringService class T\u1ea1o endpoint /iterate \u0111\u1ec3 Online serving API g\u1eedi data t\u1edbi Bi\u1ebfn \u0111\u1ed5i data nh\u1eadn v\u00e0o th\u00e0nh DataFrame G\u1ecdi h\u00e0m iterate \u0111\u1ec3 th\u1ef1c hi\u1ec7n \u0111\u00e1nh gi\u00e1 data drift v\u00e0 model performance Ch\u1ea1y Flask app t\u1ea1i port 8309 \u1edf m\u00e1y local \u0110\u1ec3 Prometheus thu th\u1eadp \u0111\u01b0\u1ee3c metrics g\u1eedi qua endpoint /metrics , b\u1ea1n c\u1ea7n t\u1ea1o 1 Prometheus Job trong file config c\u1ee7a Prometheus server \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u1ea1i prom-graf/prometheus/config/prometheus.yml trong repo mlops-crash-course-platform . Prometheus Job n\u00e0y \u0111\u00e3 \u0111\u01b0\u1ee3c t\u1ea1o s\u1eb5n nh\u01b0 d\u01b0\u1edbi \u0111\u00e2y. prom-graf/prometheus/config/prometheus.yml 1 2 3 4 5 - job_name : \"monitoring_service\" scrape_interval : 5s static_configs : - targets : - \"localhost:8309\" Sau khi code xong monitoring service, ch\u00fang ta s\u1ebd c\u1eadp nh\u1eadt code trong Online serving API \u0111\u1ec3 g\u1eedi data t\u1edbi Monitoring API sau khi model th\u1ef1c hi\u1ec7n d\u1ef1 \u0111o\u00e1n.","title":"Monitoring API"},{"location":"mlops-crash-course/monitoring/trien-khai-monitoring-service.html#tich-hop-online-serving","text":"B\u1ea1n m\u1edf file code c\u1ee7a Online serving API t\u1ea1i model_serving/src/bentoml_service.py trong repo mlops-crash-course-code . H\u00e3y ch\u00fa \u00fd t\u1edbi \u0111o\u1ea1n code trong h\u00e0m inference . model_serving/src/bentoml_service.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 @svc . api ( ... ) def inference ( request : InferenceRequest , ctx : bentoml . Context ) -> Dict [ str , Any ]: try : ... result = predict ( input_features [ sorted ( input_features )]) df [ \"prediction\" ] = result best_idx = df [ \"prediction\" ] . argmax () # (1) best_driver_id = df [ \"driver_id\" ] . iloc [ best_idx ] # (2) # monitor monitor_df = df . iloc [[ best_idx ]] # (3) monitor_df = monitor_df . assign ( request_id = [ request . request_id ]) # (4) monitor_df = monitor_df . assign ( best_driver_id = [ best_driver_id ]) # (5) monitor_request ( monitor_df ) # (6) except Exception as e : ... def monitor_request ( df : pd . DataFrame ): try : data = json . dumps ( df . to_dict (), cls = NumpyEncoder ) # (7) response = requests . post ( # (8) MONITORING_SERVICE_API , data = data , headers = { \"content-type\" : \"application/json\" }, ) ... except Exception as error : ... L\u1ea5y ra index c\u1ee7a t\u00e0i x\u1ebf c\u00f3 kh\u1ea3 n\u0103ng cao nh\u1ea5t s\u1ebd ho\u00e0n th\u00e0nh cu\u1ed1c xe L\u1ea5y ra ID c\u1ee7a t\u00e0i x\u1ebf \u0111\u01b0\u1ee3c ch\u1ecdn L\u1ea5y ra record trong DataFrame g\u1ed1c c\u1ee7a t\u00e0i x\u1ebf \u0111\u01b0\u1ee3c ch\u1ecdn Th\u00eam c\u1ed9t request_id v\u00e0o monitor_df v\u1edbi gi\u00e1 tr\u1ecb l\u00e0 request_id \u0111\u01b0\u1ee3c g\u1eedi t\u1edbi trong request Th\u00eam c\u1ed9t best_driver_id v\u00e0o monitor_df . Vi\u1ec7c l\u01b0u tr\u1eef l\u1ea1i th\u00f4ng tin v\u1ec1 d\u1ef1 \u0111o\u00e1n c\u1ee7a model l\u00e0 c\u1ea7n thi\u1ebft, gi\u00fap cho vi\u1ec7c theo d\u00f5i data v\u00e0 debug \u1edf production d\u1ec5 d\u00e0ng h\u01a1n G\u1ecdi t\u1edbi h\u00e0m monitor_request \u0111\u1ec3 g\u1eedi data t\u1edbi Monitoring API. Data \u0111\u01b0\u1ee3c g\u1eedi bao g\u1ed3m c\u00e1c c\u1ed9t ch\u00ednh: request_id , c\u00e1c c\u1ed9t features, prediction v\u00e0 best_driver_id Bi\u1ebfn \u0111\u1ed5i DataFrame th\u00e0nh d\u1ea1ng JSON v\u1edbi s\u1ef1 h\u1ed7 tr\u1ee3 c\u1ee7a NumpyEncoder class, gi\u00fap cho vi\u1ec7c bi\u1ebfn \u0111\u1ed5i JSON tr\u1edf l\u1ea1i th\u00e0nh DataFrame \u1edf ph\u00eda Monitoring API d\u1ec5 d\u00e0ng h\u01a1n G\u1eedi POST request t\u1edbi Monitoring API Nh\u01b0 v\u1eady l\u00e0 ch\u00fang ta v\u1eeba t\u00edch h\u1ee3p Online serving API v\u1edbi Monitoring API c\u1ee7a Monitoring service. Sau khi model th\u1ef1c hi\u1ec7n d\u1ef1 \u0111o\u00e1n \u1edf Online serving API, data \u0111\u01b0\u1ee3c t\u1ed5ng h\u1ee3p t\u1eeb requests v\u00e0 prediction c\u1ee7a model s\u1ebd \u0111\u01b0\u1ee3c g\u1eedi sang Monitoring API \u0111\u1ec3 \u0111\u01b0\u1ee3c theo d\u00f5i v\u00e0 \u0111\u00e1nh gi\u00e1. Monitoring API s\u1ebd th\u1ef1c hi\u1ec7n vi\u1ec7c \u0111\u00e1nh gi\u00e1 data drift, model performance, r\u1ed3i g\u1eedi c\u00e1c metrics sau khi \u0111\u00e1nh gi\u00e1 ra API endpoint /metrics . Prometheus server s\u1ebd \u0111\u1ecbnh k\u00ec thu th\u1eadp c\u00e1c metrics qua endpoint /metrics n\u00e0y. Grafana s\u1ebd \u0111\u1ecdc c\u00e1c metrics t\u1eeb Prometheus server v\u00e0 hi\u1ec3n th\u1ecb l\u00ean dashboards. Trong ph\u1ea7n ti\u1ebfp theo, ch\u00fang ta s\u1ebd thi\u1ebft l\u1eadp Grafana dashboards \u0111\u1ec3 hi\u1ec3n th\u1ecb c\u00e1c metrics.","title":"T\u00edch h\u1ee3p Online serving"},{"location":"mlops-crash-course/monitoring/trien-khai-monitoring-service.html#grafana-dashboards-va-alerts","text":"C\u00f3 2 dashboards ch\u00fang ta c\u1ea7n thi\u1ebft l\u1eadp, bao g\u1ed3m: monitoring_service/dashboards/data_drift.json : Dashboard cho metrics v\u1ec1 data drift monitoring_service/dashboards/classification_performance.json : Dashboard cho metrics v\u1ec1 model performance B\u1ea1n c\u1ea7n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 tri\u1ec3n khai c\u00e1c dashboards n\u00e0y l\u00ean Grafana. Copy 2 file dashboards tr\u00ean v\u00e0o mlops-crash-course-platform/prom-graf/run_env/grafana/dashboards Truy c\u1eadp v\u00e0o Grafana server t\u1ea1i http://localhost:3000 M\u1edf 2 dashboards c\u00f3 t\u00ean Evidently Data Drift Dashboard v\u00e0 Evidently Classification Performance Dashboard","title":"Grafana dashboards v\u00e0 Alerts"},{"location":"mlops-crash-course/monitoring/trien-khai-monitoring-service.html#data-drift-dashboard","text":"Dashboard Evidently Data Drift Dashboard s\u1ebd gi\u1ed1ng nh\u01b0 h\u00ecnh d\u01b0\u1edbi \u0111\u00e2y. Dashboard n\u00e0y ch\u1ee9a c\u00e1c panels v\u1ec1 data drift bao g\u1ed3m: General information Dataset drift : Dataset c\u00f3 b\u1ecb drift hay kh\u00f4ng Share of drifted features : T\u1ec9 l\u1ec7 s\u1ed1 features b\u1ecb drift tr\u00ean t\u1ed5ng s\u1ed1 features # of drifted features : S\u1ed1 features b\u1ecb drift # of features : T\u1ed5ng s\u1ed1 features Detailed information P-value of features : p-value c\u1ee7a c\u00e1c features","title":"Data Drift Dashboard"},{"location":"mlops-crash-course/monitoring/trien-khai-monitoring-service.html#model-performance-dashboard","text":"Dashboard Evidently Classification Performance Dashboard s\u1ebd gi\u1ed1ng nh\u01b0 h\u00ecnh d\u01b0\u1edbi \u0111\u00e2y. Dashboard n\u00e0y ch\u1ee9a c\u00e1c panels v\u1ec1 model performance bao g\u1ed3m: Reference dataset data Quality : T\u1ed5ng h\u1ee3p model performance metrics theo th\u1eddi gian accuracy , f1 , precision , recall : Model performance metrics Prediction class representation : S\u1ed1 l\u01b0\u1ee3ng c\u00e1c d\u1ef1 \u0111o\u00e1n theo class Target class representation : S\u1ed1 l\u01b0\u1ee3ng c\u00e1c label theo class Class 0 information : Th\u00f4ng tin v\u1ec1 class 0 Confusion 0 : Confusion matrix cho class 0 Confusion in time : Gi\u00e1 tr\u1ecb c\u1ee7a confusion matrix theo th\u1eddi gian Quality : T\u1ed5ng h\u1ee3p model performance metrics cho class 0 theo th\u1eddi gian Class 1 information : T\u01b0\u01a1ng t\u1ef1 class 0","title":"Model Performance Dashboard"},{"location":"mlops-crash-course/monitoring/trien-khai-monitoring-service.html#alerts","text":"Grafana Alerts cho ph\u00e9p k\u00edch ho\u1ea1t c\u1ea3nh b\u00e1o khi m\u1ed9t v\u1ea5n \u0111\u1ec1 v\u1ec1 metrics x\u1ea3y ra. Trong b\u00e0i n\u00e0y, ch\u00fang ta s\u1ebd t\u1ea1o m\u1ed9t c\u1ea3nh b\u00e1o \u0111\u01a1n gi\u1ea3n \u0111\u1ec3 c\u1ea3nh b\u00e1o khi dataset b\u1ecb drift. \u1ede sidebar b\u00ean ph\u1ea3i c\u1ee7a Grafana, click Dashabords . \u1ede trang Dashboard, t\u1ea1o Folder t\u00ean l\u00e0 Alerts . Folder n\u00e0y \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 l\u01b0u c\u1ea3nh b\u00e1o ch\u00fang ta s\u1ebd t\u1ea1o \u1ede sidebar b\u00ean ph\u1ea3i c\u1ee7a Grafana, b\u1ea1n click v\u00e0o Alerting . \u1ede trang Alerting , tab Alert rules , click n\u00fat New alert rule . Trong trang t\u1ea1o c\u1ea3nh b\u00e1o, t\u1ea1o c\u1ea3nh b\u00e1o m\u1edbi t\u00ean l\u00e0 Data drift detection , \u0111i\u1ec1n c\u00e1c th\u00f4ng tin trong ph\u1ea7n 1. Set a query and alert condition nh\u01b0 \u1ea3nh d\u01b0\u1edbi, v\u1edbi query A l\u00e0: 1 evidently : data_drift : dataset_drift { dataset_name = \" drivers \"} Ph\u1ea7n 2. Alert evaluation behavior v\u00e0 3. Add details for your alert Click Save and exit Info \u0110\u1ec3 c\u1ea5u h\u00ecnh c\u00e1ch m\u00e0 Alert \u0111\u01b0\u1ee3c g\u1eedi \u0111i, b\u1ea1n v\u00e0o tab Notification polices v\u00e0 th\u00eam policy m\u1edbi. Trong b\u00e0i n\u00e0y, \u0111\u1ec3 \u0111\u01a1n gi\u1ea3n h\u01a1n ch\u00fang ta s\u1ebd gi\u1eef nguy\u00ean policy m\u1eb7c \u0111\u1ecbnh c\u1ee7a Grafana.","title":"Alerts"},{"location":"mlops-crash-course/monitoring/trien-khai-monitoring-service.html#thu-nghiem","text":"","title":"Th\u1eed nghi\u1ec7m"},{"location":"mlops-crash-course/monitoring/trien-khai-monitoring-service.html#data-bi-drift","text":"Sau khi thi\u1ebft l\u1eadp xong dashboards, ch\u00fang ta s\u1ebd vi\u1ebft code \u0111\u1ec3 g\u1eedi request gi\u1ea3 t\u1edbi Online serving API. Code \u0111\u1ec3 g\u1eedi requests \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u1ea1i monitoring_service/src/mock_request.py . monitoring_service/src/mock_request.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def construct_request ( row : pd . Series ) -> dict : # (1) request_id = row [ \"request_id\" ] driver_ids = ast . literal_eval ( row [ \"driver_ids\" ]) return { \"request_id\" : request_id , \"driver_ids\" : driver_ids , } def send_request ( request : dict ) -> None : # (2) try : data = json . dumps ( request ) response = requests . post ( ONLINE_SERVING_API , data = data , headers = { \"content-type\" : \"application/json\" }, ) ... except Exception as error : ... def main ( data_type : str , n_request : int = 1 ): # (3) data_path = AppPath . NORMAL_DATA if data_type == DataType . DRIFT : data_path = AppPath . DRIFT_DATA data_source = pd . read_parquet ( data_path , engine = \"fastparquet\" ) # (4) request_data = pd . read_csv ( AppPath . REQUEST_DATA ) # (5) ... data_source . to_parquet ( AppPath . FEAST_DATA_SOURCE , engine = \"fastparquet\" ) # (6) result = subprocess . run ([ \"make\" , \"feast_teardown\" ]) # (7) ... result = subprocess . run ([ \"make\" , \"feast_apply\" ]) # (8) ... result = subprocess . run ([ \"make\" , \"feast_materialize\" ]) # (9) ... total_request = request_data . shape [ 0 ] for idx in range ( n_request ): row = request_data . iloc [ idx % total_request ] request = construct_request ( row ) send_request ( request ) # (10) ... H\u00e0m construct_request t\u1ea1o payload d\u1ea1ng JSON \u0111\u1ec3 g\u1eedi t\u1edbi Online serving API H\u00e0m send_request g\u1eedi payload tr\u00ean t\u1edbi Online serving API H\u00e0m main th\u1ef1c hi\u1ec7n qu\u00e1 tr\u00ecnh g\u1eedi data \u0110\u1ecdc dataset ch\u1ee9a c\u00e1c features tu\u1ef3 thu\u1ed9c v\u00e0o lo\u1ea1i data l\u00e0 normal_data hay drift_data \u0110\u1ecdc request_data Ghi \u0111\u00e8 dataset ch\u1ee9a c\u00e1c features v\u00e0o file data source c\u1ee7a Feast Xo\u00e1 data \u1edf c\u1ea3 Offline Feature Store v\u00e0 Online Feature Store Ghi data t\u1eeb file data source c\u1ee7a Feast v\u00e0o Offline Feature Store Ghi data t\u1eeb Offline Feature Store v\u00e0o Online Feature Store G\u1eedi l\u1ea7n l\u01b0\u1ee3t c\u00e1c request trong request_data t\u1edbi Online serving API \u0110\u1ec3 ti\u1ebfn h\u00e0nh th\u1eed nghi\u1ec7m, b\u1ea1n l\u00e0m theo c\u00e1c b\u01b0\u1edbc sau. \u0110\u1ea3m b\u1ea3o Online serving service \u0111\u00e3 ch\u1ea1y C\u1eadp nh\u1eadt Feature Store cd ../data_pipeline make deploy_feature_repo # (1) cd ../monitoring_service Tri\u1ec3n khai code c\u1ee7a Feature Store Build docker image v\u00e0 ch\u1ea1y docker compose cho monitoring service make build_image make compose_up Tip \u0110\u1ecbnh ngh\u0129a v\u1ec1 c\u00e1c env vars \u0111\u01b0\u1ee3c d\u00f9ng trong qu\u00e1 tr\u00ecnh build image \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i monitoring_service/deployment/.env . B\u1ea1n c\u00f3 th\u1ec3 thay \u0111\u1ed5i n\u1ebfu c\u1ea7n. G\u1eedi 5 requests gi\u1ea3 ch\u1ee9a drift_data python src/mock_request.py -d drift -n 5 \u0110\u1ee3i 30s, ki\u1ec3m tra Evidently Data Drift Dashboard v\u00e0 Evidently Classification Performance Dashboard , k\u1ebft qu\u1ea3 s\u1ebd gi\u1ed1ng nh\u01b0 sau. Evidently Data Drift Dashboard - Dataset drift Evidently Classification Performance Dashboard M\u1edf trang Grafana Alerting, b\u1ea1n s\u1ebd th\u1ea5y c\u1ea3nh b\u00e1o Data drift detection \u0111ang \u1edf tr\u1ea1ng th\u00e1i Firing Click n\u00fat Show state history \u0111\u1ec3 xem th\u1eddi \u0111i\u1ec3m c\u1ee7a c\u00e1c tr\u1ea1ng th\u00e1i trong c\u1ea3nh b\u00e1o n\u00e0y.","title":"Data b\u1ecb drift"},{"location":"mlops-crash-course/monitoring/trien-khai-monitoring-service.html#data-khong-bi-drift","text":"Ti\u1ebfp theo, ch\u00fang ta s\u1ebd test tr\u01b0\u1eddng h\u1ee3p data kh\u00f4ng b\u1ecb drift. B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau. G\u1eedi 5 requests gi\u1ea3 ch\u1ee9a normal_data t\u1edbi Online serving API python src/mock_request.py -d normal -n 5 Ki\u1ec3m tra Evidently Data Drift Dashboard , b\u1ea1n s\u1ebd th\u1ea5y th\u00f4ng tin Dataset kh\u00f4ng b\u1ecb drift s\u1ed1 features b\u1ecb drift l\u00e0 0. Ngo\u00e0i ra, c\u1ea3nh b\u00e1o Data drift detection c\u0169ng \u0111\u00e3 \u1edf tr\u1ea1ng th\u00e1i Normal Evidently Data Drift Dashboard - Dataset kh\u00f4ng drift Alert Data drift detection \u1edf tr\u1ea1ng th\u00e1i Normal Tip N\u1ebfu m\u1edf Kibana ra, b\u1ea1n c\u0169ng s\u1ebd th\u1ea5y logs c\u1ee7a Monitoring service \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng thu th\u1eadp nh\u1edd ch\u1ee9c n\u0103ng t\u1ef1 \u0111\u1ed9ng thu th\u1eadp logs t\u1eeb c\u00e1c containers c\u1ee7a Filebeat","title":"Data kh\u00f4ng b\u1ecb drift"},{"location":"mlops-crash-course/monitoring/trien-khai-monitoring-service.html#tong-ket","text":"Theo d\u00f5i v\u00e0 b\u1ea3o tr\u00ec lu\u00f4n l\u00e0 m\u1ed9t ph\u1ea7n quan tr\u1ecdng trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n m\u1ed9t h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m n\u00f3i chung, \u0111\u1eb7c bi\u1ec7t l\u00e0 trong m\u1ed9t h\u1ec7 th\u1ed1ng ML n\u00f3i ri\u00eang. Trong b\u00e0i Monitoring n\u00e0y, ch\u00fang ta \u0111\u00e3 bi\u1ebft v\u1ec1 c\u00e1c metrics \u0111i\u1ec3n h\u00ecnh c\u1ee7a h\u1ec7 th\u1ed1ng v\u1ec1 data v\u00e0 v\u1ec1 model m\u00e0 m\u1ed9t h\u1ec7 th\u1ed1ng ML th\u01b0\u1eddng theo d\u00f5i. Ch\u00fang ta c\u0169ng \u0111\u00e3 ph\u00e2n t\u00edch v\u00e0 thi\u1ebft k\u1ebf m\u1ed9t service kh\u00e1 ph\u1ee9c t\u1ea1p l\u00e0 Monitoring service. B\u1ea1n \u0111\u00e3 bi\u1ebft c\u00e1ch theo d\u00f5i c\u00e1c metrics c\u1ee7a data, model nh\u01b0 Ph\u00e1t hi\u1ec7n Data drift , Theo d\u00f5i model performance , tri\u1ec3n khai v\u00e0 thi\u1ebft l\u1eadp c\u1ea3nh b\u00e1o tr\u00ean Grafana. Trong th\u1ef1c t\u1ebf, b\u1ea1n c\u00f3 th\u1ec3 s\u1ebd c\u1ea7n d\u00f9ng Grafana alert \u0111\u1ec3 k\u00edch ho\u1ea1t m\u1ed9t t\u00e1c v\u1ee5 n\u00e0o \u0111\u00f3, v\u00ed d\u1ee5 nh\u01b0 k\u00edch ho\u1ea1t training pipeline t\u1ef1 \u0111\u1ed9ng khi ph\u00e1t hi\u1ec7n dataset b\u1ecb drift hay \u0111\u01a1n gi\u1ea3n l\u00e0 g\u1eedi email th\u00f4ng b\u00e1o v\u1ec1 model performance t\u1edbi Data Scientist, v.v. Trong b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd thi\u1ebft l\u1eadp v\u00e0 tri\u1ec3n khai CI/CD cho c\u00e1c ph\u1ea7n trong h\u1ec7 th\u1ed1ng ML. CI/CD gi\u00fap ch\u00fang ta t\u1ef1 \u0111\u1ed9ng test v\u00e0 t\u1ef1 \u0111\u1ed9ng tri\u1ec3n khai c\u00e1c Airflow DAGs, c\u0169ng nh\u01b0 l\u00e0 c\u00e1c services nh\u01b0 Online serving service hay Monitoring service, thay v\u00ec g\u00f5 c\u00e1c l\u1ec7nh th\u1ee7 c\u00f4ng trong terminal.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/monitoring/trien-khai-monitoring-service.html#tai-lieu-tham-khao","text":"Flask Grafana Alerting","title":"T\u00e0i li\u1ec7u tham kh\u1ea3o"},{"location":"mlops-crash-course/poc/xay-dung-poc.html","text":"Photo by Markus Winkler on Unsplash Gi\u1edbi thi\u1ec7u Trong b\u00e0i tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 th\u1ef1c hi\u1ec7n b\u01b0\u1edbc \u0111\u1ea7u ti\u00ean c\u1ee7a m\u1ed9t d\u1ef1 \u00e1n ph\u1ea7n m\u1ec1m, \u0111\u00f3 ch\u00ednh l\u00e0 thu th\u1eadp c\u00e1c y\u00eau c\u1ea7u, ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1 kinh doanh. Qu\u00e1 tr\u00ecnh n\u00e0y gi\u00fap hi\u1ec3u r\u00f5 v\u00e0 s\u00e2u h\u01a1n v\u1ec1 v\u1ea5n \u0111\u1ec1 \u0111ang g\u1eb7p ph\u1ea3i, v\u1ec1 nh\u1eefng gi\u1ea3i ph\u00e1p ti\u1ec1m n\u0103ng, \u0111\u1ed3ng th\u1eddi l\u00ean k\u1ebf ho\u1ea1ch \u0111\u1ec3 tri\u1ec3n khai ch\u00fang. Trong b\u00e0i n\u00e0y, ch\u00fang ta b\u1eaft tay v\u00e0o x\u00e2y d\u1ef1ng m\u1ed9t d\u1ef1 \u00e1n POC. D\u1ef1 \u00e1n POC th\u1eed nghi\u1ec7m c\u00e1c gi\u1ea3i ph\u00e1p nhanh ch\u00f3ng \u0111\u1ec3 ch\u1ee9ng minh \u0111\u01b0\u1ee3c t\u1ed3n t\u1ea1i \u00edt nh\u1ea5t m\u1ed9t gi\u1ea3i ph\u00e1p gi\u1ea3i quy\u1ebft \u0111\u01b0\u1ee3c v\u1ea5n \u0111\u1ec1 kinh doanh, tr\u01b0\u1edbc khi b\u1eaft tay v\u00e0o x\u00e2y d\u1ef1ng c\u00e1c t\u00ednh n\u0103ng ph\u1ee9c t\u1ea1p kh\u00e1c. V\u00ec ML \u0111\u01b0\u1ee3c ch\u1ecdn l\u00e0m gi\u1ea3i ph\u00e1p, n\u00ean vi\u1ec7c c\u1ea7n l\u00e0m \u0111\u00f3 l\u00e0 ch\u1ee9ng minh r\u1eb1ng gi\u1ea3i ph\u00e1p ML l\u00e0 kh\u1ea3 thi, b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng MLOps platform \u0111\u00e3 \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a \u1edf b\u00e0i MLOps Platform . M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n C\u00e1c th\u01b0 vi\u1ec7n b\u1ea1n c\u1ea7n c\u00e0i \u0111\u1eb7t cho m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u1ea1i training_pipeline/dev_requirements.txt . B\u1ea1n c\u00f3 th\u1ec3 d\u00f9ng virtualenv , conda , ho\u1eb7c b\u1ea5t k\u00ec c\u00f4ng c\u1ee5 n\u00e0o \u0111\u1ec3 c\u00e0i \u0111\u1eb7t. Phi\u00ean b\u1ea3n Python \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong c\u1ea3 kho\u00e1 h\u1ecdc l\u00e0 3.9 . C\u00e1c MLOps tools \u0111\u01b0\u1ee3c d\u00f9ng trong b\u00e0i n\u00e0y bao g\u1ed3m: Jupyter notebook: th\u1eed nghi\u1ec7m data, model MLflow: ML Metadata Store, Model Registry \u0110\u1ecbnh ngh\u0129a POC Trong qu\u00e1 tr\u00ecnh ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1 kinh doanh, th\u00f4ng tin v\u1ec1 data v\u00e0 qu\u00e1 tr\u00ecnh x\u00e2y d\u1ef1ng ML model \u0111\u00e3 \u0111\u01b0\u1ee3c t\u1ed5ng h\u1ee3p nh\u01b0 sau. # C\u00e2u h\u1ecfi Tr\u1ea3 l\u1eddi 1 Data \u0111\u01b0\u1ee3c l\u1ea5y t\u1eeb \u0111\u00e2u? \u0110\u01b0\u1ee3c t\u1ed5ng h\u1ee3p b\u1edfi Data Engineer t\u1eeb \u1ee9ng d\u1ee5ng c\u1ee7a c\u00f4ng ty 2 Data s\u1ebd \u0111\u01b0\u1ee3c bi\u1ebfn \u0111\u1ed5i v\u00e0 l\u01b0u tr\u1eef th\u1ebf n\u00e0o? \u0110\u01b0\u1ee3c Data Engineer x\u1eed l\u00fd \u0111\u1ec3 th\u1ef1c hi\u1ec7n POC tr\u01b0\u1edbc, format l\u00e0 parquet , t\u1ea1m th\u1eddi l\u01b0u \u1edf Database n\u1ed9i b\u1ed9 c\u00f4ng ty 3 Feature ti\u1ec1m n\u0103ng? conv_rate , acc_rate , avg_daily_trips 4 Model architecture ti\u1ec1m n\u0103ng? Elastic Net 5 D\u00f9ng metrics n\u00e0o \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 model? MSE, RMSE, R2 Khi \u0111\u1ecbnh ngh\u0129a d\u1ef1 \u00e1n POC, ch\u00fang ta c\u1ea7n tr\u1ea3 l\u1eddi m\u1ed9t c\u00e2u h\u1ecfi quan tr\u1ecdng: Th\u1ebf n\u00e0o l\u00e0 m\u1ed9t d\u1ef1 \u00e1n POC th\u00e0nh c\u00f4ng? \u1ede nh\u1eefng d\u1ef1 \u00e1n POC \u0111\u1ea7u ti\u00ean, ML model ch\u01b0a \u0111\u01b0\u1ee3c tri\u1ec3n khai ra production m\u00e0 ch\u1ec9 \u0111\u01b0\u1ee3c th\u1eed nghi\u1ec7m offline. Do \u0111\u00f3, ch\u00fang ta c\u1ea7n s\u1eed d\u1ee5ng c\u00e1c offline metrics \u0111\u1ec3 \u0111\u00e1nh gi\u00e1. C\u1ee5 th\u1ec3, c\u1ea7n \u0111\u1eb7t m\u1ed9t threshold cho c\u00e1c metrics n\u00e0y. V\u00ed d\u1ee5, s\u1eed d\u1ee5ng metric RMSE v\u1edbi m\u1ed9t h\u1ea1n m\u1ee9c (threshold) \u0111\u1ec3 \u0111\u1ecbnh ngh\u0129a d\u1ef1 \u00e1n POC th\u00e0nh c\u00f4ng l\u00e0 RMSE ph\u1ea3i nh\u1ecf h\u01a1n 0.5 . Ngo\u00e0i RMSE cho b\u00e0i to\u00e1n logistic regression ra, m\u1ed9t s\u1ed1 metric kh\u00e1c c\u0169ng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng nh\u01b0: S\u1eed d\u1ee5ng Accuracy, F1, AUC \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 model performance cho b\u00e0i to\u00e1n classification S\u1eed d\u1ee5ng th\u1eddi gian training v\u00e0 inference c\u1ee7a ML model \u0111\u1ec3 so s\u00e1nh chi ph\u00ed v\u00e0 l\u1ee3i \u00edch v.v. Thu th\u1eadp data \u1ede d\u1ef1 \u00e1n POC \u0111\u1ea7u ti\u00ean, do data pipeline ch\u01b0a \u0111\u01b0\u1ee3c ho\u00e0n thi\u1ec7n, n\u00ean data d\u00f9ng \u0111\u1ec3 th\u1eed nghi\u1ec7m \u0111\u01b0\u1ee3c Data Engineer thu th\u1eadp t\u1eeb data sources, r\u1ed3i chuy\u1ec3n giao data th\u00f4 n\u00e0y cho Data Scientist (DS). DS s\u1ebd th\u1ef1c hi\u1ec7n c\u00e1c c\u00f4ng vi\u1ec7c sau: Ph\u00e2n t\u00edch data \u0111\u1ec3 \u0111\u1ecbnh ngh\u0129a c\u00e1c c\u00e1ch bi\u1ebfn \u0111\u1ed5i cho data. C\u00e1c c\u00e1ch bi\u1ebfn \u0111\u1ed5i n\u00e0y \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 x\u00e2y d\u1ef1ng data pipeline Ph\u00e2n t\u00edch data, th\u1eed nghi\u1ec7m v\u00e0 \u0111\u1ecbnh ngh\u0129a c\u00e1c c\u00e1ch bi\u1ebfn \u0111\u1ed5i feature engineering cho data. C\u00e1c c\u00e1ch bi\u1ebfn \u0111\u1ed5i feature engineering n\u00e0y \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 x\u00e2y d\u1ef1ng data pipeline Th\u1eed nghi\u1ec7m c\u00e1c model architecture v\u00e0 hyperparameter. C\u00e1ch train model \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 x\u00e2y d\u1ef1ng training pipeline Ph\u00e2n t\u00edch data Trong ph\u1ea7n n\u00e0y, Jupyter Notebook \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 vi\u1ebft code ph\u00e2n t\u00edch data v\u00e0 training code. Gi\u1ea3 s\u1eed Data Engineering \u0111\u00e3 thu th\u1eadp data t\u1eeb data sources v\u00e0 chuy\u1ec3n giao cho ch\u00fang ta 2 file data: training_pipeline/nbs/data/exp_driver_stats.parquet : ch\u1ee9a data c\u1ee7a c\u00e1c t\u00e0i x\u1ebf, \u0111\u01b0\u1ee3c ghi l\u1ea1i \u1edf nhi\u1ec1u th\u1eddi \u0111i\u1ec3m training_pipeline/nbs/data/exp_driver_orders.csv : ch\u1ee9a th\u00f4ng tin v\u1ec1 cu\u1ed1c xe c\u00f3 ho\u00e0n th\u00e0nh hay kh\u00f4ng c\u1ee7a c\u00e1c t\u00e0i x\u1ebf \u1edf nhi\u1ec1u th\u1eddi \u0111i\u1ec3m Hai file n\u00e0y ch\u1ee9a c\u00e1c c\u1ed9t ch\u00ednh v\u1edbi \u00fd ngh\u0129a t\u01b0\u01a1ng \u1ee9ng nh\u01b0 sau: File C\u1ed9t \u00dd ngh\u0129a exp_driver_stats.parquet datetime Th\u1eddi gian record \u0111\u01b0\u1ee3c ghi l\u1ea1i driver_id ID c\u1ee7a t\u00e0i x\u1ebf conv_rate M\u1ed9t th\u00f4ng s\u1ed1 n\u00e0o \u0111\u00f3 acc_rate M\u1ed9t th\u00f4ng s\u1ed1 n\u00e0o \u0111\u00f3 avg_daily_trips M\u1ed9t th\u00f4ng s\u1ed1 n\u00e0o \u0111\u00f3 exp_driver_orders.csv event_timestamp Th\u1eddi gian record \u0111\u01b0\u1ee3c ghi l\u1ea1i driver_id ID c\u1ee7a t\u00e0i x\u1ebf trip_completed Cu\u1ed1c xe c\u00f3 ho\u00e0n th\u00e0nh kh\u00f4ng Source code \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u1ea1i training_pipeline/nbs/poc-training-code.ipynb . training_pipeline/nbs/poc-training-code.ipynb 1 2 3 4 5 6 7 8 9 10 DATA_DIR = Path ( \"./data\" ) # (1) DATA_PATH = DATA_DIR / \"exp_driver_stats.parquet\" LABEL_PATH = DATA_DIR / \"exp_driver_orders.csv\" df_orig = pd . read_parquet ( DATA_PATH , engine = 'fastparquet' ) # (2) label_orig = pd . read_csv ( LABEL_PATH , sep = \" \\t \" ) label_orig [ \"event_timestamp\" ] = pd . to_datetime ( label_orig [ \"event_timestamp\" ]) # (3) target_col = \"trip_completed\" # (4) \u0110\u01b0\u1eddng d\u1eabn t\u1edbi data files Load data \u0110\u1ecbnh d\u1ea1ng l\u1ea1i c\u1ed9t event_timestamp \u0110\u1ecbnh ngh\u0129a t\u00ean c\u1ee7a c\u1ed9t ch\u1ee9a label Ti\u1ebfp theo, Data Scientist s\u1ebd ph\u00e2n t\u00edch data \u0111\u1ec3 hi\u1ec3u data. Qu\u00e1 tr\u00ecnh n\u00e0y th\u01b0\u1eddng ki\u1ec3m tra nh\u1eefng th\u1ee9 sau. C\u00f3 feature n\u00e0o ch\u1ee9a null kh\u00f4ng? N\u00ean thay null b\u1eb1ng gi\u00e1 tr\u1ecb n\u00e0o? C\u00f3 feature n\u00e0o c\u00f3 data kh\u00f4ng th\u1ed1ng nh\u1ea5t kh\u00f4ng? V\u00ed d\u1ee5: kh\u00e1c \u0111\u01a1n v\u1ecb (km/h, m/s), v.v C\u00f3 feature hay label n\u00e0o b\u1ecb bias kh\u00f4ng? N\u1ebfu c\u00f3 th\u00ec do qu\u00e1 tr\u00ecnh sampling hay do data qu\u00e1 c\u0169? Gi\u1ea3i quy\u1ebft th\u1ebf n\u00e0o? C\u00e1c feature c\u00f3 t\u01b0\u01a1ng quan kh\u00f4ng? N\u1ebfu c\u00f3 th\u00ec c\u00f3 c\u1ea7n lo\u1ea1i b\u1ecf feature n\u00e0o kh\u00f4ng? Data c\u00f3 outlier n\u00e0o kh\u00f4ng? N\u1ebfu c\u00f3 th\u00ec c\u00f3 n\u00ean xo\u00e1 b\u1ecf kh\u00f4ng? v.v M\u1ed7i m\u1ed9t v\u1ea5n \u0111\u1ec1 v\u1ec1 data tr\u00ean s\u1ebd c\u00f3 m\u1ed9t ho\u1eb7c nhi\u1ec1u c\u00e1ch gi\u1ea3i quy\u1ebft. Tuy nhi\u00ean, ch\u00fang ta s\u1ebd kh\u00f4ng bi\u1ebft \u0111\u01b0\u1ee3c ngay c\u00e1c c\u00e1ch gi\u1ea3i quy\u1ebft c\u00f3 hi\u1ec7u qu\u1ea3 hay kh\u00f4ng. Do v\u1eady, qu\u00e1 tr\u00ecnh ki\u1ec3m tra v\u00e0 ph\u00e2n t\u00edch data n\u00e0y th\u01b0\u1eddng s\u1ebd \u0111i k\u00e8m v\u1edbi c\u00e1c th\u1eed nghi\u1ec7m \u0111\u00e1nh gi\u00e1 model. C\u00e1c metrics khi \u0111\u00e1nh gi\u00e1 model gi\u00fap \u0111\u00e1nh gi\u00e1 xem c\u00e1c gi\u1ea3i ph\u00e1p \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n tr\u00ean data c\u00f3 hi\u1ec7u qu\u1ea3 kh\u00f4ng. V\u00ec ti\u1ebfn tr\u00ecnh th\u01b0\u1eddng g\u1eb7p c\u1ee7a Machine Learning l\u00e0 th\u1eed nghi\u1ec7m v\u1edbi data, model n\u00ean b\u01b0\u1edbc ph\u00e2n t\u00edch data n\u00e0y v\u00e0 b\u01b0\u1edbc training model nh\u01b0 m\u1ed9t v\u00f2ng l\u1eb7p \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n l\u1eb7p l\u1ea1i nhi\u1ec1u l\u1ea7n. V\u00ec c\u00e1c file data c\u1ee7a ch\u00fang ta kh\u00f4ng c\u00f3 feature n\u00e0o ch\u1ee9a null v\u00e0 \u0111\u1ec3 t\u1eadp trung v\u00e0o MLOps, ch\u00fang ta s\u1ebd t\u1ed1i gi\u1ea3n ho\u00e1 b\u01b0\u1edbc ph\u00e2n t\u00edch data n\u00e0y v\u00e0 \u0111i v\u00e0o vi\u1ebft code train model. Chu\u1ea9n b\u1ecb data Photo by Luke Chesser on Unsplash \u0110\u1ea7u ti\u00ean, features \u0111\u01b0\u1ee3c t\u1ed5ng h\u1ee3p t\u1eeb DataFrame df_orig v\u1edbi labels t\u1eeb DataFrame label_orig . C\u1ee5 th\u1ec3, v\u1edbi m\u1ed7i record trong label_orig , ch\u00fang ta mu\u1ed1n l\u1ea5y ra record m\u1edbi nh\u1ea5t t\u01b0\u01a1ng \u1ee9ng trong df_orig v\u1edbi driver_id gi\u1ed1ng nhau. Record m\u1edbi nh\u1ea5t t\u01b0\u01a1ng \u1ee9ng ngh\u0129a l\u00e0 th\u1eddi gian \u1edf c\u1ed9t datetime trong df_orig s\u1ebd x\u1ea3y ra tr\u01b0\u1edbc v\u00e0 g\u1ea7n nh\u1ea5t v\u1edbi th\u1eddi gian \u1edf c\u1ed9t event_timestamp trong label_orig . V\u00ed d\u1ee5: df_orig ch\u1ee9a 2 records nh\u01b0 sau index datetime driver_id conv_rate acc_rate avg_daily_trips 1 2022-12-01 1001 0.1 0.1 100 2 2022-11-01 1001 0.2 0.2 200 3 2022-10-01 1001 0.3 0.3 300 4 2022-09-01 1001 0.4 0.4 400 label_orig ch\u1ee9a 2 records nh\u01b0 sau index event_timestamp driver_id trip_completed 1 2022-12-15 1001 1 2 2022-09-15 1001 0 Data m\u00e0 ch\u00fang ta mu\u1ed1n t\u1ed5ng h\u1ee3p g\u1ed3m 2 records nh\u01b0 sau index event_timestamp driver_id trip_completed conv_rate acc_rate avg_daily_trips 1 2022-12-15 1001 1 0.1 0.1 100 2 2022-09-15 1001 0 0.4 0.4 400 Gi\u1ea3i th\u00edch Features t\u1eeb index 1 \u1edf df_orig \u0111\u01b0\u1ee3c l\u1ea5y ra cho record index 1 \u1edf label_orig , v\u00ec feature \u0111\u00f3 l\u00e0 m\u1edbi nh\u1ea5t ( 2022-12-01 ) so v\u1edbi event_timestamp c\u1ee7a record \u1edf index 1 ( 2022-12-15 ) trong label_orig T\u01b0\u01a1ng t\u1ef1, features t\u1eeb index 4 \u1edf df_orig \u0111\u01b0\u1ee3c l\u1ea5y ra cho record index 2 \u1edf label_orig , v\u00ec feature \u0111\u00f3 l\u00e0 m\u1edbi nh\u1ea5t v\u00e0 x\u1ea3y ra tr\u01b0\u1edbc ( 2022-09-01 ) so v\u1edbi event_timestamp c\u1ee7a record \u1edf index 2 ( 2022-09-15 ) trong label_orig Code \u0111\u1ec3 t\u1ed5ng h\u1ee3p features v\u00e0 labels nh\u01b0 d\u01b0\u1edbi \u0111\u00e2y. training_pipeline/nbs/poc-training-code.ipynb 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 groups = df_orig . groupby ( 'driver_id' ) # (1) def proc_row ( row ): # (2) global data_df end_time = row [ 'event_timestamp' ] driver_id = row [ 'driver_id' ] grp_rows = groups . get_group ( driver_id ) # (3) grp_rows = grp_rows [ grp_rows [ 'datetime' ] <= end_time ] # (4) grp_rows = grp_rows . sort_values ( 'datetime' ) # (5) grp_rows = grp_rows . iloc [ - 1 ] # (6) grp_rows [ 'event_timestamp' ] = end_time # (7) grp_rows [ 'trip_completed' ] = row [ 'trip_completed' ] return grp_rows . squeeze ( axis = 0 ) # (8) data_df = label_orig . apply ( proc_row , axis = 1 ) data_df = data_df [ data_df . columns . \\ # (9) drop ( \"datetime\" ) . \\ drop ( \"driver_id\" ) . \\ drop ( \"created\" ) . \\ drop ( \"event_timestamp\" )] Nh\u00f3m features v\u00e0o c\u00e1c nh\u00f3m theo driver_id H\u00e0m x\u1eed l\u00fd m\u1ed7i h\u00e0ng trong label_orig L\u1ea5y ra c\u00e1c h\u00e0ng trong df_orig c\u1ee7a m\u1ed9t t\u00e0i x\u1ebf L\u1ea5y ra c\u00e1c h\u00e0ng trong df_orig c\u00f3 datetime <= event_timestamp c\u1ee7a h\u00e0ng hi\u1ec7n t\u1ea1i trong label_orig S\u1eafp x\u1ebfp c\u00e1c h\u00e0ng theo c\u1ed9t datetime L\u1ea5y ra h\u00e0ng \u1edf th\u1eddi gian m\u1edbi nh\u1ea5t Th\u00eam c\u00e1c c\u1ed9t c\u1ea7n thi\u1ebft v\u00e0o Bi\u1ebfn th\u00e0nh Series (m\u1ed9t h\u00e0ng) v\u00e0 return Lo\u1ea1i b\u1ecf c\u00e1c c\u1ed9t kh\u00f4ng c\u1ea7n thi\u1ebft Training code Sau khi t\u1ed5ng h\u1ee3p features v\u00e0 labels v\u00e0o data_df , DataFrame n\u00e0y \u0111\u01b0\u1ee3c chia th\u00e0nh training set v\u00e0 test set. C\u00e1c b\u01b0\u1edbc train model v\u00e0 \u0111\u00e1nh gi\u00e1 model \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n nh\u01b0 d\u01b0\u1edbi \u0111\u00e2y. training_pipeline/nbs/poc-training-code.ipynb 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 selected_ft = [ \"conv_rate\" , \"acc_rate\" , \"avg_daily_trips\" ] # (1) TARGET_COL = \"trip_completed\" TEST_SIZE = 0.2 train , test = train_test_split ( data_df , test_size = TEST_SIZE , random_state = random_seed ) # (2) train_x = train . drop ([ TARGET_COL ], axis = 1 )[ selected_ft ] test_x = test . drop ([ TARGET_COL ], axis = 1 )[ selected_ft ] train_y = train [[ TARGET_COL ]] test_y = test [[ TARGET_COL ]] ALPHA = 0.5 L1_RATIO = 0.1 model = ElasticNet ( alpha = ALPHA , l1_ratio = L1_RATIO , random_state = random_seed ) # (3) model . fit ( train_x , train_y ) predicted_qualities = model . predict ( test_x ) # (4) ( rmse , mae , r2 ) = eval_metrics ( test_y , predicted_qualities ) Ch\u1ecdn c\u00e1c features \u0111\u1ec3 train T\u1ea1o training set v\u00e0 test set Train model \u0110\u00e1nh gi\u00e1 model Ch\u00fang ta c\u1ea7n th\u1eed nghi\u1ec7m r\u1ea5t nhi\u1ec1u b\u1ed9 feature, nhi\u1ec1u model architecture v\u1edbi c\u00e1c b\u1ed9 hyperparameter kh\u00e1c nhau. \u0110\u1ec3 c\u00f3 th\u1ec3 t\u00e1i l\u1eadp k\u1ebft qu\u1ea3 training, c\u1ea7n ph\u1ea3i bi\u1ebft \u0111\u01b0\u1ee3c th\u1eed nghi\u1ec7m n\u00e0o d\u00f9ng b\u1ed9 feature n\u00e0o, model architecture, v\u1edbi c\u00e1c hyperparameter n\u00e0o. Trong kho\u00e1 h\u1ecdc n\u00e0y, ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng MLOps Platform \u0111\u00e3 \u0111\u01b0\u1ee3c gi\u1edbi thi\u1ec7u trong b\u00e0i MLOps Platform v\u00e0 c\u1ee5 th\u1ec3 l\u00e0 MLflow s\u1ebd \u0111\u00f3ng vai tr\u00f2 ch\u00ednh gi\u00fap ch\u00fang ta theo d\u00f5i c\u00e1c th\u00f4ng tin tr\u00ean hay ML metadata c\u1ee7a c\u00e1c l\u1ea7n th\u1eed nghi\u1ec7m. Theo d\u00f5i th\u1eed nghi\u1ec7m MLflow l\u00e0 m\u1ed9t open-source platform \u0111\u1ec3 qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi v\u00e0 c\u00e1c quy tr\u00ecnh trong m\u1ed9t h\u1ec7 th\u1ed1ng ML. M\u1ed9t trong nh\u1eefng ch\u1ee9c n\u0103ng c\u1ee7a MLflow m\u00e0 ch\u00fang ta s\u1eed d\u1ee5ng \u0111\u00f3 l\u00e0 ch\u1ee9c n\u0103ng theo d\u00f5i ML metadata. Code c\u1ee7a ph\u1ea7n n\u00e0y \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u1ea1i notebook training_pipeline/nbs/poc-integrate-mlflow.ipynb . Logic c\u1ee7a code gi\u1ed1ng nh\u01b0 notebook training_pipeline/nbs/poc-training-code.ipynb , ch\u1ec9 c\u00f3 th\u00eam \u0111o\u1ea1n code \u0111\u1ec3 t\u00edch h\u1ee3p MLflow v\u00e0o. B\u1ea1n h\u00e3y l\u00e0m theo c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 t\u00edch h\u1ee3p MLflow. Clone github repo mlops-crash-course-platform , ch\u1ea1y MLflow server tr\u00ean m\u00f4i tr\u01b0\u1eddng local bash run.sh mlflow up \u0110i t\u1edbi URL http://localhost:5000 \u0111\u1ec3 ki\u1ec3m tra xem MLflow server \u0111\u00e3 \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o th\u00e0nh c\u00f4ng ch\u01b0a Trong notebook training_pipeline/nbs/poc-integrate-mlflow.ipynb , c\u00e1c b\u1ea1n \u0111\u1ec3 \u00fd \u0111o\u1ea1n code sau \u0111\u01b0\u1ee3c th\u00eam v\u00e0o \u1edf \u0111o\u1ea1n code training \u0111\u1ec3 t\u00edch h\u1ee3p MLflow v\u00e0o \u0111o\u1ea1n code training training_pipeline/nbs/poc-integrate-mlflow.ipynb 1 2 3 MLFLOW_TRACKING_URI = \"http://localhost:5000\" mlflow . set_tracking_uri ( MLFLOW_TRACKING_URI ) mlflow . sklearn . autolog () # (1) V\u00ec sklearn \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 train model, d\u00f2ng n\u00e0y t\u1ef1 \u0111\u1ed9ng qu\u00e1 tr\u00ecnh log l\u1ea1i c\u00e1c hyperparameter v\u00e0 c\u00e1c metrics trong qu\u00e1 tr\u00ecnh training. Xem th\u00eam \u1edf \u0111\u00e2y \u0111\u1ec3 bi\u1ebft th\u00eam th\u00f4ng tin v\u1ec1 c\u00e1c training framework \u0111\u01b0\u1ee3c MLflow h\u1ed7 tr\u1ee3 t\u1ef1 \u0111\u1ed9ng log ML metadata. \u0110o\u1ea1n code sau \u0111\u1ec3 log l\u1ea1i c\u00e1c hyperparameter v\u00e0 metric training_pipeline/nbs/poc-integrate-mlflow.ipynb 1 2 3 4 5 6 7 8 9 10 11 12 mlflow . set_tag ( \"mlflow.runName\" , uuid . uuid1 ()) # (1) mlflow . log_param ( \"features\" , selected_ft ) # (2) mlflow . log_param ( \"alpha\" , ALPHA ) # (3) mlflow . log_param ( \"l1_ratio\" , L1_RATIO ) mlflow . log_metric ( \"testing_rmse\" , rmse ) # (4) mlflow . log_metric ( \"testing_r2\" , r2 ) mlflow . log_metric ( \"testing_mae\" , mae ) mlflow . sklearn . log_model ( model , \"model\" ) # (5) \u0110\u1eb7t t\u00ean cho l\u1ea7n ch\u1ea1y Log l\u1ea1i feature \u0111\u01b0\u1ee3c d\u00f9ng Log l\u1ea1i hyperparameter Log l\u1ea1i metric sau khi test tr\u00ean test set Log l\u1ea1i model M\u1edf MLflow tr\u00ean browser, b\u1ea1n s\u1ebd th\u1ea5y giao di\u1ec7n nh\u01b0 sau. M\u1ecdi th\u00f4ng tin ch\u00fang ta log l\u1ea1i m\u1ed7i l\u1ea7n th\u1eed nghi\u1ec7m \u0111\u00e3 \u0111\u01b0\u1ee3c l\u01b0u l\u1ea1i. B\u1ea1n c\u00f3 th\u1ec3 xem th\u00eam th\u00f4ng tin chi ti\u1ebft v\u1ec1 m\u1ed9t l\u1ea7n ch\u1ea1y b\u1eb1ng c\u00e1ch \u1ea5n v\u00e0o c\u1ed9t Start time c\u1ee7a l\u1ea7n ch\u1ea1y \u0111\u00f3. Theo d\u00f5i features Trong ph\u1ea7n tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 coi b\u1ed9 feature m\u00e0 ch\u00fang ta s\u1eed d\u1ee5ng trong qu\u00e1 tr\u00ecnh training nh\u01b0 m\u1ed9t hyperparameter v\u00e0 d\u00f9ng MLflow \u0111\u1ec3 log l\u1ea1i. Tuy nhi\u00ean, \u0111\u00e2y ch\u01b0a ph\u1ea3i gi\u1ea3i ph\u00e1p t\u1ed1i \u01b0u \u0111\u1ec3 theo d\u00f5i c\u00e1c feature trong qu\u00e1 tr\u00ecnh th\u1eed nghi\u1ec7m. M\u1ee5c \u0111\u00edch c\u1ee7a vi\u1ec7c theo d\u00f5i c\u00e1c feature l\u00e0 \u0111\u1ec3 c\u00f3 th\u1ec3 t\u00e1i l\u1eadp k\u1ebft qu\u1ea3 c\u1ee7a m\u1ed9t th\u1eed nghi\u1ec7m. Ch\u1ec9 b\u1eb1ng vi\u1ec7c l\u01b0u l\u1ea1i t\u00ean c\u00e1c feature \u0111\u01b0\u1ee3c d\u00f9ng th\u00ec kh\u00f4ng \u0111\u1ea3m b\u1ea3o \u0111\u01b0\u1ee3c s\u1ebd t\u1ea1o l\u1ea1i \u0111\u01b0\u1ee3c k\u1ebft qu\u1ea3, v\u00ec c\u00f3 th\u1ec3 feature b\u1ecb \u0111\u1ed5i t\u00ean ho\u1eb7c t\u00ean v\u1eabn gi\u1eef nguy\u00ean nh\u01b0ng c\u00e1ch bi\u1ebfn \u0111\u1ed5i \u0111\u1ec3 sinh ra feature \u0111\u00f3 b\u1ecb thay \u0111\u1ed5i. Do \u0111\u00f3, vi\u1ec7c theo d\u00f5i c\u00e1c feature n\u00e0y kh\u00f4ng ch\u1ec9 l\u00e0 theo d\u00f5i t\u00ean c\u1ee7a c\u00e1c feature, m\u00e0 c\u1ea3 quy tr\u00ecnh sinh ra c\u00e1c feature \u0111\u00f3. \u1ede giai \u0111o\u1ea1n POC, v\u00ec ch\u01b0a c\u00f3 \u0111\u1ee7 ngu\u1ed3n l\u1ef1c \u0111\u1ec3 x\u00e2y d\u1ef1ng c\u01a1 s\u1edf h\u1ea1 t\u1ea7ng \u0111\u1ee7 m\u1ea1nh \u0111\u1ec3 h\u1ed7 tr\u1ee3 vi\u1ec7c theo d\u00f5i quy tr\u00ecnh t\u1ea1o ra feature, n\u00ean ch\u00fang ta ch\u1ec9 k\u00ec v\u1ecdng s\u1ebd theo d\u00f5i \u0111\u01b0\u1ee3c t\u00ean c\u00e1c feature l\u00e0 \u0111\u1ee7. Trong c\u00e1c b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd h\u1ecdc c\u00e1ch theo d\u00f5i version c\u1ee7a quy tr\u00ecnh bi\u1ebfn \u0111\u1ed5i feature v\u00e0 t\u00edch h\u1ee3p version \u0111\u00f3 v\u00e0o qu\u00e1 tr\u00ecnh training. T\u1ed5ng k\u1ebft Qua nhi\u1ec1u l\u1ea7n th\u1eed nghi\u1ec7m data v\u00e0 model, ngo\u00e0i vi\u1ec7c ch\u1ee9ng minh gi\u1ea3i ph\u00e1p ML l\u00e0 kh\u1ea3 thi, ch\u00fang ta s\u1ebd hi\u1ec3u r\u00f5 h\u01a1n v\u1ec1 v\u1ea5n \u0111\u1ec1 kinh doanh, gi\u1ea3i ph\u00e1p ti\u1ec1m n\u0103ng, c\u00e1ch \u0111\u00e1nh gi\u00e1 c\u00e1c gi\u1ea3i ph\u00e1p \u0111\u00f3 m\u1ed9t c\u00e1ch hi\u1ec7u qu\u1ea3. C\u00e1c \u0111\u1ea7u ra n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 c\u1eadp nh\u1eadt l\u1ea1i c\u00e1c \u0111\u1ecbnh ngh\u0129a c\u1ee7a v\u1ea5n \u0111\u1ec1 kinh doanh, c\u00e1c c\u00e1ch bi\u1ebfn \u0111\u1ed5i data \u0111\u1ec3 x\u00e2y d\u1ef1ng data pipeline, training code \u0111\u1ec3 x\u00e2y d\u1ef1ng training pipeline v\u00e0 serving code \u0111\u1ec3 x\u00e2y d\u1ef1ng model serving component. Trong b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd x\u00e2y d\u1ef1ng data pipeline, m\u1ed9t trong nh\u1eefng pipeline ph\u1ee9c t\u1ea1p nh\u1ea5t c\u1ee7a h\u1ec7 th\u1ed1ng. T\u00e0i li\u1ec7u tham kh\u1ea3o MLflow tracking MLflow Model registry","title":"POC"},{"location":"mlops-crash-course/poc/xay-dung-poc.html#gioi-thieu","text":"Trong b\u00e0i tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 th\u1ef1c hi\u1ec7n b\u01b0\u1edbc \u0111\u1ea7u ti\u00ean c\u1ee7a m\u1ed9t d\u1ef1 \u00e1n ph\u1ea7n m\u1ec1m, \u0111\u00f3 ch\u00ednh l\u00e0 thu th\u1eadp c\u00e1c y\u00eau c\u1ea7u, ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1 kinh doanh. Qu\u00e1 tr\u00ecnh n\u00e0y gi\u00fap hi\u1ec3u r\u00f5 v\u00e0 s\u00e2u h\u01a1n v\u1ec1 v\u1ea5n \u0111\u1ec1 \u0111ang g\u1eb7p ph\u1ea3i, v\u1ec1 nh\u1eefng gi\u1ea3i ph\u00e1p ti\u1ec1m n\u0103ng, \u0111\u1ed3ng th\u1eddi l\u00ean k\u1ebf ho\u1ea1ch \u0111\u1ec3 tri\u1ec3n khai ch\u00fang. Trong b\u00e0i n\u00e0y, ch\u00fang ta b\u1eaft tay v\u00e0o x\u00e2y d\u1ef1ng m\u1ed9t d\u1ef1 \u00e1n POC. D\u1ef1 \u00e1n POC th\u1eed nghi\u1ec7m c\u00e1c gi\u1ea3i ph\u00e1p nhanh ch\u00f3ng \u0111\u1ec3 ch\u1ee9ng minh \u0111\u01b0\u1ee3c t\u1ed3n t\u1ea1i \u00edt nh\u1ea5t m\u1ed9t gi\u1ea3i ph\u00e1p gi\u1ea3i quy\u1ebft \u0111\u01b0\u1ee3c v\u1ea5n \u0111\u1ec1 kinh doanh, tr\u01b0\u1edbc khi b\u1eaft tay v\u00e0o x\u00e2y d\u1ef1ng c\u00e1c t\u00ednh n\u0103ng ph\u1ee9c t\u1ea1p kh\u00e1c. V\u00ec ML \u0111\u01b0\u1ee3c ch\u1ecdn l\u00e0m gi\u1ea3i ph\u00e1p, n\u00ean vi\u1ec7c c\u1ea7n l\u00e0m \u0111\u00f3 l\u00e0 ch\u1ee9ng minh r\u1eb1ng gi\u1ea3i ph\u00e1p ML l\u00e0 kh\u1ea3 thi, b\u1eb1ng c\u00e1ch s\u1eed d\u1ee5ng MLOps platform \u0111\u00e3 \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a \u1edf b\u00e0i MLOps Platform .","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/poc/xay-dung-poc.html#moi-truong-phat-trien","text":"C\u00e1c th\u01b0 vi\u1ec7n b\u1ea1n c\u1ea7n c\u00e0i \u0111\u1eb7t cho m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u1ea1i training_pipeline/dev_requirements.txt . B\u1ea1n c\u00f3 th\u1ec3 d\u00f9ng virtualenv , conda , ho\u1eb7c b\u1ea5t k\u00ec c\u00f4ng c\u1ee5 n\u00e0o \u0111\u1ec3 c\u00e0i \u0111\u1eb7t. Phi\u00ean b\u1ea3n Python \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong c\u1ea3 kho\u00e1 h\u1ecdc l\u00e0 3.9 . C\u00e1c MLOps tools \u0111\u01b0\u1ee3c d\u00f9ng trong b\u00e0i n\u00e0y bao g\u1ed3m: Jupyter notebook: th\u1eed nghi\u1ec7m data, model MLflow: ML Metadata Store, Model Registry","title":"M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n"},{"location":"mlops-crash-course/poc/xay-dung-poc.html#inh-nghia-poc","text":"Trong qu\u00e1 tr\u00ecnh ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1 kinh doanh, th\u00f4ng tin v\u1ec1 data v\u00e0 qu\u00e1 tr\u00ecnh x\u00e2y d\u1ef1ng ML model \u0111\u00e3 \u0111\u01b0\u1ee3c t\u1ed5ng h\u1ee3p nh\u01b0 sau. # C\u00e2u h\u1ecfi Tr\u1ea3 l\u1eddi 1 Data \u0111\u01b0\u1ee3c l\u1ea5y t\u1eeb \u0111\u00e2u? \u0110\u01b0\u1ee3c t\u1ed5ng h\u1ee3p b\u1edfi Data Engineer t\u1eeb \u1ee9ng d\u1ee5ng c\u1ee7a c\u00f4ng ty 2 Data s\u1ebd \u0111\u01b0\u1ee3c bi\u1ebfn \u0111\u1ed5i v\u00e0 l\u01b0u tr\u1eef th\u1ebf n\u00e0o? \u0110\u01b0\u1ee3c Data Engineer x\u1eed l\u00fd \u0111\u1ec3 th\u1ef1c hi\u1ec7n POC tr\u01b0\u1edbc, format l\u00e0 parquet , t\u1ea1m th\u1eddi l\u01b0u \u1edf Database n\u1ed9i b\u1ed9 c\u00f4ng ty 3 Feature ti\u1ec1m n\u0103ng? conv_rate , acc_rate , avg_daily_trips 4 Model architecture ti\u1ec1m n\u0103ng? Elastic Net 5 D\u00f9ng metrics n\u00e0o \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 model? MSE, RMSE, R2 Khi \u0111\u1ecbnh ngh\u0129a d\u1ef1 \u00e1n POC, ch\u00fang ta c\u1ea7n tr\u1ea3 l\u1eddi m\u1ed9t c\u00e2u h\u1ecfi quan tr\u1ecdng: Th\u1ebf n\u00e0o l\u00e0 m\u1ed9t d\u1ef1 \u00e1n POC th\u00e0nh c\u00f4ng? \u1ede nh\u1eefng d\u1ef1 \u00e1n POC \u0111\u1ea7u ti\u00ean, ML model ch\u01b0a \u0111\u01b0\u1ee3c tri\u1ec3n khai ra production m\u00e0 ch\u1ec9 \u0111\u01b0\u1ee3c th\u1eed nghi\u1ec7m offline. Do \u0111\u00f3, ch\u00fang ta c\u1ea7n s\u1eed d\u1ee5ng c\u00e1c offline metrics \u0111\u1ec3 \u0111\u00e1nh gi\u00e1. C\u1ee5 th\u1ec3, c\u1ea7n \u0111\u1eb7t m\u1ed9t threshold cho c\u00e1c metrics n\u00e0y. V\u00ed d\u1ee5, s\u1eed d\u1ee5ng metric RMSE v\u1edbi m\u1ed9t h\u1ea1n m\u1ee9c (threshold) \u0111\u1ec3 \u0111\u1ecbnh ngh\u0129a d\u1ef1 \u00e1n POC th\u00e0nh c\u00f4ng l\u00e0 RMSE ph\u1ea3i nh\u1ecf h\u01a1n 0.5 . Ngo\u00e0i RMSE cho b\u00e0i to\u00e1n logistic regression ra, m\u1ed9t s\u1ed1 metric kh\u00e1c c\u0169ng \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng nh\u01b0: S\u1eed d\u1ee5ng Accuracy, F1, AUC \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 model performance cho b\u00e0i to\u00e1n classification S\u1eed d\u1ee5ng th\u1eddi gian training v\u00e0 inference c\u1ee7a ML model \u0111\u1ec3 so s\u00e1nh chi ph\u00ed v\u00e0 l\u1ee3i \u00edch v.v.","title":"\u0110\u1ecbnh ngh\u0129a POC"},{"location":"mlops-crash-course/poc/xay-dung-poc.html#thu-thap-data","text":"\u1ede d\u1ef1 \u00e1n POC \u0111\u1ea7u ti\u00ean, do data pipeline ch\u01b0a \u0111\u01b0\u1ee3c ho\u00e0n thi\u1ec7n, n\u00ean data d\u00f9ng \u0111\u1ec3 th\u1eed nghi\u1ec7m \u0111\u01b0\u1ee3c Data Engineer thu th\u1eadp t\u1eeb data sources, r\u1ed3i chuy\u1ec3n giao data th\u00f4 n\u00e0y cho Data Scientist (DS). DS s\u1ebd th\u1ef1c hi\u1ec7n c\u00e1c c\u00f4ng vi\u1ec7c sau: Ph\u00e2n t\u00edch data \u0111\u1ec3 \u0111\u1ecbnh ngh\u0129a c\u00e1c c\u00e1ch bi\u1ebfn \u0111\u1ed5i cho data. C\u00e1c c\u00e1ch bi\u1ebfn \u0111\u1ed5i n\u00e0y \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 x\u00e2y d\u1ef1ng data pipeline Ph\u00e2n t\u00edch data, th\u1eed nghi\u1ec7m v\u00e0 \u0111\u1ecbnh ngh\u0129a c\u00e1c c\u00e1ch bi\u1ebfn \u0111\u1ed5i feature engineering cho data. C\u00e1c c\u00e1ch bi\u1ebfn \u0111\u1ed5i feature engineering n\u00e0y \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 x\u00e2y d\u1ef1ng data pipeline Th\u1eed nghi\u1ec7m c\u00e1c model architecture v\u00e0 hyperparameter. C\u00e1ch train model \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 x\u00e2y d\u1ef1ng training pipeline","title":"Thu th\u1eadp data"},{"location":"mlops-crash-course/poc/xay-dung-poc.html#phan-tich-data","text":"Trong ph\u1ea7n n\u00e0y, Jupyter Notebook \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 vi\u1ebft code ph\u00e2n t\u00edch data v\u00e0 training code. Gi\u1ea3 s\u1eed Data Engineering \u0111\u00e3 thu th\u1eadp data t\u1eeb data sources v\u00e0 chuy\u1ec3n giao cho ch\u00fang ta 2 file data: training_pipeline/nbs/data/exp_driver_stats.parquet : ch\u1ee9a data c\u1ee7a c\u00e1c t\u00e0i x\u1ebf, \u0111\u01b0\u1ee3c ghi l\u1ea1i \u1edf nhi\u1ec1u th\u1eddi \u0111i\u1ec3m training_pipeline/nbs/data/exp_driver_orders.csv : ch\u1ee9a th\u00f4ng tin v\u1ec1 cu\u1ed1c xe c\u00f3 ho\u00e0n th\u00e0nh hay kh\u00f4ng c\u1ee7a c\u00e1c t\u00e0i x\u1ebf \u1edf nhi\u1ec1u th\u1eddi \u0111i\u1ec3m Hai file n\u00e0y ch\u1ee9a c\u00e1c c\u1ed9t ch\u00ednh v\u1edbi \u00fd ngh\u0129a t\u01b0\u01a1ng \u1ee9ng nh\u01b0 sau: File C\u1ed9t \u00dd ngh\u0129a exp_driver_stats.parquet datetime Th\u1eddi gian record \u0111\u01b0\u1ee3c ghi l\u1ea1i driver_id ID c\u1ee7a t\u00e0i x\u1ebf conv_rate M\u1ed9t th\u00f4ng s\u1ed1 n\u00e0o \u0111\u00f3 acc_rate M\u1ed9t th\u00f4ng s\u1ed1 n\u00e0o \u0111\u00f3 avg_daily_trips M\u1ed9t th\u00f4ng s\u1ed1 n\u00e0o \u0111\u00f3 exp_driver_orders.csv event_timestamp Th\u1eddi gian record \u0111\u01b0\u1ee3c ghi l\u1ea1i driver_id ID c\u1ee7a t\u00e0i x\u1ebf trip_completed Cu\u1ed1c xe c\u00f3 ho\u00e0n th\u00e0nh kh\u00f4ng Source code \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u1ea1i training_pipeline/nbs/poc-training-code.ipynb . training_pipeline/nbs/poc-training-code.ipynb 1 2 3 4 5 6 7 8 9 10 DATA_DIR = Path ( \"./data\" ) # (1) DATA_PATH = DATA_DIR / \"exp_driver_stats.parquet\" LABEL_PATH = DATA_DIR / \"exp_driver_orders.csv\" df_orig = pd . read_parquet ( DATA_PATH , engine = 'fastparquet' ) # (2) label_orig = pd . read_csv ( LABEL_PATH , sep = \" \\t \" ) label_orig [ \"event_timestamp\" ] = pd . to_datetime ( label_orig [ \"event_timestamp\" ]) # (3) target_col = \"trip_completed\" # (4) \u0110\u01b0\u1eddng d\u1eabn t\u1edbi data files Load data \u0110\u1ecbnh d\u1ea1ng l\u1ea1i c\u1ed9t event_timestamp \u0110\u1ecbnh ngh\u0129a t\u00ean c\u1ee7a c\u1ed9t ch\u1ee9a label Ti\u1ebfp theo, Data Scientist s\u1ebd ph\u00e2n t\u00edch data \u0111\u1ec3 hi\u1ec3u data. Qu\u00e1 tr\u00ecnh n\u00e0y th\u01b0\u1eddng ki\u1ec3m tra nh\u1eefng th\u1ee9 sau. C\u00f3 feature n\u00e0o ch\u1ee9a null kh\u00f4ng? N\u00ean thay null b\u1eb1ng gi\u00e1 tr\u1ecb n\u00e0o? C\u00f3 feature n\u00e0o c\u00f3 data kh\u00f4ng th\u1ed1ng nh\u1ea5t kh\u00f4ng? V\u00ed d\u1ee5: kh\u00e1c \u0111\u01a1n v\u1ecb (km/h, m/s), v.v C\u00f3 feature hay label n\u00e0o b\u1ecb bias kh\u00f4ng? N\u1ebfu c\u00f3 th\u00ec do qu\u00e1 tr\u00ecnh sampling hay do data qu\u00e1 c\u0169? Gi\u1ea3i quy\u1ebft th\u1ebf n\u00e0o? C\u00e1c feature c\u00f3 t\u01b0\u01a1ng quan kh\u00f4ng? N\u1ebfu c\u00f3 th\u00ec c\u00f3 c\u1ea7n lo\u1ea1i b\u1ecf feature n\u00e0o kh\u00f4ng? Data c\u00f3 outlier n\u00e0o kh\u00f4ng? N\u1ebfu c\u00f3 th\u00ec c\u00f3 n\u00ean xo\u00e1 b\u1ecf kh\u00f4ng? v.v M\u1ed7i m\u1ed9t v\u1ea5n \u0111\u1ec1 v\u1ec1 data tr\u00ean s\u1ebd c\u00f3 m\u1ed9t ho\u1eb7c nhi\u1ec1u c\u00e1ch gi\u1ea3i quy\u1ebft. Tuy nhi\u00ean, ch\u00fang ta s\u1ebd kh\u00f4ng bi\u1ebft \u0111\u01b0\u1ee3c ngay c\u00e1c c\u00e1ch gi\u1ea3i quy\u1ebft c\u00f3 hi\u1ec7u qu\u1ea3 hay kh\u00f4ng. Do v\u1eady, qu\u00e1 tr\u00ecnh ki\u1ec3m tra v\u00e0 ph\u00e2n t\u00edch data n\u00e0y th\u01b0\u1eddng s\u1ebd \u0111i k\u00e8m v\u1edbi c\u00e1c th\u1eed nghi\u1ec7m \u0111\u00e1nh gi\u00e1 model. C\u00e1c metrics khi \u0111\u00e1nh gi\u00e1 model gi\u00fap \u0111\u00e1nh gi\u00e1 xem c\u00e1c gi\u1ea3i ph\u00e1p \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n tr\u00ean data c\u00f3 hi\u1ec7u qu\u1ea3 kh\u00f4ng. V\u00ec ti\u1ebfn tr\u00ecnh th\u01b0\u1eddng g\u1eb7p c\u1ee7a Machine Learning l\u00e0 th\u1eed nghi\u1ec7m v\u1edbi data, model n\u00ean b\u01b0\u1edbc ph\u00e2n t\u00edch data n\u00e0y v\u00e0 b\u01b0\u1edbc training model nh\u01b0 m\u1ed9t v\u00f2ng l\u1eb7p \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n l\u1eb7p l\u1ea1i nhi\u1ec1u l\u1ea7n. V\u00ec c\u00e1c file data c\u1ee7a ch\u00fang ta kh\u00f4ng c\u00f3 feature n\u00e0o ch\u1ee9a null v\u00e0 \u0111\u1ec3 t\u1eadp trung v\u00e0o MLOps, ch\u00fang ta s\u1ebd t\u1ed1i gi\u1ea3n ho\u00e1 b\u01b0\u1edbc ph\u00e2n t\u00edch data n\u00e0y v\u00e0 \u0111i v\u00e0o vi\u1ebft code train model.","title":"Ph\u00e2n t\u00edch data"},{"location":"mlops-crash-course/poc/xay-dung-poc.html#chuan-bi-data","text":"Photo by Luke Chesser on Unsplash \u0110\u1ea7u ti\u00ean, features \u0111\u01b0\u1ee3c t\u1ed5ng h\u1ee3p t\u1eeb DataFrame df_orig v\u1edbi labels t\u1eeb DataFrame label_orig . C\u1ee5 th\u1ec3, v\u1edbi m\u1ed7i record trong label_orig , ch\u00fang ta mu\u1ed1n l\u1ea5y ra record m\u1edbi nh\u1ea5t t\u01b0\u01a1ng \u1ee9ng trong df_orig v\u1edbi driver_id gi\u1ed1ng nhau. Record m\u1edbi nh\u1ea5t t\u01b0\u01a1ng \u1ee9ng ngh\u0129a l\u00e0 th\u1eddi gian \u1edf c\u1ed9t datetime trong df_orig s\u1ebd x\u1ea3y ra tr\u01b0\u1edbc v\u00e0 g\u1ea7n nh\u1ea5t v\u1edbi th\u1eddi gian \u1edf c\u1ed9t event_timestamp trong label_orig . V\u00ed d\u1ee5: df_orig ch\u1ee9a 2 records nh\u01b0 sau index datetime driver_id conv_rate acc_rate avg_daily_trips 1 2022-12-01 1001 0.1 0.1 100 2 2022-11-01 1001 0.2 0.2 200 3 2022-10-01 1001 0.3 0.3 300 4 2022-09-01 1001 0.4 0.4 400 label_orig ch\u1ee9a 2 records nh\u01b0 sau index event_timestamp driver_id trip_completed 1 2022-12-15 1001 1 2 2022-09-15 1001 0 Data m\u00e0 ch\u00fang ta mu\u1ed1n t\u1ed5ng h\u1ee3p g\u1ed3m 2 records nh\u01b0 sau index event_timestamp driver_id trip_completed conv_rate acc_rate avg_daily_trips 1 2022-12-15 1001 1 0.1 0.1 100 2 2022-09-15 1001 0 0.4 0.4 400 Gi\u1ea3i th\u00edch Features t\u1eeb index 1 \u1edf df_orig \u0111\u01b0\u1ee3c l\u1ea5y ra cho record index 1 \u1edf label_orig , v\u00ec feature \u0111\u00f3 l\u00e0 m\u1edbi nh\u1ea5t ( 2022-12-01 ) so v\u1edbi event_timestamp c\u1ee7a record \u1edf index 1 ( 2022-12-15 ) trong label_orig T\u01b0\u01a1ng t\u1ef1, features t\u1eeb index 4 \u1edf df_orig \u0111\u01b0\u1ee3c l\u1ea5y ra cho record index 2 \u1edf label_orig , v\u00ec feature \u0111\u00f3 l\u00e0 m\u1edbi nh\u1ea5t v\u00e0 x\u1ea3y ra tr\u01b0\u1edbc ( 2022-09-01 ) so v\u1edbi event_timestamp c\u1ee7a record \u1edf index 2 ( 2022-09-15 ) trong label_orig Code \u0111\u1ec3 t\u1ed5ng h\u1ee3p features v\u00e0 labels nh\u01b0 d\u01b0\u1edbi \u0111\u00e2y. training_pipeline/nbs/poc-training-code.ipynb 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 groups = df_orig . groupby ( 'driver_id' ) # (1) def proc_row ( row ): # (2) global data_df end_time = row [ 'event_timestamp' ] driver_id = row [ 'driver_id' ] grp_rows = groups . get_group ( driver_id ) # (3) grp_rows = grp_rows [ grp_rows [ 'datetime' ] <= end_time ] # (4) grp_rows = grp_rows . sort_values ( 'datetime' ) # (5) grp_rows = grp_rows . iloc [ - 1 ] # (6) grp_rows [ 'event_timestamp' ] = end_time # (7) grp_rows [ 'trip_completed' ] = row [ 'trip_completed' ] return grp_rows . squeeze ( axis = 0 ) # (8) data_df = label_orig . apply ( proc_row , axis = 1 ) data_df = data_df [ data_df . columns . \\ # (9) drop ( \"datetime\" ) . \\ drop ( \"driver_id\" ) . \\ drop ( \"created\" ) . \\ drop ( \"event_timestamp\" )] Nh\u00f3m features v\u00e0o c\u00e1c nh\u00f3m theo driver_id H\u00e0m x\u1eed l\u00fd m\u1ed7i h\u00e0ng trong label_orig L\u1ea5y ra c\u00e1c h\u00e0ng trong df_orig c\u1ee7a m\u1ed9t t\u00e0i x\u1ebf L\u1ea5y ra c\u00e1c h\u00e0ng trong df_orig c\u00f3 datetime <= event_timestamp c\u1ee7a h\u00e0ng hi\u1ec7n t\u1ea1i trong label_orig S\u1eafp x\u1ebfp c\u00e1c h\u00e0ng theo c\u1ed9t datetime L\u1ea5y ra h\u00e0ng \u1edf th\u1eddi gian m\u1edbi nh\u1ea5t Th\u00eam c\u00e1c c\u1ed9t c\u1ea7n thi\u1ebft v\u00e0o Bi\u1ebfn th\u00e0nh Series (m\u1ed9t h\u00e0ng) v\u00e0 return Lo\u1ea1i b\u1ecf c\u00e1c c\u1ed9t kh\u00f4ng c\u1ea7n thi\u1ebft","title":"Chu\u1ea9n b\u1ecb data"},{"location":"mlops-crash-course/poc/xay-dung-poc.html#training-code","text":"Sau khi t\u1ed5ng h\u1ee3p features v\u00e0 labels v\u00e0o data_df , DataFrame n\u00e0y \u0111\u01b0\u1ee3c chia th\u00e0nh training set v\u00e0 test set. C\u00e1c b\u01b0\u1edbc train model v\u00e0 \u0111\u00e1nh gi\u00e1 model \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n nh\u01b0 d\u01b0\u1edbi \u0111\u00e2y. training_pipeline/nbs/poc-training-code.ipynb 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 selected_ft = [ \"conv_rate\" , \"acc_rate\" , \"avg_daily_trips\" ] # (1) TARGET_COL = \"trip_completed\" TEST_SIZE = 0.2 train , test = train_test_split ( data_df , test_size = TEST_SIZE , random_state = random_seed ) # (2) train_x = train . drop ([ TARGET_COL ], axis = 1 )[ selected_ft ] test_x = test . drop ([ TARGET_COL ], axis = 1 )[ selected_ft ] train_y = train [[ TARGET_COL ]] test_y = test [[ TARGET_COL ]] ALPHA = 0.5 L1_RATIO = 0.1 model = ElasticNet ( alpha = ALPHA , l1_ratio = L1_RATIO , random_state = random_seed ) # (3) model . fit ( train_x , train_y ) predicted_qualities = model . predict ( test_x ) # (4) ( rmse , mae , r2 ) = eval_metrics ( test_y , predicted_qualities ) Ch\u1ecdn c\u00e1c features \u0111\u1ec3 train T\u1ea1o training set v\u00e0 test set Train model \u0110\u00e1nh gi\u00e1 model Ch\u00fang ta c\u1ea7n th\u1eed nghi\u1ec7m r\u1ea5t nhi\u1ec1u b\u1ed9 feature, nhi\u1ec1u model architecture v\u1edbi c\u00e1c b\u1ed9 hyperparameter kh\u00e1c nhau. \u0110\u1ec3 c\u00f3 th\u1ec3 t\u00e1i l\u1eadp k\u1ebft qu\u1ea3 training, c\u1ea7n ph\u1ea3i bi\u1ebft \u0111\u01b0\u1ee3c th\u1eed nghi\u1ec7m n\u00e0o d\u00f9ng b\u1ed9 feature n\u00e0o, model architecture, v\u1edbi c\u00e1c hyperparameter n\u00e0o. Trong kho\u00e1 h\u1ecdc n\u00e0y, ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng MLOps Platform \u0111\u00e3 \u0111\u01b0\u1ee3c gi\u1edbi thi\u1ec7u trong b\u00e0i MLOps Platform v\u00e0 c\u1ee5 th\u1ec3 l\u00e0 MLflow s\u1ebd \u0111\u00f3ng vai tr\u00f2 ch\u00ednh gi\u00fap ch\u00fang ta theo d\u00f5i c\u00e1c th\u00f4ng tin tr\u00ean hay ML metadata c\u1ee7a c\u00e1c l\u1ea7n th\u1eed nghi\u1ec7m.","title":"Training code"},{"location":"mlops-crash-course/poc/xay-dung-poc.html#theo-doi-thu-nghiem","text":"MLflow l\u00e0 m\u1ed9t open-source platform \u0111\u1ec3 qu\u1ea3n l\u00fd v\u00f2ng \u0111\u1eddi v\u00e0 c\u00e1c quy tr\u00ecnh trong m\u1ed9t h\u1ec7 th\u1ed1ng ML. M\u1ed9t trong nh\u1eefng ch\u1ee9c n\u0103ng c\u1ee7a MLflow m\u00e0 ch\u00fang ta s\u1eed d\u1ee5ng \u0111\u00f3 l\u00e0 ch\u1ee9c n\u0103ng theo d\u00f5i ML metadata. Code c\u1ee7a ph\u1ea7n n\u00e0y \u0111\u01b0\u1ee3c \u0111\u1eb7t t\u1ea1i notebook training_pipeline/nbs/poc-integrate-mlflow.ipynb . Logic c\u1ee7a code gi\u1ed1ng nh\u01b0 notebook training_pipeline/nbs/poc-training-code.ipynb , ch\u1ec9 c\u00f3 th\u00eam \u0111o\u1ea1n code \u0111\u1ec3 t\u00edch h\u1ee3p MLflow v\u00e0o. B\u1ea1n h\u00e3y l\u00e0m theo c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 t\u00edch h\u1ee3p MLflow. Clone github repo mlops-crash-course-platform , ch\u1ea1y MLflow server tr\u00ean m\u00f4i tr\u01b0\u1eddng local bash run.sh mlflow up \u0110i t\u1edbi URL http://localhost:5000 \u0111\u1ec3 ki\u1ec3m tra xem MLflow server \u0111\u00e3 \u0111\u01b0\u1ee3c kh\u1edfi t\u1ea1o th\u00e0nh c\u00f4ng ch\u01b0a Trong notebook training_pipeline/nbs/poc-integrate-mlflow.ipynb , c\u00e1c b\u1ea1n \u0111\u1ec3 \u00fd \u0111o\u1ea1n code sau \u0111\u01b0\u1ee3c th\u00eam v\u00e0o \u1edf \u0111o\u1ea1n code training \u0111\u1ec3 t\u00edch h\u1ee3p MLflow v\u00e0o \u0111o\u1ea1n code training training_pipeline/nbs/poc-integrate-mlflow.ipynb 1 2 3 MLFLOW_TRACKING_URI = \"http://localhost:5000\" mlflow . set_tracking_uri ( MLFLOW_TRACKING_URI ) mlflow . sklearn . autolog () # (1) V\u00ec sklearn \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 train model, d\u00f2ng n\u00e0y t\u1ef1 \u0111\u1ed9ng qu\u00e1 tr\u00ecnh log l\u1ea1i c\u00e1c hyperparameter v\u00e0 c\u00e1c metrics trong qu\u00e1 tr\u00ecnh training. Xem th\u00eam \u1edf \u0111\u00e2y \u0111\u1ec3 bi\u1ebft th\u00eam th\u00f4ng tin v\u1ec1 c\u00e1c training framework \u0111\u01b0\u1ee3c MLflow h\u1ed7 tr\u1ee3 t\u1ef1 \u0111\u1ed9ng log ML metadata. \u0110o\u1ea1n code sau \u0111\u1ec3 log l\u1ea1i c\u00e1c hyperparameter v\u00e0 metric training_pipeline/nbs/poc-integrate-mlflow.ipynb 1 2 3 4 5 6 7 8 9 10 11 12 mlflow . set_tag ( \"mlflow.runName\" , uuid . uuid1 ()) # (1) mlflow . log_param ( \"features\" , selected_ft ) # (2) mlflow . log_param ( \"alpha\" , ALPHA ) # (3) mlflow . log_param ( \"l1_ratio\" , L1_RATIO ) mlflow . log_metric ( \"testing_rmse\" , rmse ) # (4) mlflow . log_metric ( \"testing_r2\" , r2 ) mlflow . log_metric ( \"testing_mae\" , mae ) mlflow . sklearn . log_model ( model , \"model\" ) # (5) \u0110\u1eb7t t\u00ean cho l\u1ea7n ch\u1ea1y Log l\u1ea1i feature \u0111\u01b0\u1ee3c d\u00f9ng Log l\u1ea1i hyperparameter Log l\u1ea1i metric sau khi test tr\u00ean test set Log l\u1ea1i model M\u1edf MLflow tr\u00ean browser, b\u1ea1n s\u1ebd th\u1ea5y giao di\u1ec7n nh\u01b0 sau. M\u1ecdi th\u00f4ng tin ch\u00fang ta log l\u1ea1i m\u1ed7i l\u1ea7n th\u1eed nghi\u1ec7m \u0111\u00e3 \u0111\u01b0\u1ee3c l\u01b0u l\u1ea1i. B\u1ea1n c\u00f3 th\u1ec3 xem th\u00eam th\u00f4ng tin chi ti\u1ebft v\u1ec1 m\u1ed9t l\u1ea7n ch\u1ea1y b\u1eb1ng c\u00e1ch \u1ea5n v\u00e0o c\u1ed9t Start time c\u1ee7a l\u1ea7n ch\u1ea1y \u0111\u00f3.","title":"Theo d\u00f5i th\u1eed nghi\u1ec7m"},{"location":"mlops-crash-course/poc/xay-dung-poc.html#theo-doi-features","text":"Trong ph\u1ea7n tr\u01b0\u1edbc, ch\u00fang ta \u0111\u00e3 coi b\u1ed9 feature m\u00e0 ch\u00fang ta s\u1eed d\u1ee5ng trong qu\u00e1 tr\u00ecnh training nh\u01b0 m\u1ed9t hyperparameter v\u00e0 d\u00f9ng MLflow \u0111\u1ec3 log l\u1ea1i. Tuy nhi\u00ean, \u0111\u00e2y ch\u01b0a ph\u1ea3i gi\u1ea3i ph\u00e1p t\u1ed1i \u01b0u \u0111\u1ec3 theo d\u00f5i c\u00e1c feature trong qu\u00e1 tr\u00ecnh th\u1eed nghi\u1ec7m. M\u1ee5c \u0111\u00edch c\u1ee7a vi\u1ec7c theo d\u00f5i c\u00e1c feature l\u00e0 \u0111\u1ec3 c\u00f3 th\u1ec3 t\u00e1i l\u1eadp k\u1ebft qu\u1ea3 c\u1ee7a m\u1ed9t th\u1eed nghi\u1ec7m. Ch\u1ec9 b\u1eb1ng vi\u1ec7c l\u01b0u l\u1ea1i t\u00ean c\u00e1c feature \u0111\u01b0\u1ee3c d\u00f9ng th\u00ec kh\u00f4ng \u0111\u1ea3m b\u1ea3o \u0111\u01b0\u1ee3c s\u1ebd t\u1ea1o l\u1ea1i \u0111\u01b0\u1ee3c k\u1ebft qu\u1ea3, v\u00ec c\u00f3 th\u1ec3 feature b\u1ecb \u0111\u1ed5i t\u00ean ho\u1eb7c t\u00ean v\u1eabn gi\u1eef nguy\u00ean nh\u01b0ng c\u00e1ch bi\u1ebfn \u0111\u1ed5i \u0111\u1ec3 sinh ra feature \u0111\u00f3 b\u1ecb thay \u0111\u1ed5i. Do \u0111\u00f3, vi\u1ec7c theo d\u00f5i c\u00e1c feature n\u00e0y kh\u00f4ng ch\u1ec9 l\u00e0 theo d\u00f5i t\u00ean c\u1ee7a c\u00e1c feature, m\u00e0 c\u1ea3 quy tr\u00ecnh sinh ra c\u00e1c feature \u0111\u00f3. \u1ede giai \u0111o\u1ea1n POC, v\u00ec ch\u01b0a c\u00f3 \u0111\u1ee7 ngu\u1ed3n l\u1ef1c \u0111\u1ec3 x\u00e2y d\u1ef1ng c\u01a1 s\u1edf h\u1ea1 t\u1ea7ng \u0111\u1ee7 m\u1ea1nh \u0111\u1ec3 h\u1ed7 tr\u1ee3 vi\u1ec7c theo d\u00f5i quy tr\u00ecnh t\u1ea1o ra feature, n\u00ean ch\u00fang ta ch\u1ec9 k\u00ec v\u1ecdng s\u1ebd theo d\u00f5i \u0111\u01b0\u1ee3c t\u00ean c\u00e1c feature l\u00e0 \u0111\u1ee7. Trong c\u00e1c b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd h\u1ecdc c\u00e1ch theo d\u00f5i version c\u1ee7a quy tr\u00ecnh bi\u1ebfn \u0111\u1ed5i feature v\u00e0 t\u00edch h\u1ee3p version \u0111\u00f3 v\u00e0o qu\u00e1 tr\u00ecnh training.","title":"Theo d\u00f5i features"},{"location":"mlops-crash-course/poc/xay-dung-poc.html#tong-ket","text":"Qua nhi\u1ec1u l\u1ea7n th\u1eed nghi\u1ec7m data v\u00e0 model, ngo\u00e0i vi\u1ec7c ch\u1ee9ng minh gi\u1ea3i ph\u00e1p ML l\u00e0 kh\u1ea3 thi, ch\u00fang ta s\u1ebd hi\u1ec3u r\u00f5 h\u01a1n v\u1ec1 v\u1ea5n \u0111\u1ec1 kinh doanh, gi\u1ea3i ph\u00e1p ti\u1ec1m n\u0103ng, c\u00e1ch \u0111\u00e1nh gi\u00e1 c\u00e1c gi\u1ea3i ph\u00e1p \u0111\u00f3 m\u1ed9t c\u00e1ch hi\u1ec7u qu\u1ea3. C\u00e1c \u0111\u1ea7u ra n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 c\u1eadp nh\u1eadt l\u1ea1i c\u00e1c \u0111\u1ecbnh ngh\u0129a c\u1ee7a v\u1ea5n \u0111\u1ec1 kinh doanh, c\u00e1c c\u00e1ch bi\u1ebfn \u0111\u1ed5i data \u0111\u1ec3 x\u00e2y d\u1ef1ng data pipeline, training code \u0111\u1ec3 x\u00e2y d\u1ef1ng training pipeline v\u00e0 serving code \u0111\u1ec3 x\u00e2y d\u1ef1ng model serving component. Trong b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd x\u00e2y d\u1ef1ng data pipeline, m\u1ed9t trong nh\u1eefng pipeline ph\u1ee9c t\u1ea1p nh\u1ea5t c\u1ee7a h\u1ec7 th\u1ed1ng.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/poc/xay-dung-poc.html#tai-lieu-tham-khao","text":"MLflow tracking MLflow Model registry","title":"T\u00e0i li\u1ec7u tham kh\u1ea3o"},{"location":"mlops-crash-course/tong-ket/tom-tat-noi-dung.html","text":"T\u00f3m t\u1eaft n\u1ed9i dung kh\u00f3a h\u1ecdc Ch\u00fang ta \u0111\u00e3 c\u00f9ng nhau \u0111i qua m\u1ed9t ch\u1eb7ng \u0111\u01b0\u1eddng d\u00e0i, t\u1eeb l\u00fac l\u00e0m r\u00f5 b\u00e0i to\u00e1n kinh doanh, th\u1ef1c hi\u1ec7n POC ch\u1ee9ng minh hi\u1ec7u qu\u1ea3 c\u1ee7a model, \u0111\u1ebfn x\u00e2y d\u1ef1ng c\u00e1c data pipeline, training pipeline, sau \u0111\u00f3 \u0111\u00f3ng g\u00f3i \u0111\u1ec3 serve model v\u00e0 cu\u1ed1i c\u00f9ng l\u00e0 t\u1ef1 \u0111\u1ed9ng h\u00f3a t\u1ea5t c\u1ea3 c\u00e1c b\u01b0\u1edbc tr\u00ean. Trong su\u1ed1t c\u1ea3 qu\u00e3ng \u0111\u01b0\u1eddng n\u00e0y, \u0111\u00e3 c\u00f9ng nhau l\u00e0m quen v\u1edbi r\u1ea5t nhi\u1ec1u c\u00f4ng c\u1ee5, \u0111i k\u00e8m v\u1edbi best practices \u0111\u01b0\u1ee3c \u0111\u00fac k\u1ebft v\u00e0 thu th\u1eadp t\u1eeb nhi\u1ec1u ngu\u1ed3n t\u00e0i li\u1ec7u kh\u00e1c nhau c\u00f3 th\u1ec3 k\u1ec3 t\u1edbi nh\u01b0 Airflow, MLFLow, Feast, .v.v. Vi\u1ec7c h\u1ecdc c\u00e1ch s\u1eed d\u1ee5ng c\u00e1c c\u00f4ng c\u1ee5 n\u00e0y l\u00e0 c\u1ea7n thi\u1ebft, song kh\u00f4ng n\u00ean qu\u00e1 ph\u1ee5 thu\u1ed9c hay l\u1ea1m d\u1ee5ng n\u00f3 m\u00e0 qu\u00ean \u0111i v\u1ea5n \u0111\u1ec1 ch\u00ednh l\u00e0 l\u00e0m th\u1ebf n\u00e0o \u0111\u1ec3 gi\u1ea3i quy\u1ebft b\u00e0i to\u00e1n m\u1ed9t c\u00e1ch \u0111\u01a1n gi\u1ea3n v\u00e0 hi\u1ec7u qu\u1ea3 nh\u1ea5t. \u0110\u1ed3ng th\u1eddi ch\u00fang ta \u0111\u00e3 t\u00ecm hi\u1ec3u v\u1ec1 ki\u1ec3m th\u1eed trong m\u1ed9t h\u1ec7 th\u1ed1ng ML, n\u00f3 kh\u00f4ng \u0111\u01a1n thu\u1ea7n ch\u1ec9 l\u00e0 ki\u1ec3m th\u1eed code nh\u01b0 b\u00ean software, m\u00e0 ch\u00fang ta c\u00f2n ph\u1ea3i quan t\u00e2m t\u1edbi data v\u00e0 model n\u1eefa. Vi\u1ec7c l\u00e0m n\u00e0y quan tr\u1ecdng nh\u01b0 l\u00e0 x\u00e2y d\u1ef1ng model v\u1eady, v\u00ec n\u1ebfu kh\u00f4ng c\u00f3 ki\u1ec3m th\u1eed th\u00ec \u0111\u1ea7u ra s\u1ebd kh\u00f4ng th\u1ec3 tin c\u1eady \u0111\u01b0\u1ee3c (garbage in - garbage out). Feature store c\u0169ng l\u00e0 m\u1ed9t th\u00e0nh ph\u1ea7n th\u00fa v\u1ecb trong chu\u1ed7i b\u00e0i gi\u1ea3ng n\u00e0y. N\u00f3 \u0111ang xu\u1ea5t hi\u1ec7n ng\u00e0y c\u00e0ng nhi\u1ec1u \u1edf c\u00e1c c\u00f4ng ty, gi\u00fap cho vi\u1ec7c qu\u1ea3n l\u00fd, \u0111\u00e1nh gi\u00e1 v\u00e0 chia s\u1ebb feature m\u1ed9t c\u00e1ch d\u1ec5 d\u00e0ng gi\u1eefa c\u00e1c th\u00e0nh vi\u00ean trong team, gi\u1eefa c\u00e1c team trong to\u00e0n t\u1ed5 ch\u1ee9c. \u1ee8ng d\u1ee5ng n\u00e0y s\u1ebd gi\u1ea3m thi\u1ec3u r\u1ea5t nhi\u1ec1u c\u00f4ng s\u1ee9c c\u1ee7a con ng\u01b0\u1eddi, b\u00ean c\u1ea1nh \u0111\u00f3 vi\u1ec7c l\u00e0m n\u00e0y v\u00f4 c\u00f9ng ti\u1ec1m n\u0103ng trong l\u00fac c\u1ea3i thi\u1ec7n ch\u1ea5t l\u01b0\u1ee3ng model th\u00f4ng qua vi\u1ec7c n\u00e2ng cao ch\u1ea5t l\u01b0\u1ee3ng feature. Nh\u00ecn xa h\u01a1n n\u1eefa, c\u00e1c c\u00f4ng c\u1ee5 m\u00e0 ch\u00fang ta \u0111\u00e3 deploy t\u1ea1o n\u00ean m\u1ed9t MLOps platform, c\u00f3 t\u00ednh t\u00e1i s\u1eed d\u1ee5ng \u1edf nhi\u1ec1u d\u1ef1 \u00e1n ML kh\u00e1c nhau, \u0111\u1eb7t ra m\u1ed9t quy chu\u1ea9n trong vi\u1ec7c thi\u1ebft k\u1ebf v\u00e0 x\u00e2y d\u1ef1ng h\u1ec7 th\u1ed1ng ML, \u0111\u1ed3ng th\u1eddi gi\u1ea3m thi\u1ec3u t\u1ed1i \u0111a c\u00e1c c\u00f4ng vi\u1ec7c tr\u00f9ng l\u1eb7p gi\u1eefa nhi\u1ec1u team v\u1edbi nhau. D\u1ecdn d\u1eb9p m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n \u0110\u1ec3 d\u1ecdn d\u1eb9p m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n, ti\u1ebfn h\u00e0nh c\u00e1c b\u01b0\u1edbc sau: Teardown mlops-platform cd mlops-crash-course-platform bash run.sh all down --volumes Stop c\u00e1c service kh\u00e1c cd mlops-crash-course-code make -C model_serving compose_down make -C monitoring_service compose_down cd stream_emitting && bash deploy.sh stop Xo\u00e1 ho\u00e0n to\u00e0n data c\u1ee7a c\u00e1c services Trong repo mlops-crash-course-platform , xo\u00e1 to\u00e0n b\u1ed9 folders/files trong folder airflow/run_env , tr\u1eeb file .gitkeep L\u00e0m t\u01b0\u01a1ng t\u1ef1 v\u1edbi c\u00e1c services kh\u00e1c C\u00e1c h\u01b0\u1edbng ph\u00e1t tri\u1ec3n ti\u1ebfp theo Sau khi ho\u00e0n th\u00e0nh kh\u00f3a h\u1ecdc n\u00e0y, b\u1ea1n ho\u00e0n to\u00e0n c\u00f3 th\u1ec3 t\u1ef1 h\u1ecdc th\u00eam b\u1eb1ng c\u00e1ch: T\u1eadp d\u1eef li\u1ec7u: Th\u1eed nghi\u1ec7m v\u1edbi t\u1eadp d\u1eef li\u1ec7u ph\u1ee9c t\u1ea1p h\u01a1n, v\u1edbi nhi\u1ec1u d\u00f2ng v\u00e0 nhi\u1ec1u c\u1ed9t h\u01a1n C\u1ea3i thi\u1ec7n c\u00e1c b\u01b0\u1edbc preprocess/postprocess b\u1eb1ng nh\u1eefng x\u1eed l\u00fd ph\u1ee9c t\u1ea1p h\u01a1n Model serving: Th\u1ef1c hi\u1ec7n c\u00e1c lo\u1ea1i deployment kh\u00e1c nhau, v\u00ed d\u1ee5 canary ho\u1eb7c shadow Th\u1ef1c hi\u1ec7n A/B ho\u1eb7c multi-armed bandits testing Pipeline: Th\u1ef1c hi\u1ec7n trigger pipeline th\u00f4ng qua Alert Manager thay v\u00ec ch\u1ea1y \u0111\u1ecbnh k\u1ef3 Logging: L\u01b0u th\u00eam log t\u1eeb c\u00e1c pipelines, thay v\u00ec ch\u1ec9 model serving CI/CD: Th\u1ef1c hi\u1ec7n c\u00e1c nhi\u1ec1u m\u00f4i tr\u01b0\u1eddng kh\u00e1c nhau Infrastructure: Tri\u1ec3n khai h\u1ec7 th\u1ed1ng tr\u00ean Kubernetes \u0110\u00f3ng g\u00f3p \u00fd ki\u1ebfn ph\u1ea3n h\u1ed3i MLOpsVN Team xin g\u1eedi l\u1eddi c\u1ea3m \u01a1n t\u1edbi c\u00e1c b\u1ea1n \u0111\u00e3 quan t\u00e2m v\u00e0 tham gi\u00e1 kho\u00e1 h\u1ecdc MLOps Crash Course . \u0110\u1ec3 nh\u1eefng d\u1ef1 \u00e1n ti\u1ebfp theo c\u1ee7a MLOpsVN Team \u0111\u01b0\u1ee3c tr\u1ecdn v\u1eb9n h\u01a1n, c\u00e1c b\u1ea1n c\u00f3 th\u1ec3 d\u00e0nh ch\u00fat th\u1eddi gian \u0111\u1ec3 g\u1eedi \u00fd ki\u1ebfn ph\u1ea3n h\u1ed3i cho kho\u00e1 h\u1ecdc t\u1ea1i \u0111\u00e2y . Hy v\u1ecdng kho\u00e1 h\u1ecdc MLOps Crash Course \u0111\u00e3 \u0111\u00f3ng g\u00f3p \u00edt nhi\u1ec1u cho s\u1ef1 ph\u00e1t tri\u1ec3n c\u1ee7a c\u1ed9ng \u0111\u1ed3ng AI Vi\u1ec7t Nam. H\u1eb9n g\u1eb7p l\u1ea1i c\u00e1c b\u1ea1n trong c\u00e1c d\u1ef1 \u00e1n ti\u1ebfp theo c\u1ee7a MLOpsVN.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/tong-ket/tom-tat-noi-dung.html#tom-tat-noi-dung-khoa-hoc","text":"Ch\u00fang ta \u0111\u00e3 c\u00f9ng nhau \u0111i qua m\u1ed9t ch\u1eb7ng \u0111\u01b0\u1eddng d\u00e0i, t\u1eeb l\u00fac l\u00e0m r\u00f5 b\u00e0i to\u00e1n kinh doanh, th\u1ef1c hi\u1ec7n POC ch\u1ee9ng minh hi\u1ec7u qu\u1ea3 c\u1ee7a model, \u0111\u1ebfn x\u00e2y d\u1ef1ng c\u00e1c data pipeline, training pipeline, sau \u0111\u00f3 \u0111\u00f3ng g\u00f3i \u0111\u1ec3 serve model v\u00e0 cu\u1ed1i c\u00f9ng l\u00e0 t\u1ef1 \u0111\u1ed9ng h\u00f3a t\u1ea5t c\u1ea3 c\u00e1c b\u01b0\u1edbc tr\u00ean. Trong su\u1ed1t c\u1ea3 qu\u00e3ng \u0111\u01b0\u1eddng n\u00e0y, \u0111\u00e3 c\u00f9ng nhau l\u00e0m quen v\u1edbi r\u1ea5t nhi\u1ec1u c\u00f4ng c\u1ee5, \u0111i k\u00e8m v\u1edbi best practices \u0111\u01b0\u1ee3c \u0111\u00fac k\u1ebft v\u00e0 thu th\u1eadp t\u1eeb nhi\u1ec1u ngu\u1ed3n t\u00e0i li\u1ec7u kh\u00e1c nhau c\u00f3 th\u1ec3 k\u1ec3 t\u1edbi nh\u01b0 Airflow, MLFLow, Feast, .v.v. Vi\u1ec7c h\u1ecdc c\u00e1ch s\u1eed d\u1ee5ng c\u00e1c c\u00f4ng c\u1ee5 n\u00e0y l\u00e0 c\u1ea7n thi\u1ebft, song kh\u00f4ng n\u00ean qu\u00e1 ph\u1ee5 thu\u1ed9c hay l\u1ea1m d\u1ee5ng n\u00f3 m\u00e0 qu\u00ean \u0111i v\u1ea5n \u0111\u1ec1 ch\u00ednh l\u00e0 l\u00e0m th\u1ebf n\u00e0o \u0111\u1ec3 gi\u1ea3i quy\u1ebft b\u00e0i to\u00e1n m\u1ed9t c\u00e1ch \u0111\u01a1n gi\u1ea3n v\u00e0 hi\u1ec7u qu\u1ea3 nh\u1ea5t. \u0110\u1ed3ng th\u1eddi ch\u00fang ta \u0111\u00e3 t\u00ecm hi\u1ec3u v\u1ec1 ki\u1ec3m th\u1eed trong m\u1ed9t h\u1ec7 th\u1ed1ng ML, n\u00f3 kh\u00f4ng \u0111\u01a1n thu\u1ea7n ch\u1ec9 l\u00e0 ki\u1ec3m th\u1eed code nh\u01b0 b\u00ean software, m\u00e0 ch\u00fang ta c\u00f2n ph\u1ea3i quan t\u00e2m t\u1edbi data v\u00e0 model n\u1eefa. Vi\u1ec7c l\u00e0m n\u00e0y quan tr\u1ecdng nh\u01b0 l\u00e0 x\u00e2y d\u1ef1ng model v\u1eady, v\u00ec n\u1ebfu kh\u00f4ng c\u00f3 ki\u1ec3m th\u1eed th\u00ec \u0111\u1ea7u ra s\u1ebd kh\u00f4ng th\u1ec3 tin c\u1eady \u0111\u01b0\u1ee3c (garbage in - garbage out). Feature store c\u0169ng l\u00e0 m\u1ed9t th\u00e0nh ph\u1ea7n th\u00fa v\u1ecb trong chu\u1ed7i b\u00e0i gi\u1ea3ng n\u00e0y. N\u00f3 \u0111ang xu\u1ea5t hi\u1ec7n ng\u00e0y c\u00e0ng nhi\u1ec1u \u1edf c\u00e1c c\u00f4ng ty, gi\u00fap cho vi\u1ec7c qu\u1ea3n l\u00fd, \u0111\u00e1nh gi\u00e1 v\u00e0 chia s\u1ebb feature m\u1ed9t c\u00e1ch d\u1ec5 d\u00e0ng gi\u1eefa c\u00e1c th\u00e0nh vi\u00ean trong team, gi\u1eefa c\u00e1c team trong to\u00e0n t\u1ed5 ch\u1ee9c. \u1ee8ng d\u1ee5ng n\u00e0y s\u1ebd gi\u1ea3m thi\u1ec3u r\u1ea5t nhi\u1ec1u c\u00f4ng s\u1ee9c c\u1ee7a con ng\u01b0\u1eddi, b\u00ean c\u1ea1nh \u0111\u00f3 vi\u1ec7c l\u00e0m n\u00e0y v\u00f4 c\u00f9ng ti\u1ec1m n\u0103ng trong l\u00fac c\u1ea3i thi\u1ec7n ch\u1ea5t l\u01b0\u1ee3ng model th\u00f4ng qua vi\u1ec7c n\u00e2ng cao ch\u1ea5t l\u01b0\u1ee3ng feature. Nh\u00ecn xa h\u01a1n n\u1eefa, c\u00e1c c\u00f4ng c\u1ee5 m\u00e0 ch\u00fang ta \u0111\u00e3 deploy t\u1ea1o n\u00ean m\u1ed9t MLOps platform, c\u00f3 t\u00ednh t\u00e1i s\u1eed d\u1ee5ng \u1edf nhi\u1ec1u d\u1ef1 \u00e1n ML kh\u00e1c nhau, \u0111\u1eb7t ra m\u1ed9t quy chu\u1ea9n trong vi\u1ec7c thi\u1ebft k\u1ebf v\u00e0 x\u00e2y d\u1ef1ng h\u1ec7 th\u1ed1ng ML, \u0111\u1ed3ng th\u1eddi gi\u1ea3m thi\u1ec3u t\u1ed1i \u0111a c\u00e1c c\u00f4ng vi\u1ec7c tr\u00f9ng l\u1eb7p gi\u1eefa nhi\u1ec1u team v\u1edbi nhau.","title":"T\u00f3m t\u1eaft n\u1ed9i dung kh\u00f3a h\u1ecdc"},{"location":"mlops-crash-course/tong-ket/tom-tat-noi-dung.html#don-dep-moi-truong-phat-trien","text":"\u0110\u1ec3 d\u1ecdn d\u1eb9p m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n, ti\u1ebfn h\u00e0nh c\u00e1c b\u01b0\u1edbc sau: Teardown mlops-platform cd mlops-crash-course-platform bash run.sh all down --volumes Stop c\u00e1c service kh\u00e1c cd mlops-crash-course-code make -C model_serving compose_down make -C monitoring_service compose_down cd stream_emitting && bash deploy.sh stop Xo\u00e1 ho\u00e0n to\u00e0n data c\u1ee7a c\u00e1c services Trong repo mlops-crash-course-platform , xo\u00e1 to\u00e0n b\u1ed9 folders/files trong folder airflow/run_env , tr\u1eeb file .gitkeep L\u00e0m t\u01b0\u01a1ng t\u1ef1 v\u1edbi c\u00e1c services kh\u00e1c","title":"D\u1ecdn d\u1eb9p m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n"},{"location":"mlops-crash-course/tong-ket/tom-tat-noi-dung.html#cac-huong-phat-trien-tiep-theo","text":"Sau khi ho\u00e0n th\u00e0nh kh\u00f3a h\u1ecdc n\u00e0y, b\u1ea1n ho\u00e0n to\u00e0n c\u00f3 th\u1ec3 t\u1ef1 h\u1ecdc th\u00eam b\u1eb1ng c\u00e1ch: T\u1eadp d\u1eef li\u1ec7u: Th\u1eed nghi\u1ec7m v\u1edbi t\u1eadp d\u1eef li\u1ec7u ph\u1ee9c t\u1ea1p h\u01a1n, v\u1edbi nhi\u1ec1u d\u00f2ng v\u00e0 nhi\u1ec1u c\u1ed9t h\u01a1n C\u1ea3i thi\u1ec7n c\u00e1c b\u01b0\u1edbc preprocess/postprocess b\u1eb1ng nh\u1eefng x\u1eed l\u00fd ph\u1ee9c t\u1ea1p h\u01a1n Model serving: Th\u1ef1c hi\u1ec7n c\u00e1c lo\u1ea1i deployment kh\u00e1c nhau, v\u00ed d\u1ee5 canary ho\u1eb7c shadow Th\u1ef1c hi\u1ec7n A/B ho\u1eb7c multi-armed bandits testing Pipeline: Th\u1ef1c hi\u1ec7n trigger pipeline th\u00f4ng qua Alert Manager thay v\u00ec ch\u1ea1y \u0111\u1ecbnh k\u1ef3 Logging: L\u01b0u th\u00eam log t\u1eeb c\u00e1c pipelines, thay v\u00ec ch\u1ec9 model serving CI/CD: Th\u1ef1c hi\u1ec7n c\u00e1c nhi\u1ec1u m\u00f4i tr\u01b0\u1eddng kh\u00e1c nhau Infrastructure: Tri\u1ec3n khai h\u1ec7 th\u1ed1ng tr\u00ean Kubernetes","title":"C\u00e1c h\u01b0\u1edbng ph\u00e1t tri\u1ec3n ti\u1ebfp theo"},{"location":"mlops-crash-course/tong-ket/tom-tat-noi-dung.html#ong-gop-y-kien-phan-hoi","text":"MLOpsVN Team xin g\u1eedi l\u1eddi c\u1ea3m \u01a1n t\u1edbi c\u00e1c b\u1ea1n \u0111\u00e3 quan t\u00e2m v\u00e0 tham gi\u00e1 kho\u00e1 h\u1ecdc MLOps Crash Course . \u0110\u1ec3 nh\u1eefng d\u1ef1 \u00e1n ti\u1ebfp theo c\u1ee7a MLOpsVN Team \u0111\u01b0\u1ee3c tr\u1ecdn v\u1eb9n h\u01a1n, c\u00e1c b\u1ea1n c\u00f3 th\u1ec3 d\u00e0nh ch\u00fat th\u1eddi gian \u0111\u1ec3 g\u1eedi \u00fd ki\u1ebfn ph\u1ea3n h\u1ed3i cho kho\u00e1 h\u1ecdc t\u1ea1i \u0111\u00e2y . Hy v\u1ecdng kho\u00e1 h\u1ecdc MLOps Crash Course \u0111\u00e3 \u0111\u00f3ng g\u00f3p \u00edt nhi\u1ec1u cho s\u1ef1 ph\u00e1t tri\u1ec3n c\u1ee7a c\u1ed9ng \u0111\u1ed3ng AI Vi\u1ec7t Nam. H\u1eb9n g\u1eb7p l\u1ea1i c\u00e1c b\u1ea1n trong c\u00e1c d\u1ef1 \u00e1n ti\u1ebfp theo c\u1ee7a MLOpsVN.","title":"\u0110\u00f3ng g\u00f3p \u00fd ki\u1ebfn ph\u1ea3n h\u1ed3i"},{"location":"mlops-crash-course/tong-quan-he-thong/mlops-platform.html","text":"Photo by Coussement Bruno on Towards Data Science Gi\u1edbi thi\u1ec7u MLOps platform l\u00e0 n\u1ec1n t\u1ea3ng cung c\u1ea5p c\u00e1c c\u00f4ng c\u1ee5 c\u1ea7n thi\u1ebft \u0111\u1ec3 ph\u00e1t tri\u1ec3n, qu\u1ea3n l\u00fd v\u00e0 tri\u1ec3n khai c\u00e1c d\u1ef1 \u00e1n ML. Trong m\u1ed9t s\u1ed1 t\u00e0i li\u1ec7u kh\u00e1c MLOps platform c\u00f2n c\u00f3 t\u00ean l\u00e0 AI platform ho\u1eb7c ML platform. \u1ede kh\u00f3a h\u1ecdc n\u00e0y ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng m\u1ed9t MLOps platform v\u1edbi c\u00e1c th\u00e0nh ph\u1ea7n v\u00e0 c\u00f4ng c\u1ee5 t\u01b0\u01a1ng \u1ee9ng nh\u01b0 sau: T\u00ean th\u00e0nh ph\u1ea7n \u00dd ngh\u0129a Tool s\u1eed d\u1ee5ng Source control Qu\u1ea3n l\u00fd c\u00e1c phi\u00ean b\u1ea3n v\u1ec1 m\u00e3 ngu\u1ed3n v\u00e0 d\u1eef li\u1ec7u Git & Github Feature store L\u01b0u tr\u1eef, qu\u1ea3n l\u00fd v\u00e0 t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c t\u00ednh n\u0103ng (feature) Feast (PostgreSQL & Redis backend) Experiment tracking L\u01b0u tr\u1eef th\u00f4ng tin v\u00e0 qu\u1ea3n l\u00fd c\u00e1c th\u00ed nghi\u1ec7m (experiments) MLFlow Model registry L\u01b0u tr\u1eef v\u00e0 qu\u1ea3n l\u00fd c\u00e1c m\u00f4 h\u00ecnh MLFlow ML metadata Store L\u01b0u tr\u1eef th\u00f4ng tin (artifact) c\u1ee7a c\u00e1c lu\u1ed3ng (pipeline) MLFlow Workflow orchestrator X\u00e2y d\u1ef1ng v\u00e0 qu\u1ea3n l\u00fd c\u00e1c lu\u1ed3ng quy tr\u00ecnh Airflow Monitoring Theo d\u00f5i t\u00e0i nguy\u00ean h\u1ec7 th\u1ed1ng, hi\u1ec7u n\u0103ng c\u1ee7a m\u00f4 h\u00ecnh v\u00e0 ch\u1ea5t l\u01b0\u1ee3ng d\u1eef li\u1ec7u tr\u00ean production Prometheus & Grafana & ELK CI/CD T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh test v\u00e0 deploy Jenkins Info Ch\u00fang ta c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng m\u1ed9t c\u00f4ng c\u1ee5 cho nhi\u1ec1u m\u1ee5c \u0111\u00edch kh\u00e1c nhau, v\u00ed d\u1ee5 MLFlow, v\u1edbi m\u1ee5c \u0111\u00edch s\u1eed d\u1ee5ng t\u1ed1i thi\u1ec3u c\u00e1c c\u00f4ng c\u1ee5 c\u1ea7n thi\u1ebft m\u00e0 v\u1eabn \u0111\u1ea3m b\u1ea3o \u0111\u01b0\u1ee3c 9 MLOps Principles , 9 MLOps Components v\u00e0 5 MLOps Workflows \u0111\u01b0\u1ee3c \u00e1p d\u1ee5ng (xem l\u1ea1i b\u00e0i T\u1ed5ng quan MLOps ). Vi\u1ec7c s\u1eed d\u1ee5ng qu\u00e1 nhi\u1ec1u c\u00f4ng c\u1ee5 c\u00f3 th\u1ec3 d\u1eabn t\u1edbi vi\u1ec7c v\u1eadn h\u00e0nh MLOps platform tr\u1edf n\u00ean ph\u1ee9c t\u1ea1p, \u0111\u1ed3ng th\u1eddi khi\u1ebfn ng\u01b0\u1eddi d\u00f9ng d\u1ec5 b\u1ecb cho\u00e1ng ng\u1ee3p do kh\u00f4ng bi\u1ebft s\u1eed d\u1ee5ng v\u00e0 qu\u1ea3n l\u00fd m\u1ed9t c\u00e1ch hi\u1ec7u qu\u1ea3. Architecture Ki\u1ebfn tr\u00fac MLOps platform c\u1ee7a ch\u00fang ta s\u1ebd nh\u01b0 sau: C\u00e1c t\u01b0\u01a1ng t\u00e1c ch\u00ednh trong MLOps platform: 1. Data Pipeline k\u00e9o v\u00e0 x\u1eed l\u00fd d\u1eef li\u1ec7u t\u1eeb file source 2. D\u1eef li\u1ec7u sau khi x\u1eed l\u00fd b\u1edfi Data Pipeline s\u1ebd \u0111\u01b0\u1ee3c \u0111\u1ea9y v\u00e0o Feature Store 3. Data Scientist (DS) k\u00e9o feature t\u1eeb Feature Store \u0111\u1ec3 th\u1ef1c hi\u1ec7n c\u00e1c th\u00ed nghi\u1ec7m tr\u00ean notebook 4. Training Pipeline k\u00e9o feature v\u1ec1 \u0111\u1ec3 train model 5. Metadata c\u1ee7a c\u00e1c experiment, v\u00ed d\u1ee5 nh\u01b0 hyperparameters v\u00e0 metrics, ... \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o Metadata Store 6. Metadata c\u1ee7a Training Pipeline c\u0169ng \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o Metadata Store 7. Model sau khi train s\u1ebd \u0111\u01b0\u1ee3c l\u01b0u tr\u1eef \u1edf Model Registry 8. Batch Serving Pipeline v\u00e0 Online Serving API k\u00e9o model t\u1eeb Model Registry v\u1ec1 \u0111\u1ec3 serve 9. Logs v\u00e0 metrics \u0111\u01b0\u1ee3c scrape t\u1eeb Online Serving API 10. 11. 12. 13. DS push code l\u00ean Github k\u00edch ho\u1ea1t tri\u1ec3n khai t\u1ef1 \u0111\u1ed9ng (CI/CD) cho c\u00e1c pipelines v\u00e0 Online Serving API 14. Ngo\u00e0i data source \u1edf d\u1ea1ng t\u0129nh (static data), streaming data t\u1eeb Kafka s\u1ebd ghi li\u00ean t\u1ee5c v\u00e0o Feature Store \u0111\u1ec3 c\u1eadp nh\u1eadt feature C\u00e1c t\u01b0\u01a1ng t\u00e1c v\u00e0 c\u00e1c c\u00f4ng c\u1ee5 \u0111\u01b0\u1ee3c nh\u1eafc \u0111\u1ebfn \u1edf tr\u00ean s\u1ebd \u0111\u01b0\u1ee3c h\u01b0\u1edbng d\u1eabn c\u1ee5 th\u1ec3 xuy\u00ean su\u1ed1t c\u1ea3 kho\u00e1 h\u1ecdc. S\u1eed d\u1ee5ng platform Start \u0110\u1ec3 start c\u00e1c services trong MLOps platform, b\u1ea1n l\u00e0m theo c\u00e1c b\u01b0\u1edbc sau. Clone code mlops-crash-course-platform t\u1ea1i \u0111\u00e2y C\u00e0i Docker theo h\u01b0\u1edbng d\u1eabn t\u1ea1i \u0111\u00e2y C\u00e0i Docker Compose version v2.10.2 theo h\u01b0\u1edbng d\u1eabn t\u1ea1i \u0111\u00e2y Warning Series b\u00e0i gi\u1ea3ng n\u00e0y s\u1eed d\u1ee5ng docker-compose v2.10.2 v\u1edbi command docker-compose (thay v\u00ec compose plugin c\u1ee7a Docker v\u1edbi command docker compose ). S\u1eed d\u1ee5ng version kh\u00e1c v2.10.2 c\u00f3 th\u1ec3 g\u00e2y ra nhi\u1ec1u l\u1ed7i kh\u00f4ng mong mu\u1ed1n. Start services C\u00e1ch 1: Start t\u1ea5t c\u1ea3 services m\u1ed9t l\u00fac ( n\u1ebfu m\u00e1y b\u1ea1n c\u00f3 c\u1ea5u h\u00ecnh m\u1ea1nh ): cd mlops-crash-course-platform bash run.sh all up Info M\u1ed7i b\u00e0i h\u1ecdc ti\u1ebfp theo s\u1ebd h\u01b0\u1edbng d\u1eabn c\u00e1ch start c\u00e1c service li\u00ean quan \u0111\u1ebfn b\u00e0i h\u1ecdc \u0111\u00f3. Do v\u1eady, b\u1ea1n kh\u00f4ng c\u1ea7n ph\u1ea3i start t\u1ea5t c\u1ea3 c\u00e1c services c\u00f9ng m\u1ed9t l\u00fac. C\u00e1ch 2: Start t\u1eebng nh\u00f3m service m\u1ed9t: cd mlops-crash-course-platform bash run.sh feast up # (1) Start c\u00e1c service li\u00ean quan \u0111\u1ebfn feast Bug Khi start c\u00e1c service, n\u1ebfu b\u1ea1n g\u1eb7p l\u1ed7i port is already allocated t\u01b0\u01a1ng t\u1ef1 nh\u01b0 sau: Error response from daemon: driver failed programming external connectivity on endpoint mlflow-mlflow-1 ( 2383a7be19ea5d2449033194211cabbd7ad13902d8d4c2dd215a63ab78038283 ) : Bind for 0 .0.0.0:5000 failed: port is already allocated c\u00f3 ngh\u0129a l\u00e0 \u0111ang c\u00f3 m\u1ed9t service kh\u00e1c ch\u1ea1y \u1edf port 5000 v\u00e0 mlflow kh\u00f4ng th\u1ec3 s\u1eed d\u1ee5ng port \u0111\u00f3 n\u1eefa, khi \u0111\u00f3 b\u1ea1n s\u1ebd thay b\u1eb1ng port kh\u00e1c nh\u01b0 b\u00ean d\u01b0\u1edbi \u0111\u00e2y. B\u1ea1n s\u1ebd x\u1eed l\u00fd t\u01b0\u01a1ng t\u1ef1 v\u1edbi c\u00e1c service kh\u00e1c. mlops-crash-course-platform/mlflow/mlflow-docker-compose.yml 1 2 3 4 5 6 7 8 9 # Source: https://hub.docker.com/r/atcommons/mlflow-server version : '3' services : mlflow : ... ports : - \"5000:5000\" # (1) ... Thay b\u1eb1ng \"another_port:5000\" , v\u00ed d\u1ee5\" \"5001:5000\" . Khi \u0111\u00f3, sau khi start service mlflow b\u1ea1n s\u1ebd truy c\u1eadp service n\u00e0y t\u1ea1i http://localhost:5001 . Stop \u0110\u1ec3 stop c\u00e1c services trong MLOps platform, b\u1ea1n l\u00e0m theo c\u00e1c c\u00e1ch sau. C\u00e1ch 1: Stop t\u1ea5t c\u1ea3 service m\u00e0 kh\u00f4ng l\u00e0m m\u1ea5t docker volumes li\u00ean quan cd mlops-crash-course-platform bash run.sh all down C\u00e1ch 2: Stop m\u1ed9t nh\u00f3m service m\u00e0 kh\u00f4ng l\u00e0m m\u1ea5t docker volumes li\u00ean quan cd mlops-crash-course-platform bash run.sh feast down C\u00e1ch 3: Stop service v\u00e0 docker volumes li\u00ean quan t\u1edbi service cd mlops-crash-course-platform bash run.sh feast down --volumes # (1) bash run.sh all down --volumes # (2) Stop service feast v\u00e0 docker volumes li\u00ean quan t\u1edbi service n\u00e0y Stop t\u1ea5t c\u1ea3 services v\u00e0 docker volumes li\u00ean quan Warning S\u1eed d\u1ee5ng c\u00e1ch 3 s\u1ebd kh\u00f4ng xo\u00e1 data n\u1eb1m trong c\u00e1c local folders m\u00e0 \u0111\u01b0\u1ee3c mount v\u1edbi c\u00e1c docker containers c\u1ee7a c\u00e1c services. \u0110\u1ec3 xo\u00e1 ho\u00e0n to\u00e0n data li\u00ean quan t\u1edbi services, b\u1ea1n c\u1ea7n xo\u00e1 c\u00e1c local folders n\u00e0y th\u1ee7 c\u00f4ng. C\u00e1c b\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau: Trong repo mlops-crash-course-platform , m\u1edf folder t\u01b0\u01a1ng \u1ee9ng v\u1edbi service b\u1ea1n mu\u1ed1n xo\u00e1 data, v\u00ed d\u1ee5 folder airflow Xo\u00e1 to\u00e0n b\u1ed9 folders/files trong folder airflow/run_env , tr\u1eeb file .gitkeep Restart \u0110\u1ec3 restart c\u00e1c services trong MLOps platform, b\u1ea1n l\u00e0m nh\u01b0 d\u01b0\u1edbi \u0111\u00e2y. cd mlops-crash-course-platform bash run.sh feast restart # (1) bash run.sh all restart # (2) Restart service feast Restart t\u1ea5t c\u1ea3 services C\u1ea5u tr\u00fac code \u0110\u1ec3 ti\u1ec7n cho vi\u1ec7c code \u0111\u1ed3ng th\u1eddi qu\u1ea3n l\u00fd c\u00e1c service trong MLOps platform th\u00ec b\u1ea1n \u0111\u1eb7t repo mlops-crash-course-platform v\u00e0 mlops-crash-course-code trong c\u00f9ng 1 folder nh\u01b0 sau: mlops - crash - course \u251c\u2500\u2500 mlops - crash - course - platform / \u2514\u2500\u2500 mlops - crash - course - code / Trong \u0111\u00f3: Repo mlops-crash-course-platform : ch\u1ee9a docker-compose files \u0111\u1ec3 tri\u1ec3n khai MLOps platform Repo mlops-crash-course-code : ch\u1ee9a code c\u1ee7a d\u1ef1 \u00e1n ML m\u00e0 ch\u00fang ta s\u1ebd ph\u00e1t tri\u1ec3n v\u00e0 s\u1eed d\u1ee5ng MLOps platform Warning Trong m\u1ed7i module \u1edf mlops-crash-course-code/ v\u00ed d\u1ee5 nh\u01b0: data_pipeline v\u00e0 model_serving s\u1ebd \u0111\u1ec1u c\u00f3 1 file l\u00e0 dev_requirements.txt . B\u1ea1n h\u00e3y t\u1ea1o m\u1ed9t m\u00f4i tr\u01b0\u1eddng m\u1edbi t\u01b0\u01a1ng t\u1ef1 nh\u01b0 b\u00ean d\u01b0\u1edbi tr\u01b0\u1edbc khi c\u00e0i \u0111\u1eb7t c\u00e1c th\u01b0 vi\u1ec7n \u0111\u1ec3 tr\u00e1nh xung \u0111\u1ed9t th\u01b0 vi\u1ec7n v\u1edbi c\u00e1c d\u1ef1 \u00e1n kh\u00e1c: conda create -n myenv python = 3 .9 conda activate myenv cd data_pipeline pip install -r dev_requirements.txt Infra layer Ph\u1ea7n n\u00e0y cung c\u1ea5p cho b\u1ea1n m\u1ed9t c\u00e1i nh\u00ecn t\u1ed5ng quan h\u01a1n n\u1eefa v\u1ec1 MLOps platform khi \u0111\u01b0\u1ee3c \u0111\u1eb7t trong c\u01a1 s\u1edf h\u1ea1 t\u1ea7ng IT c\u1ee7a m\u1ed9t t\u1ed5 ch\u1ee9c. Th\u00f4ng th\u01b0\u1eddng, m\u1ed9t t\u1ed5 ch\u1ee9c s\u1ebd c\u00f3 m\u1ed9t nh\u00f3m c\u00e1c k\u1ef9 s\u01b0 h\u1ea1 t\u1ea7ng (Infra engineer) l\u00e0m nhi\u1ec7m v\u1ee5 x\u00e2y d\u1ef1ng Infra layer. Ch\u1ee9c n\u0103ng ch\u00ednh c\u1ee7a Infra layer l\u00e0 qu\u1ea3n l\u00fd, cung c\u1ea5p t\u00e0i nguy\u00ean t\u00ednh to\u00e1n, l\u01b0u tr\u1eef cho c\u00e1c \u1ee9ng d\u1ee5ng \u1edf c\u00e1c layer tr\u00ean n\u00f3. Infra layer c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng \u0111\u01a1n gi\u1ea3n s\u1eed d\u1ee5ng docker-compose, Docker Swarm ho\u1eb7c ph\u1ee9c t\u1ea1p h\u01a1n nh\u01b0 Kubernetes. Trong kho\u00e1 h\u1ecdc n\u00e0y, gi\u1ea3 s\u1eed r\u1eb1ng ch\u00fang ta s\u1eed d\u1ee5ng docker-compose \u1edf Infra layer \u0111\u1ec3 qu\u1ea3n l\u00fd c\u00e1c containers v\u00e0 cung c\u1ea5p t\u00e0i nguy\u00ean t\u00ednh to\u00e1n, l\u01b0u tr\u1eef cho c\u00e1c service. Tr\u00ean Infra layer l\u00e0 Application layer hay ch\u00ednh l\u00e0 n\u01a1i m\u00e0 c\u00e1c engineer kh\u00e1c x\u00e2y d\u1ef1ng c\u00e1c \u1ee9ng d\u1ee5ng cho ch\u00ednh t\u1ed5 ch\u1ee9c \u0111\u00f3. C\u00e1c \u1ee9ng d\u1ee5ng n\u00e0y c\u00f3 th\u1ec3 l\u00e0 m\u00f4i tr\u01b0\u1eddng Jupyter notebook, Gitlab server, Jenkins server, monitoring platform, v.v. MLOps platform m\u00e0 ch\u00fang ta \u0111ang x\u00e2y d\u1ef1ng c\u0169ng n\u1eb1m tr\u00ean Application layer n\u00e0y. T\u1ed5ng k\u1ebft Sau khi \u0111\u00e3 tr\u1ea3 l\u1eddi m\u1ed9t lo\u1ea1t c\u00e1c c\u00e2u h\u1ecfi v\u1ec1 h\u1ec7 th\u1ed1ng ML \u1edf b\u00e0i tr\u01b0\u1edbc v\u00e0 \u0111\u1ecbnh ngh\u0129a MLOps platform \u1edf b\u00e0i n\u00e0y, ch\u00fang ta \u0111\u00e3 c\u00f3 m\u1ed9t c\u00e1i nh\u00ecn k\u0129 l\u01b0\u1ee1ng h\u01a1n v\u1ec1 h\u1ec7 th\u1ed1ng c\u1ea7n \u0111\u01b0\u1ee3c ph\u00e1t tri\u1ec3n. Trong b\u00e0i ti\u1ebfp theo, b\u1ea1n s\u1ebd \u0111\u01b0\u1ee3c t\u00ecm hi\u1ec3u v\u1ec1 c\u00e1c c\u00f4ng vi\u1ec7c v\u00e0 c\u00e1ch ho\u1ea1t \u0111\u1ed9ng c\u0169ng nh\u01b0 tri\u1ec3n khai m\u1ed9t d\u1ef1 \u00e1n POC. T\u00e0i li\u1ec7u tham kh\u1ea3o https://ml-ops.org/content/end-to-end-ml-workflow https://valohai.com/mlops-platforms-compared/ https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning","title":"MLOps platform"},{"location":"mlops-crash-course/tong-quan-he-thong/mlops-platform.html#gioi-thieu","text":"MLOps platform l\u00e0 n\u1ec1n t\u1ea3ng cung c\u1ea5p c\u00e1c c\u00f4ng c\u1ee5 c\u1ea7n thi\u1ebft \u0111\u1ec3 ph\u00e1t tri\u1ec3n, qu\u1ea3n l\u00fd v\u00e0 tri\u1ec3n khai c\u00e1c d\u1ef1 \u00e1n ML. Trong m\u1ed9t s\u1ed1 t\u00e0i li\u1ec7u kh\u00e1c MLOps platform c\u00f2n c\u00f3 t\u00ean l\u00e0 AI platform ho\u1eb7c ML platform. \u1ede kh\u00f3a h\u1ecdc n\u00e0y ch\u00fang ta s\u1ebd s\u1eed d\u1ee5ng m\u1ed9t MLOps platform v\u1edbi c\u00e1c th\u00e0nh ph\u1ea7n v\u00e0 c\u00f4ng c\u1ee5 t\u01b0\u01a1ng \u1ee9ng nh\u01b0 sau: T\u00ean th\u00e0nh ph\u1ea7n \u00dd ngh\u0129a Tool s\u1eed d\u1ee5ng Source control Qu\u1ea3n l\u00fd c\u00e1c phi\u00ean b\u1ea3n v\u1ec1 m\u00e3 ngu\u1ed3n v\u00e0 d\u1eef li\u1ec7u Git & Github Feature store L\u01b0u tr\u1eef, qu\u1ea3n l\u00fd v\u00e0 t\u01b0\u01a1ng t\u00e1c v\u1edbi c\u00e1c t\u00ednh n\u0103ng (feature) Feast (PostgreSQL & Redis backend) Experiment tracking L\u01b0u tr\u1eef th\u00f4ng tin v\u00e0 qu\u1ea3n l\u00fd c\u00e1c th\u00ed nghi\u1ec7m (experiments) MLFlow Model registry L\u01b0u tr\u1eef v\u00e0 qu\u1ea3n l\u00fd c\u00e1c m\u00f4 h\u00ecnh MLFlow ML metadata Store L\u01b0u tr\u1eef th\u00f4ng tin (artifact) c\u1ee7a c\u00e1c lu\u1ed3ng (pipeline) MLFlow Workflow orchestrator X\u00e2y d\u1ef1ng v\u00e0 qu\u1ea3n l\u00fd c\u00e1c lu\u1ed3ng quy tr\u00ecnh Airflow Monitoring Theo d\u00f5i t\u00e0i nguy\u00ean h\u1ec7 th\u1ed1ng, hi\u1ec7u n\u0103ng c\u1ee7a m\u00f4 h\u00ecnh v\u00e0 ch\u1ea5t l\u01b0\u1ee3ng d\u1eef li\u1ec7u tr\u00ean production Prometheus & Grafana & ELK CI/CD T\u1ef1 \u0111\u1ed9ng h\u00f3a qu\u00e1 tr\u00ecnh test v\u00e0 deploy Jenkins Info Ch\u00fang ta c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng m\u1ed9t c\u00f4ng c\u1ee5 cho nhi\u1ec1u m\u1ee5c \u0111\u00edch kh\u00e1c nhau, v\u00ed d\u1ee5 MLFlow, v\u1edbi m\u1ee5c \u0111\u00edch s\u1eed d\u1ee5ng t\u1ed1i thi\u1ec3u c\u00e1c c\u00f4ng c\u1ee5 c\u1ea7n thi\u1ebft m\u00e0 v\u1eabn \u0111\u1ea3m b\u1ea3o \u0111\u01b0\u1ee3c 9 MLOps Principles , 9 MLOps Components v\u00e0 5 MLOps Workflows \u0111\u01b0\u1ee3c \u00e1p d\u1ee5ng (xem l\u1ea1i b\u00e0i T\u1ed5ng quan MLOps ). Vi\u1ec7c s\u1eed d\u1ee5ng qu\u00e1 nhi\u1ec1u c\u00f4ng c\u1ee5 c\u00f3 th\u1ec3 d\u1eabn t\u1edbi vi\u1ec7c v\u1eadn h\u00e0nh MLOps platform tr\u1edf n\u00ean ph\u1ee9c t\u1ea1p, \u0111\u1ed3ng th\u1eddi khi\u1ebfn ng\u01b0\u1eddi d\u00f9ng d\u1ec5 b\u1ecb cho\u00e1ng ng\u1ee3p do kh\u00f4ng bi\u1ebft s\u1eed d\u1ee5ng v\u00e0 qu\u1ea3n l\u00fd m\u1ed9t c\u00e1ch hi\u1ec7u qu\u1ea3.","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/tong-quan-he-thong/mlops-platform.html#architecture","text":"Ki\u1ebfn tr\u00fac MLOps platform c\u1ee7a ch\u00fang ta s\u1ebd nh\u01b0 sau: C\u00e1c t\u01b0\u01a1ng t\u00e1c ch\u00ednh trong MLOps platform: 1. Data Pipeline k\u00e9o v\u00e0 x\u1eed l\u00fd d\u1eef li\u1ec7u t\u1eeb file source 2. D\u1eef li\u1ec7u sau khi x\u1eed l\u00fd b\u1edfi Data Pipeline s\u1ebd \u0111\u01b0\u1ee3c \u0111\u1ea9y v\u00e0o Feature Store 3. Data Scientist (DS) k\u00e9o feature t\u1eeb Feature Store \u0111\u1ec3 th\u1ef1c hi\u1ec7n c\u00e1c th\u00ed nghi\u1ec7m tr\u00ean notebook 4. Training Pipeline k\u00e9o feature v\u1ec1 \u0111\u1ec3 train model 5. Metadata c\u1ee7a c\u00e1c experiment, v\u00ed d\u1ee5 nh\u01b0 hyperparameters v\u00e0 metrics, ... \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o Metadata Store 6. Metadata c\u1ee7a Training Pipeline c\u0169ng \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o Metadata Store 7. Model sau khi train s\u1ebd \u0111\u01b0\u1ee3c l\u01b0u tr\u1eef \u1edf Model Registry 8. Batch Serving Pipeline v\u00e0 Online Serving API k\u00e9o model t\u1eeb Model Registry v\u1ec1 \u0111\u1ec3 serve 9. Logs v\u00e0 metrics \u0111\u01b0\u1ee3c scrape t\u1eeb Online Serving API 10. 11. 12. 13. DS push code l\u00ean Github k\u00edch ho\u1ea1t tri\u1ec3n khai t\u1ef1 \u0111\u1ed9ng (CI/CD) cho c\u00e1c pipelines v\u00e0 Online Serving API 14. Ngo\u00e0i data source \u1edf d\u1ea1ng t\u0129nh (static data), streaming data t\u1eeb Kafka s\u1ebd ghi li\u00ean t\u1ee5c v\u00e0o Feature Store \u0111\u1ec3 c\u1eadp nh\u1eadt feature C\u00e1c t\u01b0\u01a1ng t\u00e1c v\u00e0 c\u00e1c c\u00f4ng c\u1ee5 \u0111\u01b0\u1ee3c nh\u1eafc \u0111\u1ebfn \u1edf tr\u00ean s\u1ebd \u0111\u01b0\u1ee3c h\u01b0\u1edbng d\u1eabn c\u1ee5 th\u1ec3 xuy\u00ean su\u1ed1t c\u1ea3 kho\u00e1 h\u1ecdc.","title":"Architecture"},{"location":"mlops-crash-course/tong-quan-he-thong/mlops-platform.html#su-dung-platform","text":"","title":"S\u1eed d\u1ee5ng platform"},{"location":"mlops-crash-course/tong-quan-he-thong/mlops-platform.html#start","text":"\u0110\u1ec3 start c\u00e1c services trong MLOps platform, b\u1ea1n l\u00e0m theo c\u00e1c b\u01b0\u1edbc sau. Clone code mlops-crash-course-platform t\u1ea1i \u0111\u00e2y C\u00e0i Docker theo h\u01b0\u1edbng d\u1eabn t\u1ea1i \u0111\u00e2y C\u00e0i Docker Compose version v2.10.2 theo h\u01b0\u1edbng d\u1eabn t\u1ea1i \u0111\u00e2y Warning Series b\u00e0i gi\u1ea3ng n\u00e0y s\u1eed d\u1ee5ng docker-compose v2.10.2 v\u1edbi command docker-compose (thay v\u00ec compose plugin c\u1ee7a Docker v\u1edbi command docker compose ). S\u1eed d\u1ee5ng version kh\u00e1c v2.10.2 c\u00f3 th\u1ec3 g\u00e2y ra nhi\u1ec1u l\u1ed7i kh\u00f4ng mong mu\u1ed1n. Start services C\u00e1ch 1: Start t\u1ea5t c\u1ea3 services m\u1ed9t l\u00fac ( n\u1ebfu m\u00e1y b\u1ea1n c\u00f3 c\u1ea5u h\u00ecnh m\u1ea1nh ): cd mlops-crash-course-platform bash run.sh all up Info M\u1ed7i b\u00e0i h\u1ecdc ti\u1ebfp theo s\u1ebd h\u01b0\u1edbng d\u1eabn c\u00e1ch start c\u00e1c service li\u00ean quan \u0111\u1ebfn b\u00e0i h\u1ecdc \u0111\u00f3. Do v\u1eady, b\u1ea1n kh\u00f4ng c\u1ea7n ph\u1ea3i start t\u1ea5t c\u1ea3 c\u00e1c services c\u00f9ng m\u1ed9t l\u00fac. C\u00e1ch 2: Start t\u1eebng nh\u00f3m service m\u1ed9t: cd mlops-crash-course-platform bash run.sh feast up # (1) Start c\u00e1c service li\u00ean quan \u0111\u1ebfn feast Bug Khi start c\u00e1c service, n\u1ebfu b\u1ea1n g\u1eb7p l\u1ed7i port is already allocated t\u01b0\u01a1ng t\u1ef1 nh\u01b0 sau: Error response from daemon: driver failed programming external connectivity on endpoint mlflow-mlflow-1 ( 2383a7be19ea5d2449033194211cabbd7ad13902d8d4c2dd215a63ab78038283 ) : Bind for 0 .0.0.0:5000 failed: port is already allocated c\u00f3 ngh\u0129a l\u00e0 \u0111ang c\u00f3 m\u1ed9t service kh\u00e1c ch\u1ea1y \u1edf port 5000 v\u00e0 mlflow kh\u00f4ng th\u1ec3 s\u1eed d\u1ee5ng port \u0111\u00f3 n\u1eefa, khi \u0111\u00f3 b\u1ea1n s\u1ebd thay b\u1eb1ng port kh\u00e1c nh\u01b0 b\u00ean d\u01b0\u1edbi \u0111\u00e2y. B\u1ea1n s\u1ebd x\u1eed l\u00fd t\u01b0\u01a1ng t\u1ef1 v\u1edbi c\u00e1c service kh\u00e1c. mlops-crash-course-platform/mlflow/mlflow-docker-compose.yml 1 2 3 4 5 6 7 8 9 # Source: https://hub.docker.com/r/atcommons/mlflow-server version : '3' services : mlflow : ... ports : - \"5000:5000\" # (1) ... Thay b\u1eb1ng \"another_port:5000\" , v\u00ed d\u1ee5\" \"5001:5000\" . Khi \u0111\u00f3, sau khi start service mlflow b\u1ea1n s\u1ebd truy c\u1eadp service n\u00e0y t\u1ea1i http://localhost:5001 .","title":"Start"},{"location":"mlops-crash-course/tong-quan-he-thong/mlops-platform.html#stop","text":"\u0110\u1ec3 stop c\u00e1c services trong MLOps platform, b\u1ea1n l\u00e0m theo c\u00e1c c\u00e1ch sau. C\u00e1ch 1: Stop t\u1ea5t c\u1ea3 service m\u00e0 kh\u00f4ng l\u00e0m m\u1ea5t docker volumes li\u00ean quan cd mlops-crash-course-platform bash run.sh all down C\u00e1ch 2: Stop m\u1ed9t nh\u00f3m service m\u00e0 kh\u00f4ng l\u00e0m m\u1ea5t docker volumes li\u00ean quan cd mlops-crash-course-platform bash run.sh feast down C\u00e1ch 3: Stop service v\u00e0 docker volumes li\u00ean quan t\u1edbi service cd mlops-crash-course-platform bash run.sh feast down --volumes # (1) bash run.sh all down --volumes # (2) Stop service feast v\u00e0 docker volumes li\u00ean quan t\u1edbi service n\u00e0y Stop t\u1ea5t c\u1ea3 services v\u00e0 docker volumes li\u00ean quan Warning S\u1eed d\u1ee5ng c\u00e1ch 3 s\u1ebd kh\u00f4ng xo\u00e1 data n\u1eb1m trong c\u00e1c local folders m\u00e0 \u0111\u01b0\u1ee3c mount v\u1edbi c\u00e1c docker containers c\u1ee7a c\u00e1c services. \u0110\u1ec3 xo\u00e1 ho\u00e0n to\u00e0n data li\u00ean quan t\u1edbi services, b\u1ea1n c\u1ea7n xo\u00e1 c\u00e1c local folders n\u00e0y th\u1ee7 c\u00f4ng. C\u00e1c b\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau: Trong repo mlops-crash-course-platform , m\u1edf folder t\u01b0\u01a1ng \u1ee9ng v\u1edbi service b\u1ea1n mu\u1ed1n xo\u00e1 data, v\u00ed d\u1ee5 folder airflow Xo\u00e1 to\u00e0n b\u1ed9 folders/files trong folder airflow/run_env , tr\u1eeb file .gitkeep","title":"Stop"},{"location":"mlops-crash-course/tong-quan-he-thong/mlops-platform.html#restart","text":"\u0110\u1ec3 restart c\u00e1c services trong MLOps platform, b\u1ea1n l\u00e0m nh\u01b0 d\u01b0\u1edbi \u0111\u00e2y. cd mlops-crash-course-platform bash run.sh feast restart # (1) bash run.sh all restart # (2) Restart service feast Restart t\u1ea5t c\u1ea3 services","title":"Restart"},{"location":"mlops-crash-course/tong-quan-he-thong/mlops-platform.html#cau-truc-code","text":"\u0110\u1ec3 ti\u1ec7n cho vi\u1ec7c code \u0111\u1ed3ng th\u1eddi qu\u1ea3n l\u00fd c\u00e1c service trong MLOps platform th\u00ec b\u1ea1n \u0111\u1eb7t repo mlops-crash-course-platform v\u00e0 mlops-crash-course-code trong c\u00f9ng 1 folder nh\u01b0 sau: mlops - crash - course \u251c\u2500\u2500 mlops - crash - course - platform / \u2514\u2500\u2500 mlops - crash - course - code / Trong \u0111\u00f3: Repo mlops-crash-course-platform : ch\u1ee9a docker-compose files \u0111\u1ec3 tri\u1ec3n khai MLOps platform Repo mlops-crash-course-code : ch\u1ee9a code c\u1ee7a d\u1ef1 \u00e1n ML m\u00e0 ch\u00fang ta s\u1ebd ph\u00e1t tri\u1ec3n v\u00e0 s\u1eed d\u1ee5ng MLOps platform Warning Trong m\u1ed7i module \u1edf mlops-crash-course-code/ v\u00ed d\u1ee5 nh\u01b0: data_pipeline v\u00e0 model_serving s\u1ebd \u0111\u1ec1u c\u00f3 1 file l\u00e0 dev_requirements.txt . B\u1ea1n h\u00e3y t\u1ea1o m\u1ed9t m\u00f4i tr\u01b0\u1eddng m\u1edbi t\u01b0\u01a1ng t\u1ef1 nh\u01b0 b\u00ean d\u01b0\u1edbi tr\u01b0\u1edbc khi c\u00e0i \u0111\u1eb7t c\u00e1c th\u01b0 vi\u1ec7n \u0111\u1ec3 tr\u00e1nh xung \u0111\u1ed9t th\u01b0 vi\u1ec7n v\u1edbi c\u00e1c d\u1ef1 \u00e1n kh\u00e1c: conda create -n myenv python = 3 .9 conda activate myenv cd data_pipeline pip install -r dev_requirements.txt","title":"C\u1ea5u tr\u00fac code"},{"location":"mlops-crash-course/tong-quan-he-thong/mlops-platform.html#infra-layer","text":"Ph\u1ea7n n\u00e0y cung c\u1ea5p cho b\u1ea1n m\u1ed9t c\u00e1i nh\u00ecn t\u1ed5ng quan h\u01a1n n\u1eefa v\u1ec1 MLOps platform khi \u0111\u01b0\u1ee3c \u0111\u1eb7t trong c\u01a1 s\u1edf h\u1ea1 t\u1ea7ng IT c\u1ee7a m\u1ed9t t\u1ed5 ch\u1ee9c. Th\u00f4ng th\u01b0\u1eddng, m\u1ed9t t\u1ed5 ch\u1ee9c s\u1ebd c\u00f3 m\u1ed9t nh\u00f3m c\u00e1c k\u1ef9 s\u01b0 h\u1ea1 t\u1ea7ng (Infra engineer) l\u00e0m nhi\u1ec7m v\u1ee5 x\u00e2y d\u1ef1ng Infra layer. Ch\u1ee9c n\u0103ng ch\u00ednh c\u1ee7a Infra layer l\u00e0 qu\u1ea3n l\u00fd, cung c\u1ea5p t\u00e0i nguy\u00ean t\u00ednh to\u00e1n, l\u01b0u tr\u1eef cho c\u00e1c \u1ee9ng d\u1ee5ng \u1edf c\u00e1c layer tr\u00ean n\u00f3. Infra layer c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng \u0111\u01a1n gi\u1ea3n s\u1eed d\u1ee5ng docker-compose, Docker Swarm ho\u1eb7c ph\u1ee9c t\u1ea1p h\u01a1n nh\u01b0 Kubernetes. Trong kho\u00e1 h\u1ecdc n\u00e0y, gi\u1ea3 s\u1eed r\u1eb1ng ch\u00fang ta s\u1eed d\u1ee5ng docker-compose \u1edf Infra layer \u0111\u1ec3 qu\u1ea3n l\u00fd c\u00e1c containers v\u00e0 cung c\u1ea5p t\u00e0i nguy\u00ean t\u00ednh to\u00e1n, l\u01b0u tr\u1eef cho c\u00e1c service. Tr\u00ean Infra layer l\u00e0 Application layer hay ch\u00ednh l\u00e0 n\u01a1i m\u00e0 c\u00e1c engineer kh\u00e1c x\u00e2y d\u1ef1ng c\u00e1c \u1ee9ng d\u1ee5ng cho ch\u00ednh t\u1ed5 ch\u1ee9c \u0111\u00f3. C\u00e1c \u1ee9ng d\u1ee5ng n\u00e0y c\u00f3 th\u1ec3 l\u00e0 m\u00f4i tr\u01b0\u1eddng Jupyter notebook, Gitlab server, Jenkins server, monitoring platform, v.v. MLOps platform m\u00e0 ch\u00fang ta \u0111ang x\u00e2y d\u1ef1ng c\u0169ng n\u1eb1m tr\u00ean Application layer n\u00e0y.","title":"Infra layer"},{"location":"mlops-crash-course/tong-quan-he-thong/mlops-platform.html#tong-ket","text":"Sau khi \u0111\u00e3 tr\u1ea3 l\u1eddi m\u1ed9t lo\u1ea1t c\u00e1c c\u00e2u h\u1ecfi v\u1ec1 h\u1ec7 th\u1ed1ng ML \u1edf b\u00e0i tr\u01b0\u1edbc v\u00e0 \u0111\u1ecbnh ngh\u0129a MLOps platform \u1edf b\u00e0i n\u00e0y, ch\u00fang ta \u0111\u00e3 c\u00f3 m\u1ed9t c\u00e1i nh\u00ecn k\u0129 l\u01b0\u1ee1ng h\u01a1n v\u1ec1 h\u1ec7 th\u1ed1ng c\u1ea7n \u0111\u01b0\u1ee3c ph\u00e1t tri\u1ec3n. Trong b\u00e0i ti\u1ebfp theo, b\u1ea1n s\u1ebd \u0111\u01b0\u1ee3c t\u00ecm hi\u1ec3u v\u1ec1 c\u00e1c c\u00f4ng vi\u1ec7c v\u00e0 c\u00e1ch ho\u1ea1t \u0111\u1ed9ng c\u0169ng nh\u01b0 tri\u1ec3n khai m\u1ed9t d\u1ef1 \u00e1n POC.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/tong-quan-he-thong/mlops-platform.html#tai-lieu-tham-khao","text":"https://ml-ops.org/content/end-to-end-ml-workflow https://valohai.com/mlops-platforms-compared/ https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning","title":"T\u00e0i li\u1ec7u tham kh\u1ea3o"},{"location":"mlops-crash-course/tong-quan-he-thong/phan-tich-van-de.html","text":"Gi\u1edbi thi\u1ec7u H\u1ec7 th\u1ed1ng ML t\u01b0\u01a1ng t\u1ef1 nh\u01b0 l\u00e0 h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m. Khi x\u00e2y d\u1ef1ng h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m, vi\u1ec7c \u0111\u1ea7u ti\u00ean c\u1ea7n l\u00e0m \u0111\u00f3 l\u00e0 x\u00e1c \u0111\u1ecbnh c\u00e1c v\u1ea5n \u0111\u1ec1 v\u00e0 c\u1ee5 th\u1ec3 ho\u00e1 th\u00e0nh c\u00e1c y\u00eau c\u1ea7u c\u00f3 th\u1ec3 \u0111\u00e1nh gi\u00e1 \u0111\u01b0\u1ee3c v\u00e0 \u0111\u1ec1 xu\u1ea5t c\u00e1c gi\u1ea3i ph\u00e1p kh\u1ea3 thi \u0111\u1ec3 gi\u1ea3i quy\u1ebft c\u00e1c y\u00eau c\u1ea7u \u0111\u00f3. C\u1ed1t l\u00f5i c\u1ee7a h\u1ec7 th\u1ed1ng ML khi \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng v\u1eabn l\u00e0 \u0111\u01b0a ra v\u00e0 x\u1eed l\u00fd \u0111\u01b0\u1ee3c b\u00e0i to\u00e1n kinh doanh c\u1ee7a m\u1ed9t t\u1ed5 ch\u1ee9c. Trong kho\u00e1 h\u1ecdc n\u00e0y, ch\u00fang ta c\u00f9ng nhau t\u00ecm hi\u1ec3u b\u00e0i to\u00e1n gi\u1ea3 \u0111\u1ecbnh c\u1ee7a m\u1ed9t c\u00f4ng ty c\u00f3 m\u00f4 h\u00ecnh kinh doanh t\u01b0\u01a1ng t\u1ef1 Grab v\u00e0 \u0111\u00e3 t\u00ecm hi\u1ec3u v\u1ec1 ML ch\u1ecdn \u0111\u00f3 l\u00e0m gi\u1ea3i ph\u00e1p, v\u1ea5n \u0111\u1ec1 kinh doanh c\u1ee7a c\u00f4ng ty c\u1ee7a b\u1ea1n l\u00e0: L\u00e0m th\u1ebf n\u00e0o \u0111\u1ec3 ch\u1ecdn ra t\u00e0i x\u1ebf c\u00f3 kh\u1ea3 n\u0103ng cao nh\u1ea5t s\u1ebd ho\u00e0n th\u00e0nh m\u1ed9t cu\u1ed1c xe khi c\u00f3 y\u00eau c\u1ea7u \u0111\u1eb7t xe t\u1eeb kh\u00e1ch h\u00e0ng? H\u00ecnh d\u01b0\u1edbi \u0111\u00e2y th\u1ec3 hi\u1ec7n y\u00eau c\u1ea7u v\u1ec1 \u0111\u1ea7u v\u00e0o v\u00e0 \u0111\u1ea7u ra c\u1ee7a v\u1ea5n \u0111\u1ec1. graph LR n01[ ] --Th\u00f4ng tin t\u00e0i x\u1ebf 1--> n1[H\u1ec7 th\u1ed1ng ML] --T\u00e0i x\u1ebf c\u00f3 kh\u1ea3 n\u0103ng cao nh\u1ea5t<br>ho\u00e0n th\u00e0nh cu\u1ed1c xe--> n02[ ] n03[ ] --Th\u00f4ng tin t\u00e0i x\u1ebf 2--> n1 n04[ ] --Th\u00f4ng tin t\u00e0i x\u1ebf 3--> n1 style n01 height:0px; style n02 height:0px; style n03 height:0px; style n04 height:0px; Ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1 Qu\u00e1 tr\u00ecnh \u0111\u1ecbnh ngh\u0129a v\u1ea5n \u0111\u1ec1 kinh doanh l\u00e0 qu\u00e1 tr\u00ecnh tr\u1ea3 l\u1eddi nhi\u1ec1u c\u00e2u h\u1ecfi. B\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y li\u1ec7t k\u00ea c\u00e1c c\u00e2u h\u1ecfi ti\u00eau bi\u1ec3u v\u00e0 c\u00e1c c\u00e2u tr\u1ea3 l\u1eddi. Ch\u1ee7 \u0111\u1ec1 C\u00e2u h\u1ecfi Tr\u1ea3 l\u1eddi M\u1ee5c ti\u00eau M\u1ee5c ti\u00eau kinh doanh? T\u0103ng s\u1ed1 l\u01b0\u1ee3ng cu\u1ed1c xe \u0111\u01b0\u1ee3c ho\u00e0n th\u00e0nh trong 1 th\u00e1ng 10% C\u00e1c ch\u1ee9c n\u0103ng ch\u00ednh? Ch\u1ecdn t\u00e0i x\u1ebf c\u00f3 kh\u1ea3 n\u0103ng cao nh\u1ea5t ho\u00e0n th\u00e0nh cu\u1ed1c xe C\u00e1c b\u00ean li\u00ean quan Ai l\u00e0 ng\u01b0\u1eddi tham gia? Vai tr\u00f2 v\u00e0 tr\u00e1ch nhi\u1ec7m? Product owner, Product manager, Solution Architect, Data Scientist, Data engineer, ML engineer Ai c\u1ea7n \u0111\u01b0\u1ee3c th\u00f4ng b\u00e1o v\u1ec1 d\u1ef1 \u00e1n? Head of Engineering, CTO, CEO Ai l\u00e0 ng\u01b0\u1eddi d\u00f9ng cu\u1ed1i? Kh\u00e1ch h\u00e0ng Data C\u00f3 th\u1ec3 l\u1ea5y \u1edf c\u00e1c ngu\u1ed3n n\u00e0o? Static data v\u00e0 streaming data t\u1eeb \u1ee9ng d\u1ee5ng \u0111\u1eb7t xe c\u1ee7a c\u00f4ng ty \u0110\u1ecbnh ngh\u0129a quy tr\u00ecnh \u0111\u1ec3 bi\u1ebfn \u0111\u1ed5i data sang format c\u00f3 th\u1ec3 d\u00f9ng \u0111\u01b0\u1ee3c? Gi\u1ea3 s\u1eed quy tr\u00ecnh \u0111\u1ec3 bi\u1ebfn \u0111\u1ed5i data, feature engineering \u0111\u00e3 \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a Ph\u00e1t tri\u1ec3n model C\u00f3 gi\u1ea3i ph\u00e1p n\u00e0o \u0111\u00e3 \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n \u0111\u1ec3 \u0111\u1ed1i chi\u1ebfu? Gi\u1ea3 s\u1eed \u0111\u00e3 t\u00ecm hi\u1ec3u c\u00e1c gi\u1ea3i ph\u00e1p c\u1ee7a \u0111\u1ed1i th\u1ee7 c\u1ea1nh tranh C\u00f3 nh\u1eefng thresholds n\u00e0o \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 khi\u1ebfn gi\u1ea3i ph\u00e1p tr\u1edf n\u00ean h\u1eefu \u00edch? Model inference kh\u00f4ng \u0111\u01b0\u1ee3c ch\u1ea1y qu\u00e1 500ms C\u00e2n nh\u1eafc tradeoffs False positives (false alarm) c\u00f3 \u1ea3nh h\u01b0\u1edfng nghi\u00eam tr\u1ecdng h\u01a1n C\u00f3 c\u1ea7n confidence score kh\u00f4ng? D\u00f9ng threshold n\u00e0o? Kh\u00f4ng c\u1ea7n, rank c\u00e1c t\u00e0i x\u1ebf theo x\u00e1c su\u1ea5t m\u00e0 model d\u1ef1 \u0111o\u00e1n sau L\u00e0m g\u00ec v\u1edbi c\u00e1c d\u1ef1 \u0111o\u00e1n kh\u00f4ng \u0111\u01b0\u1ee3c ch\u1ecdn? \u0110\u01b0\u1ee3c log l\u1ea1i v\u00e0 g\u00e1n label \u0110\u00e1nh gi\u00e1 model D\u00f9ng metrics n\u00e0o \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 model l\u00fac ph\u00e1t tri\u1ec3n v\u00e0 \u1edf production? D\u00f9ng metrics Root Mean Square Error (RMSE) L\u00e0m sao \u0111\u1ec3 li\u00ean k\u1ebft model performance v\u1edbi m\u1ee5c ti\u00eau kinh doanh? \u1ede production, ngo\u00e0i RMSE \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 model performance, c\u1ea7n t\u00ednh t\u1ec9 l\u1ec7 ho\u00e0n th\u00e0nh c\u00e1c cu\u1ed1c xe trong 1 th\u00e1ng g\u1ea7n nh\u1ea5t Tri\u1ec3n khai Data c\u1ee7a qu\u00e1 tr\u00ecnh inference s\u1ebd \u0111\u01b0\u1ee3c l\u1ea5y t\u1eeb \u0111\u00e2u? \u0110\u01b0\u1ee3c format v\u00e0 l\u01b0u tr\u1eef th\u1ebf n\u00e0o? Data \u0111\u1ea7u v\u00e0o c\u1ee7a qu\u00e1 tr\u00ecnh inference \u0111\u01b0\u1ee3c l\u1ea5y t\u1eeb Online Feature Store (s\u1ebd \u0111\u01b0\u1ee3c gi\u1ea3i th\u00edch trong b\u00e0i Model serving ) Model \u0111\u01b0\u1ee3c tri\u1ec3n khai \u1edf \u0111\u00e2u? L\u00ean server n\u1ed9i b\u1ed9 c\u1ee7a c\u00f4ng ty Khi n\u00e0o ch\u1ea1y batch prediction? Khi n\u00e0o ch\u1ea1y online prediction? Ch\u1ea1y batch prediction m\u1ed7i gi\u1edd cho c\u00e1c t\u00e0i x\u1ebf \u00edt ho\u1ea1t \u0111\u1ed9ng, data \u00edt thay \u0111\u1ed5i. Ch\u1ea1y online prediction cho c\u00e1c t\u00e0i x\u1ebf ho\u1ea1t \u0111\u1ed9ng nhi\u1ec1u T\u1ed1c \u0111\u1ed9 thay \u0111\u1ed5i c\u1ee7a data th\u1ebf n\u00e0o? V\u00e0i features s\u1ebd thay \u0111\u1ed5i kh\u00f4ng th\u01b0\u1eddng xuy\u00ean, \u0111\u1eb7t l\u1ecbch \u0111\u1ec3 c\u1eadp nh\u1eadt h\u00e0ng ng\u00e0y. V\u00e0i features c\u1ea7n l\u1ea5y t\u1eeb streaming data, c\u1ea7n data pipeline ri\u00eang \u0111\u1ec3 x\u1eed l\u00fd v\u00e0 l\u01b0u tr\u1eef Bao l\u00e2u th\u00ec c\u1ea7n train l\u1ea1i model? D\u1ef1a v\u00e0o t\u1ed1c \u0111\u1ed9 thay \u0111\u1ed5i c\u1ee7a data ho\u1eb7c ch\u1ea5t l\u01b0\u1ee3ng data \u1edf production Labels \u1edf production \u0111\u01b0\u1ee3c thu th\u1eadp nh\u01b0 th\u1ebf n\u00e0o? Sau khi t\u00e0i x\u1ebf \u0111\u01b0\u1ee3c ch\u1ecdn, \u1ee9ng d\u1ee5ng \u0111\u1eb7t xe s\u1ebd tr\u1ea3 v\u1ec1 k\u1ebft qu\u1ea3 xem cu\u1ed1c xe c\u00f3 ho\u00e0n th\u00e0nh kh\u00f4ng Quy\u1ec1n ri\u00eang t\u01b0 C\u00f3 y\u00eau c\u1ea7u n\u00e0o v\u1ec1 quy\u1ec1n ri\u00eang t\u01b0 c\u1ee7a data, labels, v.v Data v\u00e0 labels ch\u1ec9 \u0111\u01b0\u1ee3c d\u00f9ng trong n\u1ed9i b\u1ed9 c\u00f4ng ty H\u1ec7 th\u1ed1ng c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c k\u1ebft n\u1ed1i v\u1edbi internet kh\u00f4ng? C\u00f3 C\u00f3 th\u1ec3 gi\u1eef data c\u1ee7a users trong bao l\u00e2u? Kh\u00f4ng gi\u1edbi h\u1ea1n Chi ph\u00ed v\u00e0 l\u1ee3i \u00edch Ng\u00e2n s\u00e1ch ban \u0111\u1ea7u $500,000 So s\u00e1nh chi ph\u00ed v\u00e0 l\u1ee3i \u00edch L\u1ee3i \u00edch l\u1edbn h\u01a1n chi ph\u00ed nhi\u1ec1u, h\u1ec7 th\u1ed1ng c\u00f3 th\u1ec3 t\u00e1i s\u1eed d\u1ee5ng, chi ph\u00ed \u0111\u1ec3 optimize kh\u00f4ng l\u1edbn C\u1ea7n \u0111\u1ea1t y\u00eau c\u1ea7u n\u00e0o \u0111\u1ec3 t\u0103ng kinh ph\u00ed? Ho\u00e0n th\u00e0nh c\u00e1c m\u1ed1c th\u1eddi gian ti\u1ebfp theo, tri\u1ec3n khai model ra production v\u00e0 ti\u1ebfp t\u1ee5c ch\u1ee9ng minh l\u1ee3i \u00edch l\u1edbn h\u01a1n nhi\u1ec1u chi ph\u00ed R\u1ee7i ro Ph\u00e2n t\u00edch r\u1ee7i ro \u0111i k\u00e8m C\u00f3 th\u1ec3 model \u0111\u01b0\u1ee3c \u0111\u00e1nh gi\u00e1 offline l\u00e0 t\u1ed1t, nh\u01b0ng \u1edf production kh\u00f4ng mang l\u1ea1i hi\u1ec7u qu\u1ea3 cao Ph\u00e2n t\u00edch r\u1ee7i ro kinh doanh kh\u00e1c H\u1ebft ti\u1ec1n tr\u01b0\u1edbc khi ho\u00e0n thi\u1ec7n POC R\u00e0ng bu\u1ed9c k\u0129 thu\u1eadt C\u00f3 h\u1ec7 th\u1ed1ng c\u0169 n\u00e0o c\u1ea7n t\u00edch h\u1ee3p v\u1edbi kh\u00f4ng? Kh\u00f4ng Architecture v\u00e0 tools s\u1ebd d\u00f9ng? \u0110\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a \u1edf b\u00e0i ti\u1ebfp theo Ngo\u00e0i m\u1ed9t v\u00e0i c\u00e2u h\u1ecfi \u0111\u01b0\u1ee3c n\u00eau \u1edf tr\u00ean, tu\u1ef3 v\u00e0o m\u1ee5c ti\u00eau kinh doanh s\u1ebd c\u00f3 c\u00e1c v\u1ea5n \u0111\u1ec1 v\u00e0 c\u00e2u h\u1ecfi kh\u00e1c \u0111\u01b0\u1ee3c \u0111\u01b0a ra. Trong b\u1ea3ng tr\u00ean, nhi\u1ec1u c\u00e2u tr\u1ea3 l\u1eddi li\u00ean quan t\u1edbi m\u1ea3ng kinh doanh c\u1ee7a c\u00f4ng ty \u0111\u00e3 \u0111\u01b0\u1ee3c tr\u1ea3 l\u1eddi ng\u1eafn g\u1ecdn. Nh\u1eefng c\u00e2u tr\u1ea3 l\u1eddi n\u00e0y th\u00f4ng th\u01b0\u1eddng \u0111\u01b0\u1ee3c m\u1ed9t \u0111\u1ed9i ng\u0169 c\u00e1c Data Analyst v\u00e0 Business Strategist th\u1ea3o lu\u1eadn, ph\u00e2n t\u00edch, v\u00e0 gi\u1ea3i \u0111\u00e1p. Trong qu\u00e1 tr\u00ecnh th\u1ef1c hi\u1ec7n d\u1ef1 \u00e1n, c\u00e1c c\u00e2u h\u1ecfi tr\u00ean s\u1ebd \u0111\u01b0\u1ee3c c\u1eadp nh\u1eadt li\u00ean t\u1ee5c. Ch\u00fang ta kh\u00f4ng mong \u0111\u1ee3i c\u00e2u tr\u1ea3 l\u1eddi s\u1ebd ch\u00ednh x\u00e1c t\u1eeb khi c\u00f2n ch\u01b0a b\u1eaft \u0111\u1ea7u th\u1ef1c hi\u1ec7n d\u1ef1 \u00e1n. B\u1ea1n c\u00f3 th\u1ec3 tham kh\u1ea3o th\u00eam \u1edf \u0111\u00e2y v\u1ec1 c\u00e1c c\u00e2u h\u1ecfi kh\u00e1c khi \u0111\u1ecbnh ngh\u0129a v\u1ea5n \u0111\u1ec1 kinh doanh. T\u1ed5ng k\u1ebft Trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n h\u1ec7 th\u1ed1ng ML, m\u1ecdi th\u00e0nh vi\u00ean \u0111\u1ec1u c\u1ea7n ch\u00fa \u00fd t\u1edbi 4 t\u00ednh ch\u1ea5t c\u01a1 b\u1ea3n c\u1ee7a m\u1ed9t h\u1ec7 th\u1ed1ng ML, bao g\u1ed3m T\u00ednh tin c\u1eady (Reliability), kh\u1ea3 n\u0103ng thay \u0111\u1ed5i quy m\u00f4 (Scalability), kh\u1ea3 n\u0103ng b\u1ea3o tr\u00ec (Maintainability) v\u00e0 t\u00ednh th\u00edch nghi (Adaptability) . B\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc th\u00eam \u1edf kho\u00e1 h\u1ecdc CS 329S: Machine Learning Systems Design \u0111\u1ec3 hi\u1ec3u r\u00f5 h\u01a1n v\u1ec1 ch\u00fang. Trong b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd c\u00f9ng t\u00ecm hi\u1ec3u v\u1ec1 c\u00e1c architecture, workflows v\u00e0 MLOps platform \u0111\u01b0\u1ee3c d\u00f9ng trong kho\u00e1 h\u1ecdc. T\u00e0i li\u1ec7u tham kh\u1ea3o CS 329S. Lecture 2. ML and Data Systems Fundamentals","title":"Ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1"},{"location":"mlops-crash-course/tong-quan-he-thong/phan-tich-van-de.html#gioi-thieu","text":"H\u1ec7 th\u1ed1ng ML t\u01b0\u01a1ng t\u1ef1 nh\u01b0 l\u00e0 h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m. Khi x\u00e2y d\u1ef1ng h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m, vi\u1ec7c \u0111\u1ea7u ti\u00ean c\u1ea7n l\u00e0m \u0111\u00f3 l\u00e0 x\u00e1c \u0111\u1ecbnh c\u00e1c v\u1ea5n \u0111\u1ec1 v\u00e0 c\u1ee5 th\u1ec3 ho\u00e1 th\u00e0nh c\u00e1c y\u00eau c\u1ea7u c\u00f3 th\u1ec3 \u0111\u00e1nh gi\u00e1 \u0111\u01b0\u1ee3c v\u00e0 \u0111\u1ec1 xu\u1ea5t c\u00e1c gi\u1ea3i ph\u00e1p kh\u1ea3 thi \u0111\u1ec3 gi\u1ea3i quy\u1ebft c\u00e1c y\u00eau c\u1ea7u \u0111\u00f3. C\u1ed1t l\u00f5i c\u1ee7a h\u1ec7 th\u1ed1ng ML khi \u0111\u01b0\u1ee3c x\u00e2y d\u1ef1ng v\u1eabn l\u00e0 \u0111\u01b0a ra v\u00e0 x\u1eed l\u00fd \u0111\u01b0\u1ee3c b\u00e0i to\u00e1n kinh doanh c\u1ee7a m\u1ed9t t\u1ed5 ch\u1ee9c. Trong kho\u00e1 h\u1ecdc n\u00e0y, ch\u00fang ta c\u00f9ng nhau t\u00ecm hi\u1ec3u b\u00e0i to\u00e1n gi\u1ea3 \u0111\u1ecbnh c\u1ee7a m\u1ed9t c\u00f4ng ty c\u00f3 m\u00f4 h\u00ecnh kinh doanh t\u01b0\u01a1ng t\u1ef1 Grab v\u00e0 \u0111\u00e3 t\u00ecm hi\u1ec3u v\u1ec1 ML ch\u1ecdn \u0111\u00f3 l\u00e0m gi\u1ea3i ph\u00e1p, v\u1ea5n \u0111\u1ec1 kinh doanh c\u1ee7a c\u00f4ng ty c\u1ee7a b\u1ea1n l\u00e0: L\u00e0m th\u1ebf n\u00e0o \u0111\u1ec3 ch\u1ecdn ra t\u00e0i x\u1ebf c\u00f3 kh\u1ea3 n\u0103ng cao nh\u1ea5t s\u1ebd ho\u00e0n th\u00e0nh m\u1ed9t cu\u1ed1c xe khi c\u00f3 y\u00eau c\u1ea7u \u0111\u1eb7t xe t\u1eeb kh\u00e1ch h\u00e0ng? H\u00ecnh d\u01b0\u1edbi \u0111\u00e2y th\u1ec3 hi\u1ec7n y\u00eau c\u1ea7u v\u1ec1 \u0111\u1ea7u v\u00e0o v\u00e0 \u0111\u1ea7u ra c\u1ee7a v\u1ea5n \u0111\u1ec1. graph LR n01[ ] --Th\u00f4ng tin t\u00e0i x\u1ebf 1--> n1[H\u1ec7 th\u1ed1ng ML] --T\u00e0i x\u1ebf c\u00f3 kh\u1ea3 n\u0103ng cao nh\u1ea5t<br>ho\u00e0n th\u00e0nh cu\u1ed1c xe--> n02[ ] n03[ ] --Th\u00f4ng tin t\u00e0i x\u1ebf 2--> n1 n04[ ] --Th\u00f4ng tin t\u00e0i x\u1ebf 3--> n1 style n01 height:0px; style n02 height:0px; style n03 height:0px; style n04 height:0px;","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/tong-quan-he-thong/phan-tich-van-de.html#phan-tich-van-e","text":"Qu\u00e1 tr\u00ecnh \u0111\u1ecbnh ngh\u0129a v\u1ea5n \u0111\u1ec1 kinh doanh l\u00e0 qu\u00e1 tr\u00ecnh tr\u1ea3 l\u1eddi nhi\u1ec1u c\u00e2u h\u1ecfi. B\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y li\u1ec7t k\u00ea c\u00e1c c\u00e2u h\u1ecfi ti\u00eau bi\u1ec3u v\u00e0 c\u00e1c c\u00e2u tr\u1ea3 l\u1eddi. Ch\u1ee7 \u0111\u1ec1 C\u00e2u h\u1ecfi Tr\u1ea3 l\u1eddi M\u1ee5c ti\u00eau M\u1ee5c ti\u00eau kinh doanh? T\u0103ng s\u1ed1 l\u01b0\u1ee3ng cu\u1ed1c xe \u0111\u01b0\u1ee3c ho\u00e0n th\u00e0nh trong 1 th\u00e1ng 10% C\u00e1c ch\u1ee9c n\u0103ng ch\u00ednh? Ch\u1ecdn t\u00e0i x\u1ebf c\u00f3 kh\u1ea3 n\u0103ng cao nh\u1ea5t ho\u00e0n th\u00e0nh cu\u1ed1c xe C\u00e1c b\u00ean li\u00ean quan Ai l\u00e0 ng\u01b0\u1eddi tham gia? Vai tr\u00f2 v\u00e0 tr\u00e1ch nhi\u1ec7m? Product owner, Product manager, Solution Architect, Data Scientist, Data engineer, ML engineer Ai c\u1ea7n \u0111\u01b0\u1ee3c th\u00f4ng b\u00e1o v\u1ec1 d\u1ef1 \u00e1n? Head of Engineering, CTO, CEO Ai l\u00e0 ng\u01b0\u1eddi d\u00f9ng cu\u1ed1i? Kh\u00e1ch h\u00e0ng Data C\u00f3 th\u1ec3 l\u1ea5y \u1edf c\u00e1c ngu\u1ed3n n\u00e0o? Static data v\u00e0 streaming data t\u1eeb \u1ee9ng d\u1ee5ng \u0111\u1eb7t xe c\u1ee7a c\u00f4ng ty \u0110\u1ecbnh ngh\u0129a quy tr\u00ecnh \u0111\u1ec3 bi\u1ebfn \u0111\u1ed5i data sang format c\u00f3 th\u1ec3 d\u00f9ng \u0111\u01b0\u1ee3c? Gi\u1ea3 s\u1eed quy tr\u00ecnh \u0111\u1ec3 bi\u1ebfn \u0111\u1ed5i data, feature engineering \u0111\u00e3 \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a Ph\u00e1t tri\u1ec3n model C\u00f3 gi\u1ea3i ph\u00e1p n\u00e0o \u0111\u00e3 \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n \u0111\u1ec3 \u0111\u1ed1i chi\u1ebfu? Gi\u1ea3 s\u1eed \u0111\u00e3 t\u00ecm hi\u1ec3u c\u00e1c gi\u1ea3i ph\u00e1p c\u1ee7a \u0111\u1ed1i th\u1ee7 c\u1ea1nh tranh C\u00f3 nh\u1eefng thresholds n\u00e0o \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 khi\u1ebfn gi\u1ea3i ph\u00e1p tr\u1edf n\u00ean h\u1eefu \u00edch? Model inference kh\u00f4ng \u0111\u01b0\u1ee3c ch\u1ea1y qu\u00e1 500ms C\u00e2n nh\u1eafc tradeoffs False positives (false alarm) c\u00f3 \u1ea3nh h\u01b0\u1edfng nghi\u00eam tr\u1ecdng h\u01a1n C\u00f3 c\u1ea7n confidence score kh\u00f4ng? D\u00f9ng threshold n\u00e0o? Kh\u00f4ng c\u1ea7n, rank c\u00e1c t\u00e0i x\u1ebf theo x\u00e1c su\u1ea5t m\u00e0 model d\u1ef1 \u0111o\u00e1n sau L\u00e0m g\u00ec v\u1edbi c\u00e1c d\u1ef1 \u0111o\u00e1n kh\u00f4ng \u0111\u01b0\u1ee3c ch\u1ecdn? \u0110\u01b0\u1ee3c log l\u1ea1i v\u00e0 g\u00e1n label \u0110\u00e1nh gi\u00e1 model D\u00f9ng metrics n\u00e0o \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 model l\u00fac ph\u00e1t tri\u1ec3n v\u00e0 \u1edf production? D\u00f9ng metrics Root Mean Square Error (RMSE) L\u00e0m sao \u0111\u1ec3 li\u00ean k\u1ebft model performance v\u1edbi m\u1ee5c ti\u00eau kinh doanh? \u1ede production, ngo\u00e0i RMSE \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 model performance, c\u1ea7n t\u00ednh t\u1ec9 l\u1ec7 ho\u00e0n th\u00e0nh c\u00e1c cu\u1ed1c xe trong 1 th\u00e1ng g\u1ea7n nh\u1ea5t Tri\u1ec3n khai Data c\u1ee7a qu\u00e1 tr\u00ecnh inference s\u1ebd \u0111\u01b0\u1ee3c l\u1ea5y t\u1eeb \u0111\u00e2u? \u0110\u01b0\u1ee3c format v\u00e0 l\u01b0u tr\u1eef th\u1ebf n\u00e0o? Data \u0111\u1ea7u v\u00e0o c\u1ee7a qu\u00e1 tr\u00ecnh inference \u0111\u01b0\u1ee3c l\u1ea5y t\u1eeb Online Feature Store (s\u1ebd \u0111\u01b0\u1ee3c gi\u1ea3i th\u00edch trong b\u00e0i Model serving ) Model \u0111\u01b0\u1ee3c tri\u1ec3n khai \u1edf \u0111\u00e2u? L\u00ean server n\u1ed9i b\u1ed9 c\u1ee7a c\u00f4ng ty Khi n\u00e0o ch\u1ea1y batch prediction? Khi n\u00e0o ch\u1ea1y online prediction? Ch\u1ea1y batch prediction m\u1ed7i gi\u1edd cho c\u00e1c t\u00e0i x\u1ebf \u00edt ho\u1ea1t \u0111\u1ed9ng, data \u00edt thay \u0111\u1ed5i. Ch\u1ea1y online prediction cho c\u00e1c t\u00e0i x\u1ebf ho\u1ea1t \u0111\u1ed9ng nhi\u1ec1u T\u1ed1c \u0111\u1ed9 thay \u0111\u1ed5i c\u1ee7a data th\u1ebf n\u00e0o? V\u00e0i features s\u1ebd thay \u0111\u1ed5i kh\u00f4ng th\u01b0\u1eddng xuy\u00ean, \u0111\u1eb7t l\u1ecbch \u0111\u1ec3 c\u1eadp nh\u1eadt h\u00e0ng ng\u00e0y. V\u00e0i features c\u1ea7n l\u1ea5y t\u1eeb streaming data, c\u1ea7n data pipeline ri\u00eang \u0111\u1ec3 x\u1eed l\u00fd v\u00e0 l\u01b0u tr\u1eef Bao l\u00e2u th\u00ec c\u1ea7n train l\u1ea1i model? D\u1ef1a v\u00e0o t\u1ed1c \u0111\u1ed9 thay \u0111\u1ed5i c\u1ee7a data ho\u1eb7c ch\u1ea5t l\u01b0\u1ee3ng data \u1edf production Labels \u1edf production \u0111\u01b0\u1ee3c thu th\u1eadp nh\u01b0 th\u1ebf n\u00e0o? Sau khi t\u00e0i x\u1ebf \u0111\u01b0\u1ee3c ch\u1ecdn, \u1ee9ng d\u1ee5ng \u0111\u1eb7t xe s\u1ebd tr\u1ea3 v\u1ec1 k\u1ebft qu\u1ea3 xem cu\u1ed1c xe c\u00f3 ho\u00e0n th\u00e0nh kh\u00f4ng Quy\u1ec1n ri\u00eang t\u01b0 C\u00f3 y\u00eau c\u1ea7u n\u00e0o v\u1ec1 quy\u1ec1n ri\u00eang t\u01b0 c\u1ee7a data, labels, v.v Data v\u00e0 labels ch\u1ec9 \u0111\u01b0\u1ee3c d\u00f9ng trong n\u1ed9i b\u1ed9 c\u00f4ng ty H\u1ec7 th\u1ed1ng c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c k\u1ebft n\u1ed1i v\u1edbi internet kh\u00f4ng? C\u00f3 C\u00f3 th\u1ec3 gi\u1eef data c\u1ee7a users trong bao l\u00e2u? Kh\u00f4ng gi\u1edbi h\u1ea1n Chi ph\u00ed v\u00e0 l\u1ee3i \u00edch Ng\u00e2n s\u00e1ch ban \u0111\u1ea7u $500,000 So s\u00e1nh chi ph\u00ed v\u00e0 l\u1ee3i \u00edch L\u1ee3i \u00edch l\u1edbn h\u01a1n chi ph\u00ed nhi\u1ec1u, h\u1ec7 th\u1ed1ng c\u00f3 th\u1ec3 t\u00e1i s\u1eed d\u1ee5ng, chi ph\u00ed \u0111\u1ec3 optimize kh\u00f4ng l\u1edbn C\u1ea7n \u0111\u1ea1t y\u00eau c\u1ea7u n\u00e0o \u0111\u1ec3 t\u0103ng kinh ph\u00ed? Ho\u00e0n th\u00e0nh c\u00e1c m\u1ed1c th\u1eddi gian ti\u1ebfp theo, tri\u1ec3n khai model ra production v\u00e0 ti\u1ebfp t\u1ee5c ch\u1ee9ng minh l\u1ee3i \u00edch l\u1edbn h\u01a1n nhi\u1ec1u chi ph\u00ed R\u1ee7i ro Ph\u00e2n t\u00edch r\u1ee7i ro \u0111i k\u00e8m C\u00f3 th\u1ec3 model \u0111\u01b0\u1ee3c \u0111\u00e1nh gi\u00e1 offline l\u00e0 t\u1ed1t, nh\u01b0ng \u1edf production kh\u00f4ng mang l\u1ea1i hi\u1ec7u qu\u1ea3 cao Ph\u00e2n t\u00edch r\u1ee7i ro kinh doanh kh\u00e1c H\u1ebft ti\u1ec1n tr\u01b0\u1edbc khi ho\u00e0n thi\u1ec7n POC R\u00e0ng bu\u1ed9c k\u0129 thu\u1eadt C\u00f3 h\u1ec7 th\u1ed1ng c\u0169 n\u00e0o c\u1ea7n t\u00edch h\u1ee3p v\u1edbi kh\u00f4ng? Kh\u00f4ng Architecture v\u00e0 tools s\u1ebd d\u00f9ng? \u0110\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a \u1edf b\u00e0i ti\u1ebfp theo Ngo\u00e0i m\u1ed9t v\u00e0i c\u00e2u h\u1ecfi \u0111\u01b0\u1ee3c n\u00eau \u1edf tr\u00ean, tu\u1ef3 v\u00e0o m\u1ee5c ti\u00eau kinh doanh s\u1ebd c\u00f3 c\u00e1c v\u1ea5n \u0111\u1ec1 v\u00e0 c\u00e2u h\u1ecfi kh\u00e1c \u0111\u01b0\u1ee3c \u0111\u01b0a ra. Trong b\u1ea3ng tr\u00ean, nhi\u1ec1u c\u00e2u tr\u1ea3 l\u1eddi li\u00ean quan t\u1edbi m\u1ea3ng kinh doanh c\u1ee7a c\u00f4ng ty \u0111\u00e3 \u0111\u01b0\u1ee3c tr\u1ea3 l\u1eddi ng\u1eafn g\u1ecdn. Nh\u1eefng c\u00e2u tr\u1ea3 l\u1eddi n\u00e0y th\u00f4ng th\u01b0\u1eddng \u0111\u01b0\u1ee3c m\u1ed9t \u0111\u1ed9i ng\u0169 c\u00e1c Data Analyst v\u00e0 Business Strategist th\u1ea3o lu\u1eadn, ph\u00e2n t\u00edch, v\u00e0 gi\u1ea3i \u0111\u00e1p. Trong qu\u00e1 tr\u00ecnh th\u1ef1c hi\u1ec7n d\u1ef1 \u00e1n, c\u00e1c c\u00e2u h\u1ecfi tr\u00ean s\u1ebd \u0111\u01b0\u1ee3c c\u1eadp nh\u1eadt li\u00ean t\u1ee5c. Ch\u00fang ta kh\u00f4ng mong \u0111\u1ee3i c\u00e2u tr\u1ea3 l\u1eddi s\u1ebd ch\u00ednh x\u00e1c t\u1eeb khi c\u00f2n ch\u01b0a b\u1eaft \u0111\u1ea7u th\u1ef1c hi\u1ec7n d\u1ef1 \u00e1n. B\u1ea1n c\u00f3 th\u1ec3 tham kh\u1ea3o th\u00eam \u1edf \u0111\u00e2y v\u1ec1 c\u00e1c c\u00e2u h\u1ecfi kh\u00e1c khi \u0111\u1ecbnh ngh\u0129a v\u1ea5n \u0111\u1ec1 kinh doanh.","title":"Ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1"},{"location":"mlops-crash-course/tong-quan-he-thong/phan-tich-van-de.html#tong-ket","text":"Trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n h\u1ec7 th\u1ed1ng ML, m\u1ecdi th\u00e0nh vi\u00ean \u0111\u1ec1u c\u1ea7n ch\u00fa \u00fd t\u1edbi 4 t\u00ednh ch\u1ea5t c\u01a1 b\u1ea3n c\u1ee7a m\u1ed9t h\u1ec7 th\u1ed1ng ML, bao g\u1ed3m T\u00ednh tin c\u1eady (Reliability), kh\u1ea3 n\u0103ng thay \u0111\u1ed5i quy m\u00f4 (Scalability), kh\u1ea3 n\u0103ng b\u1ea3o tr\u00ec (Maintainability) v\u00e0 t\u00ednh th\u00edch nghi (Adaptability) . B\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc th\u00eam \u1edf kho\u00e1 h\u1ecdc CS 329S: Machine Learning Systems Design \u0111\u1ec3 hi\u1ec3u r\u00f5 h\u01a1n v\u1ec1 ch\u00fang. Trong b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd c\u00f9ng t\u00ecm hi\u1ec3u v\u1ec1 c\u00e1c architecture, workflows v\u00e0 MLOps platform \u0111\u01b0\u1ee3c d\u00f9ng trong kho\u00e1 h\u1ecdc.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/tong-quan-he-thong/phan-tich-van-de.html#tai-lieu-tham-khao","text":"CS 329S. Lecture 2. ML and Data Systems Fundamentals","title":"T\u00e0i li\u1ec7u tham kh\u1ea3o"},{"location":"mlops-crash-course/tong-quan-he-thong/tong-quan-mlops.html","text":"Sculley, et al. 2015. Hidden technical debt in machine learning systems. Proceedings of the 28th International Conference on Neural Information Processing Systems, Volume 2 (NIPS 2015) Gi\u1edbi thi\u1ec7u Trong c\u00e1c d\u1ef1 \u00e1n Machine Learning (ML) th\u1ef1c t\u1ebf kh\u00f4ng ch\u1ec9 nh\u1eb1m m\u1ee5c \u0111\u00edch nghi\u00ean c\u1ee9u ph\u00e1t tri\u1ec3n, m\u00e0 c\u00f2n h\u01b0\u1edbng \u0111\u1ebfn \u0111\u00edch cu\u1ed1i l\u00e0 nhanh ch\u00f3ng tri\u1ec3n khai h\u1ec7 th\u1ed1ng ML ra th\u1ef1c ti\u1ec5n (production). \u1ede th\u1eddi \u0111i\u1ec3m hi\u1ec7n t\u1ea1i, c\u00f3 nhi\u1ec1u th\u00e1ch th\u1ee9c m\u00e0 c\u00e1c k\u0129 s\u01b0 g\u1eb7p ph\u1ea3i \u0111\u1ec3 t\u1ef1 \u0111\u1ed9ng ho\u00e1 c\u00e1c quy tr\u00ecnh trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n v\u00e0 tri\u1ec3n khai h\u1ec7 th\u1ed1ng ML. MLOps ra \u0111\u1eddi nh\u01b0 m\u1ed9t thu\u1eadt ng\u1eef \u0111\u1ec3 m\u00f4 t\u1ea3 c\u00e1c v\u1ea5n \u0111\u1ec1 v\u00e0 h\u01b0\u1edbng ti\u1ebfp c\u1eadn \u0111\u1ec3 gi\u1ea3i quy\u1ebft c\u00e1c v\u1ea5n \u0111\u1ec1 \u0111\u00f3 trong m\u1ed9t d\u1ef1 \u00e1n ph\u00e1t tri\u1ec3n v\u00e0 tri\u1ec3n khai ML. Trong b\u00e0i n\u00e0y, d\u1ef1a tr\u00ean ki\u1ebfn th\u1ee9c t\u1eeb b\u00e0i b\u00e1o Machine Learning Operations (MLOps): Overview, Definition, and Architecture , ch\u00fang ta s\u1ebd t\u00ecm hi\u1ec3u s\u01a1 l\u01b0\u1ee3c v\u1ec1 l\u00fd thuy\u1ebft, c\u00e1c nguy\u00ean t\u1eafc (principles) v\u00e0 quy tr\u00ecnh (workflows) \u0111i\u1ec3n h\u00ecnh trong MLOps. Warning Kh\u00e1i ni\u1ec7m v\u1ec1 MLOps v\u00e0 c\u00e1c l\u00fd thuy\u1ebft li\u00ean quan \u0111\u01b0\u1ee3c nhi\u1ec1u ngu\u1ed3n kh\u00e1c nhau \u0111\u1ecbnh ngh\u0129a kh\u00e1c nhau. Ch\u00fang ta s\u1ebd duy tr\u00ec s\u1ef1 c\u1edfi m\u1edf v\u1ec1 s\u1ef1 kh\u00e1c nhau gi\u1eefa c\u00e1c ngu\u1ed3n t\u00e0i li\u1ec7u n\u00e0y. \u0110\u1ecbnh ngh\u0129a Theo b\u00e0i b\u00e1o tr\u00ean , \u0111\u1ecbnh ngh\u0129a v\u1ec1 MLOps c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c hi\u1ec3u v\u00e0 t\u00f3m g\u1ecdn l\u1ea1i v\u00e0o c\u00e1c \u00fd sau: MLOps l\u00e0 m\u1ed9t m\u00f4 h\u00ecnh, bao g\u1ed3m c\u00e1c c\u00e1ch th\u1ef1c thi t\u1ed1t nh\u1ea5t (best practices), kh\u00e1i ni\u1ec7m, v\u0103n ho\u00e1 l\u00e0m vi\u1ec7c, trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n, tri\u1ec3n khai v\u00e0 theo d\u00f5i m\u1ed9t h\u1ec7 th\u1ed1ng ML. MLOps g\u1ed3m c\u00e1c k\u0129 thu\u1eadt h\u1ed9i t\u1ee5 b\u1edfi 3 m\u1ea3ng: machine learning, software engineering (\u0111\u1eb7c bi\u1ec7t l\u00e0 DevOps) v\u00e0 data engineering. MLOps t\u1ea1o \u0111i\u1ec1u ki\u1ec7n thu\u1eadt l\u1ee3i cho qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n v\u00e0 tri\u1ec3n khai c\u00e1c h\u1ec7 th\u1ed1ng ML ra production hi\u1ec7u qu\u1ea3 h\u01a1n, th\u00f4ng qua c\u00e1c nguy\u00ean t\u1eafc m\u00e0 ch\u00fang ta s\u1ebd xem x\u00e9t ngay sau \u0111\u00e2y. Nguy\u00ean T\u1eafc (Principles) Photo by Austin Distel on Unsplash Nguy\u00ean t\u1eafc \u0111\u01b0\u1ee3c xem nh\u01b0 l\u00e0 m\u1ed9t ph\u1ea7n c\u1ee7a best practices hay n\u00f3i c\u00e1ch kh\u00e1c \u0111\u00f3 l\u00e0 s\u1ef1 h\u01b0\u1edbng d\u1eabn, g\u1ee3i \u00fd cho c\u00e1c quy\u1ebft \u0111\u1ecbnh \u0111\u01b0\u1ee3c \u0111\u01b0a ra trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n h\u1ec7 th\u1ed1ng ML. C\u00e1c nguy\u00ean t\u1eafc (principles) trong MLOps bao g\u1ed3m: 1. T\u1ef1 \u0111\u1ed9ng ho\u00e1 trong t\u00edch h\u1ee3p v\u00e0 tri\u1ec3n khai (Continuous Integration/Continuous Delivery - CI/CD automation) Nguy\u00ean t\u1eafc n\u00e0y \u0111\u1ea3m b\u1ea3o vi\u1ec7c t\u00edch h\u1ee3p v\u00e0 tri\u1ec3n khai code di\u1ec5n ra t\u1ef1 \u0111\u1ed9ng. 2. H\u1ee3p ph\u1ed1i quy trinh (Workflow orchestration) Trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n h\u1ec7 th\u1ed1ng ML, c\u00f3 nhi\u1ec1u lu\u1ed3ng (pipeline) c\u1ea7n \u0111\u01b0\u1ee3c ch\u1ea1y v\u00e0o nh\u1eefng th\u1eddi \u0111i\u1ec3m nh\u1ea5t \u0111\u1ecbnh, v\u1edbi c\u00e1c b\u01b0\u1edbc trong lu\u1ed3ng ph\u1ee5 thu\u1ed9c l\u1eabn nhau. Ngo\u00e0i ra, th\u01b0 vi\u1ec7n, m\u00f4i tr\u01b0\u1eddng ch\u1ea1y c\u0169ng kh\u00e1c nhau. Nguy\u00ean t\u1eafc n\u00e0y \u0111\u1ea3m b\u1ea3o vi\u1ec7c t\u1ef1 \u0111\u1ed9ng ho\u00e1 \u0111i\u1ec1u ph\u1ed1i c\u00e1c b\u01b0\u1edbc trong m\u1ed9t lu\u1ed3ng ch\u1ea1y \u0111\u00fang th\u1ee9 t\u1ef1 v\u00e0 th\u1eddi gian \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh. 3. Kh\u1ea3 n\u0103ng \u0111\u01b0\u1ee3c t\u00e1i l\u1eadp l\u1ea1i (Reproducibility) Kh\u1ea3 n\u0103ng t\u00e1i l\u1eadp l\u1ea1i (reproduce) m\u1ed9t k\u1ebft qu\u1ea3 hay m\u1ed9t l\u1ea7n th\u1eed nghi\u1ec7m l\u00e0 m\u1ed9t y\u00eau c\u1ea7u th\u01b0\u1eddng th\u1ea5y khi ph\u00e1t tri\u1ec3n m\u1ed9t h\u1ec7 th\u1ed1ng ML. Y\u00eau c\u1ea7u n\u00e0y \u0111\u1ea3m b\u1ea3o vi\u1ec7c ch\u1ea1y suy di\u1ec5n m\u00f4 h\u00ecnh (model inference) \u1edf production \u1ed5n \u0111\u1ecbnh v\u00e0 debug qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n model hi\u1ec7u qu\u1ea3 h\u01a1n. 4. Qu\u1ea3n l\u00fd phi\u00ean b\u1ea3n m\u00e3 ngu\u1ed3n, d\u1eef li\u1ec7u v\u00e0 m\u00f4 h\u00ecnh (Versioning code, data, model) Nguy\u00ean t\u1eafc n\u00e0y \u0111\u1ea3m b\u1ea3o m\u00e3 ngu\u1ed3n (code), d\u1eef li\u1ec7u (data) v\u00e0 m\u00f4 h\u00ecnh (model) \u0111\u01b0\u1ee3c qu\u1ea3n l\u00fd theo c\u00e1c phi\u00ean b\u1ea3n (versions). \u0110i\u1ec1u n\u00e0y l\u00e0m thu\u1eadn ti\u1ec7n cho vi\u1ec7c ph\u00e1t tri\u1ec3n, ki\u1ec3m tra phi\u00ean b\u1ea3n model \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n (train) v\u1edbi phi\u00ean b\u1ea3n data n\u00e0o v\u00e0 s\u1eed d\u1ee5ng code \u1edf phi\u00ean b\u1ea3n n\u00e0o \u0111\u1ec3 train. 5. H\u1ee3p t\u00e1c trong ph\u00e1t tri\u1ec3n (Collaboration) Trong m\u1ed9t d\u1ef1 \u00e1n ML, nhi\u1ec1u k\u0129 s\u01b0 v\u1edbi chuy\u00ean m\u00f4n kh\u00e1c nhau c\u00f9ng tham gia v\u00e0o ph\u00e1t tri\u1ec3n h\u1ec7 th\u1ed1ng. Nguy\u00ean t\u1eafc n\u00e0y \u0111\u1ea3m b\u1ea3o vi\u1ec7c thi\u1ebft l\u1eadp m\u1ed9t b\u1ed9 c\u00e1c quy t\u1eafc, c\u00f4ng c\u1ee5 v\u00e0 v\u0103n ho\u00e1 l\u00e0m vi\u1ec7c \u0111\u1ec3 qu\u00e1 tr\u00ecnh c\u1ed9ng t\u00e1c gi\u1eefa c\u00e1c c\u00e1 nh\u00e2n, \u1edf c\u00e1c vai tr\u00f2, tr\u00e1ch nhi\u1ec7m kh\u00e1c nhau, di\u1ec5n ra hi\u1ec7u qu\u1ea3. 6. Hu\u1ea5n luy\u1ec7n v\u00e0 \u0111\u00e1nh gi\u00e1 ML li\u00ean t\u1ee5c (Continuous ML training & evaluation) \u1ede m\u00f4i tr\u01b0\u1eddng production, vi\u1ec7c d\u1eef li\u1ec7u thay \u0111\u1ed5i li\u00ean t\u1ee5c khi\u1ebfn hi\u1ec7u n\u0103ng c\u1ee7a m\u00f4 h\u00ecnh gi\u1ea3m nhanh ch\u00f3ng. Nguy\u00ean t\u1eafc n\u00e0y \u0111\u1ea3m b\u1ea3o vi\u1ec7c x\u00e2y d\u1ef1ng m\u1ed9t lu\u1ed3ng \u0111\u1ec3 hu\u1ea5n luy\u1ec7n v\u00e0 \u0111\u00e1nh gi\u00e1 m\u00f4 h\u00ecnh m\u1ed9t c\u00e1ch t\u1ef1 \u0111\u1ed9ng \u0111\u1ecbnh k\u00ec ho\u1eb7c ngay khi c\u1ea7n thi\u1ebft. 7. Theo d\u1ea5u metadata trong ML (ML metadata tracking) Trong m\u1ed9t h\u1ec7 th\u1ed1ng ML, c\u00e1c c\u1ea5u h\u00ecnh hay data \u0111\u1ea7u v\u00e0o/\u0111\u1ea7u ra \u0111\u01b0\u1ee3c y\u00eau c\u1ea7u c\u1ee5 th\u1ec3, \u1edf m\u1ed7i b\u01b0\u1edbc c\u1ee7a m\u1ed9t lu\u1ed3ng. Nguy\u00ean t\u1eafc n\u00e0y \u0111\u01b0\u1ee3c \u0111\u1eb7t ra nh\u1eb1m theo d\u00f5i v\u00e0 ghi l\u1ea1i c\u00e1c \u0111\u1ea7u v\u00e0o v\u00e0 \u0111\u1ea7u ra \u0111\u00f3, k\u00e8m theo th\u00f4ng tin v\u1ec1 nh\u1eefng l\u1ea7n ch\u1ea1y c\u1ee7a c\u00e1c lu\u1ed3ng, v\u00ed d\u1ee5 nh\u01b0: Ng\u00e0y, th\u00e1ng, th\u1eddi gian ch\u1ea1y Phi\u00ean b\u1ea3n c\u1ee7a data \u0111ang ch\u1ea1y Hyperparameter d\u00f9ng \u0111\u1ec3 train model N\u01a1i l\u01b0u tr\u1eef model sau khi train xong v.v. 8. Theo d\u00f5i li\u00ean t\u1ee5c (Continuous monitoring) Nguy\u00ean t\u1eafc n\u00e0y \u0111\u1ea3m b\u1ea3o vi\u1ec7c theo d\u00f5i li\u00ean t\u1ee5c c\u00e1c th\u00f4ng s\u1ed1 li\u00ean quan t\u1edbi d\u1eef li\u1ec7u, m\u00f4 h\u00ecnh, h\u1ea1 t\u1ea7ng (infrastructure), \u0111\u1ec3 ph\u00e1t hi\u1ec7n v\u00e0 gi\u1ea3i quy\u1ebft c\u00e1c l\u1ed7i k\u1ecbp th\u1eddi. M\u1ed9t v\u00e0i th\u00f4ng s\u1ed1 \u0111i\u1ec3n h\u00ecnh bao g\u1ed3m: C\u00e1c t\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a data \u1edf production Model performance L\u01b0\u1ee3ng request \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn server Th\u1eddi gian x\u1eed l\u00fd m\u1ed9t request v.v. 9. V\u00f2ng l\u1eb7p \u00fd ki\u1ebfn ph\u1ea3n h\u1ed3i (Feedback loops) Khi ph\u00e1t tri\u1ec3n m\u1ed9t h\u1ec7 th\u1ed1ng ML, s\u1ef1 ph\u1ea3n h\u1ed3i t\u1eeb ph\u1ea7n \u0111\u00e1nh gi\u00e1 ng\u01b0\u1ee3c v\u1ec1 ph\u1ea7n ph\u00e1t tri\u1ec3n th\u01b0\u1eddng xuy\u00ean x\u1ea3y ra, v\u00ed d\u1ee5: Ph\u1ea3n h\u1ed3i t\u1eeb qu\u00e1 tr\u00ecnh th\u1eed nghi\u1ec7m data v\u00e0 model ng\u01b0\u1ee3c v\u1ec1 qu\u00e1 tr\u00ecnh x\u1eed l\u00fd d\u1eef li\u1ec7u th\u00f4 (raw data) Ph\u1ea3n h\u1ed3i t\u1eeb qu\u00e1 tr\u00ecnh \u0111\u00e1nh gi\u00e1 model performance \u1edf production ng\u01b0\u1ee3c v\u1ec1 qu\u00e1 tr\u00ecnh th\u1eed nghi\u1ec7m model v.v. Xuy\u00ean su\u1ed1t kho\u00e1 h\u1ecdc, c\u00e1c nguy\u00ean t\u1eafc n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c ng\u1ea7m hi\u1ec3u v\u00e0 s\u1eed d\u1ee5ng trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n h\u1ec7 th\u1ed1ng. \u0110\u1ec3 bi\u1ebft th\u00eam chi ti\u1ebft, b\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc k\u0129 h\u01a1n \u1edf b\u00e0i b\u00e1o tr\u00ean . C\u00e1c th\u00e0nh ph\u1ea7n c\u1ee7a MLOps (MLOps Components) Photo by Jorge Ramirez on Unsplash C\u00e1c th\u00e0nh ph\u1ea7n trong MLOps bao g\u1ed3m c\u00e1c c\u1ea5u ph\u1ea7n trong m\u1ed9t h\u1ec7 th\u1ed1ng ML. C\u00e1c th\u00e0nh ph\u1ea7n \u0111\u01b0\u1ee3c li\u1ec7t k\u00ea nh\u01b0 sau. CI/CD component Source code repository Workflow orchestration Feature store Model training infrastructure Model registry ML metadata store Model serving component Monitoring component T\u00ean c\u00e1c components \u0111\u00e3 gi\u1ea3i th\u00edch \u00fd ngh\u0129a v\u00e0 c\u00f4ng vi\u1ec7c c\u1ee7a c\u00e1c components \u0111\u00f3, \u0111\u1ed3ng th\u1eddi ch\u00fang c\u0169ng th\u1ef1c hi\u1ec7n nhi\u1ec7m v\u1ee5 c\u1ee7a m\u1ed9t ho\u1eb7c nhi\u1ec1u principle \u1edf ph\u1ea7n tr\u01b0\u1edbc, n\u00ean ch\u00fang ta s\u1ebd kh\u00f4ng \u0111\u1ec1 c\u1eadp chi ti\u1ebft \u1edf \u0111\u00e2y. \u0110\u1ec3 hi\u1ec3u r\u00f5 h\u01a1n v\u1ec1 m\u1ed1i quan h\u1ec7 c\u1ee7a c\u00e1c components v\u1edbi principles trong MLOps, b\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc k\u0129 h\u01a1n \u1edf b\u00e0i b\u00e1o tr\u00ean . C\u00e1c workflows Trong ph\u1ea7n n\u00e0y, ch\u00fang ta s\u1ebd t\u00ecm hi\u1ec3u v\u1ec1 c\u00e1c workflows \u0111i\u1ec3n h\u00ecnh trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n m\u1ed9t h\u1ec7 th\u1ed1ng ML. C\u00e1c workflows \u0111\u01b0\u1ee3c m\u00f4 t\u1ea3 \u1edf b\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y. # Workflow M\u00f4 t\u1ea3 1 Ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1 Ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1 kinh doanh, thi\u1ebft k\u1ebf h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m, quy\u1ebft \u0111\u1ecbnh gi\u1ea3i ph\u00e1p v\u1ec1 c\u00f4ng ngh\u1ec7 s\u1ebd d\u00f9ng, \u0111\u1ecbnh ngh\u0129a v\u1ea5n \u0111\u1ec1 ML c\u1ea7n gi\u1ea3i quy\u1ebft, t\u00ecm ki\u1ebfm data c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng, thu th\u1eadp data v\u00e0 ph\u00e2n t\u00edch data 2 \u0110\u1ecbnh ngh\u0129a quy lu\u1eadt bi\u1ebfn \u0111\u1ed5i data \u0110\u1ecbnh ngh\u0129a c\u00e1c quy lu\u1eadt \u0111\u1ec3 bi\u1ebfn \u0111\u1ed5i data th\u00e0nh d\u1ea1ng c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng \u0111\u01b0\u1ee3c \u0111\u1ec3 th\u1eed nghi\u1ec7m 3 X\u00e2y d\u1ef1ng data pipeline Quy lu\u1eadt bi\u1ebfn \u0111\u1ed5i data s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 x\u00e2y d\u1ef1ng data pipeline 4 Th\u1eed nghi\u1ec7m model Th\u1eed nghi\u1ec7m data v\u00e0 model, train model t\u1ed1t nh\u1ea5t 5 T\u1ef1 \u0111\u1ed9ng ho\u00e1 ML pipeline Code t\u1eeb qu\u00e1 tr\u00ecnh th\u1eed nghi\u1ec7m data v\u00e0 model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng v\u00e0o ML pipeline. Model sau khi train xong s\u1ebd \u0111\u01b0\u1ee3c tri\u1ec3n khai t\u1ef1 \u0111\u1ed9ng l\u00ean Model serving component v\u00e0 t\u00edch h\u1ee3p v\u1edbi Monitoring component C\u00e1c workflows tr\u00ean kh\u00f4ng ph\u1ea3i l\u00e0 th\u1ee9 t\u1ef1 ch\u00ednh x\u00e1c v\u1ec1 c\u00e1c c\u00f4ng vi\u1ec7c khi x\u00e2y d\u1ef1ng m\u1ed9t h\u1ec7 th\u1ed1ng ML. H\u00ecnh d\u01b0\u1edbi \u0111\u00e2y l\u00e0 m\u1ed9t v\u00ed d\u1ee5 v\u1ec1 th\u1ee9 t\u1ef1 trong th\u1ef1c t\u1ebf. flowchart TD n1[Kh\u1edfi \u0111\u1ed9ng d\u1ef1 \u00e1n] --> n2[\u0110\u1ecbnh ngh\u0129a v\u1ea5n \u0111\u1ec1] --> n3[POC 1] --> n4[POC 2] --> n5[X\u00e2y d\u1ef1ng c\u00e1c pipelines] --> n6[T\u1ef1 \u0111\u1ed9ng ho\u00e1 c\u00e1c pipelines] --> n7[Production] n3 --\u0110\u1ecbnh ngh\u0129a l\u1ea1i<br>v\u1ea5n \u0111\u1ec1--> n2 n4 --C\u1eadp nh\u1eadt c\u00e1ch<br>bi\u1ebfn \u0111\u1ed5i data--> n2 n7 --C\u1eadp nh\u1eadt c\u00e1ch<br>train model--> n2 \u0110\u1ea7u ti\u00ean, ch\u00fang ta c\u1ea7n \u0111\u1ecbnh ngh\u0129a v\u00e0 ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1 kinh doanh \u0111\u1ec3 hi\u1ec3u r\u00f5 y\u00eau c\u1ea7u v\u1ec1 c\u00e1c ch\u1ee9c n\u0103ng c\u1ee7a h\u1ec7 th\u1ed1ng ML. Sau \u0111\u00f3, d\u1ef1 \u00e1n Proof Of Concept (POC) s\u1ebd \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n \u0111\u1ec3 ch\u1ee9ng minh r\u1eb1ng gi\u1ea3i ph\u00e1p \u0111\u1ec1 ra l\u00e0 kh\u1ea3 thi, tr\u01b0\u1edbc khi b\u1eaft tay v\u00e0o x\u00e2y d\u1ef1ng chi ti\u1ebft c\u00e1c ch\u1ee9c n\u0103ng ph\u1ee9c t\u1ea1p. C\u00f3 th\u1ec3 c\u00f3 nhi\u1ec1u d\u1ef1 \u00e1n POC \u1edf c\u00e1c m\u1ee9c \u0111\u1ed9 kh\u00e1c nhau. Trong qu\u00e1 tr\u00ecnh th\u1ef1c hi\u1ec7n d\u1ef1 \u00e1n POC, c\u00e1c data engineer, software engineer, ML engineer hay MLOps engineer c\u0169ng th\u1ef1c hi\u1ec7n song song vi\u1ec7c x\u00e2y d\u1ef1ng data pipeline, training pipeline, model serving component, monitoring component v\u00e0 CI/CD cho t\u1ea5t c\u1ea3 pipeline, components \u0111\u00f3. D\u1ef1a tr\u00ean c\u00e1c b\u01b0\u1edbc x\u00e2y d\u1ef1ng m\u1ed9t h\u1ec7 th\u1ed1ng ML trong th\u1ef1c t\u1ebf, kho\u00e1 h\u1ecdc n\u00e0y s\u1ebd bao g\u1ed3m c\u00e1c b\u00e0i h\u1ecdc l\u1ea7n l\u01b0\u1ee3t nh\u01b0 sau: Ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1 POC Data pipeline Training pipeline Model serving Monitoring CI/CD T\u1ed5ng k\u1ebft Trong b\u00e0i n\u00e0y, ch\u00fang ta \u0111\u00e3 t\u00ecm hi\u1ec3u kh\u00e1 nhi\u1ec1u v\u1ea5n \u0111\u1ec1 c\u0169ng nh\u01b0 vi\u1ec7c \u0111\u01b0a ra \u0111\u01b0\u1ee3c ph\u01b0\u01a1ng ph\u00e1p gi\u1ea3i quy\u1ebft d\u1ef1a tr\u00ean c\u00e1c quy t\u1eafc (principles), th\u00e0nh ph\u1ea7n (components), quy tr\u00ecnh (workflows) \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a trong MLOps. Tuy nhi\u00ean, MLOps v\u1eabn c\u00f2n l\u00e0 m\u1ed9t m\u1ea3ng kh\u00e1 m\u1edbi, c\u00f2n t\u1ed3n t\u1ea1i kh\u00e1 nhi\u1ec1u th\u1eed th\u00e1ch d\u00e0nh cho c\u00e1c k\u0129 s\u01b0. Hy v\u1ecdng r\u1eb1ng kho\u00e1 h\u1ecdc MLOps Crash Course s\u1ebd l\u00e0 m\u1ed9t b\u01b0\u1edbc n\u1ec1n t\u1ea3ng gi\u00fap cho c\u1ed9ng \u0111\u1ed3ng AI/ML t\u1ea1i Vi\u1ec7t Nam ph\u00e1t tri\u1ec3n m\u1ea1nh m\u1ebd, g\u00f3p ph\u1ea7n v\u00e0o s\u1ef1 ph\u00e1t tri\u1ec3n chung c\u1ee7a AI/ML tr\u00ean th\u1ebf gi\u1edbi. Trong b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd b\u1eaft \u0111\u1ea7u c\u00e1c b\u01b0\u1edbc \u0111\u1ea7u ti\u00ean khi x\u00e2y d\u1ef1ng m\u1ed9t d\u1ef1 \u00e1n ML, \u0111\u00f3 l\u00e0 b\u01b0\u1edbc Ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1 .","title":"T\u1ed5ng quan MLOps"},{"location":"mlops-crash-course/tong-quan-he-thong/tong-quan-mlops.html#gioi-thieu","text":"Trong c\u00e1c d\u1ef1 \u00e1n Machine Learning (ML) th\u1ef1c t\u1ebf kh\u00f4ng ch\u1ec9 nh\u1eb1m m\u1ee5c \u0111\u00edch nghi\u00ean c\u1ee9u ph\u00e1t tri\u1ec3n, m\u00e0 c\u00f2n h\u01b0\u1edbng \u0111\u1ebfn \u0111\u00edch cu\u1ed1i l\u00e0 nhanh ch\u00f3ng tri\u1ec3n khai h\u1ec7 th\u1ed1ng ML ra th\u1ef1c ti\u1ec5n (production). \u1ede th\u1eddi \u0111i\u1ec3m hi\u1ec7n t\u1ea1i, c\u00f3 nhi\u1ec1u th\u00e1ch th\u1ee9c m\u00e0 c\u00e1c k\u0129 s\u01b0 g\u1eb7p ph\u1ea3i \u0111\u1ec3 t\u1ef1 \u0111\u1ed9ng ho\u00e1 c\u00e1c quy tr\u00ecnh trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n v\u00e0 tri\u1ec3n khai h\u1ec7 th\u1ed1ng ML. MLOps ra \u0111\u1eddi nh\u01b0 m\u1ed9t thu\u1eadt ng\u1eef \u0111\u1ec3 m\u00f4 t\u1ea3 c\u00e1c v\u1ea5n \u0111\u1ec1 v\u00e0 h\u01b0\u1edbng ti\u1ebfp c\u1eadn \u0111\u1ec3 gi\u1ea3i quy\u1ebft c\u00e1c v\u1ea5n \u0111\u1ec1 \u0111\u00f3 trong m\u1ed9t d\u1ef1 \u00e1n ph\u00e1t tri\u1ec3n v\u00e0 tri\u1ec3n khai ML. Trong b\u00e0i n\u00e0y, d\u1ef1a tr\u00ean ki\u1ebfn th\u1ee9c t\u1eeb b\u00e0i b\u00e1o Machine Learning Operations (MLOps): Overview, Definition, and Architecture , ch\u00fang ta s\u1ebd t\u00ecm hi\u1ec3u s\u01a1 l\u01b0\u1ee3c v\u1ec1 l\u00fd thuy\u1ebft, c\u00e1c nguy\u00ean t\u1eafc (principles) v\u00e0 quy tr\u00ecnh (workflows) \u0111i\u1ec3n h\u00ecnh trong MLOps. Warning Kh\u00e1i ni\u1ec7m v\u1ec1 MLOps v\u00e0 c\u00e1c l\u00fd thuy\u1ebft li\u00ean quan \u0111\u01b0\u1ee3c nhi\u1ec1u ngu\u1ed3n kh\u00e1c nhau \u0111\u1ecbnh ngh\u0129a kh\u00e1c nhau. Ch\u00fang ta s\u1ebd duy tr\u00ec s\u1ef1 c\u1edfi m\u1edf v\u1ec1 s\u1ef1 kh\u00e1c nhau gi\u1eefa c\u00e1c ngu\u1ed3n t\u00e0i li\u1ec7u n\u00e0y.","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/tong-quan-he-thong/tong-quan-mlops.html#inh-nghia","text":"Theo b\u00e0i b\u00e1o tr\u00ean , \u0111\u1ecbnh ngh\u0129a v\u1ec1 MLOps c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c hi\u1ec3u v\u00e0 t\u00f3m g\u1ecdn l\u1ea1i v\u00e0o c\u00e1c \u00fd sau: MLOps l\u00e0 m\u1ed9t m\u00f4 h\u00ecnh, bao g\u1ed3m c\u00e1c c\u00e1ch th\u1ef1c thi t\u1ed1t nh\u1ea5t (best practices), kh\u00e1i ni\u1ec7m, v\u0103n ho\u00e1 l\u00e0m vi\u1ec7c, trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n, tri\u1ec3n khai v\u00e0 theo d\u00f5i m\u1ed9t h\u1ec7 th\u1ed1ng ML. MLOps g\u1ed3m c\u00e1c k\u0129 thu\u1eadt h\u1ed9i t\u1ee5 b\u1edfi 3 m\u1ea3ng: machine learning, software engineering (\u0111\u1eb7c bi\u1ec7t l\u00e0 DevOps) v\u00e0 data engineering. MLOps t\u1ea1o \u0111i\u1ec1u ki\u1ec7n thu\u1eadt l\u1ee3i cho qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n v\u00e0 tri\u1ec3n khai c\u00e1c h\u1ec7 th\u1ed1ng ML ra production hi\u1ec7u qu\u1ea3 h\u01a1n, th\u00f4ng qua c\u00e1c nguy\u00ean t\u1eafc m\u00e0 ch\u00fang ta s\u1ebd xem x\u00e9t ngay sau \u0111\u00e2y.","title":"\u0110\u1ecbnh ngh\u0129a"},{"location":"mlops-crash-course/tong-quan-he-thong/tong-quan-mlops.html#nguyen-tac-principles","text":"Photo by Austin Distel on Unsplash Nguy\u00ean t\u1eafc \u0111\u01b0\u1ee3c xem nh\u01b0 l\u00e0 m\u1ed9t ph\u1ea7n c\u1ee7a best practices hay n\u00f3i c\u00e1ch kh\u00e1c \u0111\u00f3 l\u00e0 s\u1ef1 h\u01b0\u1edbng d\u1eabn, g\u1ee3i \u00fd cho c\u00e1c quy\u1ebft \u0111\u1ecbnh \u0111\u01b0\u1ee3c \u0111\u01b0a ra trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n h\u1ec7 th\u1ed1ng ML. C\u00e1c nguy\u00ean t\u1eafc (principles) trong MLOps bao g\u1ed3m: 1. T\u1ef1 \u0111\u1ed9ng ho\u00e1 trong t\u00edch h\u1ee3p v\u00e0 tri\u1ec3n khai (Continuous Integration/Continuous Delivery - CI/CD automation) Nguy\u00ean t\u1eafc n\u00e0y \u0111\u1ea3m b\u1ea3o vi\u1ec7c t\u00edch h\u1ee3p v\u00e0 tri\u1ec3n khai code di\u1ec5n ra t\u1ef1 \u0111\u1ed9ng. 2. H\u1ee3p ph\u1ed1i quy trinh (Workflow orchestration) Trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n h\u1ec7 th\u1ed1ng ML, c\u00f3 nhi\u1ec1u lu\u1ed3ng (pipeline) c\u1ea7n \u0111\u01b0\u1ee3c ch\u1ea1y v\u00e0o nh\u1eefng th\u1eddi \u0111i\u1ec3m nh\u1ea5t \u0111\u1ecbnh, v\u1edbi c\u00e1c b\u01b0\u1edbc trong lu\u1ed3ng ph\u1ee5 thu\u1ed9c l\u1eabn nhau. Ngo\u00e0i ra, th\u01b0 vi\u1ec7n, m\u00f4i tr\u01b0\u1eddng ch\u1ea1y c\u0169ng kh\u00e1c nhau. Nguy\u00ean t\u1eafc n\u00e0y \u0111\u1ea3m b\u1ea3o vi\u1ec7c t\u1ef1 \u0111\u1ed9ng ho\u00e1 \u0111i\u1ec1u ph\u1ed1i c\u00e1c b\u01b0\u1edbc trong m\u1ed9t lu\u1ed3ng ch\u1ea1y \u0111\u00fang th\u1ee9 t\u1ef1 v\u00e0 th\u1eddi gian \u0111\u01b0\u1ee3c ch\u1ec9 \u0111\u1ecbnh. 3. Kh\u1ea3 n\u0103ng \u0111\u01b0\u1ee3c t\u00e1i l\u1eadp l\u1ea1i (Reproducibility) Kh\u1ea3 n\u0103ng t\u00e1i l\u1eadp l\u1ea1i (reproduce) m\u1ed9t k\u1ebft qu\u1ea3 hay m\u1ed9t l\u1ea7n th\u1eed nghi\u1ec7m l\u00e0 m\u1ed9t y\u00eau c\u1ea7u th\u01b0\u1eddng th\u1ea5y khi ph\u00e1t tri\u1ec3n m\u1ed9t h\u1ec7 th\u1ed1ng ML. Y\u00eau c\u1ea7u n\u00e0y \u0111\u1ea3m b\u1ea3o vi\u1ec7c ch\u1ea1y suy di\u1ec5n m\u00f4 h\u00ecnh (model inference) \u1edf production \u1ed5n \u0111\u1ecbnh v\u00e0 debug qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n model hi\u1ec7u qu\u1ea3 h\u01a1n. 4. Qu\u1ea3n l\u00fd phi\u00ean b\u1ea3n m\u00e3 ngu\u1ed3n, d\u1eef li\u1ec7u v\u00e0 m\u00f4 h\u00ecnh (Versioning code, data, model) Nguy\u00ean t\u1eafc n\u00e0y \u0111\u1ea3m b\u1ea3o m\u00e3 ngu\u1ed3n (code), d\u1eef li\u1ec7u (data) v\u00e0 m\u00f4 h\u00ecnh (model) \u0111\u01b0\u1ee3c qu\u1ea3n l\u00fd theo c\u00e1c phi\u00ean b\u1ea3n (versions). \u0110i\u1ec1u n\u00e0y l\u00e0m thu\u1eadn ti\u1ec7n cho vi\u1ec7c ph\u00e1t tri\u1ec3n, ki\u1ec3m tra phi\u00ean b\u1ea3n model \u0111\u01b0\u1ee3c hu\u1ea5n luy\u1ec7n (train) v\u1edbi phi\u00ean b\u1ea3n data n\u00e0o v\u00e0 s\u1eed d\u1ee5ng code \u1edf phi\u00ean b\u1ea3n n\u00e0o \u0111\u1ec3 train. 5. H\u1ee3p t\u00e1c trong ph\u00e1t tri\u1ec3n (Collaboration) Trong m\u1ed9t d\u1ef1 \u00e1n ML, nhi\u1ec1u k\u0129 s\u01b0 v\u1edbi chuy\u00ean m\u00f4n kh\u00e1c nhau c\u00f9ng tham gia v\u00e0o ph\u00e1t tri\u1ec3n h\u1ec7 th\u1ed1ng. Nguy\u00ean t\u1eafc n\u00e0y \u0111\u1ea3m b\u1ea3o vi\u1ec7c thi\u1ebft l\u1eadp m\u1ed9t b\u1ed9 c\u00e1c quy t\u1eafc, c\u00f4ng c\u1ee5 v\u00e0 v\u0103n ho\u00e1 l\u00e0m vi\u1ec7c \u0111\u1ec3 qu\u00e1 tr\u00ecnh c\u1ed9ng t\u00e1c gi\u1eefa c\u00e1c c\u00e1 nh\u00e2n, \u1edf c\u00e1c vai tr\u00f2, tr\u00e1ch nhi\u1ec7m kh\u00e1c nhau, di\u1ec5n ra hi\u1ec7u qu\u1ea3. 6. Hu\u1ea5n luy\u1ec7n v\u00e0 \u0111\u00e1nh gi\u00e1 ML li\u00ean t\u1ee5c (Continuous ML training & evaluation) \u1ede m\u00f4i tr\u01b0\u1eddng production, vi\u1ec7c d\u1eef li\u1ec7u thay \u0111\u1ed5i li\u00ean t\u1ee5c khi\u1ebfn hi\u1ec7u n\u0103ng c\u1ee7a m\u00f4 h\u00ecnh gi\u1ea3m nhanh ch\u00f3ng. Nguy\u00ean t\u1eafc n\u00e0y \u0111\u1ea3m b\u1ea3o vi\u1ec7c x\u00e2y d\u1ef1ng m\u1ed9t lu\u1ed3ng \u0111\u1ec3 hu\u1ea5n luy\u1ec7n v\u00e0 \u0111\u00e1nh gi\u00e1 m\u00f4 h\u00ecnh m\u1ed9t c\u00e1ch t\u1ef1 \u0111\u1ed9ng \u0111\u1ecbnh k\u00ec ho\u1eb7c ngay khi c\u1ea7n thi\u1ebft. 7. Theo d\u1ea5u metadata trong ML (ML metadata tracking) Trong m\u1ed9t h\u1ec7 th\u1ed1ng ML, c\u00e1c c\u1ea5u h\u00ecnh hay data \u0111\u1ea7u v\u00e0o/\u0111\u1ea7u ra \u0111\u01b0\u1ee3c y\u00eau c\u1ea7u c\u1ee5 th\u1ec3, \u1edf m\u1ed7i b\u01b0\u1edbc c\u1ee7a m\u1ed9t lu\u1ed3ng. Nguy\u00ean t\u1eafc n\u00e0y \u0111\u01b0\u1ee3c \u0111\u1eb7t ra nh\u1eb1m theo d\u00f5i v\u00e0 ghi l\u1ea1i c\u00e1c \u0111\u1ea7u v\u00e0o v\u00e0 \u0111\u1ea7u ra \u0111\u00f3, k\u00e8m theo th\u00f4ng tin v\u1ec1 nh\u1eefng l\u1ea7n ch\u1ea1y c\u1ee7a c\u00e1c lu\u1ed3ng, v\u00ed d\u1ee5 nh\u01b0: Ng\u00e0y, th\u00e1ng, th\u1eddi gian ch\u1ea1y Phi\u00ean b\u1ea3n c\u1ee7a data \u0111ang ch\u1ea1y Hyperparameter d\u00f9ng \u0111\u1ec3 train model N\u01a1i l\u01b0u tr\u1eef model sau khi train xong v.v. 8. Theo d\u00f5i li\u00ean t\u1ee5c (Continuous monitoring) Nguy\u00ean t\u1eafc n\u00e0y \u0111\u1ea3m b\u1ea3o vi\u1ec7c theo d\u00f5i li\u00ean t\u1ee5c c\u00e1c th\u00f4ng s\u1ed1 li\u00ean quan t\u1edbi d\u1eef li\u1ec7u, m\u00f4 h\u00ecnh, h\u1ea1 t\u1ea7ng (infrastructure), \u0111\u1ec3 ph\u00e1t hi\u1ec7n v\u00e0 gi\u1ea3i quy\u1ebft c\u00e1c l\u1ed7i k\u1ecbp th\u1eddi. M\u1ed9t v\u00e0i th\u00f4ng s\u1ed1 \u0111i\u1ec3n h\u00ecnh bao g\u1ed3m: C\u00e1c t\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a data \u1edf production Model performance L\u01b0\u1ee3ng request \u0111\u01b0\u1ee3c g\u1eedi \u0111\u1ebfn server Th\u1eddi gian x\u1eed l\u00fd m\u1ed9t request v.v. 9. V\u00f2ng l\u1eb7p \u00fd ki\u1ebfn ph\u1ea3n h\u1ed3i (Feedback loops) Khi ph\u00e1t tri\u1ec3n m\u1ed9t h\u1ec7 th\u1ed1ng ML, s\u1ef1 ph\u1ea3n h\u1ed3i t\u1eeb ph\u1ea7n \u0111\u00e1nh gi\u00e1 ng\u01b0\u1ee3c v\u1ec1 ph\u1ea7n ph\u00e1t tri\u1ec3n th\u01b0\u1eddng xuy\u00ean x\u1ea3y ra, v\u00ed d\u1ee5: Ph\u1ea3n h\u1ed3i t\u1eeb qu\u00e1 tr\u00ecnh th\u1eed nghi\u1ec7m data v\u00e0 model ng\u01b0\u1ee3c v\u1ec1 qu\u00e1 tr\u00ecnh x\u1eed l\u00fd d\u1eef li\u1ec7u th\u00f4 (raw data) Ph\u1ea3n h\u1ed3i t\u1eeb qu\u00e1 tr\u00ecnh \u0111\u00e1nh gi\u00e1 model performance \u1edf production ng\u01b0\u1ee3c v\u1ec1 qu\u00e1 tr\u00ecnh th\u1eed nghi\u1ec7m model v.v. Xuy\u00ean su\u1ed1t kho\u00e1 h\u1ecdc, c\u00e1c nguy\u00ean t\u1eafc n\u00e0y s\u1ebd \u0111\u01b0\u1ee3c ng\u1ea7m hi\u1ec3u v\u00e0 s\u1eed d\u1ee5ng trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n h\u1ec7 th\u1ed1ng. \u0110\u1ec3 bi\u1ebft th\u00eam chi ti\u1ebft, b\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc k\u0129 h\u01a1n \u1edf b\u00e0i b\u00e1o tr\u00ean .","title":"Nguy\u00ean T\u1eafc (Principles)"},{"location":"mlops-crash-course/tong-quan-he-thong/tong-quan-mlops.html#cac-thanh-phan-cua-mlops-mlops-components","text":"Photo by Jorge Ramirez on Unsplash C\u00e1c th\u00e0nh ph\u1ea7n trong MLOps bao g\u1ed3m c\u00e1c c\u1ea5u ph\u1ea7n trong m\u1ed9t h\u1ec7 th\u1ed1ng ML. C\u00e1c th\u00e0nh ph\u1ea7n \u0111\u01b0\u1ee3c li\u1ec7t k\u00ea nh\u01b0 sau. CI/CD component Source code repository Workflow orchestration Feature store Model training infrastructure Model registry ML metadata store Model serving component Monitoring component T\u00ean c\u00e1c components \u0111\u00e3 gi\u1ea3i th\u00edch \u00fd ngh\u0129a v\u00e0 c\u00f4ng vi\u1ec7c c\u1ee7a c\u00e1c components \u0111\u00f3, \u0111\u1ed3ng th\u1eddi ch\u00fang c\u0169ng th\u1ef1c hi\u1ec7n nhi\u1ec7m v\u1ee5 c\u1ee7a m\u1ed9t ho\u1eb7c nhi\u1ec1u principle \u1edf ph\u1ea7n tr\u01b0\u1edbc, n\u00ean ch\u00fang ta s\u1ebd kh\u00f4ng \u0111\u1ec1 c\u1eadp chi ti\u1ebft \u1edf \u0111\u00e2y. \u0110\u1ec3 hi\u1ec3u r\u00f5 h\u01a1n v\u1ec1 m\u1ed1i quan h\u1ec7 c\u1ee7a c\u00e1c components v\u1edbi principles trong MLOps, b\u1ea1n c\u00f3 th\u1ec3 \u0111\u1ecdc k\u0129 h\u01a1n \u1edf b\u00e0i b\u00e1o tr\u00ean .","title":"C\u00e1c th\u00e0nh ph\u1ea7n c\u1ee7a MLOps (MLOps Components)"},{"location":"mlops-crash-course/tong-quan-he-thong/tong-quan-mlops.html#cac-workflows","text":"Trong ph\u1ea7n n\u00e0y, ch\u00fang ta s\u1ebd t\u00ecm hi\u1ec3u v\u1ec1 c\u00e1c workflows \u0111i\u1ec3n h\u00ecnh trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n m\u1ed9t h\u1ec7 th\u1ed1ng ML. C\u00e1c workflows \u0111\u01b0\u1ee3c m\u00f4 t\u1ea3 \u1edf b\u1ea3ng d\u01b0\u1edbi \u0111\u00e2y. # Workflow M\u00f4 t\u1ea3 1 Ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1 Ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1 kinh doanh, thi\u1ebft k\u1ebf h\u1ec7 th\u1ed1ng ph\u1ea7n m\u1ec1m, quy\u1ebft \u0111\u1ecbnh gi\u1ea3i ph\u00e1p v\u1ec1 c\u00f4ng ngh\u1ec7 s\u1ebd d\u00f9ng, \u0111\u1ecbnh ngh\u0129a v\u1ea5n \u0111\u1ec1 ML c\u1ea7n gi\u1ea3i quy\u1ebft, t\u00ecm ki\u1ebfm data c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng, thu th\u1eadp data v\u00e0 ph\u00e2n t\u00edch data 2 \u0110\u1ecbnh ngh\u0129a quy lu\u1eadt bi\u1ebfn \u0111\u1ed5i data \u0110\u1ecbnh ngh\u0129a c\u00e1c quy lu\u1eadt \u0111\u1ec3 bi\u1ebfn \u0111\u1ed5i data th\u00e0nh d\u1ea1ng c\u00f3 th\u1ec3 s\u1eed d\u1ee5ng \u0111\u01b0\u1ee3c \u0111\u1ec3 th\u1eed nghi\u1ec7m 3 X\u00e2y d\u1ef1ng data pipeline Quy lu\u1eadt bi\u1ebfn \u0111\u1ed5i data s\u1ebd \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 x\u00e2y d\u1ef1ng data pipeline 4 Th\u1eed nghi\u1ec7m model Th\u1eed nghi\u1ec7m data v\u00e0 model, train model t\u1ed1t nh\u1ea5t 5 T\u1ef1 \u0111\u1ed9ng ho\u00e1 ML pipeline Code t\u1eeb qu\u00e1 tr\u00ecnh th\u1eed nghi\u1ec7m data v\u00e0 model s\u1ebd \u0111\u01b0\u1ee3c t\u1ef1 \u0111\u1ed9ng v\u00e0o ML pipeline. Model sau khi train xong s\u1ebd \u0111\u01b0\u1ee3c tri\u1ec3n khai t\u1ef1 \u0111\u1ed9ng l\u00ean Model serving component v\u00e0 t\u00edch h\u1ee3p v\u1edbi Monitoring component C\u00e1c workflows tr\u00ean kh\u00f4ng ph\u1ea3i l\u00e0 th\u1ee9 t\u1ef1 ch\u00ednh x\u00e1c v\u1ec1 c\u00e1c c\u00f4ng vi\u1ec7c khi x\u00e2y d\u1ef1ng m\u1ed9t h\u1ec7 th\u1ed1ng ML. H\u00ecnh d\u01b0\u1edbi \u0111\u00e2y l\u00e0 m\u1ed9t v\u00ed d\u1ee5 v\u1ec1 th\u1ee9 t\u1ef1 trong th\u1ef1c t\u1ebf. flowchart TD n1[Kh\u1edfi \u0111\u1ed9ng d\u1ef1 \u00e1n] --> n2[\u0110\u1ecbnh ngh\u0129a v\u1ea5n \u0111\u1ec1] --> n3[POC 1] --> n4[POC 2] --> n5[X\u00e2y d\u1ef1ng c\u00e1c pipelines] --> n6[T\u1ef1 \u0111\u1ed9ng ho\u00e1 c\u00e1c pipelines] --> n7[Production] n3 --\u0110\u1ecbnh ngh\u0129a l\u1ea1i<br>v\u1ea5n \u0111\u1ec1--> n2 n4 --C\u1eadp nh\u1eadt c\u00e1ch<br>bi\u1ebfn \u0111\u1ed5i data--> n2 n7 --C\u1eadp nh\u1eadt c\u00e1ch<br>train model--> n2 \u0110\u1ea7u ti\u00ean, ch\u00fang ta c\u1ea7n \u0111\u1ecbnh ngh\u0129a v\u00e0 ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1 kinh doanh \u0111\u1ec3 hi\u1ec3u r\u00f5 y\u00eau c\u1ea7u v\u1ec1 c\u00e1c ch\u1ee9c n\u0103ng c\u1ee7a h\u1ec7 th\u1ed1ng ML. Sau \u0111\u00f3, d\u1ef1 \u00e1n Proof Of Concept (POC) s\u1ebd \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n \u0111\u1ec3 ch\u1ee9ng minh r\u1eb1ng gi\u1ea3i ph\u00e1p \u0111\u1ec1 ra l\u00e0 kh\u1ea3 thi, tr\u01b0\u1edbc khi b\u1eaft tay v\u00e0o x\u00e2y d\u1ef1ng chi ti\u1ebft c\u00e1c ch\u1ee9c n\u0103ng ph\u1ee9c t\u1ea1p. C\u00f3 th\u1ec3 c\u00f3 nhi\u1ec1u d\u1ef1 \u00e1n POC \u1edf c\u00e1c m\u1ee9c \u0111\u1ed9 kh\u00e1c nhau. Trong qu\u00e1 tr\u00ecnh th\u1ef1c hi\u1ec7n d\u1ef1 \u00e1n POC, c\u00e1c data engineer, software engineer, ML engineer hay MLOps engineer c\u0169ng th\u1ef1c hi\u1ec7n song song vi\u1ec7c x\u00e2y d\u1ef1ng data pipeline, training pipeline, model serving component, monitoring component v\u00e0 CI/CD cho t\u1ea5t c\u1ea3 pipeline, components \u0111\u00f3. D\u1ef1a tr\u00ean c\u00e1c b\u01b0\u1edbc x\u00e2y d\u1ef1ng m\u1ed9t h\u1ec7 th\u1ed1ng ML trong th\u1ef1c t\u1ebf, kho\u00e1 h\u1ecdc n\u00e0y s\u1ebd bao g\u1ed3m c\u00e1c b\u00e0i h\u1ecdc l\u1ea7n l\u01b0\u1ee3t nh\u01b0 sau: Ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1 POC Data pipeline Training pipeline Model serving Monitoring CI/CD","title":"C\u00e1c workflows"},{"location":"mlops-crash-course/tong-quan-he-thong/tong-quan-mlops.html#tong-ket","text":"Trong b\u00e0i n\u00e0y, ch\u00fang ta \u0111\u00e3 t\u00ecm hi\u1ec3u kh\u00e1 nhi\u1ec1u v\u1ea5n \u0111\u1ec1 c\u0169ng nh\u01b0 vi\u1ec7c \u0111\u01b0a ra \u0111\u01b0\u1ee3c ph\u01b0\u01a1ng ph\u00e1p gi\u1ea3i quy\u1ebft d\u1ef1a tr\u00ean c\u00e1c quy t\u1eafc (principles), th\u00e0nh ph\u1ea7n (components), quy tr\u00ecnh (workflows) \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a trong MLOps. Tuy nhi\u00ean, MLOps v\u1eabn c\u00f2n l\u00e0 m\u1ed9t m\u1ea3ng kh\u00e1 m\u1edbi, c\u00f2n t\u1ed3n t\u1ea1i kh\u00e1 nhi\u1ec1u th\u1eed th\u00e1ch d\u00e0nh cho c\u00e1c k\u0129 s\u01b0. Hy v\u1ecdng r\u1eb1ng kho\u00e1 h\u1ecdc MLOps Crash Course s\u1ebd l\u00e0 m\u1ed9t b\u01b0\u1edbc n\u1ec1n t\u1ea3ng gi\u00fap cho c\u1ed9ng \u0111\u1ed3ng AI/ML t\u1ea1i Vi\u1ec7t Nam ph\u00e1t tri\u1ec3n m\u1ea1nh m\u1ebd, g\u00f3p ph\u1ea7n v\u00e0o s\u1ef1 ph\u00e1t tri\u1ec3n chung c\u1ee7a AI/ML tr\u00ean th\u1ebf gi\u1edbi. Trong b\u00e0i ti\u1ebfp theo, ch\u00fang ta s\u1ebd b\u1eaft \u0111\u1ea7u c\u00e1c b\u01b0\u1edbc \u0111\u1ea7u ti\u00ean khi x\u00e2y d\u1ef1ng m\u1ed9t d\u1ef1 \u00e1n ML, \u0111\u00f3 l\u00e0 b\u01b0\u1edbc Ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1 .","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/training-pipeline/xay-dung-training-pipeline.html","text":"Photo by SEL\u0130M ARDA ERYILMAZ on Unsplash Gi\u1edbi thi\u1ec7u Sau khi th\u1ef1c hi\u1ec7n \u00edt nh\u1ea5t m\u1ed9t d\u1ef1 \u00e1n POC th\u00e0nh c\u00f4ng, ch\u00fang ta \u0111\u00e3 c\u00f3 \u0111\u01b0\u1ee3c: C\u00e1ch bi\u1ebfn \u0111\u1ed5i data t\u1eeb data source C\u00e1ch bi\u1ebfn \u0111\u1ed5i feature engineering Code chu\u1ea9n b\u1ecb data \u0111\u1ec3 train model Code train model Code \u0111\u00e1nh gi\u00e1 model Ph\u1ea7n 1, 2 \u0111\u01b0\u1ee3c d\u00f9ng trong b\u00e0i x\u00e2y d\u1ef1ng data pipeline . Ph\u1ea7n 3, 4 v\u00e0 5 s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng trong b\u00e0i n\u00e0y \u0111\u1ec3 x\u00e2y d\u1ef1ng training pipeline v\u1edbi c\u00e1c task nh\u01b0 h\u00ecnh d\u01b0\u1edbi. flowchart LR n1[1. C\u1eadp nh\u1eadt<br>Feature Store] --> n2[2. Data<br>extraction] --> n3[3. Data<br>validation] --> n4[4. Data<br>preparation] --> n5[5. Model<br>training] --> n6[6. Model<br>evaluation] --> n7[7. Model<br>validation] M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n C\u00e1c b\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 c\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n: C\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng Python 3.9 m\u1edbi v\u1edbi c\u00e1c th\u01b0 vi\u1ec7n c\u1ea7n thi\u1ebft trong file training_pipeline/dev_requirements.txt \u0110\u1eb7t environment variable TRAINING_PIPELINE_DIR \u1edf terminal b\u1ea1n d\u00f9ng b\u1eb1ng \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i t\u1edbi folder training_pipeline v\u00e0 MLFLOW_TRACKING_URI b\u1eb1ng URL c\u1ee7a MLflow server. Hai env var n\u00e0y h\u1ed7 tr\u1ee3 ch\u1ea1y python code \u1edf folder training_pipeline/src trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n. cd mlops-crash-course-code/training_pipeline export TRAINING_PIPELINE_DIR = $( pwd ) export MLFLOW_TRACKING_URI = \"http://localhost:5000\" C\u00e1c MLOps tools \u0111\u01b0\u1ee3c d\u00f9ng trong b\u00e0i n\u00e0y bao g\u1ed3m: Feast: truy xu\u1ea5t Feature Store MLflow: ML Metadata Store, Model Registry Airflow: \u0111i\u1ec1u ph\u1ed1i training pipeline Note Trong qu\u00e1 tr\u00ecnh ch\u1ea1y code cho t\u1ea5t c\u1ea3 c\u00e1c ph\u1ea7n d\u01b0\u1edbi \u0111\u00e2y, ch\u00fang ta gi\u1ea3 s\u1eed r\u1eb1ng folder g\u1ed1c n\u01a1i ch\u00fang ta l\u00e0m vi\u1ec7c l\u00e0 folder training_pipeline . C\u1eadp nh\u1eadt Feature Store Trong kho\u00e1 h\u1ecdc n\u00e0y, Feast \u0111\u01b0\u1ee3c d\u00f9ng l\u00e0m Feature Store \u0111\u1ec3 qu\u1ea3n l\u00fd phi\u00ean b\u1ea3n c\u00e1c features v\u00e0 c\u00e1c b\u1ed9 features. Feast s\u1eed d\u1ee5ng Feature Registry \u0111\u1ec3 t\u1eadp trung l\u01b0u tr\u1eef \u0111\u1ecbnh ngh\u0129a v\u1ec1 c\u00e1c feature v\u00e0 metadata. Do Feature Registry n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u \u1edf d\u1ea1ng file \u1edf m\u00e1y local, n\u00ean m\u1ed7i Data Scientist c\u1ea7n t\u1ef1 update Feature Registry tr\u00ean m\u00e1y c\u1ee7a m\u00ecnh. Tr\u01b0\u1edbc khi c\u1eadp nh\u1eadt Feature Store, c\u1ea7n \u0111\u1ea3m b\u1ea3o code c\u1ee7a Feature Store \u0111\u00e3 \u0111\u01b0\u1ee3c tri\u1ec3n khai l\u00ean m\u00e1y c\u1ee7a b\u1ea1n. Trong th\u1ef1c t\u1ebf, code c\u1ee7a Feature Store s\u1ebd \u0111\u01b0\u1ee3c Data Engineer build v\u00e0 release nh\u01b0 m\u1ed9t library cho ph\u00e9p ML engineer download v\u1ec1 v\u00e0 s\u1eed d\u1ee5ng. Code c\u1ee7a Feature Store n\u1eb1m t\u1ea1i data_pipeline/feature_repo . \u0110\u1ec3 tri\u1ec3n khai sang training pipeline, ch\u00fang ta s\u1ebd copy code t\u1eeb data_pipeline/feature_repo sang training_pipeline/feature_repo . B\u1ea1n h\u00e3y ch\u1ea1y c\u00e1c l\u1ec7nh sau. cd ../data_pipeline make deploy_feature_repo # (1) cd ../training_pipeline cd feature_repo feast apply # (2) cd .. Tri\u1ec3n khai code c\u1ee7a Feature Store C\u1eadp nh\u1eadt Feature Registry v\u00e0 Offline Feature Store c\u1ee7a Feast Data extraction Trong task n\u00e0y, c\u00e1c features \u0111\u01b0\u1ee3c l\u1ea5y t\u1eeb Offline Feature Store \u0111\u1ec3 ph\u1ee5c v\u1ee5 cho qu\u00e1 tr\u00ecnh train model. \u0110\u1ea7u v\u00e0o: t\u00ean c\u00e1c features ch\u00fang ta mu\u1ed1n l\u1ea5y \u0110\u1ea7u ra: file data ch\u1ee9a features \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o disk Code c\u1ee7a task n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i training_pipeline/src/data_extraction.py . training_pipeline/src/data_extraction.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 fs = feast . FeatureStore ( repo_path = AppPath . FEATURE_REPO ) # (1) orders = pd . read_csv ( AppPath . DATA / \"driver_orders.csv\" , sep = \" \\t \" ) # (2) orders [ \"event_timestamp\" ] = pd . to_datetime ( orders [ \"event_timestamp\" ]) # (3) training_df = fs . get_historical_features ( # (4) entity_df = orders , features = [ \"driver_stats:conv_rate\" , # (5) \"driver_stats:acc_rate\" , \"driver_stats:avg_daily_trips\" , ], ) . to_df () # (6) to_parquet ( training_df , AppPath . TRAINING_PQ ) # (7) T\u1ea1o k\u1ebft n\u1ed1i t\u1edbi Feature Store \u0110\u1ecdc label t\u1eeb file driver_orders.csv \u0110\u1ecbnh d\u1ea1ng l\u1ea1i format cho c\u1ed9t event_timestamp Download features t\u1eeb Offline Feature Store. C\u00e1c feature ch\u00fang ta mu\u1ed1n l\u1ea5y bao g\u1ed3m conv_rate , acc_rate v\u00e0 avg_daily_trips . driver_stats l\u00e0 t\u00ean FeatureView m\u00e0 ch\u00fang ta \u0111\u00e3 \u0111\u1ecbnh ngh\u0129a t\u1ea1i data_pipeline/feature_repo/features.py C\u00e1ch m\u00e0 Feast l\u1ea5y ra features gi\u1ed1ng nh\u01b0 c\u00e1ch ch\u00fang ta chu\u1ea9n b\u1ecb data \u1edf d\u1ef1 \u00e1n POC. B\u1ea1n c\u00f3 th\u1ec3 xem l\u1ea1i t\u1ea1i \u0111\u00e2y . L\u01b0u data v\u00e0o disk \u0111\u1ec3 s\u1eed d\u1ee5ng trong c\u00e1c task ti\u1ebfp theo. B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 test th\u1eed code. Ch\u1ea1y code cd src python data_extraction.py cd .. Bug N\u1ebfu c\u00e1c b\u1ea1n g\u1eb7p l\u1ed7i sau: PermissionError: [ Errno 13 ] Permission denied: '/training_pipeline' Th\u00ec c\u00e1c b\u1ea1n c\u1ea7n \u0111\u1eb7t environment variable TRAINING_PIPELINE_DIR nh\u01b0 h\u01b0\u1edbng d\u1eabn \u1edf ph\u1ea7n M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n . Ki\u1ec3m tra folder training_pipeline/artifacts , b\u1ea1n s\u1ebd th\u1ea5y file training.parquet Data validation Photo by Diane Serik on Unsplash Sau khi l\u1ea5y \u0111\u01b0\u1ee3c data t\u1eeb Offline Feature Store, ch\u00fang ta c\u1ea7n \u0111\u00e1nh gi\u00e1 data c\u00f3 h\u1ee3p l\u1ec7 kh\u00f4ng tr\u01b0\u1edbc khi train model, b\u1eb1ng c\u00e1ch ki\u1ec3m tra. C\u1ea5u tr\u00fac data Nh\u1eadn \u0111\u01b0\u1ee3c feature n\u00e0o kh\u00f4ng mong mu\u1ed1n kh\u00f4ng? Nh\u1eadn \u0111\u1ee7 feature mong mu\u1ed1n kh\u00f4ng? Feature c\u00f3 \u1edf format mong mu\u1ed1n kh\u00f4ng? Gi\u00e1 tr\u1ecb c\u1ee7a data C\u00e1c t\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a data c\u00f3 nh\u01b0 mong mu\u1ed1n kh\u00f4ng? C\u00e1c gi\u1ea3 s\u1eed v\u1ec1 data c\u00f3 nh\u01b0 mong mu\u1ed1n kh\u00f4ng? Task n\u00e0y kh\u00f4ng sinh ra c\u00e1c artifact hay file n\u00e0o, m\u00e0 n\u00f3 s\u1ebd quy\u1ebft \u0111\u1ecbnh xem task ti\u1ebfp theo c\u00f3 \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n hay kh\u00f4ng. Code c\u1ee7a task n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i training_pipeline/src/data_validation.py . training_pipeline/src/data_validation.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def check_unexpected_features ( df : pd . DataFrame ): # (1) cols = set ( df . columns ) for col in cols : if not col in config . feature_dict : # (2) # B\u00e1o l\u1ed7i feature 'col' kh\u00f4ng mong mu\u1ed1n def check_expected_features ( df : pd . DataFrame ): # (3) dtypes = dict ( df . dtypes ) for feature in config . feature_dict : if not feature in dtypes : # B\u00e1o l\u1ed7i feature 'feature' kh\u00f4ng t\u00ecm th\u1ea5y else : expected_type = config . feature_dict [ feature ] real_type = dtypes [ feature ] if expected_type != real_type : # B\u00e1o l\u1ed7i feature 'feature' c\u00f3 \u0111\u1ecbnh d\u1ea1ng kh\u00f4ng mong mu\u1ed1n Ki\u1ec3m tra xem c\u00f3 feature n\u00e0o kh\u00f4ng mong mu\u1ed1n config.feature_dict l\u00e0 dictionary v\u1edbi key l\u00e0 t\u00ean c\u00e1c feature mong mu\u1ed1n v\u00e0 value l\u00e0 format mong mu\u1ed1n c\u1ee7a c\u00e1c feature Ki\u1ec3m tra xem c\u00f3 feature mong mu\u1ed1n v\u00e0 \u1edf \u0111\u1ecbnh d\u1ea1ng mong mu\u1ed1n kh\u00f4ng \u0110\u1ec3 \u0111\u01a1n gian ho\u00e1 code v\u00e0 t\u1eadp trung v\u00e0o MLOps, ch\u00fang ta s\u1ebd kh\u00f4ng ki\u1ec3m tra c\u00e1c t\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a data. B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 test th\u1eed code. cd src python data_validation.py cd .. Data preparation Task Data preparation c\u00f3 \u0111\u1ea7u v\u00e0o v\u00e0 \u0111\u1ea7u ra nh\u01b0 sau. \u0110\u1ea7u v\u00e0o: file data ch\u1ee9a features \u1edf b\u01b0\u1edbc Data extraction \u0110\u1ea7u ra: training set v\u00e0 test set \u0111\u00e3 \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o disk Task n\u00e0y th\u1ef1c hi\u1ec7n c\u00e1c vi\u1ec7c sau. Bi\u1ebfn \u0111\u1ed5i data n\u1ebfu c\u1ea7n, c\u00f3 th\u1ec3 x\u1ea3y ra n\u1ebfu features l\u1ea5y t\u1eeb Offline Feature Store kh\u00f4ng \u1edf \u0111\u1ecbnh d\u1ea1ng mong mu\u1ed1n Bi\u1ebfn \u0111\u1ed5i feature engineering n\u1ebfu c\u1ea7n T\u1ea1o training set, test set \u0111\u1ec3 train v\u00e0 \u0111\u00e1nh gi\u00e1 model Code c\u1ee7a task n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i training_pipeline/src/data_preparation.py . training_pipeline/src/data_preparation.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 target_col = 'trip_completed' train , test = train_test_split ( # (1) df , test_size = config . test_size , random_state = config . random_seed ) target_col = config . target_col train_x = train . drop ([ target_col ], axis = 1 ) train_y = train [[ target_col ]] test_x = test . drop ([ target_col ], axis = 1 ) test_y = test [[ target_col ]] to_parquet ( train_x , AppPath . TRAIN_X_PQ ) # (2) to_parquet ( train_y , AppPath . TRAIN_Y_PQ ) to_parquet ( test_x , AppPath . TEST_X_PQ ) to_parquet ( test_y , AppPath . TEST_Y_PQ ) Chia data ra th\u00e0nh training set v\u00e0 test set, v\u00ec gi\u1ea3 s\u1eed ch\u00fang ta \u0111\u00e3 l\u1ea5y \u0111\u01b0\u1ee3c c\u00e1c feature mong mu\u1ed1n \u1edf \u0111\u1ecbnh d\u1ea1ng mong mu\u1ed1n, c\u0169ng kh\u00f4ng c\u1ea7n th\u1ef1c hi\u1ec7n th\u00eam c\u00e1c b\u01b0\u1edbc bi\u1ec3n \u0111\u1ed5i data, ho\u1eb7c sinh ra c\u00e1c feature kh\u00e1c n\u1eefa L\u01b0u data v\u00e0o disk \u0111\u1ec3 s\u1eed d\u1ee5ng trong c\u00e1c task ti\u1ebfp theo. B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 test th\u1eed code. Ch\u1ea1y code cd src python data_preparation.py cd .. Ki\u1ec3m tra folder training_pipeline/artifacts , b\u1ea1n s\u1ebd th\u1ea5y c\u00e1c files training.parquet , train_x.parquet , test_x.parquet , train_y.parquet v\u00e0 test_y.parquet Model training Task Model training s\u1ebd train model v\u00e0 th\u1ef1c hi\u1ec7n hyperparameter tuning \u0111\u1ec3 train model t\u1ed1t nh\u1ea5t. Tuy nhi\u00ean trong b\u00e0i n\u00e0y, ch\u00fang ta s\u1ebd kh\u00f4ng th\u1ef1c hi\u1ec7n hyperparameter tuning. Task n\u00e0y c\u00f3: \u0110\u1ea7u v\u00e0o: data \u0111\u01b0\u1ee3c chu\u1ea9n b\u1ecb \u1edf task Data preparation \u0110\u1ea7u ra: model \u0111\u00e3 \u0111\u01b0\u1ee3c train Code cho task Model training \u0111\u00e3 \u0111\u01b0\u1ee3c vi\u1ebft \u1edf d\u1ef1 \u00e1n POC. Code c\u1ee7a task n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i training_pipeline/src/model_training.py . training_pipeline/src/model_training.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 mlflow . set_tracking_uri ( config . mlflow_tracking_uri ) # (1) train_x = load_df ( AppPath . TRAIN_X_PQ ) # (2) train_y = load_df ( AppPath . TRAIN_Y_PQ ) model = ElasticNet ( # (3) alpha = config . alpha , l1_ratio = config . l1_ratio , random_state = config . random_seed , ) model . fit ( train_x , train_y ) mlflow . log_param ( \"alpha\" , config . alpha ) # (4) mlflow . log_param ( \"l1_ratio\" , config . l1_ratio ) mlflow . sklearn . log_model ( model , # n\u01a1i l\u01b0u model ) run_id = mlflow . last_active_run () . info . run_id # (5) run_info = RunInfo ( run_id ) run_info . save () Set URI t\u1edbi MLflow server Load data Train model Log metadata L\u01b0u l\u1ea1i th\u00f4ng tin v\u1ec1 l\u1ea7n ch\u1ea1y hi\u1ec7n t\u1ea1i \u0111\u1ec3 c\u00e1c task ti\u1ebfp theo bi\u1ebft \u0111\u01b0\u1ee3c model n\u00e0o v\u1eeba \u0111\u01b0\u1ee3c train, \u0111\u1ec3 c\u00f3 th\u1ec3 download model v\u00e0 \u0111\u00e1nh gi\u00e1 model \u1ede b\u01b0\u1edbc Log metadata, ch\u00fang ta kh\u00f4ng c\u1ea7n log l\u1ea1i danh s\u00e1ch c\u00e1c feature \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng n\u1eefa, v\u00ec b\u1ed9 feature \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u00e3 \u0111\u01b0\u1ee3c version trong code \u1edf b\u01b0\u1edbc Data extraction. N\u1ebfu c\u00f3 th\u1ec3, ch\u00fang ta n\u00ean l\u01b0u c\u1ea3 \u0111\u01b0\u1eddng d\u1eabn t\u1edbi data source \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o c\u00f3 th\u1ec3 theo d\u00f5i l\u1ea1i \u0111\u01b0\u1ee3c ngu\u1ed3n g\u1ed1c c\u1ee7a data. B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 test th\u1eed code. M\u1edf repo mlops-crash-course-platform v\u00e0 ch\u1ea1y mlflow server. bash run.sh mlflow up Ch\u1ea1y code cd src python model_training.py cd .. Ki\u1ec3m tra folder training_pipeline/artifacts , b\u1ea1n s\u1ebd th\u1ea5y file run_info.json M\u1edf MLflow server, b\u1ea1n s\u1ebd th\u1ea5y m\u1ed9t experiment \u0111\u01b0\u1ee3c t\u1ea1o ra Model evaluation Task Model evaluation th\u1ef1c hi\u1ec7n ch\u1ea1y prediction cho model tr\u00ean test set. Task n\u00e0y c\u00f3: \u0110\u1ea7u v\u00e0o: model \u0111\u00e3 \u0111\u01b0\u1ee3c train \u0110\u1ea7u ra: c\u00e1c metrics \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 ch\u1ea5t l\u01b0\u1ee3ng model Code cho task Model evaluation \u0111\u00e3 \u0111\u01b0\u1ee3c vi\u1ebft \u1edf d\u1ef1 \u00e1n POC. Code c\u1ee7a task n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i training_pipeline/src/model_evaluation.py . training_pipeline/src/model_evaluation.py 1 2 3 4 5 6 7 8 9 10 11 model = mlflow . pyfunc . load_model ( # n\u01a1i l\u01b0u model ) test_x = load_df ( AppPath . TEST_X_PQ ) # (1) test_y = load_df ( AppPath . TEST_Y_PQ ) predicted_qualities = model . predict ( test_x ) ( rmse , mae ) = eval_metrics ( test_y , predicted_qualities ) eval_result = EvaluationResult ( rmse , mae ) # (2) eval_result . save () Ch\u1ea1y inference tr\u00ean test set L\u01b0u l\u1ea1i k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 l\u00e0 offline metrics, s\u1ebd \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o disk, \u0111\u1ec3 ph\u1ee5c v\u1ee5 cho task Model validation. B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 test th\u1eed code. Ch\u1ea1y code cd src python model_evaluation.py cd .. Ki\u1ec3m tra folder training_pipeline/artifacts , b\u1ea1n s\u1ebd th\u1ea5y file evaluation.json Model validation Trong task n\u00e0y, ch\u00fang ta d\u00f9ng c\u00e1c metrics t\u1eeb task Model evaluation \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 model. C\u00e1c baseline v\u1ec1 metrics n\u00ean \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a \u1edf b\u01b0\u1edbc Ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1 . Vi\u1ec7c \u0111\u00e1nh gi\u00e1 model d\u1ef1a tr\u00ean c\u00e1c metrics \u0111\u1ec3 ch\u1ee9ng t\u1ecf model m\u1edbi c\u00f3 performance t\u1ed1t h\u01a1n model c\u0169 tr\u01b0\u1edbc khi tri\u1ec3n khai ra production. Model performance c\u1ea7n \u0111\u01b0\u1ee3c \u0111\u00e1nh gi\u00e1 tr\u00ean c\u00e1c ph\u1ea7n kh\u00e1c nhau c\u1ee7a dataset. V\u00ed d\u1ee5 nh\u01b0 model m\u1edbi c\u00f3 Accuracy cao h\u01a1n model c\u0169 khi \u0111\u00e1nh gi\u00e1 tr\u00ean t\u1ea5t c\u1ea3 kh\u00e1ch h\u00e0ng, nh\u01b0ng c\u00f3 Accuracy tr\u00ean data c\u1ee7a kh\u00e1ch h\u00e0ng \u1edf v\u00e0i khu v\u1ef1c \u0111\u1ecba l\u00fd th\u1ea5p h\u01a1n model c\u0169. Ngo\u00e0i ra, model c\u00f3 th\u1ec3 c\u1ea7n \u0111\u01b0\u1ee3c ki\u1ec3m tra xem c\u00f3 t\u01b0\u01a1ng th\u00edch v\u1edbi h\u1ec7 th\u1ed1ng \u1edf production kh\u00f4ng. V\u00ed d\u1ee5: Ki\u1ec3m tra model m\u1edbi c\u00f3 nh\u1eadn v\u00e0o \u0111\u1ecbnh d\u1ea1ng \u0111\u1ea7u v\u00e0o v\u00e0 tr\u1ea3 v\u1ec1 \u0111\u1ecbnh d\u1ea1ng \u0111\u1ea7u ra t\u01b0\u01a1ng th\u00edch kh\u00f4ng Th\u1eddi gian inference c\u00f3 \u0111\u1ea3m b\u1ea3o n\u1eb1m trong m\u1ed9t kho\u1ea3ng y\u00eau c\u1ea7u c\u1ee7a v\u1ea5n \u0111\u1ec1 kinh doanh kh\u00f4ng Trong task n\u00e0y, ch\u00fang ta ch\u1ec9 vi\u1ebft code \u0111\u1ec3 so s\u00e1nh offline metrics v\u1edbi c\u00e1c thresholds \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a trong file training_pipeline/.env . N\u1ebfu model tho\u1ea3 m\u00e3n c\u00e1c thresholds, ch\u00fang ta c\u00f3 th\u1ec3 t\u1ef1 \u0111\u1ed9ng l\u01b0u model v\u00e0o Model Registry. Th\u00f4ng tin c\u1ee7a model \u0111\u01b0\u1ee3c l\u01b0u v\u00e0 version c\u1ee7a n\u00f3 c\u0169ng \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o disk \u0111\u1ec3 s\u1eed d\u1ee5ng khi c\u1ea7n, v\u00ed d\u1ee5 \u0111\u1ec3 tri\u1ec3n khai ra production. Code c\u1ee7a task n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i training_pipeline/src/model_validation.py . training_pipeline/src/model_validation.py 1 2 3 4 5 6 7 8 9 10 11 12 13 eval_result = EvaluationResult . load ( AppPath . EVALUATION_RESULT ) if eval_result . rmse > config . rmse_threshold : # return v\u00ec RMSE kh\u00f4ng tho\u1ea3 m\u00e3n threshold if eval_result . mae > config . mae_threshold : # return v\u00ec MAE kh\u00f4ng tho\u1ea3 m\u00e3n threshold result = mlflow . register_model ( # (1) # th\u00f4ng tin v\u1ec1 model ) dump_json ( result . __dict__ , AppPath . REGISTERED_MODEL_VERSION ) # (2) L\u01b0u model v\u00e0o Model Registry n\u1ebfu c\u00e1c offline metrics tho\u1ea3 m\u00e3n threshold L\u01b0u l\u1ea1i th\u00f4ng tin v\u1ec1 model B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 test th\u1eed code. Ch\u1ea1y code cd src python model_validation.py cd .. N\u1ebfu model tho\u1ea3 m\u00e3n c\u00e1c thresholds, ki\u1ec3m tra folder training_pipeline/artifacts , b\u1ea1n s\u1ebd th\u1ea5y file registered_model_version.json M\u1edf MLflow server, b\u1ea1n s\u1ebd th\u1ea5y model \u0111\u00e3 \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o Model Registry Click v\u00e0o model \u0111\u1ec3 xem th\u00eam th\u00f4ng tin model. Nh\u01b0 h\u00ecnh d\u01b0\u1edbi, MLflow \u0111\u00e3 ghi l\u1ea1i c\u1ea3 \u0111\u1ecbnh d\u1ea1ng h\u1ee3p l\u1ec7 cho input v\u00e0 output c\u1ee7a model Tip Ph\u1ea7n Schema \u0111\u1ecbnh ngh\u0129a \u0111\u1ecbnh d\u1ea1ng \u0111\u1ea7u v\u00e0o v\u00e0 \u0111\u1ea7u ra c\u1ee7a model. \u0110\u1ecbnh d\u1ea1ng n\u00e0y \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 Model Signature Airflow DAG \u1ede ph\u1ea7n n\u00e0y, Airflow DAG \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 k\u1ebft n\u1ed1i c\u00e1c task tr\u00ean l\u1ea1i th\u00e0nh m\u1ed9t DAG hay m\u1ed9t pipeline ho\u00e0n ch\u1ec9nh. Code \u0111\u1ecbnh ngh\u0129a Airflow DAG \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i training_pipeline/dags/training_dag.py . training_pipeline/dags/training_dag.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 with DAG ( dag_id = \"training_pipeline\" , schedule_interval = \"@once\" , # (1) # c\u00e1c argument kh\u00e1c ) as dag : feature_store_init_task = DockerOperator ( # (2) task_id = \"feature_store_init_task\" , command = \"bash -c 'cd feature_repo && feast apply'\" , # (3) ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , # (4) ) data_extraction_task = DockerOperator ( task_id = \"data_extraction_task\" , command = \"bash -c 'cd src && python data_extraction.py'\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , ) # c\u00e1c task kh\u00e1c DAG s\u1ebd ch\u1ea1y m\u1ed9t l\u1ea7n khi \u0111\u01b0\u1ee3c b\u1eadt, sau \u0111\u00f3 s\u1ebd c\u1ea7n k\u00edch ho\u1ea1t l\u1ea1i b\u1eb1ng tay V\u00ec c\u00e1c task kh\u00e1c nhau c\u00f3 m\u00f4i tr\u01b0\u1eddng ch\u1ea1y v\u00e0 c\u00e1c dependencies kh\u00e1c nhau, n\u00ean DockerOperator \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 c\u00e1ch ly c\u00e1c task trong c\u00e1c docker containers kh\u00e1c nhau. \u0110\u1ec3 \u0111\u01a1n gi\u1ea3n, ch\u00fang ta ch\u1ec9 d\u00f9ng m\u1ed9t Docker image duy nh\u1ea5t cho t\u1ea5t c\u1ea3 c\u00e1c task Command s\u1ebd \u0111\u01b0\u1ee3c g\u1ecdi trong m\u1ed7i task. Command n\u00e0y gi\u1ed1ng v\u1edbi command b\u1ea1n \u0111\u00e3 ch\u1ea1y trong qu\u00e1 tr\u00ecnh vi\u1ebft code \u1edf tr\u00ean V\u00ec ch\u1ec9 m\u1ed9t docker image duy nh\u1ea5t d\u00f9ng cho c\u00e1c tasks, n\u00ean ch\u1ec9 c\u1ea7n m\u1ed9t config chung cho c\u00e1c docker containers \u0111\u01b0\u1ee3c t\u1ea1o ra \u1edf m\u1ed7i task. Config chung n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u trong bi\u1ebfn DefaultConfig.DEFAULT_DOCKER_OPERATOR_ARGS . Ti\u1ebfp theo, ch\u00fang ta c\u1ea7n build docker image mlopsvn/mlops_crash_course/training_pipeline:latest v\u00e0 tri\u1ec3n khai Airflow DAG b\u1eb1ng c\u00e1c b\u01b0\u1edbc sau. \u0110\u0103ng nh\u1eadp v\u00e0o Airflow UI v\u1edbi t\u00e0i kho\u1ea3n v\u00e0 m\u1eadt kh\u1ea9u l\u00e0 airflow . \u0110\u1eb7t Airflow Variable MLOPS_CRASH_COURSE_CODE_DIR b\u1eb1ng \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i t\u1edbi folder mlops-crash-course-code/ . Tham kh\u1ea3o h\u01b0\u1edbng d\u1eabn n\u00e0y \u0111\u1ec3 \u0111\u1eb7t Airflow Variable. Ch\u1ea1y l\u1ec7nh make build_image make deploy_dags # (1) Copy training_pipeline/dags/* v\u00e0o folder dags c\u1ee7a Airflow Tip \u0110\u1ecbnh ngh\u0129a v\u1ec1 c\u00e1c env vars \u0111\u01b0\u1ee3c d\u00f9ng trong qu\u00e1 tr\u00ecnh ch\u1ea1y Airflow DAG \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i training_pipeline/.env . B\u1ea1n c\u00f3 th\u1ec3 thay \u0111\u1ed5i n\u1ebfu c\u1ea7n. K\u00edch ho\u1ea1t training pipeline v\u00e0 \u0111\u1ee3i k\u1ebft qu\u1ea3 Sau khi Airflow DAG ho\u00e0n th\u00e0nh, ki\u1ec3m tra MLflow server, b\u1ea1n s\u1ebd th\u1ea5y metadata c\u1ee7a l\u1ea7n ch\u1ea1y experiment m\u1edbi v\u00e0 model train xong \u0111\u00e3 \u0111\u01b0\u1ee3c log l\u1ea1i T\u1ed5ng k\u1ebft Ch\u00fang ta v\u1eeba tr\u1ea3i qua quy tr\u00ecnh ph\u00e1t tri\u1ec3n \u0111i\u1ec3n h\u00ecnh cho training pipeline. Tu\u1ef3 thu\u1ed9c v\u00e0o m\u1ee9c \u0111\u1ed9 ph\u1ee9c t\u1ea1p c\u1ee7a d\u1ef1 \u00e1n v\u00e0 c\u00e1c ch\u1ee9c n\u0103ng c\u1ee7a d\u1ef1 \u00e1n m\u00e0 c\u00f3 th\u1ec3 b\u1ecf b\u1edbt ho\u1eb7c th\u00eam v\u00e0o c\u00e1c task kh\u00e1c. C\u00e1c task c\u0169ng c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c chia nh\u1ecf ra \u0111\u1ec3 th\u1ef1c hi\u1ec7n c\u00e1c c\u00f4ng vi\u1ec7c \u0111\u00f2i h\u1ecfi t\u00ednh to\u00e1n n\u1eb7ng, tr\u00e1nh vi\u1ec7c ph\u1ea3i ch\u1ea1y l\u1ea1i nhi\u1ec1u l\u1ea7n. Trong m\u1ed9t d\u1ef1 \u00e1n ML, trong khi Data Scientist v\u1eabn th\u1ef1c hi\u1ec7n c\u00e1c th\u1eed nghi\u1ec7m tr\u00ean data v\u00e0 model, ML engineer/MLOps engineer c\u00f3 th\u1ec3 x\u00e2y d\u1ef1ng training pipeline \u0111\u01b0\u1ee3c c\u1eadp nh\u1eadt li\u00ean t\u1ee5c d\u1ef1a tr\u00ean y\u00eau c\u1ea7u t\u1eeb Data Scientist. Sau khi t\u1ef1 \u0111\u1ed9ng ho\u00e1 training pipeline, trong b\u00e0i ti\u1ebfp theo ch\u00fang ta s\u1ebd x\u00e2y d\u1ef1ng v\u00e0 t\u1ef1 \u0111\u1ed9ng ho\u00e1 qu\u00e1 tr\u00ecnh tri\u1ec3n khai model. T\u00e0i li\u1ec7u tham kh\u1ea3o CS 329S. Lecture 5. Model Development MLOps: Continuous delivery and automation pipelines in machine learning","title":"Training pipeline"},{"location":"mlops-crash-course/training-pipeline/xay-dung-training-pipeline.html#gioi-thieu","text":"Sau khi th\u1ef1c hi\u1ec7n \u00edt nh\u1ea5t m\u1ed9t d\u1ef1 \u00e1n POC th\u00e0nh c\u00f4ng, ch\u00fang ta \u0111\u00e3 c\u00f3 \u0111\u01b0\u1ee3c: C\u00e1ch bi\u1ebfn \u0111\u1ed5i data t\u1eeb data source C\u00e1ch bi\u1ebfn \u0111\u1ed5i feature engineering Code chu\u1ea9n b\u1ecb data \u0111\u1ec3 train model Code train model Code \u0111\u00e1nh gi\u00e1 model Ph\u1ea7n 1, 2 \u0111\u01b0\u1ee3c d\u00f9ng trong b\u00e0i x\u00e2y d\u1ef1ng data pipeline . Ph\u1ea7n 3, 4 v\u00e0 5 s\u1ebd \u0111\u01b0\u1ee3c d\u00f9ng trong b\u00e0i n\u00e0y \u0111\u1ec3 x\u00e2y d\u1ef1ng training pipeline v\u1edbi c\u00e1c task nh\u01b0 h\u00ecnh d\u01b0\u1edbi. flowchart LR n1[1. C\u1eadp nh\u1eadt<br>Feature Store] --> n2[2. Data<br>extraction] --> n3[3. Data<br>validation] --> n4[4. Data<br>preparation] --> n5[5. Model<br>training] --> n6[6. Model<br>evaluation] --> n7[7. Model<br>validation]","title":"Gi\u1edbi thi\u1ec7u"},{"location":"mlops-crash-course/training-pipeline/xay-dung-training-pipeline.html#moi-truong-phat-trien","text":"C\u00e1c b\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 c\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n: C\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng Python 3.9 m\u1edbi v\u1edbi c\u00e1c th\u01b0 vi\u1ec7n c\u1ea7n thi\u1ebft trong file training_pipeline/dev_requirements.txt \u0110\u1eb7t environment variable TRAINING_PIPELINE_DIR \u1edf terminal b\u1ea1n d\u00f9ng b\u1eb1ng \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i t\u1edbi folder training_pipeline v\u00e0 MLFLOW_TRACKING_URI b\u1eb1ng URL c\u1ee7a MLflow server. Hai env var n\u00e0y h\u1ed7 tr\u1ee3 ch\u1ea1y python code \u1edf folder training_pipeline/src trong qu\u00e1 tr\u00ecnh ph\u00e1t tri\u1ec3n. cd mlops-crash-course-code/training_pipeline export TRAINING_PIPELINE_DIR = $( pwd ) export MLFLOW_TRACKING_URI = \"http://localhost:5000\" C\u00e1c MLOps tools \u0111\u01b0\u1ee3c d\u00f9ng trong b\u00e0i n\u00e0y bao g\u1ed3m: Feast: truy xu\u1ea5t Feature Store MLflow: ML Metadata Store, Model Registry Airflow: \u0111i\u1ec1u ph\u1ed1i training pipeline Note Trong qu\u00e1 tr\u00ecnh ch\u1ea1y code cho t\u1ea5t c\u1ea3 c\u00e1c ph\u1ea7n d\u01b0\u1edbi \u0111\u00e2y, ch\u00fang ta gi\u1ea3 s\u1eed r\u1eb1ng folder g\u1ed1c n\u01a1i ch\u00fang ta l\u00e0m vi\u1ec7c l\u00e0 folder training_pipeline .","title":"M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n"},{"location":"mlops-crash-course/training-pipeline/xay-dung-training-pipeline.html#cap-nhat-feature-store","text":"Trong kho\u00e1 h\u1ecdc n\u00e0y, Feast \u0111\u01b0\u1ee3c d\u00f9ng l\u00e0m Feature Store \u0111\u1ec3 qu\u1ea3n l\u00fd phi\u00ean b\u1ea3n c\u00e1c features v\u00e0 c\u00e1c b\u1ed9 features. Feast s\u1eed d\u1ee5ng Feature Registry \u0111\u1ec3 t\u1eadp trung l\u01b0u tr\u1eef \u0111\u1ecbnh ngh\u0129a v\u1ec1 c\u00e1c feature v\u00e0 metadata. Do Feature Registry n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u \u1edf d\u1ea1ng file \u1edf m\u00e1y local, n\u00ean m\u1ed7i Data Scientist c\u1ea7n t\u1ef1 update Feature Registry tr\u00ean m\u00e1y c\u1ee7a m\u00ecnh. Tr\u01b0\u1edbc khi c\u1eadp nh\u1eadt Feature Store, c\u1ea7n \u0111\u1ea3m b\u1ea3o code c\u1ee7a Feature Store \u0111\u00e3 \u0111\u01b0\u1ee3c tri\u1ec3n khai l\u00ean m\u00e1y c\u1ee7a b\u1ea1n. Trong th\u1ef1c t\u1ebf, code c\u1ee7a Feature Store s\u1ebd \u0111\u01b0\u1ee3c Data Engineer build v\u00e0 release nh\u01b0 m\u1ed9t library cho ph\u00e9p ML engineer download v\u1ec1 v\u00e0 s\u1eed d\u1ee5ng. Code c\u1ee7a Feature Store n\u1eb1m t\u1ea1i data_pipeline/feature_repo . \u0110\u1ec3 tri\u1ec3n khai sang training pipeline, ch\u00fang ta s\u1ebd copy code t\u1eeb data_pipeline/feature_repo sang training_pipeline/feature_repo . B\u1ea1n h\u00e3y ch\u1ea1y c\u00e1c l\u1ec7nh sau. cd ../data_pipeline make deploy_feature_repo # (1) cd ../training_pipeline cd feature_repo feast apply # (2) cd .. Tri\u1ec3n khai code c\u1ee7a Feature Store C\u1eadp nh\u1eadt Feature Registry v\u00e0 Offline Feature Store c\u1ee7a Feast","title":"C\u1eadp nh\u1eadt Feature Store"},{"location":"mlops-crash-course/training-pipeline/xay-dung-training-pipeline.html#data-extraction","text":"Trong task n\u00e0y, c\u00e1c features \u0111\u01b0\u1ee3c l\u1ea5y t\u1eeb Offline Feature Store \u0111\u1ec3 ph\u1ee5c v\u1ee5 cho qu\u00e1 tr\u00ecnh train model. \u0110\u1ea7u v\u00e0o: t\u00ean c\u00e1c features ch\u00fang ta mu\u1ed1n l\u1ea5y \u0110\u1ea7u ra: file data ch\u1ee9a features \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o disk Code c\u1ee7a task n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i training_pipeline/src/data_extraction.py . training_pipeline/src/data_extraction.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 fs = feast . FeatureStore ( repo_path = AppPath . FEATURE_REPO ) # (1) orders = pd . read_csv ( AppPath . DATA / \"driver_orders.csv\" , sep = \" \\t \" ) # (2) orders [ \"event_timestamp\" ] = pd . to_datetime ( orders [ \"event_timestamp\" ]) # (3) training_df = fs . get_historical_features ( # (4) entity_df = orders , features = [ \"driver_stats:conv_rate\" , # (5) \"driver_stats:acc_rate\" , \"driver_stats:avg_daily_trips\" , ], ) . to_df () # (6) to_parquet ( training_df , AppPath . TRAINING_PQ ) # (7) T\u1ea1o k\u1ebft n\u1ed1i t\u1edbi Feature Store \u0110\u1ecdc label t\u1eeb file driver_orders.csv \u0110\u1ecbnh d\u1ea1ng l\u1ea1i format cho c\u1ed9t event_timestamp Download features t\u1eeb Offline Feature Store. C\u00e1c feature ch\u00fang ta mu\u1ed1n l\u1ea5y bao g\u1ed3m conv_rate , acc_rate v\u00e0 avg_daily_trips . driver_stats l\u00e0 t\u00ean FeatureView m\u00e0 ch\u00fang ta \u0111\u00e3 \u0111\u1ecbnh ngh\u0129a t\u1ea1i data_pipeline/feature_repo/features.py C\u00e1ch m\u00e0 Feast l\u1ea5y ra features gi\u1ed1ng nh\u01b0 c\u00e1ch ch\u00fang ta chu\u1ea9n b\u1ecb data \u1edf d\u1ef1 \u00e1n POC. B\u1ea1n c\u00f3 th\u1ec3 xem l\u1ea1i t\u1ea1i \u0111\u00e2y . L\u01b0u data v\u00e0o disk \u0111\u1ec3 s\u1eed d\u1ee5ng trong c\u00e1c task ti\u1ebfp theo. B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 test th\u1eed code. Ch\u1ea1y code cd src python data_extraction.py cd .. Bug N\u1ebfu c\u00e1c b\u1ea1n g\u1eb7p l\u1ed7i sau: PermissionError: [ Errno 13 ] Permission denied: '/training_pipeline' Th\u00ec c\u00e1c b\u1ea1n c\u1ea7n \u0111\u1eb7t environment variable TRAINING_PIPELINE_DIR nh\u01b0 h\u01b0\u1edbng d\u1eabn \u1edf ph\u1ea7n M\u00f4i tr\u01b0\u1eddng ph\u00e1t tri\u1ec3n . Ki\u1ec3m tra folder training_pipeline/artifacts , b\u1ea1n s\u1ebd th\u1ea5y file training.parquet","title":"Data extraction"},{"location":"mlops-crash-course/training-pipeline/xay-dung-training-pipeline.html#data-validation","text":"Photo by Diane Serik on Unsplash Sau khi l\u1ea5y \u0111\u01b0\u1ee3c data t\u1eeb Offline Feature Store, ch\u00fang ta c\u1ea7n \u0111\u00e1nh gi\u00e1 data c\u00f3 h\u1ee3p l\u1ec7 kh\u00f4ng tr\u01b0\u1edbc khi train model, b\u1eb1ng c\u00e1ch ki\u1ec3m tra. C\u1ea5u tr\u00fac data Nh\u1eadn \u0111\u01b0\u1ee3c feature n\u00e0o kh\u00f4ng mong mu\u1ed1n kh\u00f4ng? Nh\u1eadn \u0111\u1ee7 feature mong mu\u1ed1n kh\u00f4ng? Feature c\u00f3 \u1edf format mong mu\u1ed1n kh\u00f4ng? Gi\u00e1 tr\u1ecb c\u1ee7a data C\u00e1c t\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a data c\u00f3 nh\u01b0 mong mu\u1ed1n kh\u00f4ng? C\u00e1c gi\u1ea3 s\u1eed v\u1ec1 data c\u00f3 nh\u01b0 mong mu\u1ed1n kh\u00f4ng? Task n\u00e0y kh\u00f4ng sinh ra c\u00e1c artifact hay file n\u00e0o, m\u00e0 n\u00f3 s\u1ebd quy\u1ebft \u0111\u1ecbnh xem task ti\u1ebfp theo c\u00f3 \u0111\u01b0\u1ee3c th\u1ef1c hi\u1ec7n hay kh\u00f4ng. Code c\u1ee7a task n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i training_pipeline/src/data_validation.py . training_pipeline/src/data_validation.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def check_unexpected_features ( df : pd . DataFrame ): # (1) cols = set ( df . columns ) for col in cols : if not col in config . feature_dict : # (2) # B\u00e1o l\u1ed7i feature 'col' kh\u00f4ng mong mu\u1ed1n def check_expected_features ( df : pd . DataFrame ): # (3) dtypes = dict ( df . dtypes ) for feature in config . feature_dict : if not feature in dtypes : # B\u00e1o l\u1ed7i feature 'feature' kh\u00f4ng t\u00ecm th\u1ea5y else : expected_type = config . feature_dict [ feature ] real_type = dtypes [ feature ] if expected_type != real_type : # B\u00e1o l\u1ed7i feature 'feature' c\u00f3 \u0111\u1ecbnh d\u1ea1ng kh\u00f4ng mong mu\u1ed1n Ki\u1ec3m tra xem c\u00f3 feature n\u00e0o kh\u00f4ng mong mu\u1ed1n config.feature_dict l\u00e0 dictionary v\u1edbi key l\u00e0 t\u00ean c\u00e1c feature mong mu\u1ed1n v\u00e0 value l\u00e0 format mong mu\u1ed1n c\u1ee7a c\u00e1c feature Ki\u1ec3m tra xem c\u00f3 feature mong mu\u1ed1n v\u00e0 \u1edf \u0111\u1ecbnh d\u1ea1ng mong mu\u1ed1n kh\u00f4ng \u0110\u1ec3 \u0111\u01a1n gian ho\u00e1 code v\u00e0 t\u1eadp trung v\u00e0o MLOps, ch\u00fang ta s\u1ebd kh\u00f4ng ki\u1ec3m tra c\u00e1c t\u00ednh ch\u1ea5t th\u1ed1ng k\u00ea c\u1ee7a data. B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 test th\u1eed code. cd src python data_validation.py cd ..","title":"Data validation"},{"location":"mlops-crash-course/training-pipeline/xay-dung-training-pipeline.html#data-preparation","text":"Task Data preparation c\u00f3 \u0111\u1ea7u v\u00e0o v\u00e0 \u0111\u1ea7u ra nh\u01b0 sau. \u0110\u1ea7u v\u00e0o: file data ch\u1ee9a features \u1edf b\u01b0\u1edbc Data extraction \u0110\u1ea7u ra: training set v\u00e0 test set \u0111\u00e3 \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o disk Task n\u00e0y th\u1ef1c hi\u1ec7n c\u00e1c vi\u1ec7c sau. Bi\u1ebfn \u0111\u1ed5i data n\u1ebfu c\u1ea7n, c\u00f3 th\u1ec3 x\u1ea3y ra n\u1ebfu features l\u1ea5y t\u1eeb Offline Feature Store kh\u00f4ng \u1edf \u0111\u1ecbnh d\u1ea1ng mong mu\u1ed1n Bi\u1ebfn \u0111\u1ed5i feature engineering n\u1ebfu c\u1ea7n T\u1ea1o training set, test set \u0111\u1ec3 train v\u00e0 \u0111\u00e1nh gi\u00e1 model Code c\u1ee7a task n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i training_pipeline/src/data_preparation.py . training_pipeline/src/data_preparation.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 target_col = 'trip_completed' train , test = train_test_split ( # (1) df , test_size = config . test_size , random_state = config . random_seed ) target_col = config . target_col train_x = train . drop ([ target_col ], axis = 1 ) train_y = train [[ target_col ]] test_x = test . drop ([ target_col ], axis = 1 ) test_y = test [[ target_col ]] to_parquet ( train_x , AppPath . TRAIN_X_PQ ) # (2) to_parquet ( train_y , AppPath . TRAIN_Y_PQ ) to_parquet ( test_x , AppPath . TEST_X_PQ ) to_parquet ( test_y , AppPath . TEST_Y_PQ ) Chia data ra th\u00e0nh training set v\u00e0 test set, v\u00ec gi\u1ea3 s\u1eed ch\u00fang ta \u0111\u00e3 l\u1ea5y \u0111\u01b0\u1ee3c c\u00e1c feature mong mu\u1ed1n \u1edf \u0111\u1ecbnh d\u1ea1ng mong mu\u1ed1n, c\u0169ng kh\u00f4ng c\u1ea7n th\u1ef1c hi\u1ec7n th\u00eam c\u00e1c b\u01b0\u1edbc bi\u1ec3n \u0111\u1ed5i data, ho\u1eb7c sinh ra c\u00e1c feature kh\u00e1c n\u1eefa L\u01b0u data v\u00e0o disk \u0111\u1ec3 s\u1eed d\u1ee5ng trong c\u00e1c task ti\u1ebfp theo. B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 test th\u1eed code. Ch\u1ea1y code cd src python data_preparation.py cd .. Ki\u1ec3m tra folder training_pipeline/artifacts , b\u1ea1n s\u1ebd th\u1ea5y c\u00e1c files training.parquet , train_x.parquet , test_x.parquet , train_y.parquet v\u00e0 test_y.parquet","title":"Data preparation"},{"location":"mlops-crash-course/training-pipeline/xay-dung-training-pipeline.html#model-training","text":"Task Model training s\u1ebd train model v\u00e0 th\u1ef1c hi\u1ec7n hyperparameter tuning \u0111\u1ec3 train model t\u1ed1t nh\u1ea5t. Tuy nhi\u00ean trong b\u00e0i n\u00e0y, ch\u00fang ta s\u1ebd kh\u00f4ng th\u1ef1c hi\u1ec7n hyperparameter tuning. Task n\u00e0y c\u00f3: \u0110\u1ea7u v\u00e0o: data \u0111\u01b0\u1ee3c chu\u1ea9n b\u1ecb \u1edf task Data preparation \u0110\u1ea7u ra: model \u0111\u00e3 \u0111\u01b0\u1ee3c train Code cho task Model training \u0111\u00e3 \u0111\u01b0\u1ee3c vi\u1ebft \u1edf d\u1ef1 \u00e1n POC. Code c\u1ee7a task n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i training_pipeline/src/model_training.py . training_pipeline/src/model_training.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 mlflow . set_tracking_uri ( config . mlflow_tracking_uri ) # (1) train_x = load_df ( AppPath . TRAIN_X_PQ ) # (2) train_y = load_df ( AppPath . TRAIN_Y_PQ ) model = ElasticNet ( # (3) alpha = config . alpha , l1_ratio = config . l1_ratio , random_state = config . random_seed , ) model . fit ( train_x , train_y ) mlflow . log_param ( \"alpha\" , config . alpha ) # (4) mlflow . log_param ( \"l1_ratio\" , config . l1_ratio ) mlflow . sklearn . log_model ( model , # n\u01a1i l\u01b0u model ) run_id = mlflow . last_active_run () . info . run_id # (5) run_info = RunInfo ( run_id ) run_info . save () Set URI t\u1edbi MLflow server Load data Train model Log metadata L\u01b0u l\u1ea1i th\u00f4ng tin v\u1ec1 l\u1ea7n ch\u1ea1y hi\u1ec7n t\u1ea1i \u0111\u1ec3 c\u00e1c task ti\u1ebfp theo bi\u1ebft \u0111\u01b0\u1ee3c model n\u00e0o v\u1eeba \u0111\u01b0\u1ee3c train, \u0111\u1ec3 c\u00f3 th\u1ec3 download model v\u00e0 \u0111\u00e1nh gi\u00e1 model \u1ede b\u01b0\u1edbc Log metadata, ch\u00fang ta kh\u00f4ng c\u1ea7n log l\u1ea1i danh s\u00e1ch c\u00e1c feature \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng n\u1eefa, v\u00ec b\u1ed9 feature \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u00e3 \u0111\u01b0\u1ee3c version trong code \u1edf b\u01b0\u1edbc Data extraction. N\u1ebfu c\u00f3 th\u1ec3, ch\u00fang ta n\u00ean l\u01b0u c\u1ea3 \u0111\u01b0\u1eddng d\u1eabn t\u1edbi data source \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o c\u00f3 th\u1ec3 theo d\u00f5i l\u1ea1i \u0111\u01b0\u1ee3c ngu\u1ed3n g\u1ed1c c\u1ee7a data. B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 test th\u1eed code. M\u1edf repo mlops-crash-course-platform v\u00e0 ch\u1ea1y mlflow server. bash run.sh mlflow up Ch\u1ea1y code cd src python model_training.py cd .. Ki\u1ec3m tra folder training_pipeline/artifacts , b\u1ea1n s\u1ebd th\u1ea5y file run_info.json M\u1edf MLflow server, b\u1ea1n s\u1ebd th\u1ea5y m\u1ed9t experiment \u0111\u01b0\u1ee3c t\u1ea1o ra","title":"Model training"},{"location":"mlops-crash-course/training-pipeline/xay-dung-training-pipeline.html#model-evaluation","text":"Task Model evaluation th\u1ef1c hi\u1ec7n ch\u1ea1y prediction cho model tr\u00ean test set. Task n\u00e0y c\u00f3: \u0110\u1ea7u v\u00e0o: model \u0111\u00e3 \u0111\u01b0\u1ee3c train \u0110\u1ea7u ra: c\u00e1c metrics \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 ch\u1ea5t l\u01b0\u1ee3ng model Code cho task Model evaluation \u0111\u00e3 \u0111\u01b0\u1ee3c vi\u1ebft \u1edf d\u1ef1 \u00e1n POC. Code c\u1ee7a task n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i training_pipeline/src/model_evaluation.py . training_pipeline/src/model_evaluation.py 1 2 3 4 5 6 7 8 9 10 11 model = mlflow . pyfunc . load_model ( # n\u01a1i l\u01b0u model ) test_x = load_df ( AppPath . TEST_X_PQ ) # (1) test_y = load_df ( AppPath . TEST_Y_PQ ) predicted_qualities = model . predict ( test_x ) ( rmse , mae ) = eval_metrics ( test_y , predicted_qualities ) eval_result = EvaluationResult ( rmse , mae ) # (2) eval_result . save () Ch\u1ea1y inference tr\u00ean test set L\u01b0u l\u1ea1i k\u1ebft qu\u1ea3 K\u1ebft qu\u1ea3 l\u00e0 offline metrics, s\u1ebd \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o disk, \u0111\u1ec3 ph\u1ee5c v\u1ee5 cho task Model validation. B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 test th\u1eed code. Ch\u1ea1y code cd src python model_evaluation.py cd .. Ki\u1ec3m tra folder training_pipeline/artifacts , b\u1ea1n s\u1ebd th\u1ea5y file evaluation.json","title":"Model evaluation"},{"location":"mlops-crash-course/training-pipeline/xay-dung-training-pipeline.html#model-validation","text":"Trong task n\u00e0y, ch\u00fang ta d\u00f9ng c\u00e1c metrics t\u1eeb task Model evaluation \u0111\u1ec3 \u0111\u00e1nh gi\u00e1 model. C\u00e1c baseline v\u1ec1 metrics n\u00ean \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a \u1edf b\u01b0\u1edbc Ph\u00e2n t\u00edch v\u1ea5n \u0111\u1ec1 . Vi\u1ec7c \u0111\u00e1nh gi\u00e1 model d\u1ef1a tr\u00ean c\u00e1c metrics \u0111\u1ec3 ch\u1ee9ng t\u1ecf model m\u1edbi c\u00f3 performance t\u1ed1t h\u01a1n model c\u0169 tr\u01b0\u1edbc khi tri\u1ec3n khai ra production. Model performance c\u1ea7n \u0111\u01b0\u1ee3c \u0111\u00e1nh gi\u00e1 tr\u00ean c\u00e1c ph\u1ea7n kh\u00e1c nhau c\u1ee7a dataset. V\u00ed d\u1ee5 nh\u01b0 model m\u1edbi c\u00f3 Accuracy cao h\u01a1n model c\u0169 khi \u0111\u00e1nh gi\u00e1 tr\u00ean t\u1ea5t c\u1ea3 kh\u00e1ch h\u00e0ng, nh\u01b0ng c\u00f3 Accuracy tr\u00ean data c\u1ee7a kh\u00e1ch h\u00e0ng \u1edf v\u00e0i khu v\u1ef1c \u0111\u1ecba l\u00fd th\u1ea5p h\u01a1n model c\u0169. Ngo\u00e0i ra, model c\u00f3 th\u1ec3 c\u1ea7n \u0111\u01b0\u1ee3c ki\u1ec3m tra xem c\u00f3 t\u01b0\u01a1ng th\u00edch v\u1edbi h\u1ec7 th\u1ed1ng \u1edf production kh\u00f4ng. V\u00ed d\u1ee5: Ki\u1ec3m tra model m\u1edbi c\u00f3 nh\u1eadn v\u00e0o \u0111\u1ecbnh d\u1ea1ng \u0111\u1ea7u v\u00e0o v\u00e0 tr\u1ea3 v\u1ec1 \u0111\u1ecbnh d\u1ea1ng \u0111\u1ea7u ra t\u01b0\u01a1ng th\u00edch kh\u00f4ng Th\u1eddi gian inference c\u00f3 \u0111\u1ea3m b\u1ea3o n\u1eb1m trong m\u1ed9t kho\u1ea3ng y\u00eau c\u1ea7u c\u1ee7a v\u1ea5n \u0111\u1ec1 kinh doanh kh\u00f4ng Trong task n\u00e0y, ch\u00fang ta ch\u1ec9 vi\u1ebft code \u0111\u1ec3 so s\u00e1nh offline metrics v\u1edbi c\u00e1c thresholds \u0111\u01b0\u1ee3c \u0111\u1ecbnh ngh\u0129a trong file training_pipeline/.env . N\u1ebfu model tho\u1ea3 m\u00e3n c\u00e1c thresholds, ch\u00fang ta c\u00f3 th\u1ec3 t\u1ef1 \u0111\u1ed9ng l\u01b0u model v\u00e0o Model Registry. Th\u00f4ng tin c\u1ee7a model \u0111\u01b0\u1ee3c l\u01b0u v\u00e0 version c\u1ee7a n\u00f3 c\u0169ng \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o disk \u0111\u1ec3 s\u1eed d\u1ee5ng khi c\u1ea7n, v\u00ed d\u1ee5 \u0111\u1ec3 tri\u1ec3n khai ra production. Code c\u1ee7a task n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i training_pipeline/src/model_validation.py . training_pipeline/src/model_validation.py 1 2 3 4 5 6 7 8 9 10 11 12 13 eval_result = EvaluationResult . load ( AppPath . EVALUATION_RESULT ) if eval_result . rmse > config . rmse_threshold : # return v\u00ec RMSE kh\u00f4ng tho\u1ea3 m\u00e3n threshold if eval_result . mae > config . mae_threshold : # return v\u00ec MAE kh\u00f4ng tho\u1ea3 m\u00e3n threshold result = mlflow . register_model ( # (1) # th\u00f4ng tin v\u1ec1 model ) dump_json ( result . __dict__ , AppPath . REGISTERED_MODEL_VERSION ) # (2) L\u01b0u model v\u00e0o Model Registry n\u1ebfu c\u00e1c offline metrics tho\u1ea3 m\u00e3n threshold L\u01b0u l\u1ea1i th\u00f4ng tin v\u1ec1 model B\u1ea1n l\u00e0m c\u00e1c b\u01b0\u1edbc sau \u0111\u1ec3 test th\u1eed code. Ch\u1ea1y code cd src python model_validation.py cd .. N\u1ebfu model tho\u1ea3 m\u00e3n c\u00e1c thresholds, ki\u1ec3m tra folder training_pipeline/artifacts , b\u1ea1n s\u1ebd th\u1ea5y file registered_model_version.json M\u1edf MLflow server, b\u1ea1n s\u1ebd th\u1ea5y model \u0111\u00e3 \u0111\u01b0\u1ee3c l\u01b0u v\u00e0o Model Registry Click v\u00e0o model \u0111\u1ec3 xem th\u00eam th\u00f4ng tin model. Nh\u01b0 h\u00ecnh d\u01b0\u1edbi, MLflow \u0111\u00e3 ghi l\u1ea1i c\u1ea3 \u0111\u1ecbnh d\u1ea1ng h\u1ee3p l\u1ec7 cho input v\u00e0 output c\u1ee7a model Tip Ph\u1ea7n Schema \u0111\u1ecbnh ngh\u0129a \u0111\u1ecbnh d\u1ea1ng \u0111\u1ea7u v\u00e0o v\u00e0 \u0111\u1ea7u ra c\u1ee7a model. \u0110\u1ecbnh d\u1ea1ng n\u00e0y \u0111\u01b0\u1ee3c g\u1ecdi l\u00e0 Model Signature","title":"Model validation"},{"location":"mlops-crash-course/training-pipeline/xay-dung-training-pipeline.html#airflow-dag","text":"\u1ede ph\u1ea7n n\u00e0y, Airflow DAG \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 k\u1ebft n\u1ed1i c\u00e1c task tr\u00ean l\u1ea1i th\u00e0nh m\u1ed9t DAG hay m\u1ed9t pipeline ho\u00e0n ch\u1ec9nh. Code \u0111\u1ecbnh ngh\u0129a Airflow DAG \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i training_pipeline/dags/training_dag.py . training_pipeline/dags/training_dag.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 with DAG ( dag_id = \"training_pipeline\" , schedule_interval = \"@once\" , # (1) # c\u00e1c argument kh\u00e1c ) as dag : feature_store_init_task = DockerOperator ( # (2) task_id = \"feature_store_init_task\" , command = \"bash -c 'cd feature_repo && feast apply'\" , # (3) ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , # (4) ) data_extraction_task = DockerOperator ( task_id = \"data_extraction_task\" , command = \"bash -c 'cd src && python data_extraction.py'\" , ** DefaultConfig . DEFAULT_DOCKER_OPERATOR_ARGS , ) # c\u00e1c task kh\u00e1c DAG s\u1ebd ch\u1ea1y m\u1ed9t l\u1ea7n khi \u0111\u01b0\u1ee3c b\u1eadt, sau \u0111\u00f3 s\u1ebd c\u1ea7n k\u00edch ho\u1ea1t l\u1ea1i b\u1eb1ng tay V\u00ec c\u00e1c task kh\u00e1c nhau c\u00f3 m\u00f4i tr\u01b0\u1eddng ch\u1ea1y v\u00e0 c\u00e1c dependencies kh\u00e1c nhau, n\u00ean DockerOperator \u0111\u01b0\u1ee3c d\u00f9ng \u0111\u1ec3 c\u00e1ch ly c\u00e1c task trong c\u00e1c docker containers kh\u00e1c nhau. \u0110\u1ec3 \u0111\u01a1n gi\u1ea3n, ch\u00fang ta ch\u1ec9 d\u00f9ng m\u1ed9t Docker image duy nh\u1ea5t cho t\u1ea5t c\u1ea3 c\u00e1c task Command s\u1ebd \u0111\u01b0\u1ee3c g\u1ecdi trong m\u1ed7i task. Command n\u00e0y gi\u1ed1ng v\u1edbi command b\u1ea1n \u0111\u00e3 ch\u1ea1y trong qu\u00e1 tr\u00ecnh vi\u1ebft code \u1edf tr\u00ean V\u00ec ch\u1ec9 m\u1ed9t docker image duy nh\u1ea5t d\u00f9ng cho c\u00e1c tasks, n\u00ean ch\u1ec9 c\u1ea7n m\u1ed9t config chung cho c\u00e1c docker containers \u0111\u01b0\u1ee3c t\u1ea1o ra \u1edf m\u1ed7i task. Config chung n\u00e0y \u0111\u01b0\u1ee3c l\u01b0u trong bi\u1ebfn DefaultConfig.DEFAULT_DOCKER_OPERATOR_ARGS . Ti\u1ebfp theo, ch\u00fang ta c\u1ea7n build docker image mlopsvn/mlops_crash_course/training_pipeline:latest v\u00e0 tri\u1ec3n khai Airflow DAG b\u1eb1ng c\u00e1c b\u01b0\u1edbc sau. \u0110\u0103ng nh\u1eadp v\u00e0o Airflow UI v\u1edbi t\u00e0i kho\u1ea3n v\u00e0 m\u1eadt kh\u1ea9u l\u00e0 airflow . \u0110\u1eb7t Airflow Variable MLOPS_CRASH_COURSE_CODE_DIR b\u1eb1ng \u0111\u01b0\u1eddng d\u1eabn tuy\u1ec7t \u0111\u1ed1i t\u1edbi folder mlops-crash-course-code/ . Tham kh\u1ea3o h\u01b0\u1edbng d\u1eabn n\u00e0y \u0111\u1ec3 \u0111\u1eb7t Airflow Variable. Ch\u1ea1y l\u1ec7nh make build_image make deploy_dags # (1) Copy training_pipeline/dags/* v\u00e0o folder dags c\u1ee7a Airflow Tip \u0110\u1ecbnh ngh\u0129a v\u1ec1 c\u00e1c env vars \u0111\u01b0\u1ee3c d\u00f9ng trong qu\u00e1 tr\u00ecnh ch\u1ea1y Airflow DAG \u0111\u01b0\u1ee3c l\u01b0u t\u1ea1i training_pipeline/.env . B\u1ea1n c\u00f3 th\u1ec3 thay \u0111\u1ed5i n\u1ebfu c\u1ea7n. K\u00edch ho\u1ea1t training pipeline v\u00e0 \u0111\u1ee3i k\u1ebft qu\u1ea3 Sau khi Airflow DAG ho\u00e0n th\u00e0nh, ki\u1ec3m tra MLflow server, b\u1ea1n s\u1ebd th\u1ea5y metadata c\u1ee7a l\u1ea7n ch\u1ea1y experiment m\u1edbi v\u00e0 model train xong \u0111\u00e3 \u0111\u01b0\u1ee3c log l\u1ea1i","title":"Airflow DAG"},{"location":"mlops-crash-course/training-pipeline/xay-dung-training-pipeline.html#tong-ket","text":"Ch\u00fang ta v\u1eeba tr\u1ea3i qua quy tr\u00ecnh ph\u00e1t tri\u1ec3n \u0111i\u1ec3n h\u00ecnh cho training pipeline. Tu\u1ef3 thu\u1ed9c v\u00e0o m\u1ee9c \u0111\u1ed9 ph\u1ee9c t\u1ea1p c\u1ee7a d\u1ef1 \u00e1n v\u00e0 c\u00e1c ch\u1ee9c n\u0103ng c\u1ee7a d\u1ef1 \u00e1n m\u00e0 c\u00f3 th\u1ec3 b\u1ecf b\u1edbt ho\u1eb7c th\u00eam v\u00e0o c\u00e1c task kh\u00e1c. C\u00e1c task c\u0169ng c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c chia nh\u1ecf ra \u0111\u1ec3 th\u1ef1c hi\u1ec7n c\u00e1c c\u00f4ng vi\u1ec7c \u0111\u00f2i h\u1ecfi t\u00ednh to\u00e1n n\u1eb7ng, tr\u00e1nh vi\u1ec7c ph\u1ea3i ch\u1ea1y l\u1ea1i nhi\u1ec1u l\u1ea7n. Trong m\u1ed9t d\u1ef1 \u00e1n ML, trong khi Data Scientist v\u1eabn th\u1ef1c hi\u1ec7n c\u00e1c th\u1eed nghi\u1ec7m tr\u00ean data v\u00e0 model, ML engineer/MLOps engineer c\u00f3 th\u1ec3 x\u00e2y d\u1ef1ng training pipeline \u0111\u01b0\u1ee3c c\u1eadp nh\u1eadt li\u00ean t\u1ee5c d\u1ef1a tr\u00ean y\u00eau c\u1ea7u t\u1eeb Data Scientist. Sau khi t\u1ef1 \u0111\u1ed9ng ho\u00e1 training pipeline, trong b\u00e0i ti\u1ebfp theo ch\u00fang ta s\u1ebd x\u00e2y d\u1ef1ng v\u00e0 t\u1ef1 \u0111\u1ed9ng ho\u00e1 qu\u00e1 tr\u00ecnh tri\u1ec3n khai model.","title":"T\u1ed5ng k\u1ebft"},{"location":"mlops-crash-course/training-pipeline/xay-dung-training-pipeline.html#tai-lieu-tham-khao","text":"CS 329S. Lecture 5. Model Development MLOps: Continuous delivery and automation pipelines in machine learning","title":"T\u00e0i li\u1ec7u tham kh\u1ea3o"}]}